2024-11-13 17:02:04,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:02:04,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:02:04,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:02:04,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:12:07,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:12:07,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:12:07,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:12:07,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:12:50,768:WARNING:<ipython-input-8-70ef97ec7642>:9: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.
To preserve the previous behavior, use

	>>> .groupby(..., group_keys=False)

To adopt the future behavior and silence this warning, use 

	>>> .groupby(..., group_keys=True)
  df_SHIPS_24 = filtered_df.groupby('Code').apply(lambda x: x[['Original_Times', 'Code', 'Times', 'Latitude', 'Longitude', 'Vmax', 'MSLP', 'Daily_SST_Avg', 'Mid_Level_RH', 'Vshear', 'Vert_Vel']]).reset_index(drop=True)

2024-11-13 17:13:11,388:WARNING:<ipython-input-11-72a982439e21>:10: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_SHIPS_24_common.loc[:, 'New_Times'] = new_times #Add the new times to the DataFrame

2024-11-13 17:13:11,410:WARNING:<ipython-input-12-132cce1a3ba2>:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_BT_24_common['ISO_TIME'] = pd.to_datetime(df_BT_24_common['ISO_TIME'])

2024-11-13 17:13:18,589:INFO:PyCaret RegressionExperiment
2024-11-13 17:13:18,589:INFO:Logging name: reg-default-name
2024-11-13 17:13:18,589:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:13:18,589:INFO:version 3.2.0
2024-11-13 17:13:18,590:INFO:Initializing setup()
2024-11-13 17:13:18,590:INFO:self.USI: d612
2024-11-13 17:13:18,590:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:13:18,590:INFO:Checking environment
2024-11-13 17:13:18,590:INFO:python_version: 3.8.13
2024-11-13 17:13:18,590:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:13:18,590:INFO:machine: x86_64
2024-11-13 17:13:18,625:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:13:18,626:INFO:Memory: svmem(total=270355722240, available=217298403328, percent=19.6, used=50976284672, free=55903637504, active=11450572800, inactive=142715473920, buffers=8888320, cached=163466911744, shared=187334656, slab=25016049664)
2024-11-13 17:13:18,628:INFO:Physical Core: 28
2024-11-13 17:13:18,628:INFO:Logical Core: 56
2024-11-13 17:13:18,628:INFO:Checking libraries
2024-11-13 17:13:18,629:INFO:System:
2024-11-13 17:13:18,629:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:13:18,629:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:13:18,629:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:13:18,629:INFO:PyCaret required dependencies:
2024-11-13 17:13:18,826:INFO:                 pip: 22.2.2
2024-11-13 17:13:18,826:INFO:          setuptools: 63.4.2
2024-11-13 17:13:18,826:INFO:             pycaret: 3.2.0
2024-11-13 17:13:18,826:INFO:             IPython: 8.12.2
2024-11-13 17:13:18,826:INFO:          ipywidgets: 7.7.1
2024-11-13 17:13:18,826:INFO:                tqdm: 4.64.1
2024-11-13 17:13:18,826:INFO:               numpy: 1.23.5
2024-11-13 17:13:18,826:INFO:              pandas: 1.5.3
2024-11-13 17:13:18,826:INFO:              jinja2: 3.1.2
2024-11-13 17:13:18,826:INFO:               scipy: 1.10.1
2024-11-13 17:13:18,826:INFO:              joblib: 1.3.0
2024-11-13 17:13:18,826:INFO:             sklearn: 1.1.2
2024-11-13 17:13:18,827:INFO:                pyod: 2.0.2
2024-11-13 17:13:18,827:INFO:            imblearn: 0.12.4
2024-11-13 17:13:18,827:INFO:   category_encoders: 2.6.4
2024-11-13 17:13:18,827:INFO:            lightgbm: 4.5.0
2024-11-13 17:13:18,827:INFO:               numba: 0.57.1
2024-11-13 17:13:18,827:INFO:            requests: 2.28.1
2024-11-13 17:13:18,827:INFO:          matplotlib: 3.5.1
2024-11-13 17:13:18,827:INFO:          scikitplot: 0.3.7
2024-11-13 17:13:18,827:INFO:         yellowbrick: 1.5
2024-11-13 17:13:18,827:INFO:              plotly: 5.24.1
2024-11-13 17:13:18,827:INFO:    plotly-resampler: Not installed
2024-11-13 17:13:18,827:INFO:             kaleido: 0.2.1
2024-11-13 17:13:18,827:INFO:           schemdraw: 0.15
2024-11-13 17:13:18,827:INFO:         statsmodels: 0.13.2
2024-11-13 17:13:18,827:INFO:              sktime: 0.21.1
2024-11-13 17:13:18,827:INFO:               tbats: 1.1.3
2024-11-13 17:13:18,827:INFO:            pmdarima: 2.0.4
2024-11-13 17:13:18,827:INFO:              psutil: 5.9.1
2024-11-13 17:13:18,827:INFO:          markupsafe: 2.1.1
2024-11-13 17:13:18,827:INFO:             pickle5: Not installed
2024-11-13 17:13:18,827:INFO:         cloudpickle: 2.1.0
2024-11-13 17:13:18,827:INFO:         deprecation: 2.1.0
2024-11-13 17:13:18,827:INFO:              xxhash: 3.5.0
2024-11-13 17:13:18,827:INFO:           wurlitzer: 3.1.1
2024-11-13 17:13:18,827:INFO:PyCaret optional dependencies:
2024-11-13 17:13:21,326:INFO:                shap: 0.44.1
2024-11-13 17:13:21,326:INFO:           interpret: 0.6.5
2024-11-13 17:13:21,326:INFO:                umap: 0.5.7
2024-11-13 17:13:21,326:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:13:21,326:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:13:21,326:INFO:             autoviz: Not installed
2024-11-13 17:13:21,326:INFO:           fairlearn: 0.7.0
2024-11-13 17:13:21,326:INFO:          deepchecks: Not installed
2024-11-13 17:13:21,326:INFO:             xgboost: 2.1.1
2024-11-13 17:13:21,326:INFO:            catboost: 1.2.7
2024-11-13 17:13:21,326:INFO:              kmodes: 0.12.2
2024-11-13 17:13:21,326:INFO:             mlxtend: 0.23.1
2024-11-13 17:13:21,326:INFO:       statsforecast: 1.5.0
2024-11-13 17:13:21,326:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:13:21,326:INFO:                 ray: 2.10.0
2024-11-13 17:13:21,326:INFO:            hyperopt: 0.2.7
2024-11-13 17:13:21,326:INFO:              optuna: 4.1.0
2024-11-13 17:13:21,326:INFO:               skopt: 0.10.2
2024-11-13 17:13:21,326:INFO:              mlflow: 1.30.1
2024-11-13 17:13:21,326:INFO:              gradio: 3.50.2
2024-11-13 17:13:21,326:INFO:             fastapi: 0.115.5
2024-11-13 17:13:21,326:INFO:             uvicorn: 0.32.0
2024-11-13 17:13:21,326:INFO:              m2cgen: 0.10.0
2024-11-13 17:13:21,326:INFO:           evidently: 0.2.8
2024-11-13 17:13:21,326:INFO:               fugue: 0.8.6
2024-11-13 17:13:21,326:INFO:           streamlit: Not installed
2024-11-13 17:13:21,326:INFO:             prophet: Not installed
2024-11-13 17:13:21,326:INFO:None
2024-11-13 17:13:21,327:INFO:Set up data.
2024-11-13 17:13:21,351:INFO:Set up folding strategy.
2024-11-13 17:13:21,351:INFO:Set up train/test split.
2024-11-13 17:13:21,358:INFO:Set up index.
2024-11-13 17:13:21,360:INFO:Assigning column types.
2024-11-13 17:13:21,364:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 17:13:21,365:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,368:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,423:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,480:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:21,483:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:21,503:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,508:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,513:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,617:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:21,620:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:21,620:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 17:13:21,624:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,628:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,677:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,715:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:21,717:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:21,721:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,725:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,774:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,820:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:21,822:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:21,823:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 17:13:21,830:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,921:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:21,923:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:21,931:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,021:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,023:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,024:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 17:13:22,081:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,118:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,120:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,215:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,217:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,218:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 17:13:22,275:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,312:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,314:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,409:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,411:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,411:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 17:13:22,504:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,507:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,601:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,604:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,606:INFO:Preparing preprocessing pipeline...
2024-11-13 17:13:22,606:INFO:Set up simple imputation.
2024-11-13 17:13:22,610:INFO:Set up encoding of categorical features.
2024-11-13 17:13:22,725:INFO:Finished creating preprocessing pipeline.
2024-11-13 17:13:22,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Latitude', 'Longitude', 'MSLP',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel', 'USA_WSPD',
                                             'USA_PRES', 'WMO_WIND',
                                             'USA_WIND'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Code', 'USA_ATCF_ID', 'WMO_PRES'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Code', 'USA_ATCF_ID', 'WMO_PRES'],
                                    transformer=TargetEncoder(cols=['Code',
                                                                    'USA_ATCF_ID',
                                                                    'WMO_PRES'],
                                                              handle_missing='return_nan')))])
2024-11-13 17:13:22,732:INFO:Creating final display dataframe.
2024-11-13 17:13:23,047:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape       (31316, 15)
4        Transformed data shape       (31316, 15)
5   Transformed train set shape       (21921, 15)
6    Transformed test set shape        (9395, 15)
7              Numeric features                11
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              d612
2024-11-13 17:13:23,183:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:23,186:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:23,285:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:23,287:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:23,288:INFO:setup() successfully completed in 4.7s...............
2024-11-13 17:15:00,619:INFO:Initializing compare_models()
2024-11-13 17:15:00,619:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 17:15:00,620:INFO:Checking exceptions
2024-11-13 17:15:00,627:INFO:Preparing display monitor
2024-11-13 17:15:00,680:INFO:Initializing Linear Regression
2024-11-13 17:15:00,681:INFO:Total runtime is 1.9828478495279947e-06 minutes
2024-11-13 17:15:00,685:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:00,685:INFO:Initializing create_model()
2024-11-13 17:15:00,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:00,685:INFO:Checking exceptions
2024-11-13 17:15:00,685:INFO:Importing libraries
2024-11-13 17:15:00,685:INFO:Copying training dataset
2024-11-13 17:15:00,694:INFO:Defining folds
2024-11-13 17:15:00,694:INFO:Declaring metric variables
2024-11-13 17:15:00,698:INFO:Importing untrained model
2024-11-13 17:15:00,702:INFO:Linear Regression Imported successfully
2024-11-13 17:15:00,710:INFO:Starting cross validation
2024-11-13 17:15:00,713:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:05,076:INFO:Calculating mean and std
2024-11-13 17:15:05,081:INFO:Creating metrics dataframe
2024-11-13 17:15:05,090:INFO:Uploading results into container
2024-11-13 17:15:05,091:INFO:Uploading model into container now
2024-11-13 17:15:05,091:INFO:_master_model_container: 1
2024-11-13 17:15:05,091:INFO:_display_container: 2
2024-11-13 17:15:05,092:INFO:LinearRegression(n_jobs=-1)
2024-11-13 17:15:05,092:INFO:create_model() successfully completed......................................
2024-11-13 17:15:05,318:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:05,318:INFO:Creating metrics dataframe
2024-11-13 17:15:05,328:INFO:Initializing Lasso Regression
2024-11-13 17:15:05,329:INFO:Total runtime is 0.0774680495262146 minutes
2024-11-13 17:15:05,332:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:05,332:INFO:Initializing create_model()
2024-11-13 17:15:05,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:05,332:INFO:Checking exceptions
2024-11-13 17:15:05,333:INFO:Importing libraries
2024-11-13 17:15:05,333:INFO:Copying training dataset
2024-11-13 17:15:05,345:INFO:Defining folds
2024-11-13 17:15:05,345:INFO:Declaring metric variables
2024-11-13 17:15:05,350:INFO:Importing untrained model
2024-11-13 17:15:05,353:INFO:Lasso Regression Imported successfully
2024-11-13 17:15:05,360:INFO:Starting cross validation
2024-11-13 17:15:05,362:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:08,534:INFO:Calculating mean and std
2024-11-13 17:15:08,538:INFO:Creating metrics dataframe
2024-11-13 17:15:08,545:INFO:Uploading results into container
2024-11-13 17:15:08,545:INFO:Uploading model into container now
2024-11-13 17:15:08,546:INFO:_master_model_container: 2
2024-11-13 17:15:08,546:INFO:_display_container: 2
2024-11-13 17:15:08,547:INFO:Lasso(random_state=123)
2024-11-13 17:15:08,547:INFO:create_model() successfully completed......................................
2024-11-13 17:15:08,743:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:08,743:INFO:Creating metrics dataframe
2024-11-13 17:15:08,753:INFO:Initializing Ridge Regression
2024-11-13 17:15:08,753:INFO:Total runtime is 0.13455013036727906 minutes
2024-11-13 17:15:08,757:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:08,757:INFO:Initializing create_model()
2024-11-13 17:15:08,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:08,758:INFO:Checking exceptions
2024-11-13 17:15:08,758:INFO:Importing libraries
2024-11-13 17:15:08,758:INFO:Copying training dataset
2024-11-13 17:15:08,767:INFO:Defining folds
2024-11-13 17:15:08,768:INFO:Declaring metric variables
2024-11-13 17:15:08,771:INFO:Importing untrained model
2024-11-13 17:15:08,775:INFO:Ridge Regression Imported successfully
2024-11-13 17:15:08,781:INFO:Starting cross validation
2024-11-13 17:15:08,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:11,752:INFO:Calculating mean and std
2024-11-13 17:15:11,756:INFO:Creating metrics dataframe
2024-11-13 17:15:11,764:INFO:Uploading results into container
2024-11-13 17:15:11,764:INFO:Uploading model into container now
2024-11-13 17:15:11,765:INFO:_master_model_container: 3
2024-11-13 17:15:11,765:INFO:_display_container: 2
2024-11-13 17:15:11,766:INFO:Ridge(random_state=123)
2024-11-13 17:15:11,766:INFO:create_model() successfully completed......................................
2024-11-13 17:15:11,910:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:11,910:INFO:Creating metrics dataframe
2024-11-13 17:15:11,920:INFO:Initializing Elastic Net
2024-11-13 17:15:11,921:INFO:Total runtime is 0.18733490308125814 minutes
2024-11-13 17:15:11,924:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:11,924:INFO:Initializing create_model()
2024-11-13 17:15:11,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:11,924:INFO:Checking exceptions
2024-11-13 17:15:11,924:INFO:Importing libraries
2024-11-13 17:15:11,924:INFO:Copying training dataset
2024-11-13 17:15:11,932:INFO:Defining folds
2024-11-13 17:15:11,933:INFO:Declaring metric variables
2024-11-13 17:15:11,936:INFO:Importing untrained model
2024-11-13 17:15:11,939:INFO:Elastic Net Imported successfully
2024-11-13 17:15:11,945:INFO:Starting cross validation
2024-11-13 17:15:11,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:15,125:INFO:Calculating mean and std
2024-11-13 17:15:15,129:INFO:Creating metrics dataframe
2024-11-13 17:15:15,135:INFO:Uploading results into container
2024-11-13 17:15:15,136:INFO:Uploading model into container now
2024-11-13 17:15:15,137:INFO:_master_model_container: 4
2024-11-13 17:15:15,137:INFO:_display_container: 2
2024-11-13 17:15:15,137:INFO:ElasticNet(random_state=123)
2024-11-13 17:15:15,137:INFO:create_model() successfully completed......................................
2024-11-13 17:15:15,312:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:15,312:INFO:Creating metrics dataframe
2024-11-13 17:15:15,323:INFO:Initializing Least Angle Regression
2024-11-13 17:15:15,323:INFO:Total runtime is 0.24405117829640705 minutes
2024-11-13 17:15:15,327:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:15,327:INFO:Initializing create_model()
2024-11-13 17:15:15,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:15,328:INFO:Checking exceptions
2024-11-13 17:15:15,328:INFO:Importing libraries
2024-11-13 17:15:15,328:INFO:Copying training dataset
2024-11-13 17:15:15,337:INFO:Defining folds
2024-11-13 17:15:15,337:INFO:Declaring metric variables
2024-11-13 17:15:15,341:INFO:Importing untrained model
2024-11-13 17:15:15,344:INFO:Least Angle Regression Imported successfully
2024-11-13 17:15:15,351:INFO:Starting cross validation
2024-11-13 17:15:15,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:18,079:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,091:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.310e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,092:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.310e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,092:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.016e-07, with an active set of 5 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,092:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.016e-07, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,116:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,123:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.511e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,123:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.511e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,124:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.990e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,124:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.990e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,124:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.961e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,125:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.961e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,178:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,183:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.482e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,183:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.482e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,184:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.949e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,184:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.949e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,184:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.900e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,185:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.900e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,193:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,193:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,199:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.196e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,200:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.595e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,200:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.595e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,200:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.856e-07, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,225:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,230:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,232:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.576e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,233:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.611e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,233:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.021e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,233:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.860e-07, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,234:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.723e-07, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,234:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.709e-07, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,234:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.222e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,259:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,259:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,266:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.577e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,267:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.013e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,267:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.013e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,267:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.813e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,267:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.967e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,267:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.574e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,268:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.574e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,576:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,611:INFO:Calculating mean and std
2024-11-13 17:15:18,615:INFO:Creating metrics dataframe
2024-11-13 17:15:18,623:INFO:Uploading results into container
2024-11-13 17:15:18,624:INFO:Uploading model into container now
2024-11-13 17:15:18,625:INFO:_master_model_container: 5
2024-11-13 17:15:18,625:INFO:_display_container: 2
2024-11-13 17:15:18,626:INFO:Lars(random_state=123)
2024-11-13 17:15:18,626:INFO:create_model() successfully completed......................................
2024-11-13 17:15:18,785:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:18,785:INFO:Creating metrics dataframe
2024-11-13 17:15:18,796:INFO:Initializing Lasso Least Angle Regression
2024-11-13 17:15:18,796:INFO:Total runtime is 0.30193233489990234 minutes
2024-11-13 17:15:18,800:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:18,800:INFO:Initializing create_model()
2024-11-13 17:15:18,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:18,801:INFO:Checking exceptions
2024-11-13 17:15:18,801:INFO:Importing libraries
2024-11-13 17:15:18,801:INFO:Copying training dataset
2024-11-13 17:15:18,814:INFO:Defining folds
2024-11-13 17:15:18,815:INFO:Declaring metric variables
2024-11-13 17:15:18,818:INFO:Importing untrained model
2024-11-13 17:15:18,822:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 17:15:18,828:INFO:Starting cross validation
2024-11-13 17:15:18,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:19,091:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:19,110:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:19,110:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:19,118:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,459:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,590:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,650:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,697:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,712:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,743:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,780:INFO:Calculating mean and std
2024-11-13 17:15:21,784:INFO:Creating metrics dataframe
2024-11-13 17:15:21,791:INFO:Uploading results into container
2024-11-13 17:15:21,791:INFO:Uploading model into container now
2024-11-13 17:15:21,792:INFO:_master_model_container: 6
2024-11-13 17:15:21,792:INFO:_display_container: 2
2024-11-13 17:15:21,793:INFO:LassoLars(random_state=123)
2024-11-13 17:15:21,793:INFO:create_model() successfully completed......................................
2024-11-13 17:15:21,938:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:21,938:INFO:Creating metrics dataframe
2024-11-13 17:15:21,950:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 17:15:21,950:INFO:Total runtime is 0.3545009732246399 minutes
2024-11-13 17:15:21,954:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:21,954:INFO:Initializing create_model()
2024-11-13 17:15:21,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:21,954:INFO:Checking exceptions
2024-11-13 17:15:21,955:INFO:Importing libraries
2024-11-13 17:15:21,955:INFO:Copying training dataset
2024-11-13 17:15:21,963:INFO:Defining folds
2024-11-13 17:15:21,963:INFO:Declaring metric variables
2024-11-13 17:15:21,966:INFO:Importing untrained model
2024-11-13 17:15:21,970:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 17:15:21,977:INFO:Starting cross validation
2024-11-13 17:15:21,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:22,128:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,128:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,141:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,155:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,181:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,184:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,188:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,195:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,205:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,234:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,275:INFO:Calculating mean and std
2024-11-13 17:15:22,278:INFO:Creating metrics dataframe
2024-11-13 17:15:22,284:INFO:Uploading results into container
2024-11-13 17:15:22,285:INFO:Uploading model into container now
2024-11-13 17:15:22,286:INFO:_master_model_container: 7
2024-11-13 17:15:22,286:INFO:_display_container: 2
2024-11-13 17:15:22,286:INFO:OrthogonalMatchingPursuit()
2024-11-13 17:15:22,286:INFO:create_model() successfully completed......................................
2024-11-13 17:15:22,424:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:22,424:INFO:Creating metrics dataframe
2024-11-13 17:15:22,440:INFO:Initializing Bayesian Ridge
2024-11-13 17:15:22,440:INFO:Total runtime is 0.3626571933428447 minutes
2024-11-13 17:15:22,443:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:22,444:INFO:Initializing create_model()
2024-11-13 17:15:22,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:22,444:INFO:Checking exceptions
2024-11-13 17:15:22,444:INFO:Importing libraries
2024-11-13 17:15:22,445:INFO:Copying training dataset
2024-11-13 17:15:22,455:INFO:Defining folds
2024-11-13 17:15:22,455:INFO:Declaring metric variables
2024-11-13 17:15:22,458:INFO:Importing untrained model
2024-11-13 17:15:22,462:INFO:Bayesian Ridge Imported successfully
2024-11-13 17:15:22,468:INFO:Starting cross validation
2024-11-13 17:15:22,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:22,749:INFO:Calculating mean and std
2024-11-13 17:15:22,753:INFO:Creating metrics dataframe
2024-11-13 17:15:22,759:INFO:Uploading results into container
2024-11-13 17:15:22,760:INFO:Uploading model into container now
2024-11-13 17:15:22,761:INFO:_master_model_container: 8
2024-11-13 17:15:22,761:INFO:_display_container: 2
2024-11-13 17:15:22,761:INFO:BayesianRidge()
2024-11-13 17:15:22,761:INFO:create_model() successfully completed......................................
2024-11-13 17:15:22,929:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:22,929:INFO:Creating metrics dataframe
2024-11-13 17:15:22,941:INFO:Initializing Passive Aggressive Regressor
2024-11-13 17:15:22,941:INFO:Total runtime is 0.37101398309071865 minutes
2024-11-13 17:15:22,945:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:22,945:INFO:Initializing create_model()
2024-11-13 17:15:22,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:22,945:INFO:Checking exceptions
2024-11-13 17:15:22,945:INFO:Importing libraries
2024-11-13 17:15:22,946:INFO:Copying training dataset
2024-11-13 17:15:22,954:INFO:Defining folds
2024-11-13 17:15:22,954:INFO:Declaring metric variables
2024-11-13 17:15:22,958:INFO:Importing untrained model
2024-11-13 17:15:22,961:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 17:15:22,968:INFO:Starting cross validation
2024-11-13 17:15:22,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:23,354:INFO:Calculating mean and std
2024-11-13 17:15:23,358:INFO:Creating metrics dataframe
2024-11-13 17:15:23,364:INFO:Uploading results into container
2024-11-13 17:15:23,365:INFO:Uploading model into container now
2024-11-13 17:15:23,365:INFO:_master_model_container: 9
2024-11-13 17:15:23,365:INFO:_display_container: 2
2024-11-13 17:15:23,366:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 17:15:23,366:INFO:create_model() successfully completed......................................
2024-11-13 17:15:23,507:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:23,507:INFO:Creating metrics dataframe
2024-11-13 17:15:23,519:INFO:Initializing Huber Regressor
2024-11-13 17:15:23,519:INFO:Total runtime is 0.38064066569010424 minutes
2024-11-13 17:15:23,522:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:23,523:INFO:Initializing create_model()
2024-11-13 17:15:23,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:23,523:INFO:Checking exceptions
2024-11-13 17:15:23,523:INFO:Importing libraries
2024-11-13 17:15:23,523:INFO:Copying training dataset
2024-11-13 17:15:23,531:INFO:Defining folds
2024-11-13 17:15:23,531:INFO:Declaring metric variables
2024-11-13 17:15:23,535:INFO:Importing untrained model
2024-11-13 17:15:23,538:INFO:Huber Regressor Imported successfully
2024-11-13 17:15:23,545:INFO:Starting cross validation
2024-11-13 17:15:23,546:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:23,859:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,891:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,909:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,912:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,922:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,962:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,989:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:24,026:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:24,031:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:24,035:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:24,080:INFO:Calculating mean and std
2024-11-13 17:15:24,084:INFO:Creating metrics dataframe
2024-11-13 17:15:24,090:INFO:Uploading results into container
2024-11-13 17:15:24,091:INFO:Uploading model into container now
2024-11-13 17:15:24,092:INFO:_master_model_container: 10
2024-11-13 17:15:24,092:INFO:_display_container: 2
2024-11-13 17:15:24,092:INFO:HuberRegressor()
2024-11-13 17:15:24,092:INFO:create_model() successfully completed......................................
2024-11-13 17:15:24,245:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:24,245:INFO:Creating metrics dataframe
2024-11-13 17:15:24,258:INFO:Initializing K Neighbors Regressor
2024-11-13 17:15:24,258:INFO:Total runtime is 0.39295694828033456 minutes
2024-11-13 17:15:24,261:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:24,261:INFO:Initializing create_model()
2024-11-13 17:15:24,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:24,262:INFO:Checking exceptions
2024-11-13 17:15:24,262:INFO:Importing libraries
2024-11-13 17:15:24,262:INFO:Copying training dataset
2024-11-13 17:15:24,270:INFO:Defining folds
2024-11-13 17:15:24,271:INFO:Declaring metric variables
2024-11-13 17:15:24,274:INFO:Importing untrained model
2024-11-13 17:15:24,277:INFO:K Neighbors Regressor Imported successfully
2024-11-13 17:15:24,283:INFO:Starting cross validation
2024-11-13 17:15:24,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:24,727:INFO:Calculating mean and std
2024-11-13 17:15:24,730:INFO:Creating metrics dataframe
2024-11-13 17:15:24,735:INFO:Uploading results into container
2024-11-13 17:15:24,736:INFO:Uploading model into container now
2024-11-13 17:15:24,737:INFO:_master_model_container: 11
2024-11-13 17:15:24,737:INFO:_display_container: 2
2024-11-13 17:15:24,737:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 17:15:24,737:INFO:create_model() successfully completed......................................
2024-11-13 17:15:24,933:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:24,933:INFO:Creating metrics dataframe
2024-11-13 17:15:24,946:INFO:Initializing Decision Tree Regressor
2024-11-13 17:15:24,946:INFO:Total runtime is 0.4044304768244426 minutes
2024-11-13 17:15:24,949:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:24,950:INFO:Initializing create_model()
2024-11-13 17:15:24,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:24,950:INFO:Checking exceptions
2024-11-13 17:15:24,950:INFO:Importing libraries
2024-11-13 17:15:24,950:INFO:Copying training dataset
2024-11-13 17:15:24,958:INFO:Defining folds
2024-11-13 17:15:24,959:INFO:Declaring metric variables
2024-11-13 17:15:24,962:INFO:Importing untrained model
2024-11-13 17:15:24,965:INFO:Decision Tree Regressor Imported successfully
2024-11-13 17:15:24,972:INFO:Starting cross validation
2024-11-13 17:15:24,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:25,364:INFO:Calculating mean and std
2024-11-13 17:15:25,367:INFO:Creating metrics dataframe
2024-11-13 17:15:25,375:INFO:Uploading results into container
2024-11-13 17:15:25,375:INFO:Uploading model into container now
2024-11-13 17:15:25,376:INFO:_master_model_container: 12
2024-11-13 17:15:25,376:INFO:_display_container: 2
2024-11-13 17:15:25,376:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 17:15:25,376:INFO:create_model() successfully completed......................................
2024-11-13 17:15:25,529:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:25,530:INFO:Creating metrics dataframe
2024-11-13 17:15:25,542:INFO:Initializing Random Forest Regressor
2024-11-13 17:15:25,542:INFO:Total runtime is 0.4143658479054769 minutes
2024-11-13 17:15:25,545:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:25,546:INFO:Initializing create_model()
2024-11-13 17:15:25,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:25,546:INFO:Checking exceptions
2024-11-13 17:15:25,546:INFO:Importing libraries
2024-11-13 17:15:25,546:INFO:Copying training dataset
2024-11-13 17:15:25,554:INFO:Defining folds
2024-11-13 17:15:25,554:INFO:Declaring metric variables
2024-11-13 17:15:25,558:INFO:Importing untrained model
2024-11-13 17:15:25,561:INFO:Random Forest Regressor Imported successfully
2024-11-13 17:15:25,567:INFO:Starting cross validation
2024-11-13 17:15:25,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:27,039:INFO:Calculating mean and std
2024-11-13 17:15:27,042:INFO:Creating metrics dataframe
2024-11-13 17:15:27,047:INFO:Uploading results into container
2024-11-13 17:15:27,048:INFO:Uploading model into container now
2024-11-13 17:15:27,049:INFO:_master_model_container: 13
2024-11-13 17:15:27,049:INFO:_display_container: 2
2024-11-13 17:15:27,049:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:15:27,050:INFO:create_model() successfully completed......................................
2024-11-13 17:15:27,182:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:27,183:INFO:Creating metrics dataframe
2024-11-13 17:15:27,195:INFO:Initializing Extra Trees Regressor
2024-11-13 17:15:27,195:INFO:Total runtime is 0.44190859794616705 minutes
2024-11-13 17:15:27,198:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:27,199:INFO:Initializing create_model()
2024-11-13 17:15:27,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:27,199:INFO:Checking exceptions
2024-11-13 17:15:27,199:INFO:Importing libraries
2024-11-13 17:15:27,199:INFO:Copying training dataset
2024-11-13 17:15:27,207:INFO:Defining folds
2024-11-13 17:15:27,207:INFO:Declaring metric variables
2024-11-13 17:15:27,211:INFO:Importing untrained model
2024-11-13 17:15:27,214:INFO:Extra Trees Regressor Imported successfully
2024-11-13 17:15:27,221:INFO:Starting cross validation
2024-11-13 17:15:27,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:27,951:INFO:Calculating mean and std
2024-11-13 17:15:27,954:INFO:Creating metrics dataframe
2024-11-13 17:15:27,960:INFO:Uploading results into container
2024-11-13 17:15:27,960:INFO:Uploading model into container now
2024-11-13 17:15:27,961:INFO:_master_model_container: 14
2024-11-13 17:15:27,961:INFO:_display_container: 2
2024-11-13 17:15:27,961:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:15:27,961:INFO:create_model() successfully completed......................................
2024-11-13 17:15:28,095:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:28,096:INFO:Creating metrics dataframe
2024-11-13 17:15:28,108:INFO:Initializing AdaBoost Regressor
2024-11-13 17:15:28,108:INFO:Total runtime is 0.4571333726247152 minutes
2024-11-13 17:15:28,112:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:28,112:INFO:Initializing create_model()
2024-11-13 17:15:28,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:28,113:INFO:Checking exceptions
2024-11-13 17:15:28,113:INFO:Importing libraries
2024-11-13 17:15:28,113:INFO:Copying training dataset
2024-11-13 17:15:28,120:INFO:Defining folds
2024-11-13 17:15:28,121:INFO:Declaring metric variables
2024-11-13 17:15:28,124:INFO:Importing untrained model
2024-11-13 17:15:28,128:INFO:AdaBoost Regressor Imported successfully
2024-11-13 17:15:28,134:INFO:Starting cross validation
2024-11-13 17:15:28,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:29,286:INFO:Calculating mean and std
2024-11-13 17:15:29,289:INFO:Creating metrics dataframe
2024-11-13 17:15:29,295:INFO:Uploading results into container
2024-11-13 17:15:29,296:INFO:Uploading model into container now
2024-11-13 17:15:29,297:INFO:_master_model_container: 15
2024-11-13 17:15:29,297:INFO:_display_container: 2
2024-11-13 17:15:29,297:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 17:15:29,297:INFO:create_model() successfully completed......................................
2024-11-13 17:15:29,478:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:29,479:INFO:Creating metrics dataframe
2024-11-13 17:15:29,491:INFO:Initializing Gradient Boosting Regressor
2024-11-13 17:15:29,491:INFO:Total runtime is 0.4801816860834758 minutes
2024-11-13 17:15:29,495:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:29,495:INFO:Initializing create_model()
2024-11-13 17:15:29,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:29,495:INFO:Checking exceptions
2024-11-13 17:15:29,495:INFO:Importing libraries
2024-11-13 17:15:29,495:INFO:Copying training dataset
2024-11-13 17:15:29,505:INFO:Defining folds
2024-11-13 17:15:29,505:INFO:Declaring metric variables
2024-11-13 17:15:29,508:INFO:Importing untrained model
2024-11-13 17:15:29,512:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 17:15:29,518:INFO:Starting cross validation
2024-11-13 17:15:29,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:32,891:INFO:Calculating mean and std
2024-11-13 17:15:32,894:INFO:Creating metrics dataframe
2024-11-13 17:15:32,900:INFO:Uploading results into container
2024-11-13 17:15:32,901:INFO:Uploading model into container now
2024-11-13 17:15:32,902:INFO:_master_model_container: 16
2024-11-13 17:15:32,902:INFO:_display_container: 2
2024-11-13 17:15:32,902:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 17:15:32,903:INFO:create_model() successfully completed......................................
2024-11-13 17:15:33,067:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:33,067:INFO:Creating metrics dataframe
2024-11-13 17:15:33,080:INFO:Initializing Extreme Gradient Boosting
2024-11-13 17:15:33,080:INFO:Total runtime is 0.5400006532669067 minutes
2024-11-13 17:15:33,084:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:33,084:INFO:Initializing create_model()
2024-11-13 17:15:33,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:33,084:INFO:Checking exceptions
2024-11-13 17:15:33,084:INFO:Importing libraries
2024-11-13 17:15:33,084:INFO:Copying training dataset
2024-11-13 17:15:33,093:INFO:Defining folds
2024-11-13 17:15:33,093:INFO:Declaring metric variables
2024-11-13 17:15:33,097:INFO:Importing untrained model
2024-11-13 17:15:33,106:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 17:15:33,114:INFO:Starting cross validation
2024-11-13 17:15:33,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:33,699:INFO:Calculating mean and std
2024-11-13 17:15:33,703:INFO:Creating metrics dataframe
2024-11-13 17:15:33,708:INFO:Uploading results into container
2024-11-13 17:15:33,709:INFO:Uploading model into container now
2024-11-13 17:15:33,710:INFO:_master_model_container: 17
2024-11-13 17:15:33,710:INFO:_display_container: 2
2024-11-13 17:15:33,711:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 17:15:33,711:INFO:create_model() successfully completed......................................
2024-11-13 17:15:33,853:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:33,853:INFO:Creating metrics dataframe
2024-11-13 17:15:33,866:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 17:15:33,866:INFO:Total runtime is 0.5530894557634989 minutes
2024-11-13 17:15:33,869:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:33,869:INFO:Initializing create_model()
2024-11-13 17:15:33,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:33,870:INFO:Checking exceptions
2024-11-13 17:15:33,870:INFO:Importing libraries
2024-11-13 17:15:33,870:INFO:Copying training dataset
2024-11-13 17:15:33,878:INFO:Defining folds
2024-11-13 17:15:33,878:INFO:Declaring metric variables
2024-11-13 17:15:33,882:INFO:Importing untrained model
2024-11-13 17:15:33,885:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 17:15:33,892:INFO:Starting cross validation
2024-11-13 17:15:33,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:22:34,050:INFO:Calculating mean and std
2024-11-13 17:22:34,053:INFO:Creating metrics dataframe
2024-11-13 17:22:34,060:INFO:Uploading results into container
2024-11-13 17:22:34,061:INFO:Uploading model into container now
2024-11-13 17:22:34,061:INFO:_master_model_container: 18
2024-11-13 17:22:34,061:INFO:_display_container: 2
2024-11-13 17:22:34,062:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:22:34,062:INFO:create_model() successfully completed......................................
2024-11-13 17:22:34,261:INFO:SubProcess create_model() end ==================================
2024-11-13 17:22:34,261:INFO:Creating metrics dataframe
2024-11-13 17:22:34,274:INFO:Initializing CatBoost Regressor
2024-11-13 17:22:34,274:INFO:Total runtime is 7.559898801644643 minutes
2024-11-13 17:22:34,278:INFO:SubProcess create_model() called ==================================
2024-11-13 17:22:34,278:INFO:Initializing create_model()
2024-11-13 17:22:34,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:22:34,278:INFO:Checking exceptions
2024-11-13 17:22:34,278:INFO:Importing libraries
2024-11-13 17:22:34,278:INFO:Copying training dataset
2024-11-13 17:22:34,288:INFO:Defining folds
2024-11-13 17:22:34,289:INFO:Declaring metric variables
2024-11-13 17:22:34,292:INFO:Importing untrained model
2024-11-13 17:22:34,295:INFO:CatBoost Regressor Imported successfully
2024-11-13 17:22:34,301:INFO:Starting cross validation
2024-11-13 17:22:34,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:22:47,390:INFO:Calculating mean and std
2024-11-13 17:22:47,394:INFO:Creating metrics dataframe
2024-11-13 17:22:47,401:INFO:Uploading results into container
2024-11-13 17:22:47,402:INFO:Uploading model into container now
2024-11-13 17:22:47,402:INFO:_master_model_container: 19
2024-11-13 17:22:47,402:INFO:_display_container: 2
2024-11-13 17:22:47,402:INFO:<catboost.core.CatBoostRegressor object at 0x7ff6b5655fa0>
2024-11-13 17:22:47,403:INFO:create_model() successfully completed......................................
2024-11-13 17:22:47,560:INFO:SubProcess create_model() end ==================================
2024-11-13 17:22:47,561:INFO:Creating metrics dataframe
2024-11-13 17:22:47,575:INFO:Initializing Dummy Regressor
2024-11-13 17:22:47,575:INFO:Total runtime is 7.781577412287394 minutes
2024-11-13 17:22:47,578:INFO:SubProcess create_model() called ==================================
2024-11-13 17:22:47,579:INFO:Initializing create_model()
2024-11-13 17:22:47,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:22:47,579:INFO:Checking exceptions
2024-11-13 17:22:47,579:INFO:Importing libraries
2024-11-13 17:22:47,579:INFO:Copying training dataset
2024-11-13 17:22:47,588:INFO:Defining folds
2024-11-13 17:22:47,588:INFO:Declaring metric variables
2024-11-13 17:22:47,592:INFO:Importing untrained model
2024-11-13 17:22:47,595:INFO:Dummy Regressor Imported successfully
2024-11-13 17:22:47,602:INFO:Starting cross validation
2024-11-13 17:22:47,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:22:50,619:INFO:Calculating mean and std
2024-11-13 17:22:50,625:INFO:Creating metrics dataframe
2024-11-13 17:22:50,631:INFO:Uploading results into container
2024-11-13 17:22:50,632:INFO:Uploading model into container now
2024-11-13 17:22:50,633:INFO:_master_model_container: 20
2024-11-13 17:22:50,633:INFO:_display_container: 2
2024-11-13 17:22:50,633:INFO:DummyRegressor()
2024-11-13 17:22:50,633:INFO:create_model() successfully completed......................................
2024-11-13 17:22:50,837:INFO:SubProcess create_model() end ==================================
2024-11-13 17:22:50,837:INFO:Creating metrics dataframe
2024-11-13 17:22:50,863:INFO:Initializing create_model()
2024-11-13 17:22:50,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:22:50,863:INFO:Checking exceptions
2024-11-13 17:22:50,865:INFO:Importing libraries
2024-11-13 17:22:50,865:INFO:Copying training dataset
2024-11-13 17:22:50,874:INFO:Defining folds
2024-11-13 17:22:50,874:INFO:Declaring metric variables
2024-11-13 17:22:50,875:INFO:Importing untrained model
2024-11-13 17:22:50,875:INFO:Declaring custom model
2024-11-13 17:22:50,875:INFO:Linear Regression Imported successfully
2024-11-13 17:22:50,876:INFO:Cross validation set to False
2024-11-13 17:22:50,876:INFO:Fitting Model
2024-11-13 17:22:50,987:INFO:LinearRegression(n_jobs=-1)
2024-11-13 17:22:50,987:INFO:create_model() successfully completed......................................
2024-11-13 17:22:51,196:INFO:_master_model_container: 20
2024-11-13 17:22:51,196:INFO:_display_container: 2
2024-11-13 17:22:51,196:INFO:LinearRegression(n_jobs=-1)
2024-11-13 17:22:51,196:INFO:compare_models() successfully completed......................................
2024-11-13 17:23:41,967:INFO:Initializing plot_model()
2024-11-13 17:23:41,967:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, system=True)
2024-11-13 17:23:41,967:INFO:Checking exceptions
2024-11-13 17:23:41,976:INFO:Preloading libraries
2024-11-13 17:23:41,976:INFO:Copying training dataset
2024-11-13 17:23:41,976:INFO:Plot type: residuals
2024-11-13 17:23:42,379:INFO:Fitting Model
2024-11-13 17:23:42,379:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2024-11-13 17:23:42,459:INFO:Scoring test/hold-out set
2024-11-13 17:23:43,617:INFO:Visual Rendered Successfully
2024-11-13 17:23:43,782:INFO:plot_model() successfully completed......................................
2024-11-13 17:30:05,958:WARNING:<ipython-input-24-70ef97ec7642>:9: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.
To preserve the previous behavior, use

	>>> .groupby(..., group_keys=False)

To adopt the future behavior and silence this warning, use 

	>>> .groupby(..., group_keys=True)
  df_SHIPS_24 = filtered_df.groupby('Code').apply(lambda x: x[['Original_Times', 'Code', 'Times', 'Latitude', 'Longitude', 'Vmax', 'MSLP', 'Daily_SST_Avg', 'Mid_Level_RH', 'Vshear', 'Vert_Vel']]).reset_index(drop=True)

2024-11-13 17:31:04,628:WARNING:<ipython-input-29-70ef97ec7642>:9: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.
To preserve the previous behavior, use

	>>> .groupby(..., group_keys=False)

To adopt the future behavior and silence this warning, use 

	>>> .groupby(..., group_keys=True)
  df_SHIPS_24 = filtered_df.groupby('Code').apply(lambda x: x[['Original_Times', 'Code', 'Times', 'Latitude', 'Longitude', 'Vmax', 'MSLP', 'Daily_SST_Avg', 'Mid_Level_RH', 'Vshear', 'Vert_Vel']]).reset_index(drop=True)

2024-11-13 17:31:31,129:WARNING:<ipython-input-32-72a982439e21>:10: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_SHIPS_24_common.loc[:, 'New_Times'] = new_times #Add the new times to the DataFrame

2024-11-13 17:31:31,176:WARNING:<ipython-input-33-132cce1a3ba2>:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_BT_24_common['ISO_TIME'] = pd.to_datetime(df_BT_24_common['ISO_TIME'])

2024-11-13 17:33:00,649:WARNING:<ipython-input-37-cfb0873efbe0>:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_BT_24_common['ISO_TIME'] = pd.to_datetime(df_BT_24_common['ISO_TIME'])

2024-11-13 17:38:30,389:INFO:PyCaret RegressionExperiment
2024-11-13 17:38:30,389:INFO:Logging name: reg-default-name
2024-11-13 17:38:30,389:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:38:30,389:INFO:version 3.2.0
2024-11-13 17:38:30,389:INFO:Initializing setup()
2024-11-13 17:38:30,389:INFO:self.USI: e148
2024-11-13 17:38:30,389:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:38:30,389:INFO:Checking environment
2024-11-13 17:38:30,390:INFO:python_version: 3.8.13
2024-11-13 17:38:30,390:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:38:30,390:INFO:machine: x86_64
2024-11-13 17:38:30,390:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:38:30,390:INFO:Memory: svmem(total=270355722240, available=216871555072, percent=19.8, used=51403005952, free=55297449984, active=11558862848, inactive=143205117952, buffers=8888320, cached=163646377984, shared=187363328, slab=25018232832)
2024-11-13 17:38:30,392:INFO:Physical Core: 28
2024-11-13 17:38:30,392:INFO:Logical Core: 56
2024-11-13 17:38:30,392:INFO:Checking libraries
2024-11-13 17:38:30,392:INFO:System:
2024-11-13 17:38:30,392:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:38:30,392:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:38:30,393:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:38:30,393:INFO:PyCaret required dependencies:
2024-11-13 17:38:30,393:INFO:                 pip: 22.2.2
2024-11-13 17:38:30,393:INFO:          setuptools: 63.4.2
2024-11-13 17:38:30,393:INFO:             pycaret: 3.2.0
2024-11-13 17:38:30,393:INFO:             IPython: 8.12.2
2024-11-13 17:38:30,393:INFO:          ipywidgets: 7.7.1
2024-11-13 17:38:30,393:INFO:                tqdm: 4.64.1
2024-11-13 17:38:30,393:INFO:               numpy: 1.23.5
2024-11-13 17:38:30,393:INFO:              pandas: 1.5.3
2024-11-13 17:38:30,393:INFO:              jinja2: 3.1.2
2024-11-13 17:38:30,393:INFO:               scipy: 1.10.1
2024-11-13 17:38:30,393:INFO:              joblib: 1.3.0
2024-11-13 17:38:30,393:INFO:             sklearn: 1.1.2
2024-11-13 17:38:30,393:INFO:                pyod: 2.0.2
2024-11-13 17:38:30,393:INFO:            imblearn: 0.12.4
2024-11-13 17:38:30,393:INFO:   category_encoders: 2.6.4
2024-11-13 17:38:30,393:INFO:            lightgbm: 4.5.0
2024-11-13 17:38:30,393:INFO:               numba: 0.57.1
2024-11-13 17:38:30,393:INFO:            requests: 2.28.1
2024-11-13 17:38:30,393:INFO:          matplotlib: 3.5.1
2024-11-13 17:38:30,393:INFO:          scikitplot: 0.3.7
2024-11-13 17:38:30,393:INFO:         yellowbrick: 1.5
2024-11-13 17:38:30,393:INFO:              plotly: 5.24.1
2024-11-13 17:38:30,393:INFO:    plotly-resampler: Not installed
2024-11-13 17:38:30,393:INFO:             kaleido: 0.2.1
2024-11-13 17:38:30,393:INFO:           schemdraw: 0.15
2024-11-13 17:38:30,394:INFO:         statsmodels: 0.13.2
2024-11-13 17:38:30,394:INFO:              sktime: 0.21.1
2024-11-13 17:38:30,394:INFO:               tbats: 1.1.3
2024-11-13 17:38:30,394:INFO:            pmdarima: 2.0.4
2024-11-13 17:38:30,394:INFO:              psutil: 5.9.1
2024-11-13 17:38:30,394:INFO:          markupsafe: 2.1.1
2024-11-13 17:38:30,394:INFO:             pickle5: Not installed
2024-11-13 17:38:30,394:INFO:         cloudpickle: 2.1.0
2024-11-13 17:38:30,394:INFO:         deprecation: 2.1.0
2024-11-13 17:38:30,394:INFO:              xxhash: 3.5.0
2024-11-13 17:38:30,394:INFO:           wurlitzer: 3.1.1
2024-11-13 17:38:30,394:INFO:PyCaret optional dependencies:
2024-11-13 17:38:30,394:INFO:                shap: 0.44.1
2024-11-13 17:38:30,394:INFO:           interpret: 0.6.5
2024-11-13 17:38:30,394:INFO:                umap: 0.5.7
2024-11-13 17:38:30,394:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:38:30,394:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:38:30,394:INFO:             autoviz: Not installed
2024-11-13 17:38:30,394:INFO:           fairlearn: 0.7.0
2024-11-13 17:38:30,394:INFO:          deepchecks: Not installed
2024-11-13 17:38:30,394:INFO:             xgboost: 2.1.1
2024-11-13 17:38:30,394:INFO:            catboost: 1.2.7
2024-11-13 17:38:30,394:INFO:              kmodes: 0.12.2
2024-11-13 17:38:30,394:INFO:             mlxtend: 0.23.1
2024-11-13 17:38:30,394:INFO:       statsforecast: 1.5.0
2024-11-13 17:38:30,394:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:38:30,394:INFO:                 ray: 2.10.0
2024-11-13 17:38:30,394:INFO:            hyperopt: 0.2.7
2024-11-13 17:38:30,394:INFO:              optuna: 4.1.0
2024-11-13 17:38:30,394:INFO:               skopt: 0.10.2
2024-11-13 17:38:30,395:INFO:              mlflow: 1.30.1
2024-11-13 17:38:30,395:INFO:              gradio: 3.50.2
2024-11-13 17:38:30,395:INFO:             fastapi: 0.115.5
2024-11-13 17:38:30,395:INFO:             uvicorn: 0.32.0
2024-11-13 17:38:30,395:INFO:              m2cgen: 0.10.0
2024-11-13 17:38:30,395:INFO:           evidently: 0.2.8
2024-11-13 17:38:30,395:INFO:               fugue: 0.8.6
2024-11-13 17:38:30,395:INFO:           streamlit: Not installed
2024-11-13 17:38:30,395:INFO:             prophet: Not installed
2024-11-13 17:38:30,395:INFO:None
2024-11-13 17:38:30,395:INFO:Set up data.
2024-11-13 17:39:18,312:INFO:PyCaret RegressionExperiment
2024-11-13 17:39:18,312:INFO:Logging name: reg-default-name
2024-11-13 17:39:18,312:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:39:18,313:INFO:version 3.2.0
2024-11-13 17:39:18,313:INFO:Initializing setup()
2024-11-13 17:39:18,313:INFO:self.USI: 39c2
2024-11-13 17:39:18,313:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:39:18,313:INFO:Checking environment
2024-11-13 17:39:18,313:INFO:python_version: 3.8.13
2024-11-13 17:39:18,313:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:39:18,313:INFO:machine: x86_64
2024-11-13 17:39:18,313:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:18,313:INFO:Memory: svmem(total=270355722240, available=216870846464, percent=19.8, used=51403661312, free=55058685952, active=11558899712, inactive=143446773760, buffers=8888320, cached=163884486656, shared=187363328, slab=25018335232)
2024-11-13 17:39:18,316:INFO:Physical Core: 28
2024-11-13 17:39:18,316:INFO:Logical Core: 56
2024-11-13 17:39:18,316:INFO:Checking libraries
2024-11-13 17:39:18,316:INFO:System:
2024-11-13 17:39:18,316:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:39:18,316:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:39:18,316:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:18,316:INFO:PyCaret required dependencies:
2024-11-13 17:39:18,316:INFO:                 pip: 22.2.2
2024-11-13 17:39:18,316:INFO:          setuptools: 63.4.2
2024-11-13 17:39:18,316:INFO:             pycaret: 3.2.0
2024-11-13 17:39:18,316:INFO:             IPython: 8.12.2
2024-11-13 17:39:18,316:INFO:          ipywidgets: 7.7.1
2024-11-13 17:39:18,316:INFO:                tqdm: 4.64.1
2024-11-13 17:39:18,316:INFO:               numpy: 1.23.5
2024-11-13 17:39:18,317:INFO:              pandas: 1.5.3
2024-11-13 17:39:18,317:INFO:              jinja2: 3.1.2
2024-11-13 17:39:18,317:INFO:               scipy: 1.10.1
2024-11-13 17:39:18,317:INFO:              joblib: 1.3.0
2024-11-13 17:39:18,317:INFO:             sklearn: 1.1.2
2024-11-13 17:39:18,317:INFO:                pyod: 2.0.2
2024-11-13 17:39:18,317:INFO:            imblearn: 0.12.4
2024-11-13 17:39:18,317:INFO:   category_encoders: 2.6.4
2024-11-13 17:39:18,317:INFO:            lightgbm: 4.5.0
2024-11-13 17:39:18,317:INFO:               numba: 0.57.1
2024-11-13 17:39:18,317:INFO:            requests: 2.28.1
2024-11-13 17:39:18,317:INFO:          matplotlib: 3.5.1
2024-11-13 17:39:18,317:INFO:          scikitplot: 0.3.7
2024-11-13 17:39:18,317:INFO:         yellowbrick: 1.5
2024-11-13 17:39:18,317:INFO:              plotly: 5.24.1
2024-11-13 17:39:18,317:INFO:    plotly-resampler: Not installed
2024-11-13 17:39:18,317:INFO:             kaleido: 0.2.1
2024-11-13 17:39:18,317:INFO:           schemdraw: 0.15
2024-11-13 17:39:18,317:INFO:         statsmodels: 0.13.2
2024-11-13 17:39:18,317:INFO:              sktime: 0.21.1
2024-11-13 17:39:18,317:INFO:               tbats: 1.1.3
2024-11-13 17:39:18,317:INFO:            pmdarima: 2.0.4
2024-11-13 17:39:18,317:INFO:              psutil: 5.9.1
2024-11-13 17:39:18,317:INFO:          markupsafe: 2.1.1
2024-11-13 17:39:18,317:INFO:             pickle5: Not installed
2024-11-13 17:39:18,317:INFO:         cloudpickle: 2.1.0
2024-11-13 17:39:18,317:INFO:         deprecation: 2.1.0
2024-11-13 17:39:18,317:INFO:              xxhash: 3.5.0
2024-11-13 17:39:18,317:INFO:           wurlitzer: 3.1.1
2024-11-13 17:39:18,317:INFO:PyCaret optional dependencies:
2024-11-13 17:39:18,317:INFO:                shap: 0.44.1
2024-11-13 17:39:18,317:INFO:           interpret: 0.6.5
2024-11-13 17:39:18,318:INFO:                umap: 0.5.7
2024-11-13 17:39:18,318:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:39:18,318:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:39:18,318:INFO:             autoviz: Not installed
2024-11-13 17:39:18,318:INFO:           fairlearn: 0.7.0
2024-11-13 17:39:18,318:INFO:          deepchecks: Not installed
2024-11-13 17:39:18,318:INFO:             xgboost: 2.1.1
2024-11-13 17:39:18,318:INFO:            catboost: 1.2.7
2024-11-13 17:39:18,318:INFO:              kmodes: 0.12.2
2024-11-13 17:39:18,318:INFO:             mlxtend: 0.23.1
2024-11-13 17:39:18,318:INFO:       statsforecast: 1.5.0
2024-11-13 17:39:18,318:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:39:18,318:INFO:                 ray: 2.10.0
2024-11-13 17:39:18,318:INFO:            hyperopt: 0.2.7
2024-11-13 17:39:18,318:INFO:              optuna: 4.1.0
2024-11-13 17:39:18,318:INFO:               skopt: 0.10.2
2024-11-13 17:39:18,318:INFO:              mlflow: 1.30.1
2024-11-13 17:39:18,318:INFO:              gradio: 3.50.2
2024-11-13 17:39:18,318:INFO:             fastapi: 0.115.5
2024-11-13 17:39:18,318:INFO:             uvicorn: 0.32.0
2024-11-13 17:39:18,318:INFO:              m2cgen: 0.10.0
2024-11-13 17:39:18,318:INFO:           evidently: 0.2.8
2024-11-13 17:39:18,318:INFO:               fugue: 0.8.6
2024-11-13 17:39:18,318:INFO:           streamlit: Not installed
2024-11-13 17:39:18,318:INFO:             prophet: Not installed
2024-11-13 17:39:18,318:INFO:None
2024-11-13 17:39:18,318:INFO:Set up data.
2024-11-13 17:39:34,018:INFO:PyCaret RegressionExperiment
2024-11-13 17:39:34,018:INFO:Logging name: reg-default-name
2024-11-13 17:39:34,018:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:39:34,018:INFO:version 3.2.0
2024-11-13 17:39:34,019:INFO:Initializing setup()
2024-11-13 17:39:34,019:INFO:self.USI: 7207
2024-11-13 17:39:34,019:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:39:34,019:INFO:Checking environment
2024-11-13 17:39:34,019:INFO:python_version: 3.8.13
2024-11-13 17:39:34,019:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:39:34,019:INFO:machine: x86_64
2024-11-13 17:39:34,019:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:34,019:INFO:Memory: svmem(total=270355722240, available=216861130752, percent=19.8, used=51413438464, free=55228620800, active=11558920192, inactive=143269441536, buffers=8888320, cached=163704774656, shared=187363328, slab=25018122240)
2024-11-13 17:39:34,023:INFO:Physical Core: 28
2024-11-13 17:39:34,023:INFO:Logical Core: 56
2024-11-13 17:39:34,024:INFO:Checking libraries
2024-11-13 17:39:34,024:INFO:System:
2024-11-13 17:39:34,024:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:39:34,024:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:39:34,024:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:34,024:INFO:PyCaret required dependencies:
2024-11-13 17:39:34,024:INFO:                 pip: 22.2.2
2024-11-13 17:39:34,024:INFO:          setuptools: 63.4.2
2024-11-13 17:39:34,024:INFO:             pycaret: 3.2.0
2024-11-13 17:39:34,024:INFO:             IPython: 8.12.2
2024-11-13 17:39:34,024:INFO:          ipywidgets: 7.7.1
2024-11-13 17:39:34,024:INFO:                tqdm: 4.64.1
2024-11-13 17:39:34,024:INFO:               numpy: 1.23.5
2024-11-13 17:39:34,024:INFO:              pandas: 1.5.3
2024-11-13 17:39:34,024:INFO:              jinja2: 3.1.2
2024-11-13 17:39:34,025:INFO:               scipy: 1.10.1
2024-11-13 17:39:34,025:INFO:              joblib: 1.3.0
2024-11-13 17:39:34,025:INFO:             sklearn: 1.1.2
2024-11-13 17:39:34,025:INFO:                pyod: 2.0.2
2024-11-13 17:39:34,025:INFO:            imblearn: 0.12.4
2024-11-13 17:39:34,025:INFO:   category_encoders: 2.6.4
2024-11-13 17:39:34,025:INFO:            lightgbm: 4.5.0
2024-11-13 17:39:34,025:INFO:               numba: 0.57.1
2024-11-13 17:39:34,025:INFO:            requests: 2.28.1
2024-11-13 17:39:34,025:INFO:          matplotlib: 3.5.1
2024-11-13 17:39:34,025:INFO:          scikitplot: 0.3.7
2024-11-13 17:39:34,025:INFO:         yellowbrick: 1.5
2024-11-13 17:39:34,025:INFO:              plotly: 5.24.1
2024-11-13 17:39:34,025:INFO:    plotly-resampler: Not installed
2024-11-13 17:39:34,025:INFO:             kaleido: 0.2.1
2024-11-13 17:39:34,025:INFO:           schemdraw: 0.15
2024-11-13 17:39:34,025:INFO:         statsmodels: 0.13.2
2024-11-13 17:39:34,025:INFO:              sktime: 0.21.1
2024-11-13 17:39:34,025:INFO:               tbats: 1.1.3
2024-11-13 17:39:34,025:INFO:            pmdarima: 2.0.4
2024-11-13 17:39:34,025:INFO:              psutil: 5.9.1
2024-11-13 17:39:34,025:INFO:          markupsafe: 2.1.1
2024-11-13 17:39:34,025:INFO:             pickle5: Not installed
2024-11-13 17:39:34,025:INFO:         cloudpickle: 2.1.0
2024-11-13 17:39:34,025:INFO:         deprecation: 2.1.0
2024-11-13 17:39:34,025:INFO:              xxhash: 3.5.0
2024-11-13 17:39:34,025:INFO:           wurlitzer: 3.1.1
2024-11-13 17:39:34,025:INFO:PyCaret optional dependencies:
2024-11-13 17:39:34,025:INFO:                shap: 0.44.1
2024-11-13 17:39:34,025:INFO:           interpret: 0.6.5
2024-11-13 17:39:34,025:INFO:                umap: 0.5.7
2024-11-13 17:39:34,025:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:39:34,025:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:39:34,026:INFO:             autoviz: Not installed
2024-11-13 17:39:34,026:INFO:           fairlearn: 0.7.0
2024-11-13 17:39:34,026:INFO:          deepchecks: Not installed
2024-11-13 17:39:34,026:INFO:             xgboost: 2.1.1
2024-11-13 17:39:34,026:INFO:            catboost: 1.2.7
2024-11-13 17:39:34,026:INFO:              kmodes: 0.12.2
2024-11-13 17:39:34,026:INFO:             mlxtend: 0.23.1
2024-11-13 17:39:34,026:INFO:       statsforecast: 1.5.0
2024-11-13 17:39:34,026:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:39:34,026:INFO:                 ray: 2.10.0
2024-11-13 17:39:34,026:INFO:            hyperopt: 0.2.7
2024-11-13 17:39:34,026:INFO:              optuna: 4.1.0
2024-11-13 17:39:34,026:INFO:               skopt: 0.10.2
2024-11-13 17:39:34,026:INFO:              mlflow: 1.30.1
2024-11-13 17:39:34,026:INFO:              gradio: 3.50.2
2024-11-13 17:39:34,026:INFO:             fastapi: 0.115.5
2024-11-13 17:39:34,026:INFO:             uvicorn: 0.32.0
2024-11-13 17:39:34,026:INFO:              m2cgen: 0.10.0
2024-11-13 17:39:34,026:INFO:           evidently: 0.2.8
2024-11-13 17:39:34,026:INFO:               fugue: 0.8.6
2024-11-13 17:39:34,026:INFO:           streamlit: Not installed
2024-11-13 17:39:34,026:INFO:             prophet: Not installed
2024-11-13 17:39:34,026:INFO:None
2024-11-13 17:39:34,026:INFO:Set up data.
2024-11-13 17:39:34,037:INFO:Set up folding strategy.
2024-11-13 17:39:34,037:INFO:Set up train/test split.
2024-11-13 17:39:34,043:INFO:Set up index.
2024-11-13 17:39:34,044:INFO:Assigning column types.
2024-11-13 17:39:34,049:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 17:39:34,050:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,055:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,060:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,125:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,162:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,164:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,166:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,167:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,170:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,174:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,222:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,260:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,262:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,263:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 17:39:34,266:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,270:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,319:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,357:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,359:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,363:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,455:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,455:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,458:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,458:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 17:39:34,466:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,553:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,556:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,564:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,650:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,652:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,652:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 17:39:34,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,746:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,748:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,843:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,845:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,846:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 17:39:34,903:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,941:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,943:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,037:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,039:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,040:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 17:39:35,134:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,137:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,232:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,234:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,235:INFO:Preparing preprocessing pipeline...
2024-11-13 17:39:35,235:INFO:Set up simple imputation.
2024-11-13 17:39:35,252:INFO:Finished creating preprocessing pipeline.
2024-11-13 17:39:35,256:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 17:39:35,256:INFO:Creating final display dataframe.
2024-11-13 17:39:35,312:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              7207
2024-11-13 17:39:35,420:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,422:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,515:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,518:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,518:INFO:setup() successfully completed in 1.5s...............
2024-11-13 17:39:35,519:INFO:PyCaret RegressionExperiment
2024-11-13 17:39:35,519:INFO:Logging name: reg-default-name
2024-11-13 17:39:35,519:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:39:35,519:INFO:version 3.2.0
2024-11-13 17:39:35,519:INFO:Initializing setup()
2024-11-13 17:39:35,519:INFO:self.USI: a600
2024-11-13 17:39:35,519:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:39:35,520:INFO:Checking environment
2024-11-13 17:39:35,520:INFO:python_version: 3.8.13
2024-11-13 17:39:35,520:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:39:35,520:INFO:machine: x86_64
2024-11-13 17:39:35,520:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:35,520:INFO:Memory: svmem(total=270355722240, available=216854888448, percent=19.8, used=51419725824, free=55184830464, active=11558912000, inactive=143312265216, buffers=8888320, cached=163742277632, shared=187363328, slab=25018155008)
2024-11-13 17:39:35,522:INFO:Physical Core: 28
2024-11-13 17:39:35,522:INFO:Logical Core: 56
2024-11-13 17:39:35,522:INFO:Checking libraries
2024-11-13 17:39:35,522:INFO:System:
2024-11-13 17:39:35,522:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:39:35,522:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:39:35,522:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:35,522:INFO:PyCaret required dependencies:
2024-11-13 17:39:35,522:INFO:                 pip: 22.2.2
2024-11-13 17:39:35,522:INFO:          setuptools: 63.4.2
2024-11-13 17:39:35,522:INFO:             pycaret: 3.2.0
2024-11-13 17:39:35,522:INFO:             IPython: 8.12.2
2024-11-13 17:39:35,522:INFO:          ipywidgets: 7.7.1
2024-11-13 17:39:35,522:INFO:                tqdm: 4.64.1
2024-11-13 17:39:35,522:INFO:               numpy: 1.23.5
2024-11-13 17:39:35,522:INFO:              pandas: 1.5.3
2024-11-13 17:39:35,522:INFO:              jinja2: 3.1.2
2024-11-13 17:39:35,522:INFO:               scipy: 1.10.1
2024-11-13 17:39:35,522:INFO:              joblib: 1.3.0
2024-11-13 17:39:35,522:INFO:             sklearn: 1.1.2
2024-11-13 17:39:35,522:INFO:                pyod: 2.0.2
2024-11-13 17:39:35,522:INFO:            imblearn: 0.12.4
2024-11-13 17:39:35,522:INFO:   category_encoders: 2.6.4
2024-11-13 17:39:35,522:INFO:            lightgbm: 4.5.0
2024-11-13 17:39:35,522:INFO:               numba: 0.57.1
2024-11-13 17:39:35,522:INFO:            requests: 2.28.1
2024-11-13 17:39:35,522:INFO:          matplotlib: 3.5.1
2024-11-13 17:39:35,522:INFO:          scikitplot: 0.3.7
2024-11-13 17:39:35,522:INFO:         yellowbrick: 1.5
2024-11-13 17:39:35,522:INFO:              plotly: 5.24.1
2024-11-13 17:39:35,523:INFO:    plotly-resampler: Not installed
2024-11-13 17:39:35,523:INFO:             kaleido: 0.2.1
2024-11-13 17:39:35,523:INFO:           schemdraw: 0.15
2024-11-13 17:39:35,523:INFO:         statsmodels: 0.13.2
2024-11-13 17:39:35,523:INFO:              sktime: 0.21.1
2024-11-13 17:39:35,523:INFO:               tbats: 1.1.3
2024-11-13 17:39:35,523:INFO:            pmdarima: 2.0.4
2024-11-13 17:39:35,523:INFO:              psutil: 5.9.1
2024-11-13 17:39:35,523:INFO:          markupsafe: 2.1.1
2024-11-13 17:39:35,523:INFO:             pickle5: Not installed
2024-11-13 17:39:35,523:INFO:         cloudpickle: 2.1.0
2024-11-13 17:39:35,523:INFO:         deprecation: 2.1.0
2024-11-13 17:39:35,523:INFO:              xxhash: 3.5.0
2024-11-13 17:39:35,523:INFO:           wurlitzer: 3.1.1
2024-11-13 17:39:35,523:INFO:PyCaret optional dependencies:
2024-11-13 17:39:35,523:INFO:                shap: 0.44.1
2024-11-13 17:39:35,523:INFO:           interpret: 0.6.5
2024-11-13 17:39:35,523:INFO:                umap: 0.5.7
2024-11-13 17:39:35,523:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:39:35,523:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:39:35,523:INFO:             autoviz: Not installed
2024-11-13 17:39:35,523:INFO:           fairlearn: 0.7.0
2024-11-13 17:39:35,523:INFO:          deepchecks: Not installed
2024-11-13 17:39:35,523:INFO:             xgboost: 2.1.1
2024-11-13 17:39:35,523:INFO:            catboost: 1.2.7
2024-11-13 17:39:35,523:INFO:              kmodes: 0.12.2
2024-11-13 17:39:35,523:INFO:             mlxtend: 0.23.1
2024-11-13 17:39:35,523:INFO:       statsforecast: 1.5.0
2024-11-13 17:39:35,523:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:39:35,523:INFO:                 ray: 2.10.0
2024-11-13 17:39:35,523:INFO:            hyperopt: 0.2.7
2024-11-13 17:39:35,523:INFO:              optuna: 4.1.0
2024-11-13 17:39:35,523:INFO:               skopt: 0.10.2
2024-11-13 17:39:35,523:INFO:              mlflow: 1.30.1
2024-11-13 17:39:35,523:INFO:              gradio: 3.50.2
2024-11-13 17:39:35,523:INFO:             fastapi: 0.115.5
2024-11-13 17:39:35,523:INFO:             uvicorn: 0.32.0
2024-11-13 17:39:35,523:INFO:              m2cgen: 0.10.0
2024-11-13 17:39:35,523:INFO:           evidently: 0.2.8
2024-11-13 17:39:35,523:INFO:               fugue: 0.8.6
2024-11-13 17:39:35,523:INFO:           streamlit: Not installed
2024-11-13 17:39:35,524:INFO:             prophet: Not installed
2024-11-13 17:39:35,524:INFO:None
2024-11-13 17:39:35,524:INFO:Set up data.
2024-11-13 17:39:35,530:INFO:Set up folding strategy.
2024-11-13 17:39:35,530:INFO:Set up train/test split.
2024-11-13 17:39:35,534:INFO:Set up index.
2024-11-13 17:39:35,535:INFO:Assigning column types.
2024-11-13 17:39:35,539:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 17:39:35,539:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,543:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,547:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,633:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,635:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,636:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,639:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,643:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,729:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,731:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,732:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 17:39:35,736:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,788:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,825:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,827:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,831:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,835:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,920:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,922:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,923:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 17:39:35,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,980:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,017:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,018:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,021:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,029:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,078:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,115:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,117:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,118:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 17:39:36,172:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,209:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,211:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,267:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,304:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,306:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,306:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 17:39:36,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,400:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,403:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,458:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,494:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,497:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,497:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 17:39:36,589:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,591:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,686:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,689:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,690:INFO:Preparing preprocessing pipeline...
2024-11-13 17:39:36,690:INFO:Set up simple imputation.
2024-11-13 17:39:36,705:INFO:Finished creating preprocessing pipeline.
2024-11-13 17:39:36,708:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Latitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 17:39:36,709:INFO:Creating final display dataframe.
2024-11-13 17:39:36,764:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Longitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a600
2024-11-13 17:39:36,867:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,870:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,963:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,965:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,966:INFO:setup() successfully completed in 1.45s...............
2024-11-13 17:39:51,965:INFO:Initializing compare_models()
2024-11-13 17:39:51,965:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 17:39:51,965:INFO:Checking exceptions
2024-11-13 17:39:51,971:INFO:Preparing display monitor
2024-11-13 17:39:52,015:INFO:Initializing Linear Regression
2024-11-13 17:39:52,015:INFO:Total runtime is 2.5192896525065104e-06 minutes
2024-11-13 17:39:52,019:INFO:SubProcess create_model() called ==================================
2024-11-13 17:39:52,019:INFO:Initializing create_model()
2024-11-13 17:39:52,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:39:52,019:INFO:Checking exceptions
2024-11-13 17:39:52,019:INFO:Importing libraries
2024-11-13 17:39:52,019:INFO:Copying training dataset
2024-11-13 17:39:52,026:INFO:Defining folds
2024-11-13 17:39:52,026:INFO:Declaring metric variables
2024-11-13 17:39:52,030:INFO:Importing untrained model
2024-11-13 17:39:52,033:INFO:Linear Regression Imported successfully
2024-11-13 17:39:52,041:INFO:Starting cross validation
2024-11-13 17:39:52,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:39:55,751:INFO:Calculating mean and std
2024-11-13 17:39:55,756:INFO:Creating metrics dataframe
2024-11-13 17:39:55,762:INFO:Uploading results into container
2024-11-13 17:39:55,763:INFO:Uploading model into container now
2024-11-13 17:39:55,764:INFO:_master_model_container: 1
2024-11-13 17:39:55,764:INFO:_display_container: 2
2024-11-13 17:39:55,764:INFO:LinearRegression(n_jobs=-1)
2024-11-13 17:39:55,764:INFO:create_model() successfully completed......................................
2024-11-13 17:39:55,995:INFO:SubProcess create_model() end ==================================
2024-11-13 17:39:55,996:INFO:Creating metrics dataframe
2024-11-13 17:39:56,005:INFO:Initializing Lasso Regression
2024-11-13 17:39:56,005:INFO:Total runtime is 0.06649986108144124 minutes
2024-11-13 17:39:56,008:INFO:SubProcess create_model() called ==================================
2024-11-13 17:39:56,009:INFO:Initializing create_model()
2024-11-13 17:39:56,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:39:56,009:INFO:Checking exceptions
2024-11-13 17:39:56,009:INFO:Importing libraries
2024-11-13 17:39:56,009:INFO:Copying training dataset
2024-11-13 17:39:56,017:INFO:Defining folds
2024-11-13 17:39:56,017:INFO:Declaring metric variables
2024-11-13 17:39:56,021:INFO:Importing untrained model
2024-11-13 17:39:56,024:INFO:Lasso Regression Imported successfully
2024-11-13 17:39:56,030:INFO:Starting cross validation
2024-11-13 17:39:56,031:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:39:58,955:INFO:Calculating mean and std
2024-11-13 17:39:58,959:INFO:Creating metrics dataframe
2024-11-13 17:39:58,967:INFO:Uploading results into container
2024-11-13 17:39:58,967:INFO:Uploading model into container now
2024-11-13 17:39:58,968:INFO:_master_model_container: 2
2024-11-13 17:39:58,969:INFO:_display_container: 2
2024-11-13 17:39:58,969:INFO:Lasso(random_state=123)
2024-11-13 17:39:58,969:INFO:create_model() successfully completed......................................
2024-11-13 17:39:59,136:INFO:SubProcess create_model() end ==================================
2024-11-13 17:39:59,137:INFO:Creating metrics dataframe
2024-11-13 17:39:59,146:INFO:Initializing Ridge Regression
2024-11-13 17:39:59,147:INFO:Total runtime is 0.11886225541432698 minutes
2024-11-13 17:39:59,150:INFO:SubProcess create_model() called ==================================
2024-11-13 17:39:59,150:INFO:Initializing create_model()
2024-11-13 17:39:59,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:39:59,150:INFO:Checking exceptions
2024-11-13 17:39:59,151:INFO:Importing libraries
2024-11-13 17:39:59,151:INFO:Copying training dataset
2024-11-13 17:39:59,158:INFO:Defining folds
2024-11-13 17:39:59,158:INFO:Declaring metric variables
2024-11-13 17:39:59,161:INFO:Importing untrained model
2024-11-13 17:39:59,164:INFO:Ridge Regression Imported successfully
2024-11-13 17:39:59,171:INFO:Starting cross validation
2024-11-13 17:39:59,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:02,181:INFO:Calculating mean and std
2024-11-13 17:40:02,184:INFO:Creating metrics dataframe
2024-11-13 17:40:02,191:INFO:Uploading results into container
2024-11-13 17:40:02,192:INFO:Uploading model into container now
2024-11-13 17:40:02,192:INFO:_master_model_container: 3
2024-11-13 17:40:02,192:INFO:_display_container: 2
2024-11-13 17:40:02,193:INFO:Ridge(random_state=123)
2024-11-13 17:40:02,193:INFO:create_model() successfully completed......................................
2024-11-13 17:40:02,358:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:02,358:INFO:Creating metrics dataframe
2024-11-13 17:40:02,369:INFO:Initializing Elastic Net
2024-11-13 17:40:02,369:INFO:Total runtime is 0.172568408648173 minutes
2024-11-13 17:40:02,372:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:02,373:INFO:Initializing create_model()
2024-11-13 17:40:02,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:02,373:INFO:Checking exceptions
2024-11-13 17:40:02,373:INFO:Importing libraries
2024-11-13 17:40:02,373:INFO:Copying training dataset
2024-11-13 17:40:02,380:INFO:Defining folds
2024-11-13 17:40:02,380:INFO:Declaring metric variables
2024-11-13 17:40:02,384:INFO:Importing untrained model
2024-11-13 17:40:02,387:INFO:Elastic Net Imported successfully
2024-11-13 17:40:02,394:INFO:Starting cross validation
2024-11-13 17:40:02,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:05,315:INFO:Calculating mean and std
2024-11-13 17:40:05,318:INFO:Creating metrics dataframe
2024-11-13 17:40:05,326:INFO:Uploading results into container
2024-11-13 17:40:05,326:INFO:Uploading model into container now
2024-11-13 17:40:05,327:INFO:_master_model_container: 4
2024-11-13 17:40:05,327:INFO:_display_container: 2
2024-11-13 17:40:05,327:INFO:ElasticNet(random_state=123)
2024-11-13 17:40:05,327:INFO:create_model() successfully completed......................................
2024-11-13 17:40:05,509:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:05,509:INFO:Creating metrics dataframe
2024-11-13 17:40:05,522:INFO:Initializing Least Angle Regression
2024-11-13 17:40:05,522:INFO:Total runtime is 0.22511534293492633 minutes
2024-11-13 17:40:05,525:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:05,526:INFO:Initializing create_model()
2024-11-13 17:40:05,526:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:05,526:INFO:Checking exceptions
2024-11-13 17:40:05,526:INFO:Importing libraries
2024-11-13 17:40:05,526:INFO:Copying training dataset
2024-11-13 17:40:05,534:INFO:Defining folds
2024-11-13 17:40:05,534:INFO:Declaring metric variables
2024-11-13 17:40:05,538:INFO:Importing untrained model
2024-11-13 17:40:05,541:INFO:Least Angle Regression Imported successfully
2024-11-13 17:40:05,548:INFO:Starting cross validation
2024-11-13 17:40:05,549:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:08,162:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,259:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,259:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,260:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,264:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,268:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,334:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,354:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,364:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,368:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,385:INFO:Calculating mean and std
2024-11-13 17:40:08,388:INFO:Creating metrics dataframe
2024-11-13 17:40:08,395:INFO:Uploading results into container
2024-11-13 17:40:08,396:INFO:Uploading model into container now
2024-11-13 17:40:08,397:INFO:_master_model_container: 5
2024-11-13 17:40:08,397:INFO:_display_container: 2
2024-11-13 17:40:08,397:INFO:Lars(random_state=123)
2024-11-13 17:40:08,397:INFO:create_model() successfully completed......................................
2024-11-13 17:40:08,583:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:08,584:INFO:Creating metrics dataframe
2024-11-13 17:40:08,595:INFO:Initializing Lasso Least Angle Regression
2024-11-13 17:40:08,595:INFO:Total runtime is 0.27632927894592285 minutes
2024-11-13 17:40:08,598:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:08,598:INFO:Initializing create_model()
2024-11-13 17:40:08,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:08,598:INFO:Checking exceptions
2024-11-13 17:40:08,599:INFO:Importing libraries
2024-11-13 17:40:08,599:INFO:Copying training dataset
2024-11-13 17:40:08,606:INFO:Defining folds
2024-11-13 17:40:08,606:INFO:Declaring metric variables
2024-11-13 17:40:08,609:INFO:Importing untrained model
2024-11-13 17:40:08,613:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 17:40:08,620:INFO:Starting cross validation
2024-11-13 17:40:08,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:08,700:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:08,709:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:08,713:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:08,716:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,134:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,280:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,287:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,333:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,347:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,354:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,370:INFO:Calculating mean and std
2024-11-13 17:40:11,374:INFO:Creating metrics dataframe
2024-11-13 17:40:11,380:INFO:Uploading results into container
2024-11-13 17:40:11,381:INFO:Uploading model into container now
2024-11-13 17:40:11,381:INFO:_master_model_container: 6
2024-11-13 17:40:11,381:INFO:_display_container: 2
2024-11-13 17:40:11,381:INFO:LassoLars(random_state=123)
2024-11-13 17:40:11,382:INFO:create_model() successfully completed......................................
2024-11-13 17:40:11,564:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:11,564:INFO:Creating metrics dataframe
2024-11-13 17:40:11,575:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 17:40:11,575:INFO:Total runtime is 0.3260077913602193 minutes
2024-11-13 17:40:11,579:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:11,579:INFO:Initializing create_model()
2024-11-13 17:40:11,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:11,579:INFO:Checking exceptions
2024-11-13 17:40:11,580:INFO:Importing libraries
2024-11-13 17:40:11,580:INFO:Copying training dataset
2024-11-13 17:40:11,587:INFO:Defining folds
2024-11-13 17:40:11,587:INFO:Declaring metric variables
2024-11-13 17:40:11,590:INFO:Importing untrained model
2024-11-13 17:40:11,593:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 17:40:11,600:INFO:Starting cross validation
2024-11-13 17:40:11,601:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:11,636:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,640:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,657:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,663:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,668:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,689:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,690:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,698:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,704:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,707:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,727:INFO:Calculating mean and std
2024-11-13 17:40:11,731:INFO:Creating metrics dataframe
2024-11-13 17:40:11,738:INFO:Uploading results into container
2024-11-13 17:40:11,739:INFO:Uploading model into container now
2024-11-13 17:40:11,739:INFO:_master_model_container: 7
2024-11-13 17:40:11,740:INFO:_display_container: 2
2024-11-13 17:40:11,740:INFO:OrthogonalMatchingPursuit()
2024-11-13 17:40:11,740:INFO:create_model() successfully completed......................................
2024-11-13 17:40:11,888:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:11,888:INFO:Creating metrics dataframe
2024-11-13 17:40:11,899:INFO:Initializing Bayesian Ridge
2024-11-13 17:40:11,899:INFO:Total runtime is 0.33139901558558144 minutes
2024-11-13 17:40:11,902:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:11,902:INFO:Initializing create_model()
2024-11-13 17:40:11,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:11,903:INFO:Checking exceptions
2024-11-13 17:40:11,903:INFO:Importing libraries
2024-11-13 17:40:11,903:INFO:Copying training dataset
2024-11-13 17:40:11,910:INFO:Defining folds
2024-11-13 17:40:11,910:INFO:Declaring metric variables
2024-11-13 17:40:11,914:INFO:Importing untrained model
2024-11-13 17:40:11,917:INFO:Bayesian Ridge Imported successfully
2024-11-13 17:40:11,923:INFO:Starting cross validation
2024-11-13 17:40:11,924:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:12,020:INFO:Calculating mean and std
2024-11-13 17:40:12,023:INFO:Creating metrics dataframe
2024-11-13 17:40:12,031:INFO:Uploading results into container
2024-11-13 17:40:12,031:INFO:Uploading model into container now
2024-11-13 17:40:12,032:INFO:_master_model_container: 8
2024-11-13 17:40:12,032:INFO:_display_container: 2
2024-11-13 17:40:12,032:INFO:BayesianRidge()
2024-11-13 17:40:12,032:INFO:create_model() successfully completed......................................
2024-11-13 17:40:12,181:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:12,181:INFO:Creating metrics dataframe
2024-11-13 17:40:12,192:INFO:Initializing Passive Aggressive Regressor
2024-11-13 17:40:12,192:INFO:Total runtime is 0.33629222710927326 minutes
2024-11-13 17:40:12,196:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:12,196:INFO:Initializing create_model()
2024-11-13 17:40:12,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:12,196:INFO:Checking exceptions
2024-11-13 17:40:12,197:INFO:Importing libraries
2024-11-13 17:40:12,197:INFO:Copying training dataset
2024-11-13 17:40:12,204:INFO:Defining folds
2024-11-13 17:40:12,204:INFO:Declaring metric variables
2024-11-13 17:40:12,207:INFO:Importing untrained model
2024-11-13 17:40:12,211:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 17:40:12,217:INFO:Starting cross validation
2024-11-13 17:40:12,218:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:12,339:INFO:Calculating mean and std
2024-11-13 17:40:12,342:INFO:Creating metrics dataframe
2024-11-13 17:40:12,350:INFO:Uploading results into container
2024-11-13 17:40:12,351:INFO:Uploading model into container now
2024-11-13 17:40:12,351:INFO:_master_model_container: 9
2024-11-13 17:40:12,351:INFO:_display_container: 2
2024-11-13 17:40:12,352:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 17:40:12,352:INFO:create_model() successfully completed......................................
2024-11-13 17:40:12,538:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:12,538:INFO:Creating metrics dataframe
2024-11-13 17:40:12,550:INFO:Initializing Huber Regressor
2024-11-13 17:40:12,550:INFO:Total runtime is 0.3422567288080851 minutes
2024-11-13 17:40:12,554:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:12,554:INFO:Initializing create_model()
2024-11-13 17:40:12,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:12,554:INFO:Checking exceptions
2024-11-13 17:40:12,554:INFO:Importing libraries
2024-11-13 17:40:12,554:INFO:Copying training dataset
2024-11-13 17:40:12,561:INFO:Defining folds
2024-11-13 17:40:12,561:INFO:Declaring metric variables
2024-11-13 17:40:12,565:INFO:Importing untrained model
2024-11-13 17:40:12,568:INFO:Huber Regressor Imported successfully
2024-11-13 17:40:12,575:INFO:Starting cross validation
2024-11-13 17:40:12,575:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:12,825:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:40:12,905:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:40:12,922:INFO:Calculating mean and std
2024-11-13 17:40:12,926:INFO:Creating metrics dataframe
2024-11-13 17:40:12,932:INFO:Uploading results into container
2024-11-13 17:40:12,932:INFO:Uploading model into container now
2024-11-13 17:40:12,933:INFO:_master_model_container: 10
2024-11-13 17:40:12,933:INFO:_display_container: 2
2024-11-13 17:40:12,933:INFO:HuberRegressor()
2024-11-13 17:40:12,933:INFO:create_model() successfully completed......................................
2024-11-13 17:40:13,081:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:13,081:INFO:Creating metrics dataframe
2024-11-13 17:40:13,093:INFO:Initializing K Neighbors Regressor
2024-11-13 17:40:13,093:INFO:Total runtime is 0.3513080358505249 minutes
2024-11-13 17:40:13,097:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:13,097:INFO:Initializing create_model()
2024-11-13 17:40:13,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:13,097:INFO:Checking exceptions
2024-11-13 17:40:13,097:INFO:Importing libraries
2024-11-13 17:40:13,097:INFO:Copying training dataset
2024-11-13 17:40:13,104:INFO:Defining folds
2024-11-13 17:40:13,104:INFO:Declaring metric variables
2024-11-13 17:40:13,108:INFO:Importing untrained model
2024-11-13 17:40:13,111:INFO:K Neighbors Regressor Imported successfully
2024-11-13 17:40:13,118:INFO:Starting cross validation
2024-11-13 17:40:13,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:13,283:INFO:Calculating mean and std
2024-11-13 17:40:13,287:INFO:Creating metrics dataframe
2024-11-13 17:40:13,292:INFO:Uploading results into container
2024-11-13 17:40:13,292:INFO:Uploading model into container now
2024-11-13 17:40:13,293:INFO:_master_model_container: 11
2024-11-13 17:40:13,293:INFO:_display_container: 2
2024-11-13 17:40:13,293:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 17:40:13,293:INFO:create_model() successfully completed......................................
2024-11-13 17:40:13,441:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:13,441:INFO:Creating metrics dataframe
2024-11-13 17:40:13,453:INFO:Initializing Decision Tree Regressor
2024-11-13 17:40:13,453:INFO:Total runtime is 0.35730751355489093 minutes
2024-11-13 17:40:13,457:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:13,457:INFO:Initializing create_model()
2024-11-13 17:40:13,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:13,457:INFO:Checking exceptions
2024-11-13 17:40:13,457:INFO:Importing libraries
2024-11-13 17:40:13,457:INFO:Copying training dataset
2024-11-13 17:40:13,464:INFO:Defining folds
2024-11-13 17:40:13,464:INFO:Declaring metric variables
2024-11-13 17:40:13,468:INFO:Importing untrained model
2024-11-13 17:40:13,471:INFO:Decision Tree Regressor Imported successfully
2024-11-13 17:40:13,477:INFO:Starting cross validation
2024-11-13 17:40:13,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:13,662:INFO:Calculating mean and std
2024-11-13 17:40:13,663:INFO:Creating metrics dataframe
2024-11-13 17:40:13,669:INFO:Uploading results into container
2024-11-13 17:40:13,670:INFO:Uploading model into container now
2024-11-13 17:40:13,670:INFO:_master_model_container: 12
2024-11-13 17:40:13,671:INFO:_display_container: 2
2024-11-13 17:40:13,671:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 17:40:13,671:INFO:create_model() successfully completed......................................
2024-11-13 17:40:13,820:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:13,821:INFO:Creating metrics dataframe
2024-11-13 17:40:13,833:INFO:Initializing Random Forest Regressor
2024-11-13 17:40:13,833:INFO:Total runtime is 0.36363011201222734 minutes
2024-11-13 17:40:13,836:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:13,836:INFO:Initializing create_model()
2024-11-13 17:40:13,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:13,837:INFO:Checking exceptions
2024-11-13 17:40:13,837:INFO:Importing libraries
2024-11-13 17:40:13,837:INFO:Copying training dataset
2024-11-13 17:40:13,844:INFO:Defining folds
2024-11-13 17:40:13,844:INFO:Declaring metric variables
2024-11-13 17:40:13,847:INFO:Importing untrained model
2024-11-13 17:40:13,851:INFO:Random Forest Regressor Imported successfully
2024-11-13 17:40:13,857:INFO:Starting cross validation
2024-11-13 17:40:13,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:15,291:INFO:Calculating mean and std
2024-11-13 17:40:15,295:INFO:Creating metrics dataframe
2024-11-13 17:40:15,302:INFO:Uploading results into container
2024-11-13 17:40:15,303:INFO:Uploading model into container now
2024-11-13 17:40:15,303:INFO:_master_model_container: 13
2024-11-13 17:40:15,303:INFO:_display_container: 2
2024-11-13 17:40:15,304:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:40:15,304:INFO:create_model() successfully completed......................................
2024-11-13 17:40:15,449:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:15,449:INFO:Creating metrics dataframe
2024-11-13 17:40:15,462:INFO:Initializing Extra Trees Regressor
2024-11-13 17:40:15,462:INFO:Total runtime is 0.390779960155487 minutes
2024-11-13 17:40:15,465:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:15,465:INFO:Initializing create_model()
2024-11-13 17:40:15,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:15,465:INFO:Checking exceptions
2024-11-13 17:40:15,465:INFO:Importing libraries
2024-11-13 17:40:15,465:INFO:Copying training dataset
2024-11-13 17:40:15,472:INFO:Defining folds
2024-11-13 17:40:15,472:INFO:Declaring metric variables
2024-11-13 17:40:15,476:INFO:Importing untrained model
2024-11-13 17:40:15,480:INFO:Extra Trees Regressor Imported successfully
2024-11-13 17:40:15,486:INFO:Starting cross validation
2024-11-13 17:40:15,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:16,331:INFO:Calculating mean and std
2024-11-13 17:40:16,336:INFO:Creating metrics dataframe
2024-11-13 17:40:16,341:INFO:Uploading results into container
2024-11-13 17:40:16,342:INFO:Uploading model into container now
2024-11-13 17:40:16,342:INFO:_master_model_container: 14
2024-11-13 17:40:16,342:INFO:_display_container: 2
2024-11-13 17:40:16,343:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:40:16,343:INFO:create_model() successfully completed......................................
2024-11-13 17:40:16,511:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:16,511:INFO:Creating metrics dataframe
2024-11-13 17:40:16,524:INFO:Initializing AdaBoost Regressor
2024-11-13 17:40:16,524:INFO:Total runtime is 0.4084861834843953 minutes
2024-11-13 17:40:16,527:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:16,528:INFO:Initializing create_model()
2024-11-13 17:40:16,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:16,528:INFO:Checking exceptions
2024-11-13 17:40:16,528:INFO:Importing libraries
2024-11-13 17:40:16,528:INFO:Copying training dataset
2024-11-13 17:40:16,535:INFO:Defining folds
2024-11-13 17:40:16,536:INFO:Declaring metric variables
2024-11-13 17:40:16,539:INFO:Importing untrained model
2024-11-13 17:40:16,542:INFO:AdaBoost Regressor Imported successfully
2024-11-13 17:40:16,549:INFO:Starting cross validation
2024-11-13 17:40:16,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:17,321:INFO:Calculating mean and std
2024-11-13 17:40:17,331:INFO:Creating metrics dataframe
2024-11-13 17:40:17,337:INFO:Uploading results into container
2024-11-13 17:40:17,337:INFO:Uploading model into container now
2024-11-13 17:40:17,338:INFO:_master_model_container: 15
2024-11-13 17:40:17,338:INFO:_display_container: 2
2024-11-13 17:40:17,339:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 17:40:17,339:INFO:create_model() successfully completed......................................
2024-11-13 17:40:17,534:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:17,534:INFO:Creating metrics dataframe
2024-11-13 17:40:17,547:INFO:Initializing Gradient Boosting Regressor
2024-11-13 17:40:17,547:INFO:Total runtime is 0.42553798755009964 minutes
2024-11-13 17:40:17,550:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:17,551:INFO:Initializing create_model()
2024-11-13 17:40:17,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:17,551:INFO:Checking exceptions
2024-11-13 17:40:17,551:INFO:Importing libraries
2024-11-13 17:40:17,551:INFO:Copying training dataset
2024-11-13 17:40:17,558:INFO:Defining folds
2024-11-13 17:40:17,558:INFO:Declaring metric variables
2024-11-13 17:40:17,561:INFO:Importing untrained model
2024-11-13 17:40:17,565:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 17:40:17,571:INFO:Starting cross validation
2024-11-13 17:40:17,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:18,852:INFO:Calculating mean and std
2024-11-13 17:40:18,856:INFO:Creating metrics dataframe
2024-11-13 17:40:18,863:INFO:Uploading results into container
2024-11-13 17:40:18,863:INFO:Uploading model into container now
2024-11-13 17:40:18,864:INFO:_master_model_container: 16
2024-11-13 17:40:18,864:INFO:_display_container: 2
2024-11-13 17:40:18,865:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 17:40:18,865:INFO:create_model() successfully completed......................................
2024-11-13 17:40:19,011:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:19,011:INFO:Creating metrics dataframe
2024-11-13 17:40:19,023:INFO:Initializing Extreme Gradient Boosting
2024-11-13 17:40:19,023:INFO:Total runtime is 0.4501405239105224 minutes
2024-11-13 17:40:19,027:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:19,027:INFO:Initializing create_model()
2024-11-13 17:40:19,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:19,027:INFO:Checking exceptions
2024-11-13 17:40:19,027:INFO:Importing libraries
2024-11-13 17:40:19,027:INFO:Copying training dataset
2024-11-13 17:40:19,034:INFO:Defining folds
2024-11-13 17:40:19,034:INFO:Declaring metric variables
2024-11-13 17:40:19,038:INFO:Importing untrained model
2024-11-13 17:40:19,042:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 17:40:19,048:INFO:Starting cross validation
2024-11-13 17:40:19,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:19,428:INFO:Calculating mean and std
2024-11-13 17:40:19,432:INFO:Creating metrics dataframe
2024-11-13 17:40:19,439:INFO:Uploading results into container
2024-11-13 17:40:19,439:INFO:Uploading model into container now
2024-11-13 17:40:19,440:INFO:_master_model_container: 17
2024-11-13 17:40:19,440:INFO:_display_container: 2
2024-11-13 17:40:19,441:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 17:40:19,441:INFO:create_model() successfully completed......................................
2024-11-13 17:40:19,589:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:19,589:INFO:Creating metrics dataframe
2024-11-13 17:40:19,603:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 17:40:19,603:INFO:Total runtime is 0.4597971399625142 minutes
2024-11-13 17:40:19,606:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:19,606:INFO:Initializing create_model()
2024-11-13 17:40:19,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:19,607:INFO:Checking exceptions
2024-11-13 17:40:19,607:INFO:Importing libraries
2024-11-13 17:40:19,607:INFO:Copying training dataset
2024-11-13 17:40:19,614:INFO:Defining folds
2024-11-13 17:40:19,614:INFO:Declaring metric variables
2024-11-13 17:40:19,618:INFO:Importing untrained model
2024-11-13 17:40:19,621:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 17:40:19,628:INFO:Starting cross validation
2024-11-13 17:40:19,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:47:09,302:INFO:Calculating mean and std
2024-11-13 17:47:09,308:INFO:Creating metrics dataframe
2024-11-13 17:47:09,315:INFO:Uploading results into container
2024-11-13 17:47:09,315:INFO:Uploading model into container now
2024-11-13 17:47:09,316:INFO:_master_model_container: 18
2024-11-13 17:47:09,316:INFO:_display_container: 2
2024-11-13 17:47:09,317:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:47:09,317:INFO:create_model() successfully completed......................................
2024-11-13 17:47:09,519:INFO:SubProcess create_model() end ==================================
2024-11-13 17:47:09,519:INFO:Creating metrics dataframe
2024-11-13 17:47:09,532:INFO:Initializing CatBoost Regressor
2024-11-13 17:47:09,533:INFO:Total runtime is 7.291960883140564 minutes
2024-11-13 17:47:09,536:INFO:SubProcess create_model() called ==================================
2024-11-13 17:47:09,536:INFO:Initializing create_model()
2024-11-13 17:47:09,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:47:09,536:INFO:Checking exceptions
2024-11-13 17:47:09,537:INFO:Importing libraries
2024-11-13 17:47:09,537:INFO:Copying training dataset
2024-11-13 17:47:09,544:INFO:Defining folds
2024-11-13 17:47:09,545:INFO:Declaring metric variables
2024-11-13 17:47:09,548:INFO:Importing untrained model
2024-11-13 17:47:09,552:INFO:CatBoost Regressor Imported successfully
2024-11-13 17:47:09,558:INFO:Starting cross validation
2024-11-13 17:47:09,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:47:22,416:INFO:Calculating mean and std
2024-11-13 17:47:22,421:INFO:Creating metrics dataframe
2024-11-13 17:47:22,427:INFO:Uploading results into container
2024-11-13 17:47:22,428:INFO:Uploading model into container now
2024-11-13 17:47:22,429:INFO:_master_model_container: 19
2024-11-13 17:47:22,429:INFO:_display_container: 2
2024-11-13 17:47:22,429:INFO:<catboost.core.CatBoostRegressor object at 0x7ff4bc50a5b0>
2024-11-13 17:47:22,429:INFO:create_model() successfully completed......................................
2024-11-13 17:47:22,610:INFO:SubProcess create_model() end ==================================
2024-11-13 17:47:22,611:INFO:Creating metrics dataframe
2024-11-13 17:47:22,625:INFO:Initializing Dummy Regressor
2024-11-13 17:47:22,625:INFO:Total runtime is 7.5101671854654946 minutes
2024-11-13 17:47:22,628:INFO:SubProcess create_model() called ==================================
2024-11-13 17:47:22,629:INFO:Initializing create_model()
2024-11-13 17:47:22,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:47:22,629:INFO:Checking exceptions
2024-11-13 17:47:22,629:INFO:Importing libraries
2024-11-13 17:47:22,629:INFO:Copying training dataset
2024-11-13 17:47:22,637:INFO:Defining folds
2024-11-13 17:47:22,637:INFO:Declaring metric variables
2024-11-13 17:47:22,641:INFO:Importing untrained model
2024-11-13 17:47:22,644:INFO:Dummy Regressor Imported successfully
2024-11-13 17:47:22,651:INFO:Starting cross validation
2024-11-13 17:47:22,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:47:25,596:INFO:Calculating mean and std
2024-11-13 17:47:25,601:INFO:Creating metrics dataframe
2024-11-13 17:47:25,608:INFO:Uploading results into container
2024-11-13 17:47:25,609:INFO:Uploading model into container now
2024-11-13 17:47:25,610:INFO:_master_model_container: 20
2024-11-13 17:47:25,610:INFO:_display_container: 2
2024-11-13 17:47:25,610:INFO:DummyRegressor()
2024-11-13 17:47:25,610:INFO:create_model() successfully completed......................................
2024-11-13 17:47:25,780:INFO:SubProcess create_model() end ==================================
2024-11-13 17:47:25,780:INFO:Creating metrics dataframe
2024-11-13 17:47:25,804:INFO:Initializing create_model()
2024-11-13 17:47:25,805:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:47:25,805:INFO:Checking exceptions
2024-11-13 17:47:25,807:INFO:Importing libraries
2024-11-13 17:47:25,807:INFO:Copying training dataset
2024-11-13 17:47:25,814:INFO:Defining folds
2024-11-13 17:47:25,814:INFO:Declaring metric variables
2024-11-13 17:47:25,814:INFO:Importing untrained model
2024-11-13 17:47:25,814:INFO:Declaring custom model
2024-11-13 17:47:25,815:INFO:Extra Trees Regressor Imported successfully
2024-11-13 17:47:25,816:INFO:Cross validation set to False
2024-11-13 17:47:25,816:INFO:Fitting Model
2024-11-13 17:47:26,055:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:47:26,055:INFO:create_model() successfully completed......................................
2024-11-13 17:47:26,279:INFO:_master_model_container: 20
2024-11-13 17:47:26,279:INFO:_display_container: 2
2024-11-13 17:47:26,280:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:47:26,280:INFO:compare_models() successfully completed......................................
2024-11-13 17:47:46,349:INFO:Initializing plot_model()
2024-11-13 17:47:46,349:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, system=True)
2024-11-13 17:47:46,349:INFO:Checking exceptions
2024-11-13 17:47:46,417:INFO:Preloading libraries
2024-11-13 17:47:46,613:INFO:Copying training dataset
2024-11-13 17:47:46,613:INFO:Plot type: residuals
2024-11-13 17:47:46,692:INFO:Fitting Model
2024-11-13 17:47:46,692:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-13 17:47:46,868:INFO:Scoring test/hold-out set
2024-11-13 17:47:47,619:INFO:Visual Rendered Successfully
2024-11-13 17:47:47,839:INFO:plot_model() successfully completed......................................
2024-11-13 17:49:10,637:INFO:Initializing plot_model()
2024-11-13 17:49:10,638:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, system=True)
2024-11-13 17:49:10,638:INFO:Checking exceptions
2024-11-13 17:49:10,702:INFO:Preloading libraries
2024-11-13 17:49:10,875:INFO:Copying training dataset
2024-11-13 17:49:10,875:INFO:Plot type: error
2024-11-13 17:49:10,929:INFO:Fitting Model
2024-11-13 17:49:10,929:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-13 17:49:10,929:INFO:Scoring test/hold-out set
2024-11-13 17:49:11,389:INFO:Visual Rendered Successfully
2024-11-13 17:49:11,569:INFO:plot_model() successfully completed......................................
2024-11-13 17:50:24,994:INFO:Initializing plot_model()
2024-11-13 17:50:24,995:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, system=True)
2024-11-13 17:50:24,995:INFO:Checking exceptions
2024-11-13 17:50:25,048:INFO:Preloading libraries
2024-11-13 17:50:25,223:INFO:Copying training dataset
2024-11-13 17:50:25,223:INFO:Plot type: feature
2024-11-13 17:50:25,224:WARNING:No coef_ found. Trying feature_importances_
2024-11-13 17:50:25,399:INFO:Visual Rendered Successfully
2024-11-13 17:50:25,570:INFO:plot_model() successfully completed......................................
2024-11-13 17:59:59,572:INFO:PyCaret RegressionExperiment
2024-11-13 17:59:59,572:INFO:Logging name: reg-default-name
2024-11-13 17:59:59,572:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:59:59,572:INFO:version 3.2.0
2024-11-13 17:59:59,572:INFO:Initializing setup()
2024-11-13 17:59:59,572:INFO:self.USI: 4bf0
2024-11-13 17:59:59,572:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:59:59,573:INFO:Checking environment
2024-11-13 17:59:59,573:INFO:python_version: 3.8.13
2024-11-13 17:59:59,573:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:59:59,573:INFO:machine: x86_64
2024-11-13 17:59:59,573:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:59:59,573:INFO:Memory: svmem(total=270355722240, available=218218041344, percent=19.3, used=50056511488, free=56192413696, active=11650326528, inactive=142257721344, buffers=8888320, cached=164097908736, shared=187363328, slab=25014046720)
2024-11-13 17:59:59,576:INFO:Physical Core: 28
2024-11-13 17:59:59,576:INFO:Logical Core: 56
2024-11-13 17:59:59,576:INFO:Checking libraries
2024-11-13 17:59:59,576:INFO:System:
2024-11-13 17:59:59,576:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:59:59,576:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:59:59,576:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:59:59,576:INFO:PyCaret required dependencies:
2024-11-13 17:59:59,576:INFO:                 pip: 22.2.2
2024-11-13 17:59:59,576:INFO:          setuptools: 63.4.2
2024-11-13 17:59:59,576:INFO:             pycaret: 3.2.0
2024-11-13 17:59:59,576:INFO:             IPython: 8.12.2
2024-11-13 17:59:59,576:INFO:          ipywidgets: 7.7.1
2024-11-13 17:59:59,576:INFO:                tqdm: 4.64.1
2024-11-13 17:59:59,576:INFO:               numpy: 1.23.5
2024-11-13 17:59:59,576:INFO:              pandas: 1.5.3
2024-11-13 17:59:59,576:INFO:              jinja2: 3.1.2
2024-11-13 17:59:59,576:INFO:               scipy: 1.10.1
2024-11-13 17:59:59,576:INFO:              joblib: 1.3.0
2024-11-13 17:59:59,576:INFO:             sklearn: 1.1.2
2024-11-13 17:59:59,576:INFO:                pyod: 2.0.2
2024-11-13 17:59:59,576:INFO:            imblearn: 0.12.4
2024-11-13 17:59:59,576:INFO:   category_encoders: 2.6.4
2024-11-13 17:59:59,577:INFO:            lightgbm: 4.5.0
2024-11-13 17:59:59,577:INFO:               numba: 0.57.1
2024-11-13 17:59:59,577:INFO:            requests: 2.28.1
2024-11-13 17:59:59,577:INFO:          matplotlib: 3.5.1
2024-11-13 17:59:59,577:INFO:          scikitplot: 0.3.7
2024-11-13 17:59:59,577:INFO:         yellowbrick: 1.5
2024-11-13 17:59:59,577:INFO:              plotly: 5.24.1
2024-11-13 17:59:59,577:INFO:    plotly-resampler: Not installed
2024-11-13 17:59:59,577:INFO:             kaleido: 0.2.1
2024-11-13 17:59:59,577:INFO:           schemdraw: 0.15
2024-11-13 17:59:59,577:INFO:         statsmodels: 0.13.2
2024-11-13 17:59:59,577:INFO:              sktime: 0.21.1
2024-11-13 17:59:59,577:INFO:               tbats: 1.1.3
2024-11-13 17:59:59,577:INFO:            pmdarima: 2.0.4
2024-11-13 17:59:59,577:INFO:              psutil: 5.9.1
2024-11-13 17:59:59,577:INFO:          markupsafe: 2.1.1
2024-11-13 17:59:59,577:INFO:             pickle5: Not installed
2024-11-13 17:59:59,577:INFO:         cloudpickle: 2.1.0
2024-11-13 17:59:59,577:INFO:         deprecation: 2.1.0
2024-11-13 17:59:59,577:INFO:              xxhash: 3.5.0
2024-11-13 17:59:59,577:INFO:           wurlitzer: 3.1.1
2024-11-13 17:59:59,577:INFO:PyCaret optional dependencies:
2024-11-13 17:59:59,577:INFO:                shap: 0.44.1
2024-11-13 17:59:59,577:INFO:           interpret: 0.6.5
2024-11-13 17:59:59,577:INFO:                umap: 0.5.7
2024-11-13 17:59:59,577:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:59:59,577:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:59:59,577:INFO:             autoviz: Not installed
2024-11-13 17:59:59,577:INFO:           fairlearn: 0.7.0
2024-11-13 17:59:59,577:INFO:          deepchecks: Not installed
2024-11-13 17:59:59,577:INFO:             xgboost: 2.1.1
2024-11-13 17:59:59,577:INFO:            catboost: 1.2.7
2024-11-13 17:59:59,578:INFO:              kmodes: 0.12.2
2024-11-13 17:59:59,578:INFO:             mlxtend: 0.23.1
2024-11-13 17:59:59,578:INFO:       statsforecast: 1.5.0
2024-11-13 17:59:59,578:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:59:59,578:INFO:                 ray: 2.10.0
2024-11-13 17:59:59,578:INFO:            hyperopt: 0.2.7
2024-11-13 17:59:59,578:INFO:              optuna: 4.1.0
2024-11-13 17:59:59,578:INFO:               skopt: 0.10.2
2024-11-13 17:59:59,578:INFO:              mlflow: 1.30.1
2024-11-13 17:59:59,578:INFO:              gradio: 3.50.2
2024-11-13 17:59:59,578:INFO:             fastapi: 0.115.5
2024-11-13 17:59:59,578:INFO:             uvicorn: 0.32.0
2024-11-13 17:59:59,578:INFO:              m2cgen: 0.10.0
2024-11-13 17:59:59,578:INFO:           evidently: 0.2.8
2024-11-13 17:59:59,578:INFO:               fugue: 0.8.6
2024-11-13 17:59:59,578:INFO:           streamlit: Not installed
2024-11-13 17:59:59,578:INFO:             prophet: Not installed
2024-11-13 17:59:59,578:INFO:None
2024-11-13 17:59:59,578:INFO:Set up data.
2024-11-13 17:59:59,589:INFO:Set up folding strategy.
2024-11-13 17:59:59,589:INFO:Set up train/test split.
2024-11-13 17:59:59,594:INFO:Set up index.
2024-11-13 17:59:59,595:INFO:Assigning column types.
2024-11-13 17:59:59,600:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 17:59:59,600:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,605:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,610:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,708:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,709:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:59:59,711:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:59:59,712:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,716:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,719:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,768:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,805:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,806:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:59:59,808:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:59:59,809:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 17:59:59,812:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,816:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,864:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,903:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:59:59,905:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:59:59,909:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,913:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,000:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,002:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,003:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:00:00,011:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,098:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,100:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,108:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,156:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,194:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,196:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,197:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:00:00,253:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,290:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,292:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,387:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,388:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,390:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,391:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:00:00,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,485:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,488:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,583:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,585:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,585:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:00:00,679:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,681:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,776:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,778:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,779:INFO:Preparing preprocessing pipeline...
2024-11-13 18:00:00,779:INFO:Set up simple imputation.
2024-11-13 18:00:00,796:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:00:00,800:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['USA_WSPD', 'MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:00:00,800:INFO:Creating final display dataframe.
2024-11-13 18:00:00,854:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 8)
4        Transformed data shape        (31316, 8)
5   Transformed train set shape        (21921, 8)
6    Transformed test set shape         (9395, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4bf0
2024-11-13 18:00:00,962:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,964:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:01,058:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:01,060:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:01,061:INFO:setup() successfully completed in 1.49s...............
2024-11-13 18:02:40,355:INFO:Initializing compare_models()
2024-11-13 18:02:40,356:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:02:40,356:INFO:Checking exceptions
2024-11-13 18:02:40,363:INFO:Preparing display monitor
2024-11-13 18:02:40,407:INFO:Initializing Linear Regression
2024-11-13 18:02:40,407:INFO:Total runtime is 2.4040540059407553e-06 minutes
2024-11-13 18:02:40,410:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:40,411:INFO:Initializing create_model()
2024-11-13 18:02:40,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:40,411:INFO:Checking exceptions
2024-11-13 18:02:40,411:INFO:Importing libraries
2024-11-13 18:02:40,411:INFO:Copying training dataset
2024-11-13 18:02:40,418:INFO:Defining folds
2024-11-13 18:02:40,418:INFO:Declaring metric variables
2024-11-13 18:02:40,421:INFO:Importing untrained model
2024-11-13 18:02:40,425:INFO:Linear Regression Imported successfully
2024-11-13 18:02:40,433:INFO:Starting cross validation
2024-11-13 18:02:40,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:44,421:INFO:Calculating mean and std
2024-11-13 18:02:44,426:INFO:Creating metrics dataframe
2024-11-13 18:02:44,433:INFO:Uploading results into container
2024-11-13 18:02:44,434:INFO:Uploading model into container now
2024-11-13 18:02:44,434:INFO:_master_model_container: 1
2024-11-13 18:02:44,435:INFO:_display_container: 2
2024-11-13 18:02:44,435:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:02:44,435:INFO:create_model() successfully completed......................................
2024-11-13 18:02:44,690:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:44,691:INFO:Creating metrics dataframe
2024-11-13 18:02:44,701:INFO:Initializing Lasso Regression
2024-11-13 18:02:44,701:INFO:Total runtime is 0.07156848112742106 minutes
2024-11-13 18:02:44,705:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:44,705:INFO:Initializing create_model()
2024-11-13 18:02:44,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:44,705:INFO:Checking exceptions
2024-11-13 18:02:44,705:INFO:Importing libraries
2024-11-13 18:02:44,705:INFO:Copying training dataset
2024-11-13 18:02:44,714:INFO:Defining folds
2024-11-13 18:02:44,714:INFO:Declaring metric variables
2024-11-13 18:02:44,718:INFO:Importing untrained model
2024-11-13 18:02:44,721:INFO:Lasso Regression Imported successfully
2024-11-13 18:02:44,728:INFO:Starting cross validation
2024-11-13 18:02:44,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:47,610:INFO:Calculating mean and std
2024-11-13 18:02:47,613:INFO:Creating metrics dataframe
2024-11-13 18:02:47,619:INFO:Uploading results into container
2024-11-13 18:02:47,620:INFO:Uploading model into container now
2024-11-13 18:02:47,620:INFO:_master_model_container: 2
2024-11-13 18:02:47,620:INFO:_display_container: 2
2024-11-13 18:02:47,621:INFO:Lasso(random_state=123)
2024-11-13 18:02:47,621:INFO:create_model() successfully completed......................................
2024-11-13 18:02:47,797:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:47,797:INFO:Creating metrics dataframe
2024-11-13 18:02:47,807:INFO:Initializing Ridge Regression
2024-11-13 18:02:47,807:INFO:Total runtime is 0.1233436147371928 minutes
2024-11-13 18:02:47,811:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:47,811:INFO:Initializing create_model()
2024-11-13 18:02:47,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:47,811:INFO:Checking exceptions
2024-11-13 18:02:47,811:INFO:Importing libraries
2024-11-13 18:02:47,811:INFO:Copying training dataset
2024-11-13 18:02:47,818:INFO:Defining folds
2024-11-13 18:02:47,818:INFO:Declaring metric variables
2024-11-13 18:02:47,822:INFO:Importing untrained model
2024-11-13 18:02:47,825:INFO:Ridge Regression Imported successfully
2024-11-13 18:02:47,832:INFO:Starting cross validation
2024-11-13 18:02:47,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:50,608:INFO:Calculating mean and std
2024-11-13 18:02:50,612:INFO:Creating metrics dataframe
2024-11-13 18:02:50,619:INFO:Uploading results into container
2024-11-13 18:02:50,620:INFO:Uploading model into container now
2024-11-13 18:02:50,621:INFO:_master_model_container: 3
2024-11-13 18:02:50,621:INFO:_display_container: 2
2024-11-13 18:02:50,621:INFO:Ridge(random_state=123)
2024-11-13 18:02:50,621:INFO:create_model() successfully completed......................................
2024-11-13 18:02:50,796:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:50,796:INFO:Creating metrics dataframe
2024-11-13 18:02:50,807:INFO:Initializing Elastic Net
2024-11-13 18:02:50,807:INFO:Total runtime is 0.17333312034606935 minutes
2024-11-13 18:02:50,810:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:50,810:INFO:Initializing create_model()
2024-11-13 18:02:50,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:50,811:INFO:Checking exceptions
2024-11-13 18:02:50,811:INFO:Importing libraries
2024-11-13 18:02:50,811:INFO:Copying training dataset
2024-11-13 18:02:50,817:INFO:Defining folds
2024-11-13 18:02:50,818:INFO:Declaring metric variables
2024-11-13 18:02:50,821:INFO:Importing untrained model
2024-11-13 18:02:50,824:INFO:Elastic Net Imported successfully
2024-11-13 18:02:50,831:INFO:Starting cross validation
2024-11-13 18:02:50,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:53,715:INFO:Calculating mean and std
2024-11-13 18:02:53,719:INFO:Creating metrics dataframe
2024-11-13 18:02:53,725:INFO:Uploading results into container
2024-11-13 18:02:53,725:INFO:Uploading model into container now
2024-11-13 18:02:53,726:INFO:_master_model_container: 4
2024-11-13 18:02:53,726:INFO:_display_container: 2
2024-11-13 18:02:53,726:INFO:ElasticNet(random_state=123)
2024-11-13 18:02:53,726:INFO:create_model() successfully completed......................................
2024-11-13 18:02:53,912:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:53,912:INFO:Creating metrics dataframe
2024-11-13 18:02:53,925:INFO:Initializing Least Angle Regression
2024-11-13 18:02:53,925:INFO:Total runtime is 0.22530497709910074 minutes
2024-11-13 18:02:53,928:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:53,929:INFO:Initializing create_model()
2024-11-13 18:02:53,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:53,929:INFO:Checking exceptions
2024-11-13 18:02:53,929:INFO:Importing libraries
2024-11-13 18:02:53,929:INFO:Copying training dataset
2024-11-13 18:02:53,936:INFO:Defining folds
2024-11-13 18:02:53,937:INFO:Declaring metric variables
2024-11-13 18:02:53,940:INFO:Importing untrained model
2024-11-13 18:02:53,944:INFO:Least Angle Regression Imported successfully
2024-11-13 18:02:53,950:INFO:Starting cross validation
2024-11-13 18:02:53,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:56,615:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,624:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,628:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.407e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:02:56,650:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,663:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,694:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,720:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,721:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,728:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,761:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,764:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.478e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:02:56,768:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,772:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.949e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:02:56,772:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.974e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:02:56,789:INFO:Calculating mean and std
2024-11-13 18:02:56,793:INFO:Creating metrics dataframe
2024-11-13 18:02:56,800:INFO:Uploading results into container
2024-11-13 18:02:56,800:INFO:Uploading model into container now
2024-11-13 18:02:56,801:INFO:_master_model_container: 5
2024-11-13 18:02:56,801:INFO:_display_container: 2
2024-11-13 18:02:56,802:INFO:Lars(random_state=123)
2024-11-13 18:02:56,802:INFO:create_model() successfully completed......................................
2024-11-13 18:02:57,003:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:57,003:INFO:Creating metrics dataframe
2024-11-13 18:02:57,015:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:02:57,015:INFO:Total runtime is 0.27679969867070514 minutes
2024-11-13 18:02:57,018:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:57,018:INFO:Initializing create_model()
2024-11-13 18:02:57,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:57,019:INFO:Checking exceptions
2024-11-13 18:02:57,019:INFO:Importing libraries
2024-11-13 18:02:57,019:INFO:Copying training dataset
2024-11-13 18:02:57,025:INFO:Defining folds
2024-11-13 18:02:57,026:INFO:Declaring metric variables
2024-11-13 18:02:57,029:INFO:Importing untrained model
2024-11-13 18:02:57,033:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:02:57,039:INFO:Starting cross validation
2024-11-13 18:02:57,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:57,129:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:57,135:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:57,141:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:57,146:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,555:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,587:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,726:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,743:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,757:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,801:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,813:INFO:Calculating mean and std
2024-11-13 18:02:59,817:INFO:Creating metrics dataframe
2024-11-13 18:02:59,823:INFO:Uploading results into container
2024-11-13 18:02:59,824:INFO:Uploading model into container now
2024-11-13 18:02:59,825:INFO:_master_model_container: 6
2024-11-13 18:02:59,825:INFO:_display_container: 2
2024-11-13 18:02:59,825:INFO:LassoLars(random_state=123)
2024-11-13 18:02:59,825:INFO:create_model() successfully completed......................................
2024-11-13 18:02:59,980:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:59,981:INFO:Creating metrics dataframe
2024-11-13 18:02:59,991:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:02:59,992:INFO:Total runtime is 0.326414414246877 minutes
2024-11-13 18:02:59,995:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:59,995:INFO:Initializing create_model()
2024-11-13 18:02:59,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:59,995:INFO:Checking exceptions
2024-11-13 18:02:59,996:INFO:Importing libraries
2024-11-13 18:02:59,996:INFO:Copying training dataset
2024-11-13 18:03:00,002:INFO:Defining folds
2024-11-13 18:03:00,003:INFO:Declaring metric variables
2024-11-13 18:03:00,006:INFO:Importing untrained model
2024-11-13 18:03:00,010:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:03:00,016:INFO:Starting cross validation
2024-11-13 18:03:00,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:00,048:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,053:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,060:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,066:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,074:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,082:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,082:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,092:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,096:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,116:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,133:INFO:Calculating mean and std
2024-11-13 18:03:00,135:INFO:Creating metrics dataframe
2024-11-13 18:03:00,141:INFO:Uploading results into container
2024-11-13 18:03:00,142:INFO:Uploading model into container now
2024-11-13 18:03:00,142:INFO:_master_model_container: 7
2024-11-13 18:03:00,142:INFO:_display_container: 2
2024-11-13 18:03:00,143:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:03:00,143:INFO:create_model() successfully completed......................................
2024-11-13 18:03:00,294:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:00,295:INFO:Creating metrics dataframe
2024-11-13 18:03:00,306:INFO:Initializing Bayesian Ridge
2024-11-13 18:03:00,306:INFO:Total runtime is 0.331656547387441 minutes
2024-11-13 18:03:00,309:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:00,310:INFO:Initializing create_model()
2024-11-13 18:03:00,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:00,310:INFO:Checking exceptions
2024-11-13 18:03:00,310:INFO:Importing libraries
2024-11-13 18:03:00,310:INFO:Copying training dataset
2024-11-13 18:03:00,316:INFO:Defining folds
2024-11-13 18:03:00,317:INFO:Declaring metric variables
2024-11-13 18:03:00,320:INFO:Importing untrained model
2024-11-13 18:03:00,323:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:03:00,329:INFO:Starting cross validation
2024-11-13 18:03:00,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:00,476:INFO:Calculating mean and std
2024-11-13 18:03:00,480:INFO:Creating metrics dataframe
2024-11-13 18:03:00,487:INFO:Uploading results into container
2024-11-13 18:03:00,488:INFO:Uploading model into container now
2024-11-13 18:03:00,488:INFO:_master_model_container: 8
2024-11-13 18:03:00,488:INFO:_display_container: 2
2024-11-13 18:03:00,489:INFO:BayesianRidge()
2024-11-13 18:03:00,489:INFO:create_model() successfully completed......................................
2024-11-13 18:03:00,654:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:00,654:INFO:Creating metrics dataframe
2024-11-13 18:03:00,665:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:03:00,665:INFO:Total runtime is 0.33764466842015584 minutes
2024-11-13 18:03:00,669:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:00,669:INFO:Initializing create_model()
2024-11-13 18:03:00,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:00,670:INFO:Checking exceptions
2024-11-13 18:03:00,670:INFO:Importing libraries
2024-11-13 18:03:00,670:INFO:Copying training dataset
2024-11-13 18:03:00,676:INFO:Defining folds
2024-11-13 18:03:00,676:INFO:Declaring metric variables
2024-11-13 18:03:00,680:INFO:Importing untrained model
2024-11-13 18:03:00,683:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:03:00,689:INFO:Starting cross validation
2024-11-13 18:03:00,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:00,801:INFO:Calculating mean and std
2024-11-13 18:03:00,805:INFO:Creating metrics dataframe
2024-11-13 18:03:00,811:INFO:Uploading results into container
2024-11-13 18:03:00,812:INFO:Uploading model into container now
2024-11-13 18:03:00,812:INFO:_master_model_container: 9
2024-11-13 18:03:00,812:INFO:_display_container: 2
2024-11-13 18:03:00,813:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:03:00,813:INFO:create_model() successfully completed......................................
2024-11-13 18:03:00,978:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:00,978:INFO:Creating metrics dataframe
2024-11-13 18:03:00,990:INFO:Initializing Huber Regressor
2024-11-13 18:03:00,991:INFO:Total runtime is 0.34306368430455525 minutes
2024-11-13 18:03:00,994:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:00,994:INFO:Initializing create_model()
2024-11-13 18:03:00,994:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:00,994:INFO:Checking exceptions
2024-11-13 18:03:00,994:INFO:Importing libraries
2024-11-13 18:03:00,995:INFO:Copying training dataset
2024-11-13 18:03:01,003:INFO:Defining folds
2024-11-13 18:03:01,003:INFO:Declaring metric variables
2024-11-13 18:03:01,006:INFO:Importing untrained model
2024-11-13 18:03:01,009:INFO:Huber Regressor Imported successfully
2024-11-13 18:03:01,016:INFO:Starting cross validation
2024-11-13 18:03:01,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:01,288:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,298:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,310:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,323:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,336:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,341:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,367:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,367:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,371:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,384:INFO:Calculating mean and std
2024-11-13 18:03:01,387:INFO:Creating metrics dataframe
2024-11-13 18:03:01,394:INFO:Uploading results into container
2024-11-13 18:03:01,395:INFO:Uploading model into container now
2024-11-13 18:03:01,395:INFO:_master_model_container: 10
2024-11-13 18:03:01,396:INFO:_display_container: 2
2024-11-13 18:03:01,396:INFO:HuberRegressor()
2024-11-13 18:03:01,396:INFO:create_model() successfully completed......................................
2024-11-13 18:03:01,544:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:01,544:INFO:Creating metrics dataframe
2024-11-13 18:03:01,556:INFO:Initializing K Neighbors Regressor
2024-11-13 18:03:01,556:INFO:Total runtime is 0.35249264240264894 minutes
2024-11-13 18:03:01,560:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:01,560:INFO:Initializing create_model()
2024-11-13 18:03:01,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:01,560:INFO:Checking exceptions
2024-11-13 18:03:01,560:INFO:Importing libraries
2024-11-13 18:03:01,560:INFO:Copying training dataset
2024-11-13 18:03:01,567:INFO:Defining folds
2024-11-13 18:03:01,567:INFO:Declaring metric variables
2024-11-13 18:03:01,571:INFO:Importing untrained model
2024-11-13 18:03:01,574:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:03:01,580:INFO:Starting cross validation
2024-11-13 18:03:01,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:01,802:INFO:Calculating mean and std
2024-11-13 18:03:01,806:INFO:Creating metrics dataframe
2024-11-13 18:03:01,812:INFO:Uploading results into container
2024-11-13 18:03:01,813:INFO:Uploading model into container now
2024-11-13 18:03:01,814:INFO:_master_model_container: 11
2024-11-13 18:03:01,814:INFO:_display_container: 2
2024-11-13 18:03:01,815:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:03:01,815:INFO:create_model() successfully completed......................................
2024-11-13 18:03:02,001:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:02,001:INFO:Creating metrics dataframe
2024-11-13 18:03:02,013:INFO:Initializing Decision Tree Regressor
2024-11-13 18:03:02,013:INFO:Total runtime is 0.3601103901863098 minutes
2024-11-13 18:03:02,017:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:02,017:INFO:Initializing create_model()
2024-11-13 18:03:02,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:02,017:INFO:Checking exceptions
2024-11-13 18:03:02,017:INFO:Importing libraries
2024-11-13 18:03:02,017:INFO:Copying training dataset
2024-11-13 18:03:02,024:INFO:Defining folds
2024-11-13 18:03:02,024:INFO:Declaring metric variables
2024-11-13 18:03:02,028:INFO:Importing untrained model
2024-11-13 18:03:02,031:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:03:02,038:INFO:Starting cross validation
2024-11-13 18:03:02,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:02,170:INFO:Calculating mean and std
2024-11-13 18:03:02,173:INFO:Creating metrics dataframe
2024-11-13 18:03:02,180:INFO:Uploading results into container
2024-11-13 18:03:02,180:INFO:Uploading model into container now
2024-11-13 18:03:02,181:INFO:_master_model_container: 12
2024-11-13 18:03:02,181:INFO:_display_container: 2
2024-11-13 18:03:02,182:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:03:02,182:INFO:create_model() successfully completed......................................
2024-11-13 18:03:02,355:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:02,355:INFO:Creating metrics dataframe
2024-11-13 18:03:02,367:INFO:Initializing Random Forest Regressor
2024-11-13 18:03:02,367:INFO:Total runtime is 0.3660059054692586 minutes
2024-11-13 18:03:02,370:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:02,371:INFO:Initializing create_model()
2024-11-13 18:03:02,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:02,371:INFO:Checking exceptions
2024-11-13 18:03:02,371:INFO:Importing libraries
2024-11-13 18:03:02,371:INFO:Copying training dataset
2024-11-13 18:03:02,378:INFO:Defining folds
2024-11-13 18:03:02,378:INFO:Declaring metric variables
2024-11-13 18:03:02,381:INFO:Importing untrained model
2024-11-13 18:03:02,385:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:03:02,391:INFO:Starting cross validation
2024-11-13 18:03:02,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:03,345:INFO:Calculating mean and std
2024-11-13 18:03:03,350:INFO:Creating metrics dataframe
2024-11-13 18:03:03,355:INFO:Uploading results into container
2024-11-13 18:03:03,356:INFO:Uploading model into container now
2024-11-13 18:03:03,357:INFO:_master_model_container: 13
2024-11-13 18:03:03,357:INFO:_display_container: 2
2024-11-13 18:03:03,357:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:03:03,358:INFO:create_model() successfully completed......................................
2024-11-13 18:03:03,522:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:03,522:INFO:Creating metrics dataframe
2024-11-13 18:03:03,535:INFO:Initializing Extra Trees Regressor
2024-11-13 18:03:03,535:INFO:Total runtime is 0.38546599149703975 minutes
2024-11-13 18:03:03,538:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:03,538:INFO:Initializing create_model()
2024-11-13 18:03:03,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:03,539:INFO:Checking exceptions
2024-11-13 18:03:03,539:INFO:Importing libraries
2024-11-13 18:03:03,539:INFO:Copying training dataset
2024-11-13 18:03:03,547:INFO:Defining folds
2024-11-13 18:03:03,547:INFO:Declaring metric variables
2024-11-13 18:03:03,550:INFO:Importing untrained model
2024-11-13 18:03:03,554:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:03:03,561:INFO:Starting cross validation
2024-11-13 18:03:03,562:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:04,088:INFO:Calculating mean and std
2024-11-13 18:03:04,091:INFO:Creating metrics dataframe
2024-11-13 18:03:04,099:INFO:Uploading results into container
2024-11-13 18:03:04,099:INFO:Uploading model into container now
2024-11-13 18:03:04,100:INFO:_master_model_container: 14
2024-11-13 18:03:04,100:INFO:_display_container: 2
2024-11-13 18:03:04,100:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:03:04,100:INFO:create_model() successfully completed......................................
2024-11-13 18:03:04,250:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:04,250:INFO:Creating metrics dataframe
2024-11-13 18:03:04,263:INFO:Initializing AdaBoost Regressor
2024-11-13 18:03:04,263:INFO:Total runtime is 0.39761166969935097 minutes
2024-11-13 18:03:04,267:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:04,267:INFO:Initializing create_model()
2024-11-13 18:03:04,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:04,267:INFO:Checking exceptions
2024-11-13 18:03:04,267:INFO:Importing libraries
2024-11-13 18:03:04,267:INFO:Copying training dataset
2024-11-13 18:03:04,274:INFO:Defining folds
2024-11-13 18:03:04,274:INFO:Declaring metric variables
2024-11-13 18:03:04,278:INFO:Importing untrained model
2024-11-13 18:03:04,281:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:03:04,293:INFO:Starting cross validation
2024-11-13 18:03:04,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:05,029:INFO:Calculating mean and std
2024-11-13 18:03:05,034:INFO:Creating metrics dataframe
2024-11-13 18:03:05,041:INFO:Uploading results into container
2024-11-13 18:03:05,041:INFO:Uploading model into container now
2024-11-13 18:03:05,042:INFO:_master_model_container: 15
2024-11-13 18:03:05,042:INFO:_display_container: 2
2024-11-13 18:03:05,043:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:03:05,043:INFO:create_model() successfully completed......................................
2024-11-13 18:03:05,225:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:05,226:INFO:Creating metrics dataframe
2024-11-13 18:03:05,239:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:03:05,239:INFO:Total runtime is 0.41386729081471757 minutes
2024-11-13 18:03:05,242:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:05,242:INFO:Initializing create_model()
2024-11-13 18:03:05,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:05,243:INFO:Checking exceptions
2024-11-13 18:03:05,243:INFO:Importing libraries
2024-11-13 18:03:05,243:INFO:Copying training dataset
2024-11-13 18:03:05,250:INFO:Defining folds
2024-11-13 18:03:05,250:INFO:Declaring metric variables
2024-11-13 18:03:05,253:INFO:Importing untrained model
2024-11-13 18:03:05,257:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:03:05,263:INFO:Starting cross validation
2024-11-13 18:03:05,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:07,074:INFO:Calculating mean and std
2024-11-13 18:03:07,078:INFO:Creating metrics dataframe
2024-11-13 18:03:07,084:INFO:Uploading results into container
2024-11-13 18:03:07,085:INFO:Uploading model into container now
2024-11-13 18:03:07,085:INFO:_master_model_container: 16
2024-11-13 18:03:07,085:INFO:_display_container: 2
2024-11-13 18:03:07,086:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:03:07,086:INFO:create_model() successfully completed......................................
2024-11-13 18:03:07,309:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:07,310:INFO:Creating metrics dataframe
2024-11-13 18:03:07,324:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:03:07,324:INFO:Total runtime is 0.4486217419306437 minutes
2024-11-13 18:03:07,327:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:07,328:INFO:Initializing create_model()
2024-11-13 18:03:07,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:07,328:INFO:Checking exceptions
2024-11-13 18:03:07,328:INFO:Importing libraries
2024-11-13 18:03:07,328:INFO:Copying training dataset
2024-11-13 18:03:07,336:INFO:Defining folds
2024-11-13 18:03:07,336:INFO:Declaring metric variables
2024-11-13 18:03:07,339:INFO:Importing untrained model
2024-11-13 18:03:07,343:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:03:07,350:INFO:Starting cross validation
2024-11-13 18:03:07,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:07,737:INFO:Calculating mean and std
2024-11-13 18:03:07,741:INFO:Creating metrics dataframe
2024-11-13 18:03:07,748:INFO:Uploading results into container
2024-11-13 18:03:07,748:INFO:Uploading model into container now
2024-11-13 18:03:07,749:INFO:_master_model_container: 17
2024-11-13 18:03:07,749:INFO:_display_container: 2
2024-11-13 18:03:07,750:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:03:07,750:INFO:create_model() successfully completed......................................
2024-11-13 18:03:07,914:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:07,914:INFO:Creating metrics dataframe
2024-11-13 18:03:07,928:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:03:07,928:INFO:Total runtime is 0.4586907863616943 minutes
2024-11-13 18:03:07,932:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:07,932:INFO:Initializing create_model()
2024-11-13 18:03:07,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:07,932:INFO:Checking exceptions
2024-11-13 18:03:07,932:INFO:Importing libraries
2024-11-13 18:03:07,933:INFO:Copying training dataset
2024-11-13 18:03:07,939:INFO:Defining folds
2024-11-13 18:03:07,940:INFO:Declaring metric variables
2024-11-13 18:03:07,943:INFO:Importing untrained model
2024-11-13 18:03:07,947:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:03:07,953:INFO:Starting cross validation
2024-11-13 18:03:07,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:06:55,577:INFO:PyCaret RegressionExperiment
2024-11-13 18:06:55,577:INFO:Logging name: reg-default-name
2024-11-13 18:06:55,577:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:06:55,577:INFO:version 3.2.0
2024-11-13 18:06:55,578:INFO:Initializing setup()
2024-11-13 18:06:55,578:INFO:self.USI: 54d3
2024-11-13 18:06:55,578:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:06:55,578:INFO:Checking environment
2024-11-13 18:06:55,578:INFO:python_version: 3.8.13
2024-11-13 18:06:55,578:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:06:55,578:INFO:machine: x86_64
2024-11-13 18:06:55,578:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:06:55,578:INFO:Memory: svmem(total=270355722240, available=218247380992, percent=19.3, used=50027212800, free=56461357056, active=11654262784, inactive=141947662336, buffers=9957376, cached=163857195008, shared=187338752, slab=25020047360)
2024-11-13 18:06:55,581:INFO:Physical Core: 28
2024-11-13 18:06:55,581:INFO:Logical Core: 56
2024-11-13 18:06:55,581:INFO:Checking libraries
2024-11-13 18:06:55,581:INFO:System:
2024-11-13 18:06:55,581:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:06:55,581:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:06:55,581:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:06:55,581:INFO:PyCaret required dependencies:
2024-11-13 18:06:55,581:INFO:                 pip: 22.2.2
2024-11-13 18:06:55,581:INFO:          setuptools: 63.4.2
2024-11-13 18:06:55,581:INFO:             pycaret: 3.2.0
2024-11-13 18:06:55,581:INFO:             IPython: 8.12.2
2024-11-13 18:06:55,581:INFO:          ipywidgets: 7.7.1
2024-11-13 18:06:55,581:INFO:                tqdm: 4.64.1
2024-11-13 18:06:55,581:INFO:               numpy: 1.23.5
2024-11-13 18:06:55,581:INFO:              pandas: 1.5.3
2024-11-13 18:06:55,581:INFO:              jinja2: 3.1.2
2024-11-13 18:06:55,581:INFO:               scipy: 1.10.1
2024-11-13 18:06:55,581:INFO:              joblib: 1.3.0
2024-11-13 18:06:55,581:INFO:             sklearn: 1.1.2
2024-11-13 18:06:55,581:INFO:                pyod: 2.0.2
2024-11-13 18:06:55,581:INFO:            imblearn: 0.12.4
2024-11-13 18:06:55,582:INFO:   category_encoders: 2.6.4
2024-11-13 18:06:55,582:INFO:            lightgbm: 4.5.0
2024-11-13 18:06:55,582:INFO:               numba: 0.57.1
2024-11-13 18:06:55,582:INFO:            requests: 2.28.1
2024-11-13 18:06:55,582:INFO:          matplotlib: 3.5.1
2024-11-13 18:06:55,582:INFO:          scikitplot: 0.3.7
2024-11-13 18:06:55,582:INFO:         yellowbrick: 1.5
2024-11-13 18:06:55,582:INFO:              plotly: 5.24.1
2024-11-13 18:06:55,582:INFO:    plotly-resampler: Not installed
2024-11-13 18:06:55,582:INFO:             kaleido: 0.2.1
2024-11-13 18:06:55,582:INFO:           schemdraw: 0.15
2024-11-13 18:06:55,582:INFO:         statsmodels: 0.13.2
2024-11-13 18:06:55,582:INFO:              sktime: 0.21.1
2024-11-13 18:06:55,582:INFO:               tbats: 1.1.3
2024-11-13 18:06:55,582:INFO:            pmdarima: 2.0.4
2024-11-13 18:06:55,582:INFO:              psutil: 5.9.1
2024-11-13 18:06:55,582:INFO:          markupsafe: 2.1.1
2024-11-13 18:06:55,582:INFO:             pickle5: Not installed
2024-11-13 18:06:55,582:INFO:         cloudpickle: 2.1.0
2024-11-13 18:06:55,582:INFO:         deprecation: 2.1.0
2024-11-13 18:06:55,582:INFO:              xxhash: 3.5.0
2024-11-13 18:06:55,582:INFO:           wurlitzer: 3.1.1
2024-11-13 18:06:55,582:INFO:PyCaret optional dependencies:
2024-11-13 18:06:55,582:INFO:                shap: 0.44.1
2024-11-13 18:06:55,582:INFO:           interpret: 0.6.5
2024-11-13 18:06:55,582:INFO:                umap: 0.5.7
2024-11-13 18:06:55,582:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:06:55,582:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:06:55,582:INFO:             autoviz: Not installed
2024-11-13 18:06:55,582:INFO:           fairlearn: 0.7.0
2024-11-13 18:06:55,583:INFO:          deepchecks: Not installed
2024-11-13 18:06:55,583:INFO:             xgboost: 2.1.1
2024-11-13 18:06:55,583:INFO:            catboost: 1.2.7
2024-11-13 18:06:55,583:INFO:              kmodes: 0.12.2
2024-11-13 18:06:55,583:INFO:             mlxtend: 0.23.1
2024-11-13 18:06:55,583:INFO:       statsforecast: 1.5.0
2024-11-13 18:06:55,583:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:06:55,583:INFO:                 ray: 2.10.0
2024-11-13 18:06:55,583:INFO:            hyperopt: 0.2.7
2024-11-13 18:06:55,583:INFO:              optuna: 4.1.0
2024-11-13 18:06:55,583:INFO:               skopt: 0.10.2
2024-11-13 18:06:55,583:INFO:              mlflow: 1.30.1
2024-11-13 18:06:55,583:INFO:              gradio: 3.50.2
2024-11-13 18:06:55,583:INFO:             fastapi: 0.115.5
2024-11-13 18:06:55,583:INFO:             uvicorn: 0.32.0
2024-11-13 18:06:55,583:INFO:              m2cgen: 0.10.0
2024-11-13 18:06:55,583:INFO:           evidently: 0.2.8
2024-11-13 18:06:55,583:INFO:               fugue: 0.8.6
2024-11-13 18:06:55,583:INFO:           streamlit: Not installed
2024-11-13 18:06:55,583:INFO:             prophet: Not installed
2024-11-13 18:06:55,583:INFO:None
2024-11-13 18:06:55,583:INFO:Set up data.
2024-11-13 18:06:55,595:INFO:Set up folding strategy.
2024-11-13 18:06:55,595:INFO:Set up train/test split.
2024-11-13 18:06:55,601:INFO:Set up index.
2024-11-13 18:06:55,602:INFO:Assigning column types.
2024-11-13 18:06:55,606:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:06:55,607:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,613:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,618:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,689:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,732:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:55,734:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:55,735:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,739:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,843:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:55,846:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:55,847:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:06:55,851:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,856:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,912:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,954:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,954:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:55,957:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:55,961:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,966:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,063:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,065:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,066:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:06:56,074:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,130:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,173:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,175:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,184:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,240:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,282:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,285:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,285:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:06:56,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,390:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,393:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,499:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,502:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,502:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:06:56,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,608:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,611:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,716:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,719:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,719:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:06:56,824:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,827:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,932:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,939:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,941:INFO:Preparing preprocessing pipeline...
2024-11-13 18:06:56,941:INFO:Set up simple imputation.
2024-11-13 18:06:56,957:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:06:56,961:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:06:56,961:INFO:Creating final display dataframe.
2024-11-13 18:06:57,017:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 7)
4        Transformed data shape        (31316, 7)
5   Transformed train set shape        (21921, 7)
6    Transformed test set shape         (9395, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              54d3
2024-11-13 18:06:57,132:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:57,134:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:57,238:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:57,241:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:57,242:INFO:setup() successfully completed in 1.67s...............
2024-11-13 18:06:58,878:INFO:Initializing compare_models()
2024-11-13 18:06:58,878:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:06:58,878:INFO:Checking exceptions
2024-11-13 18:06:58,884:INFO:Preparing display monitor
2024-11-13 18:06:58,927:INFO:Initializing Linear Regression
2024-11-13 18:06:58,927:INFO:Total runtime is 1.9470850626627603e-06 minutes
2024-11-13 18:06:58,931:INFO:SubProcess create_model() called ==================================
2024-11-13 18:06:58,931:INFO:Initializing create_model()
2024-11-13 18:06:58,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:06:58,932:INFO:Checking exceptions
2024-11-13 18:06:58,932:INFO:Importing libraries
2024-11-13 18:06:58,932:INFO:Copying training dataset
2024-11-13 18:06:58,938:INFO:Defining folds
2024-11-13 18:06:58,938:INFO:Declaring metric variables
2024-11-13 18:06:58,942:INFO:Importing untrained model
2024-11-13 18:06:58,946:INFO:Linear Regression Imported successfully
2024-11-13 18:06:58,954:INFO:Starting cross validation
2024-11-13 18:06:58,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:03,071:INFO:Calculating mean and std
2024-11-13 18:07:03,077:INFO:Creating metrics dataframe
2024-11-13 18:07:03,083:INFO:Uploading results into container
2024-11-13 18:07:03,084:INFO:Uploading model into container now
2024-11-13 18:07:03,084:INFO:_master_model_container: 1
2024-11-13 18:07:03,085:INFO:_display_container: 2
2024-11-13 18:07:03,085:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:07:03,085:INFO:create_model() successfully completed......................................
2024-11-13 18:07:03,362:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:03,362:INFO:Creating metrics dataframe
2024-11-13 18:07:03,371:INFO:Initializing Lasso Regression
2024-11-13 18:07:03,371:INFO:Total runtime is 0.07408057053883871 minutes
2024-11-13 18:07:03,375:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:03,375:INFO:Initializing create_model()
2024-11-13 18:07:03,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:03,375:INFO:Checking exceptions
2024-11-13 18:07:03,376:INFO:Importing libraries
2024-11-13 18:07:03,376:INFO:Copying training dataset
2024-11-13 18:07:03,383:INFO:Defining folds
2024-11-13 18:07:03,384:INFO:Declaring metric variables
2024-11-13 18:07:03,387:INFO:Importing untrained model
2024-11-13 18:07:03,390:INFO:Lasso Regression Imported successfully
2024-11-13 18:07:03,397:INFO:Starting cross validation
2024-11-13 18:07:03,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:06,198:INFO:Calculating mean and std
2024-11-13 18:07:06,202:INFO:Creating metrics dataframe
2024-11-13 18:07:06,208:INFO:Uploading results into container
2024-11-13 18:07:06,209:INFO:Uploading model into container now
2024-11-13 18:07:06,209:INFO:_master_model_container: 2
2024-11-13 18:07:06,210:INFO:_display_container: 2
2024-11-13 18:07:06,210:INFO:Lasso(random_state=123)
2024-11-13 18:07:06,210:INFO:create_model() successfully completed......................................
2024-11-13 18:07:06,392:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:06,393:INFO:Creating metrics dataframe
2024-11-13 18:07:06,403:INFO:Initializing Ridge Regression
2024-11-13 18:07:06,403:INFO:Total runtime is 0.12460718552271526 minutes
2024-11-13 18:07:06,406:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:06,407:INFO:Initializing create_model()
2024-11-13 18:07:06,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:06,407:INFO:Checking exceptions
2024-11-13 18:07:06,407:INFO:Importing libraries
2024-11-13 18:07:06,407:INFO:Copying training dataset
2024-11-13 18:07:06,413:INFO:Defining folds
2024-11-13 18:07:06,414:INFO:Declaring metric variables
2024-11-13 18:07:06,417:INFO:Importing untrained model
2024-11-13 18:07:06,420:INFO:Ridge Regression Imported successfully
2024-11-13 18:07:06,427:INFO:Starting cross validation
2024-11-13 18:07:06,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:09,204:INFO:Calculating mean and std
2024-11-13 18:07:09,208:INFO:Creating metrics dataframe
2024-11-13 18:07:09,215:INFO:Uploading results into container
2024-11-13 18:07:09,216:INFO:Uploading model into container now
2024-11-13 18:07:09,216:INFO:_master_model_container: 3
2024-11-13 18:07:09,217:INFO:_display_container: 2
2024-11-13 18:07:09,217:INFO:Ridge(random_state=123)
2024-11-13 18:07:09,217:INFO:create_model() successfully completed......................................
2024-11-13 18:07:09,399:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:09,399:INFO:Creating metrics dataframe
2024-11-13 18:07:09,409:INFO:Initializing Elastic Net
2024-11-13 18:07:09,409:INFO:Total runtime is 0.1747101624806722 minutes
2024-11-13 18:07:09,413:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:09,413:INFO:Initializing create_model()
2024-11-13 18:07:09,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:09,413:INFO:Checking exceptions
2024-11-13 18:07:09,413:INFO:Importing libraries
2024-11-13 18:07:09,413:INFO:Copying training dataset
2024-11-13 18:07:09,420:INFO:Defining folds
2024-11-13 18:07:09,420:INFO:Declaring metric variables
2024-11-13 18:07:09,423:INFO:Importing untrained model
2024-11-13 18:07:09,427:INFO:Elastic Net Imported successfully
2024-11-13 18:07:09,439:INFO:Starting cross validation
2024-11-13 18:07:09,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:12,302:INFO:Calculating mean and std
2024-11-13 18:07:12,305:INFO:Creating metrics dataframe
2024-11-13 18:07:12,312:INFO:Uploading results into container
2024-11-13 18:07:12,313:INFO:Uploading model into container now
2024-11-13 18:07:12,313:INFO:_master_model_container: 4
2024-11-13 18:07:12,314:INFO:_display_container: 2
2024-11-13 18:07:12,314:INFO:ElasticNet(random_state=123)
2024-11-13 18:07:12,315:INFO:create_model() successfully completed......................................
2024-11-13 18:07:12,499:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:12,499:INFO:Creating metrics dataframe
2024-11-13 18:07:12,509:INFO:Initializing Least Angle Regression
2024-11-13 18:07:12,509:INFO:Total runtime is 0.22637803157170613 minutes
2024-11-13 18:07:12,513:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:12,513:INFO:Initializing create_model()
2024-11-13 18:07:12,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:12,513:INFO:Checking exceptions
2024-11-13 18:07:12,513:INFO:Importing libraries
2024-11-13 18:07:12,514:INFO:Copying training dataset
2024-11-13 18:07:12,520:INFO:Defining folds
2024-11-13 18:07:12,520:INFO:Declaring metric variables
2024-11-13 18:07:12,524:INFO:Importing untrained model
2024-11-13 18:07:12,528:INFO:Least Angle Regression Imported successfully
2024-11-13 18:07:12,534:INFO:Starting cross validation
2024-11-13 18:07:12,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:15,090:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,093:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.473e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,094:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.237e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,094:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.274e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,094:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.874e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,095:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.283e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,144:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,262:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,265:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.384e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,266:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.231e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,266:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.564e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,266:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.598e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,276:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,282:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,284:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,291:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,300:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,304:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.536e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,304:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.268e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,304:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.267e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,305:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.818e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,305:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.112e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,308:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,369:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,384:INFO:Calculating mean and std
2024-11-13 18:07:15,387:INFO:Creating metrics dataframe
2024-11-13 18:07:15,393:INFO:Uploading results into container
2024-11-13 18:07:15,394:INFO:Uploading model into container now
2024-11-13 18:07:15,395:INFO:_master_model_container: 5
2024-11-13 18:07:15,395:INFO:_display_container: 2
2024-11-13 18:07:15,396:INFO:Lars(random_state=123)
2024-11-13 18:07:15,396:INFO:create_model() successfully completed......................................
2024-11-13 18:07:15,562:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:15,562:INFO:Creating metrics dataframe
2024-11-13 18:07:15,573:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:07:15,573:INFO:Total runtime is 0.2774429480234782 minutes
2024-11-13 18:07:15,576:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:15,577:INFO:Initializing create_model()
2024-11-13 18:07:15,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:15,577:INFO:Checking exceptions
2024-11-13 18:07:15,577:INFO:Importing libraries
2024-11-13 18:07:15,577:INFO:Copying training dataset
2024-11-13 18:07:15,584:INFO:Defining folds
2024-11-13 18:07:15,584:INFO:Declaring metric variables
2024-11-13 18:07:15,587:INFO:Importing untrained model
2024-11-13 18:07:15,591:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:07:15,597:INFO:Starting cross validation
2024-11-13 18:07:15,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:15,682:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:15,684:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:15,690:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:15,698:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,118:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,118:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,172:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,235:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,336:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,437:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,457:INFO:Calculating mean and std
2024-11-13 18:07:18,460:INFO:Creating metrics dataframe
2024-11-13 18:07:18,467:INFO:Uploading results into container
2024-11-13 18:07:18,468:INFO:Uploading model into container now
2024-11-13 18:07:18,468:INFO:_master_model_container: 6
2024-11-13 18:07:18,468:INFO:_display_container: 2
2024-11-13 18:07:18,469:INFO:LassoLars(random_state=123)
2024-11-13 18:07:18,469:INFO:create_model() successfully completed......................................
2024-11-13 18:07:18,683:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:18,683:INFO:Creating metrics dataframe
2024-11-13 18:07:18,695:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:07:18,695:INFO:Total runtime is 0.32947830359141034 minutes
2024-11-13 18:07:18,699:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:18,699:INFO:Initializing create_model()
2024-11-13 18:07:18,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:18,699:INFO:Checking exceptions
2024-11-13 18:07:18,699:INFO:Importing libraries
2024-11-13 18:07:18,699:INFO:Copying training dataset
2024-11-13 18:07:18,707:INFO:Defining folds
2024-11-13 18:07:18,707:INFO:Declaring metric variables
2024-11-13 18:07:18,710:INFO:Importing untrained model
2024-11-13 18:07:18,714:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:07:18,720:INFO:Starting cross validation
2024-11-13 18:07:18,721:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:18,755:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,761:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,768:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,771:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,777:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,782:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,787:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,794:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,798:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,806:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,826:INFO:Calculating mean and std
2024-11-13 18:07:18,830:INFO:Creating metrics dataframe
2024-11-13 18:07:18,836:INFO:Uploading results into container
2024-11-13 18:07:18,836:INFO:Uploading model into container now
2024-11-13 18:07:18,837:INFO:_master_model_container: 7
2024-11-13 18:07:18,837:INFO:_display_container: 2
2024-11-13 18:07:18,837:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:07:18,837:INFO:create_model() successfully completed......................................
2024-11-13 18:07:19,045:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:19,045:INFO:Creating metrics dataframe
2024-11-13 18:07:19,056:INFO:Initializing Bayesian Ridge
2024-11-13 18:07:19,057:INFO:Total runtime is 0.3354992469151815 minutes
2024-11-13 18:07:19,060:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:19,060:INFO:Initializing create_model()
2024-11-13 18:07:19,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:19,061:INFO:Checking exceptions
2024-11-13 18:07:19,061:INFO:Importing libraries
2024-11-13 18:07:19,061:INFO:Copying training dataset
2024-11-13 18:07:19,068:INFO:Defining folds
2024-11-13 18:07:19,068:INFO:Declaring metric variables
2024-11-13 18:07:19,071:INFO:Importing untrained model
2024-11-13 18:07:19,075:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:07:19,081:INFO:Starting cross validation
2024-11-13 18:07:19,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:19,189:INFO:Calculating mean and std
2024-11-13 18:07:19,192:INFO:Creating metrics dataframe
2024-11-13 18:07:19,199:INFO:Uploading results into container
2024-11-13 18:07:19,200:INFO:Uploading model into container now
2024-11-13 18:07:19,200:INFO:_master_model_container: 8
2024-11-13 18:07:19,200:INFO:_display_container: 2
2024-11-13 18:07:19,201:INFO:BayesianRidge()
2024-11-13 18:07:19,201:INFO:create_model() successfully completed......................................
2024-11-13 18:07:19,393:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:19,394:INFO:Creating metrics dataframe
2024-11-13 18:07:19,405:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:07:19,405:INFO:Total runtime is 0.3413140455881755 minutes
2024-11-13 18:07:19,409:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:19,409:INFO:Initializing create_model()
2024-11-13 18:07:19,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:19,409:INFO:Checking exceptions
2024-11-13 18:07:19,409:INFO:Importing libraries
2024-11-13 18:07:19,409:INFO:Copying training dataset
2024-11-13 18:07:19,416:INFO:Defining folds
2024-11-13 18:07:19,416:INFO:Declaring metric variables
2024-11-13 18:07:19,420:INFO:Importing untrained model
2024-11-13 18:07:19,423:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:07:19,429:INFO:Starting cross validation
2024-11-13 18:07:19,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:19,554:INFO:Calculating mean and std
2024-11-13 18:07:19,557:INFO:Creating metrics dataframe
2024-11-13 18:07:19,564:INFO:Uploading results into container
2024-11-13 18:07:19,564:INFO:Uploading model into container now
2024-11-13 18:07:19,565:INFO:_master_model_container: 9
2024-11-13 18:07:19,565:INFO:_display_container: 2
2024-11-13 18:07:19,566:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:07:19,566:INFO:create_model() successfully completed......................................
2024-11-13 18:07:19,747:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:19,747:INFO:Creating metrics dataframe
2024-11-13 18:07:19,758:INFO:Initializing Huber Regressor
2024-11-13 18:07:19,758:INFO:Total runtime is 0.3471907138824464 minutes
2024-11-13 18:07:19,762:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:19,762:INFO:Initializing create_model()
2024-11-13 18:07:19,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:19,762:INFO:Checking exceptions
2024-11-13 18:07:19,762:INFO:Importing libraries
2024-11-13 18:07:19,762:INFO:Copying training dataset
2024-11-13 18:07:19,769:INFO:Defining folds
2024-11-13 18:07:19,769:INFO:Declaring metric variables
2024-11-13 18:07:19,773:INFO:Importing untrained model
2024-11-13 18:07:19,777:INFO:Huber Regressor Imported successfully
2024-11-13 18:07:19,783:INFO:Starting cross validation
2024-11-13 18:07:19,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:20,105:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:07:20,105:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:07:20,120:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:07:20,188:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:07:20,201:INFO:Calculating mean and std
2024-11-13 18:07:20,205:INFO:Creating metrics dataframe
2024-11-13 18:07:20,211:INFO:Uploading results into container
2024-11-13 18:07:20,212:INFO:Uploading model into container now
2024-11-13 18:07:20,213:INFO:_master_model_container: 10
2024-11-13 18:07:20,213:INFO:_display_container: 2
2024-11-13 18:07:20,213:INFO:HuberRegressor()
2024-11-13 18:07:20,213:INFO:create_model() successfully completed......................................
2024-11-13 18:07:20,404:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:20,404:INFO:Creating metrics dataframe
2024-11-13 18:07:20,416:INFO:Initializing K Neighbors Regressor
2024-11-13 18:07:20,416:INFO:Total runtime is 0.35815302530924487 minutes
2024-11-13 18:07:20,419:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:20,419:INFO:Initializing create_model()
2024-11-13 18:07:20,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:20,420:INFO:Checking exceptions
2024-11-13 18:07:20,420:INFO:Importing libraries
2024-11-13 18:07:20,420:INFO:Copying training dataset
2024-11-13 18:07:20,427:INFO:Defining folds
2024-11-13 18:07:20,427:INFO:Declaring metric variables
2024-11-13 18:07:20,431:INFO:Importing untrained model
2024-11-13 18:07:20,434:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:07:20,441:INFO:Starting cross validation
2024-11-13 18:07:20,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:20,630:INFO:Calculating mean and std
2024-11-13 18:07:20,633:INFO:Creating metrics dataframe
2024-11-13 18:07:20,643:INFO:Uploading results into container
2024-11-13 18:07:20,645:INFO:Uploading model into container now
2024-11-13 18:07:20,645:INFO:_master_model_container: 11
2024-11-13 18:07:20,646:INFO:_display_container: 2
2024-11-13 18:07:20,646:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:07:20,646:INFO:create_model() successfully completed......................................
2024-11-13 18:07:20,830:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:20,830:INFO:Creating metrics dataframe
2024-11-13 18:07:20,842:INFO:Initializing Decision Tree Regressor
2024-11-13 18:07:20,843:INFO:Total runtime is 0.3652656316757203 minutes
2024-11-13 18:07:20,846:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:20,846:INFO:Initializing create_model()
2024-11-13 18:07:20,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:20,846:INFO:Checking exceptions
2024-11-13 18:07:20,847:INFO:Importing libraries
2024-11-13 18:07:20,847:INFO:Copying training dataset
2024-11-13 18:07:20,854:INFO:Defining folds
2024-11-13 18:07:20,854:INFO:Declaring metric variables
2024-11-13 18:07:20,858:INFO:Importing untrained model
2024-11-13 18:07:20,861:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:07:20,868:INFO:Starting cross validation
2024-11-13 18:07:20,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:21,059:INFO:Calculating mean and std
2024-11-13 18:07:21,062:INFO:Creating metrics dataframe
2024-11-13 18:07:21,068:INFO:Uploading results into container
2024-11-13 18:07:21,068:INFO:Uploading model into container now
2024-11-13 18:07:21,069:INFO:_master_model_container: 12
2024-11-13 18:07:21,069:INFO:_display_container: 2
2024-11-13 18:07:21,070:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:07:21,070:INFO:create_model() successfully completed......................................
2024-11-13 18:07:21,276:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:21,276:INFO:Creating metrics dataframe
2024-11-13 18:07:21,288:INFO:Initializing Random Forest Regressor
2024-11-13 18:07:21,288:INFO:Total runtime is 0.372696348031362 minutes
2024-11-13 18:07:21,292:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:21,292:INFO:Initializing create_model()
2024-11-13 18:07:21,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:21,292:INFO:Checking exceptions
2024-11-13 18:07:21,292:INFO:Importing libraries
2024-11-13 18:07:21,292:INFO:Copying training dataset
2024-11-13 18:07:21,299:INFO:Defining folds
2024-11-13 18:07:21,299:INFO:Declaring metric variables
2024-11-13 18:07:21,303:INFO:Importing untrained model
2024-11-13 18:07:21,306:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:07:21,312:INFO:Starting cross validation
2024-11-13 18:07:21,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:22,890:INFO:Calculating mean and std
2024-11-13 18:07:22,893:INFO:Creating metrics dataframe
2024-11-13 18:07:22,899:INFO:Uploading results into container
2024-11-13 18:07:22,900:INFO:Uploading model into container now
2024-11-13 18:07:22,900:INFO:_master_model_container: 13
2024-11-13 18:07:22,900:INFO:_display_container: 2
2024-11-13 18:07:22,901:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:07:22,901:INFO:create_model() successfully completed......................................
2024-11-13 18:07:23,072:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:23,072:INFO:Creating metrics dataframe
2024-11-13 18:07:23,084:INFO:Initializing Extra Trees Regressor
2024-11-13 18:07:23,085:INFO:Total runtime is 0.4026317715644837 minutes
2024-11-13 18:07:23,088:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:23,088:INFO:Initializing create_model()
2024-11-13 18:07:23,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:23,088:INFO:Checking exceptions
2024-11-13 18:07:23,088:INFO:Importing libraries
2024-11-13 18:07:23,088:INFO:Copying training dataset
2024-11-13 18:07:23,095:INFO:Defining folds
2024-11-13 18:07:23,095:INFO:Declaring metric variables
2024-11-13 18:07:23,098:INFO:Importing untrained model
2024-11-13 18:07:23,102:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:07:23,108:INFO:Starting cross validation
2024-11-13 18:07:23,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:23,962:INFO:Calculating mean and std
2024-11-13 18:07:23,965:INFO:Creating metrics dataframe
2024-11-13 18:07:23,971:INFO:Uploading results into container
2024-11-13 18:07:23,972:INFO:Uploading model into container now
2024-11-13 18:07:23,973:INFO:_master_model_container: 14
2024-11-13 18:07:23,973:INFO:_display_container: 2
2024-11-13 18:07:23,973:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:07:23,973:INFO:create_model() successfully completed......................................
2024-11-13 18:07:24,143:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:24,143:INFO:Creating metrics dataframe
2024-11-13 18:07:24,156:INFO:Initializing AdaBoost Regressor
2024-11-13 18:07:24,157:INFO:Total runtime is 0.42049788236618046 minutes
2024-11-13 18:07:24,160:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:24,160:INFO:Initializing create_model()
2024-11-13 18:07:24,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:24,161:INFO:Checking exceptions
2024-11-13 18:07:24,161:INFO:Importing libraries
2024-11-13 18:07:24,161:INFO:Copying training dataset
2024-11-13 18:07:24,168:INFO:Defining folds
2024-11-13 18:07:24,168:INFO:Declaring metric variables
2024-11-13 18:07:24,172:INFO:Importing untrained model
2024-11-13 18:07:24,175:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:07:24,182:INFO:Starting cross validation
2024-11-13 18:07:24,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:24,965:INFO:Calculating mean and std
2024-11-13 18:07:24,968:INFO:Creating metrics dataframe
2024-11-13 18:07:24,975:INFO:Uploading results into container
2024-11-13 18:07:24,976:INFO:Uploading model into container now
2024-11-13 18:07:24,976:INFO:_master_model_container: 15
2024-11-13 18:07:24,976:INFO:_display_container: 2
2024-11-13 18:07:24,977:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:07:24,977:INFO:create_model() successfully completed......................................
2024-11-13 18:07:25,154:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:25,154:INFO:Creating metrics dataframe
2024-11-13 18:07:25,166:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:07:25,167:INFO:Total runtime is 0.43733329772949225 minutes
2024-11-13 18:07:25,170:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:25,170:INFO:Initializing create_model()
2024-11-13 18:07:25,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:25,170:INFO:Checking exceptions
2024-11-13 18:07:25,171:INFO:Importing libraries
2024-11-13 18:07:25,171:INFO:Copying training dataset
2024-11-13 18:07:25,177:INFO:Defining folds
2024-11-13 18:07:25,177:INFO:Declaring metric variables
2024-11-13 18:07:25,181:INFO:Importing untrained model
2024-11-13 18:07:25,184:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:07:25,190:INFO:Starting cross validation
2024-11-13 18:07:25,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:27,107:INFO:Calculating mean and std
2024-11-13 18:07:27,110:INFO:Creating metrics dataframe
2024-11-13 18:07:27,121:INFO:Uploading results into container
2024-11-13 18:07:27,122:INFO:Uploading model into container now
2024-11-13 18:07:27,123:INFO:_master_model_container: 16
2024-11-13 18:07:27,123:INFO:_display_container: 2
2024-11-13 18:07:27,123:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:07:27,123:INFO:create_model() successfully completed......................................
2024-11-13 18:07:27,337:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:27,337:INFO:Creating metrics dataframe
2024-11-13 18:07:27,351:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:07:27,351:INFO:Total runtime is 0.4737399538358053 minutes
2024-11-13 18:07:27,354:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:27,355:INFO:Initializing create_model()
2024-11-13 18:07:27,355:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:27,355:INFO:Checking exceptions
2024-11-13 18:07:27,355:INFO:Importing libraries
2024-11-13 18:07:27,355:INFO:Copying training dataset
2024-11-13 18:07:27,362:INFO:Defining folds
2024-11-13 18:07:27,362:INFO:Declaring metric variables
2024-11-13 18:07:27,365:INFO:Importing untrained model
2024-11-13 18:07:27,369:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:07:27,376:INFO:Starting cross validation
2024-11-13 18:07:27,377:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:27,703:INFO:Calculating mean and std
2024-11-13 18:07:27,706:INFO:Creating metrics dataframe
2024-11-13 18:07:27,712:INFO:Uploading results into container
2024-11-13 18:07:27,713:INFO:Uploading model into container now
2024-11-13 18:07:27,713:INFO:_master_model_container: 17
2024-11-13 18:07:27,713:INFO:_display_container: 2
2024-11-13 18:07:27,714:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:07:27,714:INFO:create_model() successfully completed......................................
2024-11-13 18:07:27,903:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:27,903:INFO:Creating metrics dataframe
2024-11-13 18:07:27,916:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:07:27,917:INFO:Total runtime is 0.48316738208134974 minutes
2024-11-13 18:07:27,920:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:27,920:INFO:Initializing create_model()
2024-11-13 18:07:27,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:27,921:INFO:Checking exceptions
2024-11-13 18:07:27,921:INFO:Importing libraries
2024-11-13 18:07:27,921:INFO:Copying training dataset
2024-11-13 18:07:27,927:INFO:Defining folds
2024-11-13 18:07:27,928:INFO:Declaring metric variables
2024-11-13 18:07:27,931:INFO:Importing untrained model
2024-11-13 18:07:27,935:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:07:27,941:INFO:Starting cross validation
2024-11-13 18:07:27,942:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:14:19,955:INFO:Calculating mean and std
2024-11-13 18:14:19,959:INFO:Creating metrics dataframe
2024-11-13 18:14:19,970:INFO:Uploading results into container
2024-11-13 18:14:19,972:INFO:Uploading model into container now
2024-11-13 18:14:19,973:INFO:_master_model_container: 18
2024-11-13 18:14:19,973:INFO:_display_container: 2
2024-11-13 18:14:19,974:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:14:19,974:INFO:create_model() successfully completed......................................
2024-11-13 18:14:20,193:INFO:SubProcess create_model() end ==================================
2024-11-13 18:14:20,193:INFO:Creating metrics dataframe
2024-11-13 18:14:20,208:INFO:Initializing CatBoost Regressor
2024-11-13 18:14:20,208:INFO:Total runtime is 7.354694394270579 minutes
2024-11-13 18:14:20,212:INFO:SubProcess create_model() called ==================================
2024-11-13 18:14:20,212:INFO:Initializing create_model()
2024-11-13 18:14:20,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:14:20,213:INFO:Checking exceptions
2024-11-13 18:14:20,213:INFO:Importing libraries
2024-11-13 18:14:20,213:INFO:Copying training dataset
2024-11-13 18:14:20,220:INFO:Defining folds
2024-11-13 18:14:20,220:INFO:Declaring metric variables
2024-11-13 18:14:20,224:INFO:Importing untrained model
2024-11-13 18:14:20,227:INFO:CatBoost Regressor Imported successfully
2024-11-13 18:14:20,234:INFO:Starting cross validation
2024-11-13 18:14:20,235:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:14:32,274:INFO:Calculating mean and std
2024-11-13 18:14:32,279:INFO:Creating metrics dataframe
2024-11-13 18:14:32,286:INFO:Uploading results into container
2024-11-13 18:14:32,286:INFO:Uploading model into container now
2024-11-13 18:14:32,287:INFO:_master_model_container: 19
2024-11-13 18:14:32,287:INFO:_display_container: 2
2024-11-13 18:14:32,287:INFO:<catboost.core.CatBoostRegressor object at 0x7ff4c561d5b0>
2024-11-13 18:14:32,287:INFO:create_model() successfully completed......................................
2024-11-13 18:14:32,494:INFO:SubProcess create_model() end ==================================
2024-11-13 18:14:32,494:INFO:Creating metrics dataframe
2024-11-13 18:14:32,509:INFO:Initializing Dummy Regressor
2024-11-13 18:14:32,509:INFO:Total runtime is 7.559710693359375 minutes
2024-11-13 18:14:32,513:INFO:SubProcess create_model() called ==================================
2024-11-13 18:14:32,513:INFO:Initializing create_model()
2024-11-13 18:14:32,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:14:32,513:INFO:Checking exceptions
2024-11-13 18:14:32,514:INFO:Importing libraries
2024-11-13 18:14:32,514:INFO:Copying training dataset
2024-11-13 18:14:32,521:INFO:Defining folds
2024-11-13 18:14:32,521:INFO:Declaring metric variables
2024-11-13 18:14:32,525:INFO:Importing untrained model
2024-11-13 18:14:32,528:INFO:Dummy Regressor Imported successfully
2024-11-13 18:14:32,535:INFO:Starting cross validation
2024-11-13 18:14:32,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:14:35,729:INFO:Calculating mean and std
2024-11-13 18:14:35,734:INFO:Creating metrics dataframe
2024-11-13 18:14:35,741:INFO:Uploading results into container
2024-11-13 18:14:35,742:INFO:Uploading model into container now
2024-11-13 18:14:35,742:INFO:_master_model_container: 20
2024-11-13 18:14:35,743:INFO:_display_container: 2
2024-11-13 18:14:35,743:INFO:DummyRegressor()
2024-11-13 18:14:35,743:INFO:create_model() successfully completed......................................
2024-11-13 18:14:35,970:INFO:SubProcess create_model() end ==================================
2024-11-13 18:14:35,970:INFO:Creating metrics dataframe
2024-11-13 18:14:35,997:INFO:Initializing create_model()
2024-11-13 18:14:35,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:14:35,997:INFO:Checking exceptions
2024-11-13 18:14:36,000:INFO:Importing libraries
2024-11-13 18:14:36,000:INFO:Copying training dataset
2024-11-13 18:14:36,005:INFO:Defining folds
2024-11-13 18:14:36,006:INFO:Declaring metric variables
2024-11-13 18:14:36,006:INFO:Importing untrained model
2024-11-13 18:14:36,006:INFO:Declaring custom model
2024-11-13 18:14:36,006:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:14:36,007:INFO:Cross validation set to False
2024-11-13 18:14:36,007:INFO:Fitting Model
2024-11-13 18:14:36,249:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:14:36,249:INFO:create_model() successfully completed......................................
2024-11-13 18:14:36,540:INFO:_master_model_container: 20
2024-11-13 18:14:36,541:INFO:_display_container: 2
2024-11-13 18:14:36,541:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:14:36,541:INFO:compare_models() successfully completed......................................
2024-11-13 18:15:23,767:INFO:PyCaret RegressionExperiment
2024-11-13 18:15:23,768:INFO:Logging name: reg-default-name
2024-11-13 18:15:23,768:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:15:23,768:INFO:version 3.2.0
2024-11-13 18:15:23,768:INFO:Initializing setup()
2024-11-13 18:15:23,768:INFO:self.USI: 7f5f
2024-11-13 18:15:23,768:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:15:23,768:INFO:Checking environment
2024-11-13 18:15:23,768:INFO:python_version: 3.8.13
2024-11-13 18:15:23,768:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:15:23,768:INFO:machine: x86_64
2024-11-13 18:15:23,768:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:15:23,768:INFO:Memory: svmem(total=270355722240, available=213997654016, percent=20.8, used=54288515072, free=52052815872, active=11655049216, inactive=146339053568, buffers=8888320, cached=164005502976, shared=187588608, slab=25029918720)
2024-11-13 18:15:23,770:INFO:Physical Core: 28
2024-11-13 18:15:23,771:INFO:Logical Core: 56
2024-11-13 18:15:23,771:INFO:Checking libraries
2024-11-13 18:15:23,771:INFO:System:
2024-11-13 18:15:23,771:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:15:23,771:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:15:23,771:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:15:23,771:INFO:PyCaret required dependencies:
2024-11-13 18:15:23,771:INFO:                 pip: 22.2.2
2024-11-13 18:15:23,771:INFO:          setuptools: 63.4.2
2024-11-13 18:15:23,771:INFO:             pycaret: 3.2.0
2024-11-13 18:15:23,771:INFO:             IPython: 8.12.2
2024-11-13 18:15:23,771:INFO:          ipywidgets: 7.7.1
2024-11-13 18:15:23,771:INFO:                tqdm: 4.64.1
2024-11-13 18:15:23,771:INFO:               numpy: 1.23.5
2024-11-13 18:15:23,771:INFO:              pandas: 1.5.3
2024-11-13 18:15:23,771:INFO:              jinja2: 3.1.2
2024-11-13 18:15:23,771:INFO:               scipy: 1.10.1
2024-11-13 18:15:23,771:INFO:              joblib: 1.3.0
2024-11-13 18:15:23,771:INFO:             sklearn: 1.1.2
2024-11-13 18:15:23,771:INFO:                pyod: 2.0.2
2024-11-13 18:15:23,771:INFO:            imblearn: 0.12.4
2024-11-13 18:15:23,771:INFO:   category_encoders: 2.6.4
2024-11-13 18:15:23,771:INFO:            lightgbm: 4.5.0
2024-11-13 18:15:23,771:INFO:               numba: 0.57.1
2024-11-13 18:15:23,772:INFO:            requests: 2.28.1
2024-11-13 18:15:23,772:INFO:          matplotlib: 3.5.1
2024-11-13 18:15:23,772:INFO:          scikitplot: 0.3.7
2024-11-13 18:15:23,772:INFO:         yellowbrick: 1.5
2024-11-13 18:15:23,772:INFO:              plotly: 5.24.1
2024-11-13 18:15:23,772:INFO:    plotly-resampler: Not installed
2024-11-13 18:15:23,772:INFO:             kaleido: 0.2.1
2024-11-13 18:15:23,772:INFO:           schemdraw: 0.15
2024-11-13 18:15:23,772:INFO:         statsmodels: 0.13.2
2024-11-13 18:15:23,772:INFO:              sktime: 0.21.1
2024-11-13 18:15:23,772:INFO:               tbats: 1.1.3
2024-11-13 18:15:23,772:INFO:            pmdarima: 2.0.4
2024-11-13 18:15:23,772:INFO:              psutil: 5.9.1
2024-11-13 18:15:23,772:INFO:          markupsafe: 2.1.1
2024-11-13 18:15:23,772:INFO:             pickle5: Not installed
2024-11-13 18:15:23,772:INFO:         cloudpickle: 2.1.0
2024-11-13 18:15:23,772:INFO:         deprecation: 2.1.0
2024-11-13 18:15:23,772:INFO:              xxhash: 3.5.0
2024-11-13 18:15:23,772:INFO:           wurlitzer: 3.1.1
2024-11-13 18:15:23,772:INFO:PyCaret optional dependencies:
2024-11-13 18:15:23,772:INFO:                shap: 0.44.1
2024-11-13 18:15:23,772:INFO:           interpret: 0.6.5
2024-11-13 18:15:23,772:INFO:                umap: 0.5.7
2024-11-13 18:15:23,772:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:15:23,772:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:15:23,772:INFO:             autoviz: Not installed
2024-11-13 18:15:23,772:INFO:           fairlearn: 0.7.0
2024-11-13 18:15:23,772:INFO:          deepchecks: Not installed
2024-11-13 18:15:23,772:INFO:             xgboost: 2.1.1
2024-11-13 18:15:23,773:INFO:            catboost: 1.2.7
2024-11-13 18:15:23,773:INFO:              kmodes: 0.12.2
2024-11-13 18:15:23,773:INFO:             mlxtend: 0.23.1
2024-11-13 18:15:23,773:INFO:       statsforecast: 1.5.0
2024-11-13 18:15:23,773:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:15:23,773:INFO:                 ray: 2.10.0
2024-11-13 18:15:23,773:INFO:            hyperopt: 0.2.7
2024-11-13 18:15:23,773:INFO:              optuna: 4.1.0
2024-11-13 18:15:23,773:INFO:               skopt: 0.10.2
2024-11-13 18:15:23,773:INFO:              mlflow: 1.30.1
2024-11-13 18:15:23,773:INFO:              gradio: 3.50.2
2024-11-13 18:15:23,773:INFO:             fastapi: 0.115.5
2024-11-13 18:15:23,773:INFO:             uvicorn: 0.32.0
2024-11-13 18:15:23,773:INFO:              m2cgen: 0.10.0
2024-11-13 18:15:23,773:INFO:           evidently: 0.2.8
2024-11-13 18:15:23,773:INFO:               fugue: 0.8.6
2024-11-13 18:15:23,773:INFO:           streamlit: Not installed
2024-11-13 18:15:23,773:INFO:             prophet: Not installed
2024-11-13 18:15:23,773:INFO:None
2024-11-13 18:15:23,773:INFO:Set up data.
2024-11-13 18:15:23,787:INFO:Set up folding strategy.
2024-11-13 18:15:23,787:INFO:Set up train/test split.
2024-11-13 18:15:23,793:INFO:Set up index.
2024-11-13 18:15:23,794:INFO:Assigning column types.
2024-11-13 18:15:23,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:15:23,799:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,804:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,873:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,924:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:23,928:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:23,929:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,933:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,937:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,987:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,023:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,024:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,026:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,027:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:15:24,030:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,034:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,082:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,119:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,121:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,126:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,130:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,182:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,218:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,220:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,222:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:15:24,229:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,277:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,314:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,316:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,324:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,408:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,408:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,410:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,411:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:15:24,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,502:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,503:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,505:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,560:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,597:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,597:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,599:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,599:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:15:24,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,693:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,695:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,789:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,791:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,792:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:15:24,884:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,886:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,983:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,985:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,987:INFO:Preparing preprocessing pipeline...
2024-11-13 18:15:24,987:INFO:Set up simple imputation.
2024-11-13 18:15:25,004:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:15:25,009:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['USA_WSPD', 'MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:15:25,009:INFO:Creating final display dataframe.
2024-11-13 18:15:25,066:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 8)
4        Transformed data shape        (31316, 8)
5   Transformed train set shape        (21921, 8)
6    Transformed test set shape         (9395, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              7f5f
2024-11-13 18:15:25,167:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:25,170:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:25,262:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:25,264:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:25,265:INFO:setup() successfully completed in 1.5s...............
2024-11-13 18:15:26,696:INFO:Initializing compare_models()
2024-11-13 18:15:26,696:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:15:26,696:INFO:Checking exceptions
2024-11-13 18:15:26,702:INFO:Preparing display monitor
2024-11-13 18:15:26,736:INFO:Initializing Linear Regression
2024-11-13 18:15:26,736:INFO:Total runtime is 2.6186307271321613e-06 minutes
2024-11-13 18:15:26,741:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:26,741:INFO:Initializing create_model()
2024-11-13 18:15:26,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:26,742:INFO:Checking exceptions
2024-11-13 18:15:26,742:INFO:Importing libraries
2024-11-13 18:15:26,742:INFO:Copying training dataset
2024-11-13 18:15:26,748:INFO:Defining folds
2024-11-13 18:15:26,748:INFO:Declaring metric variables
2024-11-13 18:15:26,752:INFO:Importing untrained model
2024-11-13 18:15:26,756:INFO:Linear Regression Imported successfully
2024-11-13 18:15:26,762:INFO:Starting cross validation
2024-11-13 18:15:26,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:29,799:INFO:Calculating mean and std
2024-11-13 18:15:29,804:INFO:Creating metrics dataframe
2024-11-13 18:15:29,811:INFO:Uploading results into container
2024-11-13 18:15:29,812:INFO:Uploading model into container now
2024-11-13 18:15:29,812:INFO:_master_model_container: 1
2024-11-13 18:15:29,812:INFO:_display_container: 2
2024-11-13 18:15:29,813:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:15:29,813:INFO:create_model() successfully completed......................................
2024-11-13 18:15:30,094:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:30,094:INFO:Creating metrics dataframe
2024-11-13 18:15:30,106:INFO:Initializing Lasso Regression
2024-11-13 18:15:30,106:INFO:Total runtime is 0.056162710984547934 minutes
2024-11-13 18:15:30,109:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:30,110:INFO:Initializing create_model()
2024-11-13 18:15:30,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:30,110:INFO:Checking exceptions
2024-11-13 18:15:30,110:INFO:Importing libraries
2024-11-13 18:15:30,110:INFO:Copying training dataset
2024-11-13 18:15:30,119:INFO:Defining folds
2024-11-13 18:15:30,119:INFO:Declaring metric variables
2024-11-13 18:15:30,122:INFO:Importing untrained model
2024-11-13 18:15:30,125:INFO:Lasso Regression Imported successfully
2024-11-13 18:15:30,132:INFO:Starting cross validation
2024-11-13 18:15:30,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:32,914:INFO:Calculating mean and std
2024-11-13 18:15:32,918:INFO:Creating metrics dataframe
2024-11-13 18:15:32,924:INFO:Uploading results into container
2024-11-13 18:15:32,925:INFO:Uploading model into container now
2024-11-13 18:15:32,926:INFO:_master_model_container: 2
2024-11-13 18:15:32,926:INFO:_display_container: 2
2024-11-13 18:15:32,926:INFO:Lasso(random_state=123)
2024-11-13 18:15:32,926:INFO:create_model() successfully completed......................................
2024-11-13 18:15:33,147:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:33,148:INFO:Creating metrics dataframe
2024-11-13 18:15:33,158:INFO:Initializing Ridge Regression
2024-11-13 18:15:33,159:INFO:Total runtime is 0.10704161723454794 minutes
2024-11-13 18:15:33,162:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:33,162:INFO:Initializing create_model()
2024-11-13 18:15:33,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:33,162:INFO:Checking exceptions
2024-11-13 18:15:33,163:INFO:Importing libraries
2024-11-13 18:15:33,163:INFO:Copying training dataset
2024-11-13 18:15:33,169:INFO:Defining folds
2024-11-13 18:15:33,170:INFO:Declaring metric variables
2024-11-13 18:15:33,173:INFO:Importing untrained model
2024-11-13 18:15:33,176:INFO:Ridge Regression Imported successfully
2024-11-13 18:15:33,183:INFO:Starting cross validation
2024-11-13 18:15:33,184:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:36,161:INFO:Calculating mean and std
2024-11-13 18:15:36,165:INFO:Creating metrics dataframe
2024-11-13 18:15:36,172:INFO:Uploading results into container
2024-11-13 18:15:36,172:INFO:Uploading model into container now
2024-11-13 18:15:36,173:INFO:_master_model_container: 3
2024-11-13 18:15:36,173:INFO:_display_container: 2
2024-11-13 18:15:36,173:INFO:Ridge(random_state=123)
2024-11-13 18:15:36,173:INFO:create_model() successfully completed......................................
2024-11-13 18:15:36,387:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:36,387:INFO:Creating metrics dataframe
2024-11-13 18:15:36,398:INFO:Initializing Elastic Net
2024-11-13 18:15:36,398:INFO:Total runtime is 0.16103380918502808 minutes
2024-11-13 18:15:36,401:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:36,402:INFO:Initializing create_model()
2024-11-13 18:15:36,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:36,402:INFO:Checking exceptions
2024-11-13 18:15:36,402:INFO:Importing libraries
2024-11-13 18:15:36,402:INFO:Copying training dataset
2024-11-13 18:15:36,409:INFO:Defining folds
2024-11-13 18:15:36,409:INFO:Declaring metric variables
2024-11-13 18:15:36,413:INFO:Importing untrained model
2024-11-13 18:15:36,416:INFO:Elastic Net Imported successfully
2024-11-13 18:15:36,422:INFO:Starting cross validation
2024-11-13 18:15:36,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:39,131:INFO:Calculating mean and std
2024-11-13 18:15:39,135:INFO:Creating metrics dataframe
2024-11-13 18:15:39,143:INFO:Uploading results into container
2024-11-13 18:15:39,143:INFO:Uploading model into container now
2024-11-13 18:15:39,144:INFO:_master_model_container: 4
2024-11-13 18:15:39,144:INFO:_display_container: 2
2024-11-13 18:15:39,145:INFO:ElasticNet(random_state=123)
2024-11-13 18:15:39,145:INFO:create_model() successfully completed......................................
2024-11-13 18:15:39,381:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:39,381:INFO:Creating metrics dataframe
2024-11-13 18:15:39,393:INFO:Initializing Least Angle Regression
2024-11-13 18:15:39,393:INFO:Total runtime is 0.21095072428385417 minutes
2024-11-13 18:15:39,396:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:39,397:INFO:Initializing create_model()
2024-11-13 18:15:39,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:39,397:INFO:Checking exceptions
2024-11-13 18:15:39,397:INFO:Importing libraries
2024-11-13 18:15:39,397:INFO:Copying training dataset
2024-11-13 18:15:39,404:INFO:Defining folds
2024-11-13 18:15:39,404:INFO:Declaring metric variables
2024-11-13 18:15:39,408:INFO:Importing untrained model
2024-11-13 18:15:39,411:INFO:Least Angle Regression Imported successfully
2024-11-13 18:15:39,418:INFO:Starting cross validation
2024-11-13 18:15:39,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:39,492:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:39,500:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:39,505:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:39,508:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:39,509:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.478e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:15:39,511:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.949e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:15:39,512:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.974e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:15:39,516:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:41,896:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:41,933:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:42,050:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:42,125:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:42,129:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.407e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:15:42,164:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:42,176:INFO:Calculating mean and std
2024-11-13 18:15:42,180:INFO:Creating metrics dataframe
2024-11-13 18:15:42,187:INFO:Uploading results into container
2024-11-13 18:15:42,188:INFO:Uploading model into container now
2024-11-13 18:15:42,189:INFO:_master_model_container: 5
2024-11-13 18:15:42,189:INFO:_display_container: 2
2024-11-13 18:15:42,189:INFO:Lars(random_state=123)
2024-11-13 18:15:42,189:INFO:create_model() successfully completed......................................
2024-11-13 18:15:42,378:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:42,378:INFO:Creating metrics dataframe
2024-11-13 18:15:42,390:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:15:42,391:INFO:Total runtime is 0.260908039410909 minutes
2024-11-13 18:15:42,394:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:42,394:INFO:Initializing create_model()
2024-11-13 18:15:42,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:42,395:INFO:Checking exceptions
2024-11-13 18:15:42,395:INFO:Importing libraries
2024-11-13 18:15:42,395:INFO:Copying training dataset
2024-11-13 18:15:42,402:INFO:Defining folds
2024-11-13 18:15:42,402:INFO:Declaring metric variables
2024-11-13 18:15:42,405:INFO:Importing untrained model
2024-11-13 18:15:42,409:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:15:42,415:INFO:Starting cross validation
2024-11-13 18:15:42,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:42,454:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,470:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,470:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,474:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,479:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,494:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,501:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,503:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,511:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:44,707:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:44,723:INFO:Calculating mean and std
2024-11-13 18:15:44,727:INFO:Creating metrics dataframe
2024-11-13 18:15:44,735:INFO:Uploading results into container
2024-11-13 18:15:44,735:INFO:Uploading model into container now
2024-11-13 18:15:44,736:INFO:_master_model_container: 6
2024-11-13 18:15:44,736:INFO:_display_container: 2
2024-11-13 18:15:44,737:INFO:LassoLars(random_state=123)
2024-11-13 18:15:44,737:INFO:create_model() successfully completed......................................
2024-11-13 18:15:44,939:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:44,939:INFO:Creating metrics dataframe
2024-11-13 18:15:44,950:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:15:44,950:INFO:Total runtime is 0.3035678466161092 minutes
2024-11-13 18:15:44,954:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:44,954:INFO:Initializing create_model()
2024-11-13 18:15:44,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:44,954:INFO:Checking exceptions
2024-11-13 18:15:44,954:INFO:Importing libraries
2024-11-13 18:15:44,954:INFO:Copying training dataset
2024-11-13 18:15:44,961:INFO:Defining folds
2024-11-13 18:15:44,961:INFO:Declaring metric variables
2024-11-13 18:15:44,965:INFO:Importing untrained model
2024-11-13 18:15:44,968:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:15:44,975:INFO:Starting cross validation
2024-11-13 18:15:44,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:45,004:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,012:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,015:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,021:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,027:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,030:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,038:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,040:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,044:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,051:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,067:INFO:Calculating mean and std
2024-11-13 18:15:45,071:INFO:Creating metrics dataframe
2024-11-13 18:15:45,078:INFO:Uploading results into container
2024-11-13 18:15:45,079:INFO:Uploading model into container now
2024-11-13 18:15:45,079:INFO:_master_model_container: 7
2024-11-13 18:15:45,079:INFO:_display_container: 2
2024-11-13 18:15:45,080:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:15:45,080:INFO:create_model() successfully completed......................................
2024-11-13 18:15:45,254:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:45,254:INFO:Creating metrics dataframe
2024-11-13 18:15:45,266:INFO:Initializing Bayesian Ridge
2024-11-13 18:15:45,266:INFO:Total runtime is 0.30882927179336545 minutes
2024-11-13 18:15:45,269:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:45,269:INFO:Initializing create_model()
2024-11-13 18:15:45,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:45,269:INFO:Checking exceptions
2024-11-13 18:15:45,270:INFO:Importing libraries
2024-11-13 18:15:45,270:INFO:Copying training dataset
2024-11-13 18:15:45,278:INFO:Defining folds
2024-11-13 18:15:45,278:INFO:Declaring metric variables
2024-11-13 18:15:45,282:INFO:Importing untrained model
2024-11-13 18:15:45,285:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:15:45,292:INFO:Starting cross validation
2024-11-13 18:15:45,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:45,455:INFO:Calculating mean and std
2024-11-13 18:15:45,459:INFO:Creating metrics dataframe
2024-11-13 18:15:45,465:INFO:Uploading results into container
2024-11-13 18:15:45,466:INFO:Uploading model into container now
2024-11-13 18:15:45,467:INFO:_master_model_container: 8
2024-11-13 18:15:45,467:INFO:_display_container: 2
2024-11-13 18:15:45,468:INFO:BayesianRidge()
2024-11-13 18:15:45,468:INFO:create_model() successfully completed......................................
2024-11-13 18:15:45,645:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:45,645:INFO:Creating metrics dataframe
2024-11-13 18:15:45,656:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:15:45,656:INFO:Total runtime is 0.31533221801122024 minutes
2024-11-13 18:15:45,659:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:45,660:INFO:Initializing create_model()
2024-11-13 18:15:45,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:45,660:INFO:Checking exceptions
2024-11-13 18:15:45,660:INFO:Importing libraries
2024-11-13 18:15:45,660:INFO:Copying training dataset
2024-11-13 18:15:45,667:INFO:Defining folds
2024-11-13 18:15:45,667:INFO:Declaring metric variables
2024-11-13 18:15:45,671:INFO:Importing untrained model
2024-11-13 18:15:45,674:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:15:45,680:INFO:Starting cross validation
2024-11-13 18:15:45,681:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:45,817:INFO:Calculating mean and std
2024-11-13 18:15:45,821:INFO:Creating metrics dataframe
2024-11-13 18:15:45,829:INFO:Uploading results into container
2024-11-13 18:15:45,830:INFO:Uploading model into container now
2024-11-13 18:15:45,830:INFO:_master_model_container: 9
2024-11-13 18:15:45,831:INFO:_display_container: 2
2024-11-13 18:15:45,831:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:15:45,831:INFO:create_model() successfully completed......................................
2024-11-13 18:15:46,057:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:46,058:INFO:Creating metrics dataframe
2024-11-13 18:15:46,070:INFO:Initializing Huber Regressor
2024-11-13 18:15:46,070:INFO:Total runtime is 0.3222341895103454 minutes
2024-11-13 18:15:46,074:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:46,074:INFO:Initializing create_model()
2024-11-13 18:15:46,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:46,074:INFO:Checking exceptions
2024-11-13 18:15:46,074:INFO:Importing libraries
2024-11-13 18:15:46,074:INFO:Copying training dataset
2024-11-13 18:15:46,081:INFO:Defining folds
2024-11-13 18:15:46,081:INFO:Declaring metric variables
2024-11-13 18:15:46,085:INFO:Importing untrained model
2024-11-13 18:15:46,088:INFO:Huber Regressor Imported successfully
2024-11-13 18:15:46,095:INFO:Starting cross validation
2024-11-13 18:15:46,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:46,360:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,361:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,384:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,433:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,463:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,520:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,528:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,532:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,557:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,575:INFO:Calculating mean and std
2024-11-13 18:15:46,578:INFO:Creating metrics dataframe
2024-11-13 18:15:46,584:INFO:Uploading results into container
2024-11-13 18:15:46,584:INFO:Uploading model into container now
2024-11-13 18:15:46,585:INFO:_master_model_container: 10
2024-11-13 18:15:46,585:INFO:_display_container: 2
2024-11-13 18:15:46,585:INFO:HuberRegressor()
2024-11-13 18:15:46,586:INFO:create_model() successfully completed......................................
2024-11-13 18:15:46,752:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:46,752:INFO:Creating metrics dataframe
2024-11-13 18:15:46,764:INFO:Initializing K Neighbors Regressor
2024-11-13 18:15:46,764:INFO:Total runtime is 0.3337962667147318 minutes
2024-11-13 18:15:46,767:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:46,767:INFO:Initializing create_model()
2024-11-13 18:15:46,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:46,768:INFO:Checking exceptions
2024-11-13 18:15:46,768:INFO:Importing libraries
2024-11-13 18:15:46,768:INFO:Copying training dataset
2024-11-13 18:15:46,775:INFO:Defining folds
2024-11-13 18:15:46,775:INFO:Declaring metric variables
2024-11-13 18:15:46,779:INFO:Importing untrained model
2024-11-13 18:15:46,782:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:15:46,788:INFO:Starting cross validation
2024-11-13 18:15:46,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:47,046:INFO:Calculating mean and std
2024-11-13 18:15:47,050:INFO:Creating metrics dataframe
2024-11-13 18:15:47,055:INFO:Uploading results into container
2024-11-13 18:15:47,055:INFO:Uploading model into container now
2024-11-13 18:15:47,056:INFO:_master_model_container: 11
2024-11-13 18:15:47,056:INFO:_display_container: 2
2024-11-13 18:15:47,057:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:15:47,057:INFO:create_model() successfully completed......................................
2024-11-13 18:15:47,241:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:47,241:INFO:Creating metrics dataframe
2024-11-13 18:15:47,254:INFO:Initializing Decision Tree Regressor
2024-11-13 18:15:47,254:INFO:Total runtime is 0.3419704635938008 minutes
2024-11-13 18:15:47,257:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:47,258:INFO:Initializing create_model()
2024-11-13 18:15:47,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:47,258:INFO:Checking exceptions
2024-11-13 18:15:47,258:INFO:Importing libraries
2024-11-13 18:15:47,258:INFO:Copying training dataset
2024-11-13 18:15:47,266:INFO:Defining folds
2024-11-13 18:15:47,267:INFO:Declaring metric variables
2024-11-13 18:15:47,270:INFO:Importing untrained model
2024-11-13 18:15:47,274:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:15:47,280:INFO:Starting cross validation
2024-11-13 18:15:47,281:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:47,421:INFO:Calculating mean and std
2024-11-13 18:15:47,425:INFO:Creating metrics dataframe
2024-11-13 18:15:47,435:INFO:Uploading results into container
2024-11-13 18:15:47,437:INFO:Uploading model into container now
2024-11-13 18:15:47,438:INFO:_master_model_container: 12
2024-11-13 18:15:47,438:INFO:_display_container: 2
2024-11-13 18:15:47,438:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:15:47,438:INFO:create_model() successfully completed......................................
2024-11-13 18:15:47,656:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:47,657:INFO:Creating metrics dataframe
2024-11-13 18:15:47,671:INFO:Initializing Random Forest Regressor
2024-11-13 18:15:47,672:INFO:Total runtime is 0.3489264090855916 minutes
2024-11-13 18:15:47,676:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:47,676:INFO:Initializing create_model()
2024-11-13 18:15:47,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:47,676:INFO:Checking exceptions
2024-11-13 18:15:47,676:INFO:Importing libraries
2024-11-13 18:15:47,677:INFO:Copying training dataset
2024-11-13 18:15:47,683:INFO:Defining folds
2024-11-13 18:15:47,684:INFO:Declaring metric variables
2024-11-13 18:15:47,687:INFO:Importing untrained model
2024-11-13 18:15:47,691:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:15:47,697:INFO:Starting cross validation
2024-11-13 18:15:47,698:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:48,647:INFO:Calculating mean and std
2024-11-13 18:15:48,650:INFO:Creating metrics dataframe
2024-11-13 18:15:48,656:INFO:Uploading results into container
2024-11-13 18:15:48,657:INFO:Uploading model into container now
2024-11-13 18:15:48,657:INFO:_master_model_container: 13
2024-11-13 18:15:48,657:INFO:_display_container: 2
2024-11-13 18:15:48,658:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:15:48,658:INFO:create_model() successfully completed......................................
2024-11-13 18:15:48,835:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:48,835:INFO:Creating metrics dataframe
2024-11-13 18:15:48,848:INFO:Initializing Extra Trees Regressor
2024-11-13 18:15:48,848:INFO:Total runtime is 0.3685339609781901 minutes
2024-11-13 18:15:48,851:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:48,852:INFO:Initializing create_model()
2024-11-13 18:15:48,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:48,852:INFO:Checking exceptions
2024-11-13 18:15:48,852:INFO:Importing libraries
2024-11-13 18:15:48,852:INFO:Copying training dataset
2024-11-13 18:15:48,859:INFO:Defining folds
2024-11-13 18:15:48,859:INFO:Declaring metric variables
2024-11-13 18:15:48,863:INFO:Importing untrained model
2024-11-13 18:15:48,866:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:15:48,873:INFO:Starting cross validation
2024-11-13 18:15:48,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:49,385:INFO:Calculating mean and std
2024-11-13 18:15:49,387:INFO:Creating metrics dataframe
2024-11-13 18:15:49,393:INFO:Uploading results into container
2024-11-13 18:15:49,394:INFO:Uploading model into container now
2024-11-13 18:15:49,395:INFO:_master_model_container: 14
2024-11-13 18:15:49,395:INFO:_display_container: 2
2024-11-13 18:15:49,396:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:15:49,396:INFO:create_model() successfully completed......................................
2024-11-13 18:15:49,565:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:49,565:INFO:Creating metrics dataframe
2024-11-13 18:15:49,580:INFO:Initializing AdaBoost Regressor
2024-11-13 18:15:49,580:INFO:Total runtime is 0.3807297309239705 minutes
2024-11-13 18:15:49,584:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:49,584:INFO:Initializing create_model()
2024-11-13 18:15:49,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:49,584:INFO:Checking exceptions
2024-11-13 18:15:49,585:INFO:Importing libraries
2024-11-13 18:15:49,585:INFO:Copying training dataset
2024-11-13 18:15:49,593:INFO:Defining folds
2024-11-13 18:15:49,593:INFO:Declaring metric variables
2024-11-13 18:15:49,597:INFO:Importing untrained model
2024-11-13 18:15:49,600:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:15:49,607:INFO:Starting cross validation
2024-11-13 18:15:49,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:50,301:INFO:Calculating mean and std
2024-11-13 18:15:50,305:INFO:Creating metrics dataframe
2024-11-13 18:15:50,312:INFO:Uploading results into container
2024-11-13 18:15:50,312:INFO:Uploading model into container now
2024-11-13 18:15:50,313:INFO:_master_model_container: 15
2024-11-13 18:15:50,313:INFO:_display_container: 2
2024-11-13 18:15:50,313:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:15:50,313:INFO:create_model() successfully completed......................................
2024-11-13 18:15:50,491:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:50,491:INFO:Creating metrics dataframe
2024-11-13 18:15:50,503:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:15:50,503:INFO:Total runtime is 0.39612113237380975 minutes
2024-11-13 18:15:50,507:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:50,507:INFO:Initializing create_model()
2024-11-13 18:15:50,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:50,507:INFO:Checking exceptions
2024-11-13 18:15:50,507:INFO:Importing libraries
2024-11-13 18:15:50,508:INFO:Copying training dataset
2024-11-13 18:15:50,514:INFO:Defining folds
2024-11-13 18:15:50,515:INFO:Declaring metric variables
2024-11-13 18:15:50,518:INFO:Importing untrained model
2024-11-13 18:15:50,522:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:15:50,528:INFO:Starting cross validation
2024-11-13 18:15:50,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:52,296:INFO:Calculating mean and std
2024-11-13 18:15:52,299:INFO:Creating metrics dataframe
2024-11-13 18:15:52,307:INFO:Uploading results into container
2024-11-13 18:15:52,307:INFO:Uploading model into container now
2024-11-13 18:15:52,308:INFO:_master_model_container: 16
2024-11-13 18:15:52,308:INFO:_display_container: 2
2024-11-13 18:15:52,308:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:15:52,308:INFO:create_model() successfully completed......................................
2024-11-13 18:15:52,512:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:52,512:INFO:Creating metrics dataframe
2024-11-13 18:15:52,525:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:15:52,525:INFO:Total runtime is 0.4298223177591959 minutes
2024-11-13 18:15:52,529:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:52,529:INFO:Initializing create_model()
2024-11-13 18:15:52,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:52,529:INFO:Checking exceptions
2024-11-13 18:15:52,529:INFO:Importing libraries
2024-11-13 18:15:52,529:INFO:Copying training dataset
2024-11-13 18:15:52,536:INFO:Defining folds
2024-11-13 18:15:52,536:INFO:Declaring metric variables
2024-11-13 18:15:52,540:INFO:Importing untrained model
2024-11-13 18:15:52,544:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:15:52,550:INFO:Starting cross validation
2024-11-13 18:15:52,551:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:52,908:INFO:Calculating mean and std
2024-11-13 18:15:52,912:INFO:Creating metrics dataframe
2024-11-13 18:15:52,919:INFO:Uploading results into container
2024-11-13 18:15:52,919:INFO:Uploading model into container now
2024-11-13 18:15:52,920:INFO:_master_model_container: 17
2024-11-13 18:15:52,920:INFO:_display_container: 2
2024-11-13 18:15:52,921:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:15:52,921:INFO:create_model() successfully completed......................................
2024-11-13 18:15:53,098:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:53,099:INFO:Creating metrics dataframe
2024-11-13 18:15:53,113:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:15:53,113:INFO:Total runtime is 0.4396182298660278 minutes
2024-11-13 18:15:53,116:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:53,117:INFO:Initializing create_model()
2024-11-13 18:15:53,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:53,117:INFO:Checking exceptions
2024-11-13 18:15:53,117:INFO:Importing libraries
2024-11-13 18:15:53,117:INFO:Copying training dataset
2024-11-13 18:15:53,124:INFO:Defining folds
2024-11-13 18:15:53,124:INFO:Declaring metric variables
2024-11-13 18:15:53,128:INFO:Importing untrained model
2024-11-13 18:15:53,132:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:15:53,138:INFO:Starting cross validation
2024-11-13 18:15:53,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:22:46,535:INFO:Calculating mean and std
2024-11-13 18:22:46,539:INFO:Creating metrics dataframe
2024-11-13 18:22:46,545:INFO:Uploading results into container
2024-11-13 18:22:46,546:INFO:Uploading model into container now
2024-11-13 18:22:46,547:INFO:_master_model_container: 18
2024-11-13 18:22:46,547:INFO:_display_container: 2
2024-11-13 18:22:46,548:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:22:46,548:INFO:create_model() successfully completed......................................
2024-11-13 18:22:46,761:INFO:SubProcess create_model() end ==================================
2024-11-13 18:22:46,761:INFO:Creating metrics dataframe
2024-11-13 18:22:46,775:INFO:Initializing CatBoost Regressor
2024-11-13 18:22:46,775:INFO:Total runtime is 7.333981847763061 minutes
2024-11-13 18:22:46,778:INFO:SubProcess create_model() called ==================================
2024-11-13 18:22:46,779:INFO:Initializing create_model()
2024-11-13 18:22:46,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:22:46,779:INFO:Checking exceptions
2024-11-13 18:22:46,779:INFO:Importing libraries
2024-11-13 18:22:46,779:INFO:Copying training dataset
2024-11-13 18:22:46,787:INFO:Defining folds
2024-11-13 18:22:46,788:INFO:Declaring metric variables
2024-11-13 18:22:46,791:INFO:Importing untrained model
2024-11-13 18:22:46,795:INFO:CatBoost Regressor Imported successfully
2024-11-13 18:22:46,801:INFO:Starting cross validation
2024-11-13 18:22:46,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:22:57,501:INFO:Calculating mean and std
2024-11-13 18:22:57,505:INFO:Creating metrics dataframe
2024-11-13 18:22:57,513:INFO:Uploading results into container
2024-11-13 18:22:57,514:INFO:Uploading model into container now
2024-11-13 18:22:57,515:INFO:_master_model_container: 19
2024-11-13 18:22:57,515:INFO:_display_container: 2
2024-11-13 18:22:57,515:INFO:<catboost.core.CatBoostRegressor object at 0x7ff4bc1cef10>
2024-11-13 18:22:57,516:INFO:create_model() successfully completed......................................
2024-11-13 18:22:57,744:INFO:SubProcess create_model() end ==================================
2024-11-13 18:22:57,744:INFO:Creating metrics dataframe
2024-11-13 18:22:57,759:INFO:Initializing Dummy Regressor
2024-11-13 18:22:57,759:INFO:Total runtime is 7.517054319381714 minutes
2024-11-13 18:22:57,763:INFO:SubProcess create_model() called ==================================
2024-11-13 18:22:57,763:INFO:Initializing create_model()
2024-11-13 18:22:57,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:22:57,763:INFO:Checking exceptions
2024-11-13 18:22:57,763:INFO:Importing libraries
2024-11-13 18:22:57,763:INFO:Copying training dataset
2024-11-13 18:22:57,773:INFO:Defining folds
2024-11-13 18:22:57,773:INFO:Declaring metric variables
2024-11-13 18:22:57,777:INFO:Importing untrained model
2024-11-13 18:22:57,780:INFO:Dummy Regressor Imported successfully
2024-11-13 18:22:57,787:INFO:Starting cross validation
2024-11-13 18:22:57,788:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:23:00,977:INFO:Calculating mean and std
2024-11-13 18:23:00,982:INFO:Creating metrics dataframe
2024-11-13 18:23:00,989:INFO:Uploading results into container
2024-11-13 18:23:00,990:INFO:Uploading model into container now
2024-11-13 18:23:00,991:INFO:_master_model_container: 20
2024-11-13 18:23:00,991:INFO:_display_container: 2
2024-11-13 18:23:00,992:INFO:DummyRegressor()
2024-11-13 18:23:00,992:INFO:create_model() successfully completed......................................
2024-11-13 18:23:01,240:INFO:SubProcess create_model() end ==================================
2024-11-13 18:23:01,240:INFO:Creating metrics dataframe
2024-11-13 18:23:01,264:INFO:Initializing create_model()
2024-11-13 18:23:01,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:23:01,265:INFO:Checking exceptions
2024-11-13 18:23:01,266:INFO:Importing libraries
2024-11-13 18:23:01,266:INFO:Copying training dataset
2024-11-13 18:23:01,273:INFO:Defining folds
2024-11-13 18:23:01,273:INFO:Declaring metric variables
2024-11-13 18:23:01,273:INFO:Importing untrained model
2024-11-13 18:23:01,273:INFO:Declaring custom model
2024-11-13 18:23:01,274:INFO:Linear Regression Imported successfully
2024-11-13 18:23:01,274:INFO:Cross validation set to False
2024-11-13 18:23:01,274:INFO:Fitting Model
2024-11-13 18:23:01,292:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:23:01,292:INFO:create_model() successfully completed......................................
2024-11-13 18:23:01,550:INFO:_master_model_container: 20
2024-11-13 18:23:01,550:INFO:_display_container: 2
2024-11-13 18:23:01,550:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:23:01,551:INFO:compare_models() successfully completed......................................
2024-11-13 18:25:27,014:INFO:Initializing plot_model()
2024-11-13 18:25:27,014:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, system=True)
2024-11-13 18:25:27,015:INFO:Checking exceptions
2024-11-13 18:25:27,025:INFO:Preloading libraries
2024-11-13 18:25:27,026:INFO:Copying training dataset
2024-11-13 18:25:27,026:INFO:Plot type: residuals
2024-11-13 18:25:27,125:INFO:Fitting Model
2024-11-13 18:25:27,125:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2024-11-13 18:25:27,201:INFO:Scoring test/hold-out set
2024-11-13 18:25:27,937:INFO:Visual Rendered Successfully
2024-11-13 18:25:28,122:INFO:plot_model() successfully completed......................................
2024-11-13 18:25:55,296:INFO:Initializing plot_model()
2024-11-13 18:25:55,297:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, system=True)
2024-11-13 18:25:55,297:INFO:Checking exceptions
2024-11-13 18:25:55,306:INFO:Preloading libraries
2024-11-13 18:25:55,306:INFO:Copying training dataset
2024-11-13 18:25:55,306:INFO:Plot type: error
2024-11-13 18:25:55,373:INFO:Fitting Model
2024-11-13 18:25:55,374:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2024-11-13 18:25:55,374:INFO:Scoring test/hold-out set
2024-11-13 18:25:55,689:INFO:Visual Rendered Successfully
2024-11-13 18:25:55,881:INFO:plot_model() successfully completed......................................
2024-11-13 18:26:27,635:INFO:Initializing plot_model()
2024-11-13 18:26:27,635:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, system=True)
2024-11-13 18:26:27,635:INFO:Checking exceptions
2024-11-13 18:26:27,643:INFO:Preloading libraries
2024-11-13 18:26:27,643:INFO:Copying training dataset
2024-11-13 18:26:27,643:INFO:Plot type: feature
2024-11-13 18:26:27,793:INFO:Visual Rendered Successfully
2024-11-13 18:26:27,973:INFO:plot_model() successfully completed......................................
2024-11-13 18:36:51,064:INFO:PyCaret RegressionExperiment
2024-11-13 18:36:51,064:INFO:Logging name: reg-default-name
2024-11-13 18:36:51,064:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:36:51,064:INFO:version 3.2.0
2024-11-13 18:36:51,065:INFO:Initializing setup()
2024-11-13 18:36:51,065:INFO:self.USI: 4560
2024-11-13 18:36:51,065:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:36:51,065:INFO:Checking environment
2024-11-13 18:36:51,065:INFO:python_version: 3.8.13
2024-11-13 18:36:51,065:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:36:51,065:INFO:machine: x86_64
2024-11-13 18:36:51,065:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:36:51,065:INFO:Memory: svmem(total=270355722240, available=218183782400, percent=19.3, used=50090749952, free=55994060800, active=11659644928, inactive=142444417024, buffers=9957376, cached=164260954112, shared=187375616, slab=25015971840)
2024-11-13 18:36:51,069:INFO:Physical Core: 28
2024-11-13 18:36:51,069:INFO:Logical Core: 56
2024-11-13 18:36:51,069:INFO:Checking libraries
2024-11-13 18:36:51,069:INFO:System:
2024-11-13 18:36:51,069:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:36:51,069:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:36:51,069:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:36:51,069:INFO:PyCaret required dependencies:
2024-11-13 18:36:51,069:INFO:                 pip: 22.2.2
2024-11-13 18:36:51,069:INFO:          setuptools: 63.4.2
2024-11-13 18:36:51,069:INFO:             pycaret: 3.2.0
2024-11-13 18:36:51,069:INFO:             IPython: 8.12.2
2024-11-13 18:36:51,069:INFO:          ipywidgets: 7.7.1
2024-11-13 18:36:51,069:INFO:                tqdm: 4.64.1
2024-11-13 18:36:51,069:INFO:               numpy: 1.23.5
2024-11-13 18:36:51,069:INFO:              pandas: 1.5.3
2024-11-13 18:36:51,070:INFO:              jinja2: 3.1.2
2024-11-13 18:36:51,070:INFO:               scipy: 1.10.1
2024-11-13 18:36:51,070:INFO:              joblib: 1.3.0
2024-11-13 18:36:51,070:INFO:             sklearn: 1.1.2
2024-11-13 18:36:51,070:INFO:                pyod: 2.0.2
2024-11-13 18:36:51,070:INFO:            imblearn: 0.12.4
2024-11-13 18:36:51,070:INFO:   category_encoders: 2.6.4
2024-11-13 18:36:51,070:INFO:            lightgbm: 4.5.0
2024-11-13 18:36:51,070:INFO:               numba: 0.57.1
2024-11-13 18:36:51,070:INFO:            requests: 2.28.1
2024-11-13 18:36:51,070:INFO:          matplotlib: 3.5.1
2024-11-13 18:36:51,070:INFO:          scikitplot: 0.3.7
2024-11-13 18:36:51,070:INFO:         yellowbrick: 1.5
2024-11-13 18:36:51,070:INFO:              plotly: 5.24.1
2024-11-13 18:36:51,070:INFO:    plotly-resampler: Not installed
2024-11-13 18:36:51,070:INFO:             kaleido: 0.2.1
2024-11-13 18:36:51,070:INFO:           schemdraw: 0.15
2024-11-13 18:36:51,070:INFO:         statsmodels: 0.13.2
2024-11-13 18:36:51,070:INFO:              sktime: 0.21.1
2024-11-13 18:36:51,070:INFO:               tbats: 1.1.3
2024-11-13 18:36:51,071:INFO:            pmdarima: 2.0.4
2024-11-13 18:36:51,071:INFO:              psutil: 5.9.1
2024-11-13 18:36:51,071:INFO:          markupsafe: 2.1.1
2024-11-13 18:36:51,071:INFO:             pickle5: Not installed
2024-11-13 18:36:51,071:INFO:         cloudpickle: 2.1.0
2024-11-13 18:36:51,071:INFO:         deprecation: 2.1.0
2024-11-13 18:36:51,071:INFO:              xxhash: 3.5.0
2024-11-13 18:36:51,071:INFO:           wurlitzer: 3.1.1
2024-11-13 18:36:51,071:INFO:PyCaret optional dependencies:
2024-11-13 18:36:51,071:INFO:                shap: 0.44.1
2024-11-13 18:36:51,071:INFO:           interpret: 0.6.5
2024-11-13 18:36:51,071:INFO:                umap: 0.5.7
2024-11-13 18:36:51,071:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:36:51,071:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:36:51,071:INFO:             autoviz: Not installed
2024-11-13 18:36:51,071:INFO:           fairlearn: 0.7.0
2024-11-13 18:36:51,071:INFO:          deepchecks: Not installed
2024-11-13 18:36:51,071:INFO:             xgboost: 2.1.1
2024-11-13 18:36:51,071:INFO:            catboost: 1.2.7
2024-11-13 18:36:51,071:INFO:              kmodes: 0.12.2
2024-11-13 18:36:51,071:INFO:             mlxtend: 0.23.1
2024-11-13 18:36:51,071:INFO:       statsforecast: 1.5.0
2024-11-13 18:36:51,071:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:36:51,071:INFO:                 ray: 2.10.0
2024-11-13 18:36:51,071:INFO:            hyperopt: 0.2.7
2024-11-13 18:36:51,071:INFO:              optuna: 4.1.0
2024-11-13 18:36:51,072:INFO:               skopt: 0.10.2
2024-11-13 18:36:51,072:INFO:              mlflow: 1.30.1
2024-11-13 18:36:51,072:INFO:              gradio: 3.50.2
2024-11-13 18:36:51,072:INFO:             fastapi: 0.115.5
2024-11-13 18:36:51,072:INFO:             uvicorn: 0.32.0
2024-11-13 18:36:51,072:INFO:              m2cgen: 0.10.0
2024-11-13 18:36:51,072:INFO:           evidently: 0.2.8
2024-11-13 18:36:51,072:INFO:               fugue: 0.8.6
2024-11-13 18:36:51,072:INFO:           streamlit: Not installed
2024-11-13 18:36:51,072:INFO:             prophet: Not installed
2024-11-13 18:36:51,072:INFO:None
2024-11-13 18:36:51,072:INFO:Set up data.
2024-11-13 18:36:51,079:INFO:Set up folding strategy.
2024-11-13 18:36:51,079:INFO:Set up train/test split.
2024-11-13 18:36:51,085:INFO:Set up index.
2024-11-13 18:36:51,086:INFO:Assigning column types.
2024-11-13 18:36:51,091:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:36:51,091:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,096:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,101:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,210:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,213:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,213:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,217:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,221:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,269:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,305:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,305:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,308:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,308:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:36:51,312:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,316:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,363:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,400:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,402:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,406:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,410:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,494:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,496:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,497:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:36:51,504:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,554:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,590:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,592:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,600:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,648:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,684:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,686:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,686:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:36:51,741:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,777:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,780:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,871:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,872:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,874:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,874:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:36:51,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,966:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,968:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,023:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:52,060:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:52,062:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,062:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:36:52,156:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:52,159:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,252:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:52,254:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,255:INFO:Preparing preprocessing pipeline...
2024-11-13 18:36:52,255:INFO:Set up simple imputation.
2024-11-13 18:36:52,272:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:36:52,275:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:36:52,275:INFO:Creating final display dataframe.
2024-11-13 18:36:52,330:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4560
2024-11-13 18:36:52,437:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:52,439:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,531:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:52,533:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,534:INFO:setup() successfully completed in 1.47s...............
2024-11-13 18:38:43,222:INFO:PyCaret RegressionExperiment
2024-11-13 18:38:43,222:INFO:Logging name: reg-default-name
2024-11-13 18:38:43,222:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:38:43,222:INFO:version 3.2.0
2024-11-13 18:38:43,222:INFO:Initializing setup()
2024-11-13 18:38:43,222:INFO:self.USI: 512d
2024-11-13 18:38:43,222:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:38:43,222:INFO:Checking environment
2024-11-13 18:38:43,222:INFO:python_version: 3.8.13
2024-11-13 18:38:43,222:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:38:43,223:INFO:machine: x86_64
2024-11-13 18:38:43,223:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:38:43,223:INFO:Memory: svmem(total=270355722240, available=218161405952, percent=19.3, used=50113228800, free=56245051392, active=11659640832, inactive=142188494848, buffers=8888320, cached=163988553728, shared=187375616, slab=25015148544)
2024-11-13 18:38:43,227:INFO:Physical Core: 28
2024-11-13 18:38:43,227:INFO:Logical Core: 56
2024-11-13 18:38:43,227:INFO:Checking libraries
2024-11-13 18:38:43,227:INFO:System:
2024-11-13 18:38:43,227:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:38:43,227:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:38:43,227:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:38:43,227:INFO:PyCaret required dependencies:
2024-11-13 18:38:43,228:INFO:                 pip: 22.2.2
2024-11-13 18:38:43,228:INFO:          setuptools: 63.4.2
2024-11-13 18:38:43,228:INFO:             pycaret: 3.2.0
2024-11-13 18:38:43,228:INFO:             IPython: 8.12.2
2024-11-13 18:38:43,228:INFO:          ipywidgets: 7.7.1
2024-11-13 18:38:43,228:INFO:                tqdm: 4.64.1
2024-11-13 18:38:43,228:INFO:               numpy: 1.23.5
2024-11-13 18:38:43,228:INFO:              pandas: 1.5.3
2024-11-13 18:38:43,228:INFO:              jinja2: 3.1.2
2024-11-13 18:38:43,228:INFO:               scipy: 1.10.1
2024-11-13 18:38:43,228:INFO:              joblib: 1.3.0
2024-11-13 18:38:43,228:INFO:             sklearn: 1.1.2
2024-11-13 18:38:43,228:INFO:                pyod: 2.0.2
2024-11-13 18:38:43,228:INFO:            imblearn: 0.12.4
2024-11-13 18:38:43,228:INFO:   category_encoders: 2.6.4
2024-11-13 18:38:43,228:INFO:            lightgbm: 4.5.0
2024-11-13 18:38:43,229:INFO:               numba: 0.57.1
2024-11-13 18:38:43,229:INFO:            requests: 2.28.1
2024-11-13 18:38:43,229:INFO:          matplotlib: 3.5.1
2024-11-13 18:38:43,229:INFO:          scikitplot: 0.3.7
2024-11-13 18:38:43,229:INFO:         yellowbrick: 1.5
2024-11-13 18:38:43,229:INFO:              plotly: 5.24.1
2024-11-13 18:38:43,229:INFO:    plotly-resampler: Not installed
2024-11-13 18:38:43,229:INFO:             kaleido: 0.2.1
2024-11-13 18:38:43,229:INFO:           schemdraw: 0.15
2024-11-13 18:38:43,229:INFO:         statsmodels: 0.13.2
2024-11-13 18:38:43,229:INFO:              sktime: 0.21.1
2024-11-13 18:38:43,229:INFO:               tbats: 1.1.3
2024-11-13 18:38:43,229:INFO:            pmdarima: 2.0.4
2024-11-13 18:38:43,229:INFO:              psutil: 5.9.1
2024-11-13 18:38:43,229:INFO:          markupsafe: 2.1.1
2024-11-13 18:38:43,229:INFO:             pickle5: Not installed
2024-11-13 18:38:43,230:INFO:         cloudpickle: 2.1.0
2024-11-13 18:38:43,230:INFO:         deprecation: 2.1.0
2024-11-13 18:38:43,230:INFO:              xxhash: 3.5.0
2024-11-13 18:38:43,230:INFO:           wurlitzer: 3.1.1
2024-11-13 18:38:43,230:INFO:PyCaret optional dependencies:
2024-11-13 18:38:43,230:INFO:                shap: 0.44.1
2024-11-13 18:38:43,230:INFO:           interpret: 0.6.5
2024-11-13 18:38:43,230:INFO:                umap: 0.5.7
2024-11-13 18:38:43,230:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:38:43,230:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:38:43,230:INFO:             autoviz: Not installed
2024-11-13 18:38:43,230:INFO:           fairlearn: 0.7.0
2024-11-13 18:38:43,230:INFO:          deepchecks: Not installed
2024-11-13 18:38:43,230:INFO:             xgboost: 2.1.1
2024-11-13 18:38:43,231:INFO:            catboost: 1.2.7
2024-11-13 18:38:43,231:INFO:              kmodes: 0.12.2
2024-11-13 18:38:43,231:INFO:             mlxtend: 0.23.1
2024-11-13 18:38:43,231:INFO:       statsforecast: 1.5.0
2024-11-13 18:38:43,231:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:38:43,231:INFO:                 ray: 2.10.0
2024-11-13 18:38:43,231:INFO:            hyperopt: 0.2.7
2024-11-13 18:38:43,231:INFO:              optuna: 4.1.0
2024-11-13 18:38:43,231:INFO:               skopt: 0.10.2
2024-11-13 18:38:43,231:INFO:              mlflow: 1.30.1
2024-11-13 18:38:43,231:INFO:              gradio: 3.50.2
2024-11-13 18:38:43,231:INFO:             fastapi: 0.115.5
2024-11-13 18:38:43,231:INFO:             uvicorn: 0.32.0
2024-11-13 18:38:43,231:INFO:              m2cgen: 0.10.0
2024-11-13 18:38:43,231:INFO:           evidently: 0.2.8
2024-11-13 18:38:43,231:INFO:               fugue: 0.8.6
2024-11-13 18:38:43,231:INFO:           streamlit: Not installed
2024-11-13 18:38:43,231:INFO:             prophet: Not installed
2024-11-13 18:38:43,232:INFO:None
2024-11-13 18:38:43,232:INFO:Set up data.
2024-11-13 18:38:43,244:INFO:Set up folding strategy.
2024-11-13 18:38:43,244:INFO:Set up train/test split.
2024-11-13 18:38:43,249:INFO:Set up index.
2024-11-13 18:38:43,252:INFO:Assigning column types.
2024-11-13 18:38:43,257:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:38:43,257:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,262:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,267:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,374:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,376:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,377:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,381:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,385:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,469:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,471:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,472:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:38:43,476:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,479:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,563:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,565:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,569:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,573:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,656:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,658:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,659:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:38:43,666:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,714:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,749:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,750:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,752:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,760:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,843:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,846:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,846:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:38:43,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,937:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,940:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:44,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:44,031:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,033:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,034:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:38:44,091:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:44,129:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,132:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,190:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:44,227:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,229:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,230:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:38:44,321:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,323:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,421:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,423:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,425:INFO:Preparing preprocessing pipeline...
2024-11-13 18:38:44,425:INFO:Set up simple imputation.
2024-11-13 18:38:44,441:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:38:44,444:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:38:44,444:INFO:Creating final display dataframe.
2024-11-13 18:38:44,498:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              512d
2024-11-13 18:38:44,601:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,603:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,695:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,697:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,698:INFO:setup() successfully completed in 1.48s...............
2024-11-13 18:39:14,328:INFO:Initializing compare_models()
2024-11-13 18:39:14,329:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:39:14,329:INFO:Checking exceptions
2024-11-13 18:39:14,335:INFO:Preparing display monitor
2024-11-13 18:39:14,375:INFO:Initializing Linear Regression
2024-11-13 18:39:14,376:INFO:Total runtime is 3.6160151163736978e-06 minutes
2024-11-13 18:39:14,379:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:14,379:INFO:Initializing create_model()
2024-11-13 18:39:14,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:14,380:INFO:Checking exceptions
2024-11-13 18:39:14,380:INFO:Importing libraries
2024-11-13 18:39:14,380:INFO:Copying training dataset
2024-11-13 18:39:14,386:INFO:Defining folds
2024-11-13 18:39:14,386:INFO:Declaring metric variables
2024-11-13 18:39:14,390:INFO:Importing untrained model
2024-11-13 18:39:14,394:INFO:Linear Regression Imported successfully
2024-11-13 18:39:14,401:INFO:Starting cross validation
2024-11-13 18:39:14,402:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:18,759:INFO:Calculating mean and std
2024-11-13 18:39:18,764:INFO:Creating metrics dataframe
2024-11-13 18:39:18,772:INFO:Uploading results into container
2024-11-13 18:39:18,772:INFO:Uploading model into container now
2024-11-13 18:39:18,773:INFO:_master_model_container: 1
2024-11-13 18:39:18,773:INFO:_display_container: 2
2024-11-13 18:39:18,774:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:39:18,774:INFO:create_model() successfully completed......................................
2024-11-13 18:39:19,053:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:19,053:INFO:Creating metrics dataframe
2024-11-13 18:39:19,063:INFO:Initializing Lasso Regression
2024-11-13 18:39:19,063:INFO:Total runtime is 0.0781342109044393 minutes
2024-11-13 18:39:19,067:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:19,067:INFO:Initializing create_model()
2024-11-13 18:39:19,067:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:19,067:INFO:Checking exceptions
2024-11-13 18:39:19,067:INFO:Importing libraries
2024-11-13 18:39:19,068:INFO:Copying training dataset
2024-11-13 18:39:19,076:INFO:Defining folds
2024-11-13 18:39:19,076:INFO:Declaring metric variables
2024-11-13 18:39:19,080:INFO:Importing untrained model
2024-11-13 18:39:19,083:INFO:Lasso Regression Imported successfully
2024-11-13 18:39:19,090:INFO:Starting cross validation
2024-11-13 18:39:19,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:21,954:INFO:Calculating mean and std
2024-11-13 18:39:21,958:INFO:Creating metrics dataframe
2024-11-13 18:39:21,964:INFO:Uploading results into container
2024-11-13 18:39:21,965:INFO:Uploading model into container now
2024-11-13 18:39:21,966:INFO:_master_model_container: 2
2024-11-13 18:39:21,966:INFO:_display_container: 2
2024-11-13 18:39:21,966:INFO:Lasso(random_state=123)
2024-11-13 18:39:21,966:INFO:create_model() successfully completed......................................
2024-11-13 18:39:22,151:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:22,152:INFO:Creating metrics dataframe
2024-11-13 18:39:22,162:INFO:Initializing Ridge Regression
2024-11-13 18:39:22,162:INFO:Total runtime is 0.12978219588597617 minutes
2024-11-13 18:39:22,165:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:22,166:INFO:Initializing create_model()
2024-11-13 18:39:22,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:22,166:INFO:Checking exceptions
2024-11-13 18:39:22,166:INFO:Importing libraries
2024-11-13 18:39:22,166:INFO:Copying training dataset
2024-11-13 18:39:22,173:INFO:Defining folds
2024-11-13 18:39:22,173:INFO:Declaring metric variables
2024-11-13 18:39:22,177:INFO:Importing untrained model
2024-11-13 18:39:22,180:INFO:Ridge Regression Imported successfully
2024-11-13 18:39:22,186:INFO:Starting cross validation
2024-11-13 18:39:22,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:25,027:INFO:Calculating mean and std
2024-11-13 18:39:25,031:INFO:Creating metrics dataframe
2024-11-13 18:39:25,037:INFO:Uploading results into container
2024-11-13 18:39:25,037:INFO:Uploading model into container now
2024-11-13 18:39:25,038:INFO:_master_model_container: 3
2024-11-13 18:39:25,039:INFO:_display_container: 2
2024-11-13 18:39:25,039:INFO:Ridge(random_state=123)
2024-11-13 18:39:25,039:INFO:create_model() successfully completed......................................
2024-11-13 18:39:25,219:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:25,219:INFO:Creating metrics dataframe
2024-11-13 18:39:25,229:INFO:Initializing Elastic Net
2024-11-13 18:39:25,229:INFO:Total runtime is 0.1809010148048401 minutes
2024-11-13 18:39:25,233:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:25,233:INFO:Initializing create_model()
2024-11-13 18:39:25,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:25,234:INFO:Checking exceptions
2024-11-13 18:39:25,234:INFO:Importing libraries
2024-11-13 18:39:25,234:INFO:Copying training dataset
2024-11-13 18:39:25,241:INFO:Defining folds
2024-11-13 18:39:25,241:INFO:Declaring metric variables
2024-11-13 18:39:25,244:INFO:Importing untrained model
2024-11-13 18:39:25,248:INFO:Elastic Net Imported successfully
2024-11-13 18:39:25,255:INFO:Starting cross validation
2024-11-13 18:39:25,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:28,116:INFO:Calculating mean and std
2024-11-13 18:39:28,120:INFO:Creating metrics dataframe
2024-11-13 18:39:28,127:INFO:Uploading results into container
2024-11-13 18:39:28,128:INFO:Uploading model into container now
2024-11-13 18:39:28,128:INFO:_master_model_container: 4
2024-11-13 18:39:28,128:INFO:_display_container: 2
2024-11-13 18:39:28,129:INFO:ElasticNet(random_state=123)
2024-11-13 18:39:28,129:INFO:create_model() successfully completed......................................
2024-11-13 18:39:28,304:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:28,305:INFO:Creating metrics dataframe
2024-11-13 18:39:28,316:INFO:Initializing Least Angle Regression
2024-11-13 18:39:28,316:INFO:Total runtime is 0.23234000205993655 minutes
2024-11-13 18:39:28,319:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:28,319:INFO:Initializing create_model()
2024-11-13 18:39:28,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:28,320:INFO:Checking exceptions
2024-11-13 18:39:28,320:INFO:Importing libraries
2024-11-13 18:39:28,320:INFO:Copying training dataset
2024-11-13 18:39:28,329:INFO:Defining folds
2024-11-13 18:39:28,329:INFO:Declaring metric variables
2024-11-13 18:39:28,333:INFO:Importing untrained model
2024-11-13 18:39:28,336:INFO:Least Angle Regression Imported successfully
2024-11-13 18:39:28,343:INFO:Starting cross validation
2024-11-13 18:39:28,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:30,883:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:30,885:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,029:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,034:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,053:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,121:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,126:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,170:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,261:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,371:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,384:INFO:Calculating mean and std
2024-11-13 18:39:31,388:INFO:Creating metrics dataframe
2024-11-13 18:39:31,395:INFO:Uploading results into container
2024-11-13 18:39:31,396:INFO:Uploading model into container now
2024-11-13 18:39:31,396:INFO:_master_model_container: 5
2024-11-13 18:39:31,397:INFO:_display_container: 2
2024-11-13 18:39:31,397:INFO:Lars(random_state=123)
2024-11-13 18:39:31,397:INFO:create_model() successfully completed......................................
2024-11-13 18:39:31,582:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:31,582:INFO:Creating metrics dataframe
2024-11-13 18:39:31,593:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:39:31,593:INFO:Total runtime is 0.2869676907857259 minutes
2024-11-13 18:39:31,597:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:31,597:INFO:Initializing create_model()
2024-11-13 18:39:31,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:31,597:INFO:Checking exceptions
2024-11-13 18:39:31,598:INFO:Importing libraries
2024-11-13 18:39:31,598:INFO:Copying training dataset
2024-11-13 18:39:31,604:INFO:Defining folds
2024-11-13 18:39:31,605:INFO:Declaring metric variables
2024-11-13 18:39:31,608:INFO:Importing untrained model
2024-11-13 18:39:31,612:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:39:31,619:INFO:Starting cross validation
2024-11-13 18:39:31,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:31,698:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:31,704:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:31,709:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:31,712:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,128:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,152:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,205:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,338:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,463:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,488:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,503:INFO:Calculating mean and std
2024-11-13 18:39:34,507:INFO:Creating metrics dataframe
2024-11-13 18:39:34,512:INFO:Uploading results into container
2024-11-13 18:39:34,513:INFO:Uploading model into container now
2024-11-13 18:39:34,513:INFO:_master_model_container: 6
2024-11-13 18:39:34,513:INFO:_display_container: 2
2024-11-13 18:39:34,514:INFO:LassoLars(random_state=123)
2024-11-13 18:39:34,514:INFO:create_model() successfully completed......................................
2024-11-13 18:39:34,703:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:34,704:INFO:Creating metrics dataframe
2024-11-13 18:39:34,715:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:39:34,715:INFO:Total runtime is 0.3390020330746969 minutes
2024-11-13 18:39:34,719:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:34,719:INFO:Initializing create_model()
2024-11-13 18:39:34,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:34,719:INFO:Checking exceptions
2024-11-13 18:39:34,719:INFO:Importing libraries
2024-11-13 18:39:34,720:INFO:Copying training dataset
2024-11-13 18:39:34,727:INFO:Defining folds
2024-11-13 18:39:34,727:INFO:Declaring metric variables
2024-11-13 18:39:34,731:INFO:Importing untrained model
2024-11-13 18:39:34,734:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:39:34,743:INFO:Starting cross validation
2024-11-13 18:39:34,744:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:34,782:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,789:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,796:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,799:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,803:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,813:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,819:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,822:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,826:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,833:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,853:INFO:Calculating mean and std
2024-11-13 18:39:34,857:INFO:Creating metrics dataframe
2024-11-13 18:39:34,863:INFO:Uploading results into container
2024-11-13 18:39:34,864:INFO:Uploading model into container now
2024-11-13 18:39:34,865:INFO:_master_model_container: 7
2024-11-13 18:39:34,865:INFO:_display_container: 2
2024-11-13 18:39:34,865:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:39:34,865:INFO:create_model() successfully completed......................................
2024-11-13 18:39:35,071:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:35,071:INFO:Creating metrics dataframe
2024-11-13 18:39:35,085:INFO:Initializing Bayesian Ridge
2024-11-13 18:39:35,085:INFO:Total runtime is 0.345161259174347 minutes
2024-11-13 18:39:35,089:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:35,089:INFO:Initializing create_model()
2024-11-13 18:39:35,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:35,089:INFO:Checking exceptions
2024-11-13 18:39:35,090:INFO:Importing libraries
2024-11-13 18:39:35,090:INFO:Copying training dataset
2024-11-13 18:39:35,098:INFO:Defining folds
2024-11-13 18:39:35,098:INFO:Declaring metric variables
2024-11-13 18:39:35,102:INFO:Importing untrained model
2024-11-13 18:39:35,106:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:39:35,114:INFO:Starting cross validation
2024-11-13 18:39:35,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:35,224:INFO:Calculating mean and std
2024-11-13 18:39:35,228:INFO:Creating metrics dataframe
2024-11-13 18:39:35,235:INFO:Uploading results into container
2024-11-13 18:39:35,235:INFO:Uploading model into container now
2024-11-13 18:39:35,236:INFO:_master_model_container: 8
2024-11-13 18:39:35,236:INFO:_display_container: 2
2024-11-13 18:39:35,237:INFO:BayesianRidge()
2024-11-13 18:39:35,237:INFO:create_model() successfully completed......................................
2024-11-13 18:39:35,420:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:35,421:INFO:Creating metrics dataframe
2024-11-13 18:39:35,432:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:39:35,432:INFO:Total runtime is 0.3509482900301616 minutes
2024-11-13 18:39:35,436:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:35,436:INFO:Initializing create_model()
2024-11-13 18:39:35,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:35,436:INFO:Checking exceptions
2024-11-13 18:39:35,436:INFO:Importing libraries
2024-11-13 18:39:35,437:INFO:Copying training dataset
2024-11-13 18:39:35,443:INFO:Defining folds
2024-11-13 18:39:35,444:INFO:Declaring metric variables
2024-11-13 18:39:35,447:INFO:Importing untrained model
2024-11-13 18:39:35,450:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:39:35,457:INFO:Starting cross validation
2024-11-13 18:39:35,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:35,654:INFO:Calculating mean and std
2024-11-13 18:39:35,658:INFO:Creating metrics dataframe
2024-11-13 18:39:35,664:INFO:Uploading results into container
2024-11-13 18:39:35,664:INFO:Uploading model into container now
2024-11-13 18:39:35,665:INFO:_master_model_container: 9
2024-11-13 18:39:35,665:INFO:_display_container: 2
2024-11-13 18:39:35,666:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:39:35,666:INFO:create_model() successfully completed......................................
2024-11-13 18:39:35,914:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:35,914:INFO:Creating metrics dataframe
2024-11-13 18:39:35,933:INFO:Initializing Huber Regressor
2024-11-13 18:39:35,934:INFO:Total runtime is 0.35930647452672326 minutes
2024-11-13 18:39:35,938:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:35,938:INFO:Initializing create_model()
2024-11-13 18:39:35,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:35,938:INFO:Checking exceptions
2024-11-13 18:39:35,939:INFO:Importing libraries
2024-11-13 18:39:35,939:INFO:Copying training dataset
2024-11-13 18:39:35,947:INFO:Defining folds
2024-11-13 18:39:35,947:INFO:Declaring metric variables
2024-11-13 18:39:35,951:INFO:Importing untrained model
2024-11-13 18:39:35,956:INFO:Huber Regressor Imported successfully
2024-11-13 18:39:35,963:INFO:Starting cross validation
2024-11-13 18:39:35,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:36,231:INFO:Calculating mean and std
2024-11-13 18:39:36,235:INFO:Creating metrics dataframe
2024-11-13 18:39:36,242:INFO:Uploading results into container
2024-11-13 18:39:36,242:INFO:Uploading model into container now
2024-11-13 18:39:36,243:INFO:_master_model_container: 10
2024-11-13 18:39:36,243:INFO:_display_container: 2
2024-11-13 18:39:36,243:INFO:HuberRegressor()
2024-11-13 18:39:36,244:INFO:create_model() successfully completed......................................
2024-11-13 18:39:36,444:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:36,444:INFO:Creating metrics dataframe
2024-11-13 18:39:36,457:INFO:Initializing K Neighbors Regressor
2024-11-13 18:39:36,457:INFO:Total runtime is 0.3680347839991252 minutes
2024-11-13 18:39:36,461:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:36,461:INFO:Initializing create_model()
2024-11-13 18:39:36,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:36,461:INFO:Checking exceptions
2024-11-13 18:39:36,461:INFO:Importing libraries
2024-11-13 18:39:36,461:INFO:Copying training dataset
2024-11-13 18:39:36,470:INFO:Defining folds
2024-11-13 18:39:36,470:INFO:Declaring metric variables
2024-11-13 18:39:36,474:INFO:Importing untrained model
2024-11-13 18:39:36,477:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:39:36,484:INFO:Starting cross validation
2024-11-13 18:39:36,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:36,651:INFO:Calculating mean and std
2024-11-13 18:39:36,655:INFO:Creating metrics dataframe
2024-11-13 18:39:36,662:INFO:Uploading results into container
2024-11-13 18:39:36,663:INFO:Uploading model into container now
2024-11-13 18:39:36,663:INFO:_master_model_container: 11
2024-11-13 18:39:36,663:INFO:_display_container: 2
2024-11-13 18:39:36,664:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:39:36,664:INFO:create_model() successfully completed......................................
2024-11-13 18:39:36,834:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:36,834:INFO:Creating metrics dataframe
2024-11-13 18:39:36,846:INFO:Initializing Decision Tree Regressor
2024-11-13 18:39:36,846:INFO:Total runtime is 0.3745107332865398 minutes
2024-11-13 18:39:36,849:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:36,849:INFO:Initializing create_model()
2024-11-13 18:39:36,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:36,850:INFO:Checking exceptions
2024-11-13 18:39:36,850:INFO:Importing libraries
2024-11-13 18:39:36,850:INFO:Copying training dataset
2024-11-13 18:39:36,857:INFO:Defining folds
2024-11-13 18:39:36,857:INFO:Declaring metric variables
2024-11-13 18:39:36,860:INFO:Importing untrained model
2024-11-13 18:39:36,863:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:39:36,869:INFO:Starting cross validation
2024-11-13 18:39:36,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:37,035:INFO:Calculating mean and std
2024-11-13 18:39:37,039:INFO:Creating metrics dataframe
2024-11-13 18:39:37,046:INFO:Uploading results into container
2024-11-13 18:39:37,047:INFO:Uploading model into container now
2024-11-13 18:39:37,048:INFO:_master_model_container: 12
2024-11-13 18:39:37,048:INFO:_display_container: 2
2024-11-13 18:39:37,048:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:39:37,048:INFO:create_model() successfully completed......................................
2024-11-13 18:39:37,229:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:37,229:INFO:Creating metrics dataframe
2024-11-13 18:39:37,241:INFO:Initializing Random Forest Regressor
2024-11-13 18:39:37,241:INFO:Total runtime is 0.3810944040616354 minutes
2024-11-13 18:39:37,244:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:37,244:INFO:Initializing create_model()
2024-11-13 18:39:37,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:37,245:INFO:Checking exceptions
2024-11-13 18:39:37,245:INFO:Importing libraries
2024-11-13 18:39:37,245:INFO:Copying training dataset
2024-11-13 18:39:37,252:INFO:Defining folds
2024-11-13 18:39:37,252:INFO:Declaring metric variables
2024-11-13 18:39:37,255:INFO:Importing untrained model
2024-11-13 18:39:37,259:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:39:37,265:INFO:Starting cross validation
2024-11-13 18:39:37,266:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:38,763:INFO:Calculating mean and std
2024-11-13 18:39:38,767:INFO:Creating metrics dataframe
2024-11-13 18:39:38,775:INFO:Uploading results into container
2024-11-13 18:39:38,775:INFO:Uploading model into container now
2024-11-13 18:39:38,776:INFO:_master_model_container: 13
2024-11-13 18:39:38,776:INFO:_display_container: 2
2024-11-13 18:39:38,776:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:39:38,776:INFO:create_model() successfully completed......................................
2024-11-13 18:39:38,951:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:38,951:INFO:Creating metrics dataframe
2024-11-13 18:39:38,964:INFO:Initializing Extra Trees Regressor
2024-11-13 18:39:38,964:INFO:Total runtime is 0.4098136425018311 minutes
2024-11-13 18:39:38,967:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:38,968:INFO:Initializing create_model()
2024-11-13 18:39:38,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:38,968:INFO:Checking exceptions
2024-11-13 18:39:38,968:INFO:Importing libraries
2024-11-13 18:39:38,968:INFO:Copying training dataset
2024-11-13 18:39:38,976:INFO:Defining folds
2024-11-13 18:39:38,976:INFO:Declaring metric variables
2024-11-13 18:39:38,980:INFO:Importing untrained model
2024-11-13 18:39:38,983:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:39:38,989:INFO:Starting cross validation
2024-11-13 18:39:38,990:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:39,822:INFO:Calculating mean and std
2024-11-13 18:39:39,825:INFO:Creating metrics dataframe
2024-11-13 18:39:39,830:INFO:Uploading results into container
2024-11-13 18:39:39,831:INFO:Uploading model into container now
2024-11-13 18:39:39,831:INFO:_master_model_container: 14
2024-11-13 18:39:39,832:INFO:_display_container: 2
2024-11-13 18:39:39,832:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:39:39,832:INFO:create_model() successfully completed......................................
2024-11-13 18:39:40,004:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:40,004:INFO:Creating metrics dataframe
2024-11-13 18:39:40,017:INFO:Initializing AdaBoost Regressor
2024-11-13 18:39:40,017:INFO:Total runtime is 0.4273564418156942 minutes
2024-11-13 18:39:40,020:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:40,020:INFO:Initializing create_model()
2024-11-13 18:39:40,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:40,021:INFO:Checking exceptions
2024-11-13 18:39:40,021:INFO:Importing libraries
2024-11-13 18:39:40,021:INFO:Copying training dataset
2024-11-13 18:39:40,028:INFO:Defining folds
2024-11-13 18:39:40,028:INFO:Declaring metric variables
2024-11-13 18:39:40,032:INFO:Importing untrained model
2024-11-13 18:39:40,035:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:39:40,042:INFO:Starting cross validation
2024-11-13 18:39:40,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:40,909:INFO:Calculating mean and std
2024-11-13 18:39:40,912:INFO:Creating metrics dataframe
2024-11-13 18:39:40,919:INFO:Uploading results into container
2024-11-13 18:39:40,920:INFO:Uploading model into container now
2024-11-13 18:39:40,920:INFO:_master_model_container: 15
2024-11-13 18:39:40,920:INFO:_display_container: 2
2024-11-13 18:39:40,920:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:39:40,921:INFO:create_model() successfully completed......................................
2024-11-13 18:39:41,085:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:41,086:INFO:Creating metrics dataframe
2024-11-13 18:39:41,098:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:39:41,098:INFO:Total runtime is 0.445381776491801 minutes
2024-11-13 18:39:41,101:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:41,102:INFO:Initializing create_model()
2024-11-13 18:39:41,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:41,102:INFO:Checking exceptions
2024-11-13 18:39:41,102:INFO:Importing libraries
2024-11-13 18:39:41,102:INFO:Copying training dataset
2024-11-13 18:39:41,109:INFO:Defining folds
2024-11-13 18:39:41,109:INFO:Declaring metric variables
2024-11-13 18:39:41,112:INFO:Importing untrained model
2024-11-13 18:39:41,116:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:39:41,122:INFO:Starting cross validation
2024-11-13 18:39:41,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:42,665:INFO:Calculating mean and std
2024-11-13 18:39:42,667:INFO:Creating metrics dataframe
2024-11-13 18:39:42,673:INFO:Uploading results into container
2024-11-13 18:39:42,674:INFO:Uploading model into container now
2024-11-13 18:39:42,674:INFO:_master_model_container: 16
2024-11-13 18:39:42,674:INFO:_display_container: 2
2024-11-13 18:39:42,675:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:39:42,675:INFO:create_model() successfully completed......................................
2024-11-13 18:39:42,873:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:42,873:INFO:Creating metrics dataframe
2024-11-13 18:39:42,887:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:39:42,887:INFO:Total runtime is 0.4751961906750997 minutes
2024-11-13 18:39:42,890:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:42,891:INFO:Initializing create_model()
2024-11-13 18:39:42,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:42,891:INFO:Checking exceptions
2024-11-13 18:39:42,891:INFO:Importing libraries
2024-11-13 18:39:42,891:INFO:Copying training dataset
2024-11-13 18:39:42,898:INFO:Defining folds
2024-11-13 18:39:42,899:INFO:Declaring metric variables
2024-11-13 18:39:42,902:INFO:Importing untrained model
2024-11-13 18:39:42,906:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:39:42,913:INFO:Starting cross validation
2024-11-13 18:39:42,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:43,300:INFO:Calculating mean and std
2024-11-13 18:39:43,304:INFO:Creating metrics dataframe
2024-11-13 18:39:43,311:INFO:Uploading results into container
2024-11-13 18:39:43,311:INFO:Uploading model into container now
2024-11-13 18:39:43,312:INFO:_master_model_container: 17
2024-11-13 18:39:43,312:INFO:_display_container: 2
2024-11-13 18:39:43,313:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:39:43,313:INFO:create_model() successfully completed......................................
2024-11-13 18:39:43,487:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:43,487:INFO:Creating metrics dataframe
2024-11-13 18:39:43,501:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:39:43,501:INFO:Total runtime is 0.48542280991872155 minutes
2024-11-13 18:39:43,504:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:43,504:INFO:Initializing create_model()
2024-11-13 18:39:43,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:43,505:INFO:Checking exceptions
2024-11-13 18:39:43,505:INFO:Importing libraries
2024-11-13 18:39:43,505:INFO:Copying training dataset
2024-11-13 18:39:43,512:INFO:Defining folds
2024-11-13 18:39:43,512:INFO:Declaring metric variables
2024-11-13 18:39:43,516:INFO:Importing untrained model
2024-11-13 18:39:43,519:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:39:43,526:INFO:Starting cross validation
2024-11-13 18:39:43,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:46:35,183:INFO:Calculating mean and std
2024-11-13 18:46:35,186:INFO:Creating metrics dataframe
2024-11-13 18:46:35,193:INFO:Uploading results into container
2024-11-13 18:46:35,194:INFO:Uploading model into container now
2024-11-13 18:46:35,194:INFO:_master_model_container: 18
2024-11-13 18:46:35,195:INFO:_display_container: 2
2024-11-13 18:46:35,195:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:46:35,195:INFO:create_model() successfully completed......................................
2024-11-13 18:46:35,405:INFO:SubProcess create_model() end ==================================
2024-11-13 18:46:35,405:INFO:Creating metrics dataframe
2024-11-13 18:46:35,418:INFO:Initializing CatBoost Regressor
2024-11-13 18:46:35,419:INFO:Total runtime is 7.350722237428029 minutes
2024-11-13 18:46:35,422:INFO:SubProcess create_model() called ==================================
2024-11-13 18:46:35,422:INFO:Initializing create_model()
2024-11-13 18:46:35,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:46:35,423:INFO:Checking exceptions
2024-11-13 18:46:35,423:INFO:Importing libraries
2024-11-13 18:46:35,423:INFO:Copying training dataset
2024-11-13 18:46:35,431:INFO:Defining folds
2024-11-13 18:46:35,431:INFO:Declaring metric variables
2024-11-13 18:46:35,434:INFO:Importing untrained model
2024-11-13 18:46:35,438:INFO:CatBoost Regressor Imported successfully
2024-11-13 18:46:35,444:INFO:Starting cross validation
2024-11-13 18:46:35,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:46:48,104:INFO:Calculating mean and std
2024-11-13 18:46:48,109:INFO:Creating metrics dataframe
2024-11-13 18:46:48,117:INFO:Uploading results into container
2024-11-13 18:46:48,118:INFO:Uploading model into container now
2024-11-13 18:46:48,118:INFO:_master_model_container: 19
2024-11-13 18:46:48,118:INFO:_display_container: 2
2024-11-13 18:46:48,118:INFO:<catboost.core.CatBoostRegressor object at 0x7ff6b5461c10>
2024-11-13 18:46:48,119:INFO:create_model() successfully completed......................................
2024-11-13 18:46:48,326:INFO:SubProcess create_model() end ==================================
2024-11-13 18:46:48,327:INFO:Creating metrics dataframe
2024-11-13 18:46:48,343:INFO:Initializing Dummy Regressor
2024-11-13 18:46:48,343:INFO:Total runtime is 7.566124173005422 minutes
2024-11-13 18:46:48,346:INFO:SubProcess create_model() called ==================================
2024-11-13 18:46:48,347:INFO:Initializing create_model()
2024-11-13 18:46:48,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:46:48,347:INFO:Checking exceptions
2024-11-13 18:46:48,347:INFO:Importing libraries
2024-11-13 18:46:48,347:INFO:Copying training dataset
2024-11-13 18:46:48,356:INFO:Defining folds
2024-11-13 18:46:48,356:INFO:Declaring metric variables
2024-11-13 18:46:48,360:INFO:Importing untrained model
2024-11-13 18:46:48,363:INFO:Dummy Regressor Imported successfully
2024-11-13 18:46:48,370:INFO:Starting cross validation
2024-11-13 18:46:48,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:46:51,276:INFO:Calculating mean and std
2024-11-13 18:46:51,282:INFO:Creating metrics dataframe
2024-11-13 18:46:51,289:INFO:Uploading results into container
2024-11-13 18:46:51,290:INFO:Uploading model into container now
2024-11-13 18:46:51,291:INFO:_master_model_container: 20
2024-11-13 18:46:51,291:INFO:_display_container: 2
2024-11-13 18:46:51,291:INFO:DummyRegressor()
2024-11-13 18:46:51,291:INFO:create_model() successfully completed......................................
2024-11-13 18:46:51,514:INFO:SubProcess create_model() end ==================================
2024-11-13 18:46:51,514:INFO:Creating metrics dataframe
2024-11-13 18:46:51,543:INFO:Initializing create_model()
2024-11-13 18:46:51,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:46:51,543:INFO:Checking exceptions
2024-11-13 18:46:51,546:INFO:Importing libraries
2024-11-13 18:46:51,546:INFO:Copying training dataset
2024-11-13 18:46:51,554:INFO:Defining folds
2024-11-13 18:46:51,554:INFO:Declaring metric variables
2024-11-13 18:46:51,554:INFO:Importing untrained model
2024-11-13 18:46:51,554:INFO:Declaring custom model
2024-11-13 18:46:51,555:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:46:51,556:INFO:Cross validation set to False
2024-11-13 18:46:51,556:INFO:Fitting Model
2024-11-13 18:46:51,826:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:46:51,826:INFO:create_model() successfully completed......................................
2024-11-13 18:46:52,078:INFO:_master_model_container: 20
2024-11-13 18:46:52,078:INFO:_display_container: 2
2024-11-13 18:46:52,079:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:46:52,079:INFO:compare_models() successfully completed......................................
2024-11-13 18:46:52,176:INFO:PyCaret RegressionExperiment
2024-11-13 18:46:52,176:INFO:Logging name: reg-default-name
2024-11-13 18:46:52,176:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:46:52,176:INFO:version 3.2.0
2024-11-13 18:46:52,176:INFO:Initializing setup()
2024-11-13 18:46:52,176:INFO:self.USI: 9634
2024-11-13 18:46:52,176:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:46:52,176:INFO:Checking environment
2024-11-13 18:46:52,176:INFO:python_version: 3.8.13
2024-11-13 18:46:52,176:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:46:52,176:INFO:machine: x86_64
2024-11-13 18:46:52,176:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:46:52,177:INFO:Memory: svmem(total=270355722240, available=213269176320, percent=21.1, used=55016202240, free=50934038528, active=11660058624, inactive=147416322048, buffers=9957376, cached=164395524096, shared=187604992, slab=25030881280)
2024-11-13 18:46:52,180:INFO:Physical Core: 28
2024-11-13 18:46:52,180:INFO:Logical Core: 56
2024-11-13 18:46:52,180:INFO:Checking libraries
2024-11-13 18:46:52,180:INFO:System:
2024-11-13 18:46:52,180:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:46:52,180:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:46:52,180:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:46:52,180:INFO:PyCaret required dependencies:
2024-11-13 18:46:52,180:INFO:                 pip: 22.2.2
2024-11-13 18:46:52,180:INFO:          setuptools: 63.4.2
2024-11-13 18:46:52,180:INFO:             pycaret: 3.2.0
2024-11-13 18:46:52,180:INFO:             IPython: 8.12.2
2024-11-13 18:46:52,180:INFO:          ipywidgets: 7.7.1
2024-11-13 18:46:52,180:INFO:                tqdm: 4.64.1
2024-11-13 18:46:52,180:INFO:               numpy: 1.23.5
2024-11-13 18:46:52,180:INFO:              pandas: 1.5.3
2024-11-13 18:46:52,180:INFO:              jinja2: 3.1.2
2024-11-13 18:46:52,180:INFO:               scipy: 1.10.1
2024-11-13 18:46:52,181:INFO:              joblib: 1.3.0
2024-11-13 18:46:52,181:INFO:             sklearn: 1.1.2
2024-11-13 18:46:52,181:INFO:                pyod: 2.0.2
2024-11-13 18:46:52,181:INFO:            imblearn: 0.12.4
2024-11-13 18:46:52,181:INFO:   category_encoders: 2.6.4
2024-11-13 18:46:52,181:INFO:            lightgbm: 4.5.0
2024-11-13 18:46:52,181:INFO:               numba: 0.57.1
2024-11-13 18:46:52,181:INFO:            requests: 2.28.1
2024-11-13 18:46:52,181:INFO:          matplotlib: 3.5.1
2024-11-13 18:46:52,181:INFO:          scikitplot: 0.3.7
2024-11-13 18:46:52,181:INFO:         yellowbrick: 1.5
2024-11-13 18:46:52,181:INFO:              plotly: 5.24.1
2024-11-13 18:46:52,181:INFO:    plotly-resampler: Not installed
2024-11-13 18:46:52,181:INFO:             kaleido: 0.2.1
2024-11-13 18:46:52,181:INFO:           schemdraw: 0.15
2024-11-13 18:46:52,181:INFO:         statsmodels: 0.13.2
2024-11-13 18:46:52,181:INFO:              sktime: 0.21.1
2024-11-13 18:46:52,181:INFO:               tbats: 1.1.3
2024-11-13 18:46:52,181:INFO:            pmdarima: 2.0.4
2024-11-13 18:46:52,181:INFO:              psutil: 5.9.1
2024-11-13 18:46:52,181:INFO:          markupsafe: 2.1.1
2024-11-13 18:46:52,181:INFO:             pickle5: Not installed
2024-11-13 18:46:52,181:INFO:         cloudpickle: 2.1.0
2024-11-13 18:46:52,181:INFO:         deprecation: 2.1.0
2024-11-13 18:46:52,182:INFO:              xxhash: 3.5.0
2024-11-13 18:46:52,182:INFO:           wurlitzer: 3.1.1
2024-11-13 18:46:52,182:INFO:PyCaret optional dependencies:
2024-11-13 18:46:52,182:INFO:                shap: 0.44.1
2024-11-13 18:46:52,182:INFO:           interpret: 0.6.5
2024-11-13 18:46:52,182:INFO:                umap: 0.5.7
2024-11-13 18:46:52,182:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:46:52,182:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:46:52,182:INFO:             autoviz: Not installed
2024-11-13 18:46:52,182:INFO:           fairlearn: 0.7.0
2024-11-13 18:46:52,182:INFO:          deepchecks: Not installed
2024-11-13 18:46:52,182:INFO:             xgboost: 2.1.1
2024-11-13 18:46:52,182:INFO:            catboost: 1.2.7
2024-11-13 18:46:52,182:INFO:              kmodes: 0.12.2
2024-11-13 18:46:52,182:INFO:             mlxtend: 0.23.1
2024-11-13 18:46:52,182:INFO:       statsforecast: 1.5.0
2024-11-13 18:46:52,182:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:46:52,182:INFO:                 ray: 2.10.0
2024-11-13 18:46:52,182:INFO:            hyperopt: 0.2.7
2024-11-13 18:46:52,182:INFO:              optuna: 4.1.0
2024-11-13 18:46:52,183:INFO:               skopt: 0.10.2
2024-11-13 18:46:52,183:INFO:              mlflow: 1.30.1
2024-11-13 18:46:52,183:INFO:              gradio: 3.50.2
2024-11-13 18:46:52,183:INFO:             fastapi: 0.115.5
2024-11-13 18:46:52,183:INFO:             uvicorn: 0.32.0
2024-11-13 18:46:52,183:INFO:              m2cgen: 0.10.0
2024-11-13 18:46:52,183:INFO:           evidently: 0.2.8
2024-11-13 18:46:52,183:INFO:               fugue: 0.8.6
2024-11-13 18:46:52,183:INFO:           streamlit: Not installed
2024-11-13 18:46:52,183:INFO:             prophet: Not installed
2024-11-13 18:46:52,183:INFO:None
2024-11-13 18:46:52,183:INFO:Set up data.
2024-11-13 18:46:52,189:INFO:Set up folding strategy.
2024-11-13 18:46:52,190:INFO:Set up train/test split.
2024-11-13 18:46:52,197:INFO:Set up index.
2024-11-13 18:46:52,199:INFO:Assigning column types.
2024-11-13 18:46:52,204:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:46:52,204:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,208:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,212:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,261:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,297:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,300:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,301:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,304:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,308:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,393:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,393:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,395:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,396:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:46:52,400:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,403:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,451:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,489:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,491:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,496:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,499:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,584:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,586:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,587:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:46:52,594:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,642:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,679:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,681:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,689:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,775:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,777:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,778:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:46:52,834:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,870:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,870:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,872:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,928:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,965:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,967:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,967:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:46:53,023:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:53,062:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,064:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:53,158:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,160:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,161:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:46:53,253:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,255:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,352:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,354:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,356:INFO:Preparing preprocessing pipeline...
2024-11-13 18:46:53,356:INFO:Set up simple imputation.
2024-11-13 18:46:53,373:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:46:53,376:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Latitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:46:53,376:INFO:Creating final display dataframe.
2024-11-13 18:46:53,435:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Longitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              9634
2024-11-13 18:46:53,536:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,538:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,629:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,632:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,632:INFO:setup() successfully completed in 1.46s...............
2024-11-13 18:46:53,634:INFO:Initializing compare_models()
2024-11-13 18:46:53,634:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:46:53,634:INFO:Checking exceptions
2024-11-13 18:46:53,637:INFO:Preparing display monitor
2024-11-13 18:46:53,668:INFO:Initializing Linear Regression
2024-11-13 18:46:53,668:INFO:Total runtime is 2.658367156982422e-06 minutes
2024-11-13 18:46:53,671:INFO:SubProcess create_model() called ==================================
2024-11-13 18:46:53,672:INFO:Initializing create_model()
2024-11-13 18:46:53,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:46:53,672:INFO:Checking exceptions
2024-11-13 18:46:53,674:INFO:Importing libraries
2024-11-13 18:46:53,674:INFO:Copying training dataset
2024-11-13 18:46:53,679:INFO:Defining folds
2024-11-13 18:46:53,679:INFO:Declaring metric variables
2024-11-13 18:46:53,682:INFO:Importing untrained model
2024-11-13 18:46:53,686:INFO:Linear Regression Imported successfully
2024-11-13 18:46:53,692:INFO:Starting cross validation
2024-11-13 18:46:53,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:46:56,703:INFO:Calculating mean and std
2024-11-13 18:46:56,709:INFO:Creating metrics dataframe
2024-11-13 18:46:56,715:INFO:Uploading results into container
2024-11-13 18:46:56,716:INFO:Uploading model into container now
2024-11-13 18:46:56,717:INFO:_master_model_container: 1
2024-11-13 18:46:56,717:INFO:_display_container: 2
2024-11-13 18:46:56,718:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:46:56,718:INFO:create_model() successfully completed......................................
2024-11-13 18:46:56,967:INFO:SubProcess create_model() end ==================================
2024-11-13 18:46:56,967:INFO:Creating metrics dataframe
2024-11-13 18:46:56,977:INFO:Initializing Lasso Regression
2024-11-13 18:46:56,977:INFO:Total runtime is 0.05514726638793945 minutes
2024-11-13 18:46:56,980:INFO:SubProcess create_model() called ==================================
2024-11-13 18:46:56,981:INFO:Initializing create_model()
2024-11-13 18:46:56,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:46:56,981:INFO:Checking exceptions
2024-11-13 18:46:56,981:INFO:Importing libraries
2024-11-13 18:46:56,981:INFO:Copying training dataset
2024-11-13 18:46:56,989:INFO:Defining folds
2024-11-13 18:46:56,989:INFO:Declaring metric variables
2024-11-13 18:46:56,992:INFO:Importing untrained model
2024-11-13 18:46:56,996:INFO:Lasso Regression Imported successfully
2024-11-13 18:46:57,003:INFO:Starting cross validation
2024-11-13 18:46:57,004:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:00,525:INFO:Calculating mean and std
2024-11-13 18:47:00,530:INFO:Creating metrics dataframe
2024-11-13 18:47:00,537:INFO:Uploading results into container
2024-11-13 18:47:00,538:INFO:Uploading model into container now
2024-11-13 18:47:00,539:INFO:_master_model_container: 2
2024-11-13 18:47:00,539:INFO:_display_container: 2
2024-11-13 18:47:00,540:INFO:Lasso(random_state=123)
2024-11-13 18:47:00,540:INFO:create_model() successfully completed......................................
2024-11-13 18:47:00,775:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:00,775:INFO:Creating metrics dataframe
2024-11-13 18:47:00,786:INFO:Initializing Ridge Regression
2024-11-13 18:47:00,786:INFO:Total runtime is 0.11862649520238241 minutes
2024-11-13 18:47:00,789:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:00,789:INFO:Initializing create_model()
2024-11-13 18:47:00,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:00,790:INFO:Checking exceptions
2024-11-13 18:47:00,790:INFO:Importing libraries
2024-11-13 18:47:00,790:INFO:Copying training dataset
2024-11-13 18:47:00,798:INFO:Defining folds
2024-11-13 18:47:00,799:INFO:Declaring metric variables
2024-11-13 18:47:00,802:INFO:Importing untrained model
2024-11-13 18:47:00,805:INFO:Ridge Regression Imported successfully
2024-11-13 18:47:00,812:INFO:Starting cross validation
2024-11-13 18:47:00,813:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:03,654:INFO:Calculating mean and std
2024-11-13 18:47:03,658:INFO:Creating metrics dataframe
2024-11-13 18:47:03,664:INFO:Uploading results into container
2024-11-13 18:47:03,665:INFO:Uploading model into container now
2024-11-13 18:47:03,665:INFO:_master_model_container: 3
2024-11-13 18:47:03,666:INFO:_display_container: 2
2024-11-13 18:47:03,666:INFO:Ridge(random_state=123)
2024-11-13 18:47:03,666:INFO:create_model() successfully completed......................................
2024-11-13 18:47:03,883:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:03,883:INFO:Creating metrics dataframe
2024-11-13 18:47:03,895:INFO:Initializing Elastic Net
2024-11-13 18:47:03,895:INFO:Total runtime is 0.1704444726308187 minutes
2024-11-13 18:47:03,898:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:03,899:INFO:Initializing create_model()
2024-11-13 18:47:03,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:03,899:INFO:Checking exceptions
2024-11-13 18:47:03,899:INFO:Importing libraries
2024-11-13 18:47:03,899:INFO:Copying training dataset
2024-11-13 18:47:03,906:INFO:Defining folds
2024-11-13 18:47:03,907:INFO:Declaring metric variables
2024-11-13 18:47:03,910:INFO:Importing untrained model
2024-11-13 18:47:03,913:INFO:Elastic Net Imported successfully
2024-11-13 18:47:03,919:INFO:Starting cross validation
2024-11-13 18:47:03,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:06,619:INFO:Calculating mean and std
2024-11-13 18:47:06,622:INFO:Creating metrics dataframe
2024-11-13 18:47:06,628:INFO:Uploading results into container
2024-11-13 18:47:06,629:INFO:Uploading model into container now
2024-11-13 18:47:06,629:INFO:_master_model_container: 4
2024-11-13 18:47:06,629:INFO:_display_container: 2
2024-11-13 18:47:06,630:INFO:ElasticNet(random_state=123)
2024-11-13 18:47:06,630:INFO:create_model() successfully completed......................................
2024-11-13 18:47:06,831:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:06,831:INFO:Creating metrics dataframe
2024-11-13 18:47:06,842:INFO:Initializing Least Angle Regression
2024-11-13 18:47:06,842:INFO:Total runtime is 0.21956852674484253 minutes
2024-11-13 18:47:06,845:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:06,846:INFO:Initializing create_model()
2024-11-13 18:47:06,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:06,846:INFO:Checking exceptions
2024-11-13 18:47:06,846:INFO:Importing libraries
2024-11-13 18:47:06,846:INFO:Copying training dataset
2024-11-13 18:47:06,853:INFO:Defining folds
2024-11-13 18:47:06,853:INFO:Declaring metric variables
2024-11-13 18:47:06,857:INFO:Importing untrained model
2024-11-13 18:47:06,860:INFO:Least Angle Regression Imported successfully
2024-11-13 18:47:06,866:INFO:Starting cross validation
2024-11-13 18:47:06,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:06,902:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:06,959:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:06,971:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:06,979:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:06,991:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:06,995:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:09,453:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:09,486:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:09,534:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:09,541:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:09,557:INFO:Calculating mean and std
2024-11-13 18:47:09,560:INFO:Creating metrics dataframe
2024-11-13 18:47:09,567:INFO:Uploading results into container
2024-11-13 18:47:09,568:INFO:Uploading model into container now
2024-11-13 18:47:09,569:INFO:_master_model_container: 5
2024-11-13 18:47:09,569:INFO:_display_container: 2
2024-11-13 18:47:09,569:INFO:Lars(random_state=123)
2024-11-13 18:47:09,569:INFO:create_model() successfully completed......................................
2024-11-13 18:47:09,778:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:09,778:INFO:Creating metrics dataframe
2024-11-13 18:47:09,789:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:47:09,789:INFO:Total runtime is 0.26868749062220254 minutes
2024-11-13 18:47:09,793:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:09,793:INFO:Initializing create_model()
2024-11-13 18:47:09,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:09,793:INFO:Checking exceptions
2024-11-13 18:47:09,793:INFO:Importing libraries
2024-11-13 18:47:09,794:INFO:Copying training dataset
2024-11-13 18:47:09,801:INFO:Defining folds
2024-11-13 18:47:09,802:INFO:Declaring metric variables
2024-11-13 18:47:09,805:INFO:Importing untrained model
2024-11-13 18:47:09,808:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:47:09,815:INFO:Starting cross validation
2024-11-13 18:47:09,816:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:09,854:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,859:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,860:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,869:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,874:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,884:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,885:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,893:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,901:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:12,121:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:12,135:INFO:Calculating mean and std
2024-11-13 18:47:12,139:INFO:Creating metrics dataframe
2024-11-13 18:47:12,146:INFO:Uploading results into container
2024-11-13 18:47:12,147:INFO:Uploading model into container now
2024-11-13 18:47:12,148:INFO:_master_model_container: 6
2024-11-13 18:47:12,148:INFO:_display_container: 2
2024-11-13 18:47:12,148:INFO:LassoLars(random_state=123)
2024-11-13 18:47:12,148:INFO:create_model() successfully completed......................................
2024-11-13 18:47:12,338:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:12,338:INFO:Creating metrics dataframe
2024-11-13 18:47:12,348:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:47:12,349:INFO:Total runtime is 0.31134126583735144 minutes
2024-11-13 18:47:12,352:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:12,352:INFO:Initializing create_model()
2024-11-13 18:47:12,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:12,353:INFO:Checking exceptions
2024-11-13 18:47:12,353:INFO:Importing libraries
2024-11-13 18:47:12,353:INFO:Copying training dataset
2024-11-13 18:47:12,360:INFO:Defining folds
2024-11-13 18:47:12,360:INFO:Declaring metric variables
2024-11-13 18:47:12,363:INFO:Importing untrained model
2024-11-13 18:47:12,367:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:47:12,373:INFO:Starting cross validation
2024-11-13 18:47:12,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:12,409:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,414:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,425:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,429:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,439:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,444:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,449:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,449:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,453:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,461:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,480:INFO:Calculating mean and std
2024-11-13 18:47:12,484:INFO:Creating metrics dataframe
2024-11-13 18:47:12,491:INFO:Uploading results into container
2024-11-13 18:47:12,492:INFO:Uploading model into container now
2024-11-13 18:47:12,492:INFO:_master_model_container: 7
2024-11-13 18:47:12,492:INFO:_display_container: 2
2024-11-13 18:47:12,492:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:47:12,493:INFO:create_model() successfully completed......................................
2024-11-13 18:47:12,677:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:12,677:INFO:Creating metrics dataframe
2024-11-13 18:47:12,689:INFO:Initializing Bayesian Ridge
2024-11-13 18:47:12,689:INFO:Total runtime is 0.31701076030731196 minutes
2024-11-13 18:47:12,692:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:12,692:INFO:Initializing create_model()
2024-11-13 18:47:12,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:12,692:INFO:Checking exceptions
2024-11-13 18:47:12,693:INFO:Importing libraries
2024-11-13 18:47:12,693:INFO:Copying training dataset
2024-11-13 18:47:12,700:INFO:Defining folds
2024-11-13 18:47:12,700:INFO:Declaring metric variables
2024-11-13 18:47:12,703:INFO:Importing untrained model
2024-11-13 18:47:12,706:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:47:12,713:INFO:Starting cross validation
2024-11-13 18:47:12,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:12,823:INFO:Calculating mean and std
2024-11-13 18:47:12,826:INFO:Creating metrics dataframe
2024-11-13 18:47:12,832:INFO:Uploading results into container
2024-11-13 18:47:12,832:INFO:Uploading model into container now
2024-11-13 18:47:12,833:INFO:_master_model_container: 8
2024-11-13 18:47:12,833:INFO:_display_container: 2
2024-11-13 18:47:12,833:INFO:BayesianRidge()
2024-11-13 18:47:12,833:INFO:create_model() successfully completed......................................
2024-11-13 18:47:13,026:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:13,026:INFO:Creating metrics dataframe
2024-11-13 18:47:13,038:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:47:13,038:INFO:Total runtime is 0.32283161083857215 minutes
2024-11-13 18:47:13,041:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:13,042:INFO:Initializing create_model()
2024-11-13 18:47:13,042:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:13,042:INFO:Checking exceptions
2024-11-13 18:47:13,042:INFO:Importing libraries
2024-11-13 18:47:13,042:INFO:Copying training dataset
2024-11-13 18:47:13,049:INFO:Defining folds
2024-11-13 18:47:13,050:INFO:Declaring metric variables
2024-11-13 18:47:13,053:INFO:Importing untrained model
2024-11-13 18:47:13,057:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:47:13,063:INFO:Starting cross validation
2024-11-13 18:47:13,064:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:13,216:INFO:Calculating mean and std
2024-11-13 18:47:13,219:INFO:Creating metrics dataframe
2024-11-13 18:47:13,225:INFO:Uploading results into container
2024-11-13 18:47:13,226:INFO:Uploading model into container now
2024-11-13 18:47:13,227:INFO:_master_model_container: 9
2024-11-13 18:47:13,227:INFO:_display_container: 2
2024-11-13 18:47:13,228:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:47:13,228:INFO:create_model() successfully completed......................................
2024-11-13 18:47:13,449:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:13,449:INFO:Creating metrics dataframe
2024-11-13 18:47:13,461:INFO:Initializing Huber Regressor
2024-11-13 18:47:13,462:INFO:Total runtime is 0.32989167769749955 minutes
2024-11-13 18:47:13,465:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:13,465:INFO:Initializing create_model()
2024-11-13 18:47:13,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:13,465:INFO:Checking exceptions
2024-11-13 18:47:13,466:INFO:Importing libraries
2024-11-13 18:47:13,466:INFO:Copying training dataset
2024-11-13 18:47:13,480:INFO:Defining folds
2024-11-13 18:47:13,480:INFO:Declaring metric variables
2024-11-13 18:47:13,484:INFO:Importing untrained model
2024-11-13 18:47:13,488:INFO:Huber Regressor Imported successfully
2024-11-13 18:47:13,496:INFO:Starting cross validation
2024-11-13 18:47:13,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:13,757:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:47:13,757:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:47:13,769:INFO:Calculating mean and std
2024-11-13 18:47:13,773:INFO:Creating metrics dataframe
2024-11-13 18:47:13,779:INFO:Uploading results into container
2024-11-13 18:47:13,780:INFO:Uploading model into container now
2024-11-13 18:47:13,780:INFO:_master_model_container: 10
2024-11-13 18:47:13,781:INFO:_display_container: 2
2024-11-13 18:47:13,781:INFO:HuberRegressor()
2024-11-13 18:47:13,781:INFO:create_model() successfully completed......................................
2024-11-13 18:47:13,993:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:13,993:INFO:Creating metrics dataframe
2024-11-13 18:47:14,005:INFO:Initializing K Neighbors Regressor
2024-11-13 18:47:14,005:INFO:Total runtime is 0.33895553350448604 minutes
2024-11-13 18:47:14,009:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:14,009:INFO:Initializing create_model()
2024-11-13 18:47:14,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:14,009:INFO:Checking exceptions
2024-11-13 18:47:14,009:INFO:Importing libraries
2024-11-13 18:47:14,010:INFO:Copying training dataset
2024-11-13 18:47:14,017:INFO:Defining folds
2024-11-13 18:47:14,017:INFO:Declaring metric variables
2024-11-13 18:47:14,020:INFO:Importing untrained model
2024-11-13 18:47:14,024:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:47:14,030:INFO:Starting cross validation
2024-11-13 18:47:14,031:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:14,195:INFO:Calculating mean and std
2024-11-13 18:47:14,198:INFO:Creating metrics dataframe
2024-11-13 18:47:14,206:INFO:Uploading results into container
2024-11-13 18:47:14,207:INFO:Uploading model into container now
2024-11-13 18:47:14,207:INFO:_master_model_container: 11
2024-11-13 18:47:14,207:INFO:_display_container: 2
2024-11-13 18:47:14,208:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:47:14,208:INFO:create_model() successfully completed......................................
2024-11-13 18:47:14,378:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:14,379:INFO:Creating metrics dataframe
2024-11-13 18:47:14,391:INFO:Initializing Decision Tree Regressor
2024-11-13 18:47:14,391:INFO:Total runtime is 0.345377759138743 minutes
2024-11-13 18:47:14,394:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:14,395:INFO:Initializing create_model()
2024-11-13 18:47:14,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:14,395:INFO:Checking exceptions
2024-11-13 18:47:14,395:INFO:Importing libraries
2024-11-13 18:47:14,395:INFO:Copying training dataset
2024-11-13 18:47:14,403:INFO:Defining folds
2024-11-13 18:47:14,403:INFO:Declaring metric variables
2024-11-13 18:47:14,407:INFO:Importing untrained model
2024-11-13 18:47:14,410:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:47:14,417:INFO:Starting cross validation
2024-11-13 18:47:14,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:14,582:INFO:Calculating mean and std
2024-11-13 18:47:14,586:INFO:Creating metrics dataframe
2024-11-13 18:47:14,592:INFO:Uploading results into container
2024-11-13 18:47:14,592:INFO:Uploading model into container now
2024-11-13 18:47:14,593:INFO:_master_model_container: 12
2024-11-13 18:47:14,593:INFO:_display_container: 2
2024-11-13 18:47:14,594:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:47:14,594:INFO:create_model() successfully completed......................................
2024-11-13 18:47:14,756:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:14,756:INFO:Creating metrics dataframe
2024-11-13 18:47:14,768:INFO:Initializing Random Forest Regressor
2024-11-13 18:47:14,768:INFO:Total runtime is 0.3516717990239461 minutes
2024-11-13 18:47:14,772:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:14,772:INFO:Initializing create_model()
2024-11-13 18:47:14,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:14,772:INFO:Checking exceptions
2024-11-13 18:47:14,773:INFO:Importing libraries
2024-11-13 18:47:14,773:INFO:Copying training dataset
2024-11-13 18:47:14,780:INFO:Defining folds
2024-11-13 18:47:14,780:INFO:Declaring metric variables
2024-11-13 18:47:14,783:INFO:Importing untrained model
2024-11-13 18:47:14,787:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:47:14,793:INFO:Starting cross validation
2024-11-13 18:47:14,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:16,250:INFO:Calculating mean and std
2024-11-13 18:47:16,254:INFO:Creating metrics dataframe
2024-11-13 18:47:16,260:INFO:Uploading results into container
2024-11-13 18:47:16,260:INFO:Uploading model into container now
2024-11-13 18:47:16,261:INFO:_master_model_container: 13
2024-11-13 18:47:16,261:INFO:_display_container: 2
2024-11-13 18:47:16,261:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:47:16,261:INFO:create_model() successfully completed......................................
2024-11-13 18:47:16,427:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:16,427:INFO:Creating metrics dataframe
2024-11-13 18:47:16,439:INFO:Initializing Extra Trees Regressor
2024-11-13 18:47:16,440:INFO:Total runtime is 0.379524552822113 minutes
2024-11-13 18:47:16,443:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:16,443:INFO:Initializing create_model()
2024-11-13 18:47:16,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:16,443:INFO:Checking exceptions
2024-11-13 18:47:16,443:INFO:Importing libraries
2024-11-13 18:47:16,444:INFO:Copying training dataset
2024-11-13 18:47:16,450:INFO:Defining folds
2024-11-13 18:47:16,451:INFO:Declaring metric variables
2024-11-13 18:47:16,454:INFO:Importing untrained model
2024-11-13 18:47:16,457:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:47:16,464:INFO:Starting cross validation
2024-11-13 18:47:16,465:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:17,309:INFO:Calculating mean and std
2024-11-13 18:47:17,313:INFO:Creating metrics dataframe
2024-11-13 18:47:17,319:INFO:Uploading results into container
2024-11-13 18:47:17,320:INFO:Uploading model into container now
2024-11-13 18:47:17,320:INFO:_master_model_container: 14
2024-11-13 18:47:17,320:INFO:_display_container: 2
2024-11-13 18:47:17,321:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:47:17,321:INFO:create_model() successfully completed......................................
2024-11-13 18:47:17,519:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:17,520:INFO:Creating metrics dataframe
2024-11-13 18:47:17,532:INFO:Initializing AdaBoost Regressor
2024-11-13 18:47:17,532:INFO:Total runtime is 0.39773809512456254 minutes
2024-11-13 18:47:17,536:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:17,536:INFO:Initializing create_model()
2024-11-13 18:47:17,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:17,536:INFO:Checking exceptions
2024-11-13 18:47:17,536:INFO:Importing libraries
2024-11-13 18:47:17,536:INFO:Copying training dataset
2024-11-13 18:47:17,543:INFO:Defining folds
2024-11-13 18:47:17,544:INFO:Declaring metric variables
2024-11-13 18:47:17,547:INFO:Importing untrained model
2024-11-13 18:47:17,550:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:47:17,557:INFO:Starting cross validation
2024-11-13 18:47:17,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:18,348:INFO:Calculating mean and std
2024-11-13 18:47:18,352:INFO:Creating metrics dataframe
2024-11-13 18:47:18,359:INFO:Uploading results into container
2024-11-13 18:47:18,360:INFO:Uploading model into container now
2024-11-13 18:47:18,360:INFO:_master_model_container: 15
2024-11-13 18:47:18,360:INFO:_display_container: 2
2024-11-13 18:47:18,361:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:47:18,361:INFO:create_model() successfully completed......................................
2024-11-13 18:47:18,542:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:18,542:INFO:Creating metrics dataframe
2024-11-13 18:47:18,555:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:47:18,555:INFO:Total runtime is 0.4147790829340616 minutes
2024-11-13 18:47:18,558:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:18,558:INFO:Initializing create_model()
2024-11-13 18:47:18,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:18,559:INFO:Checking exceptions
2024-11-13 18:47:18,559:INFO:Importing libraries
2024-11-13 18:47:18,559:INFO:Copying training dataset
2024-11-13 18:47:18,566:INFO:Defining folds
2024-11-13 18:47:18,566:INFO:Declaring metric variables
2024-11-13 18:47:18,570:INFO:Importing untrained model
2024-11-13 18:47:18,573:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:47:18,579:INFO:Starting cross validation
2024-11-13 18:47:18,580:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:20,022:INFO:Calculating mean and std
2024-11-13 18:47:20,026:INFO:Creating metrics dataframe
2024-11-13 18:47:20,032:INFO:Uploading results into container
2024-11-13 18:47:20,032:INFO:Uploading model into container now
2024-11-13 18:47:20,033:INFO:_master_model_container: 16
2024-11-13 18:47:20,033:INFO:_display_container: 2
2024-11-13 18:47:20,034:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:47:20,034:INFO:create_model() successfully completed......................................
2024-11-13 18:47:20,214:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:20,215:INFO:Creating metrics dataframe
2024-11-13 18:47:20,228:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:47:20,228:INFO:Total runtime is 0.4426716804504394 minutes
2024-11-13 18:47:20,232:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:20,232:INFO:Initializing create_model()
2024-11-13 18:47:20,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:20,232:INFO:Checking exceptions
2024-11-13 18:47:20,232:INFO:Importing libraries
2024-11-13 18:47:20,233:INFO:Copying training dataset
2024-11-13 18:47:20,240:INFO:Defining folds
2024-11-13 18:47:20,240:INFO:Declaring metric variables
2024-11-13 18:47:20,244:INFO:Importing untrained model
2024-11-13 18:47:20,248:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:47:20,254:INFO:Starting cross validation
2024-11-13 18:47:20,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:20,604:INFO:Calculating mean and std
2024-11-13 18:47:20,608:INFO:Creating metrics dataframe
2024-11-13 18:47:20,615:INFO:Uploading results into container
2024-11-13 18:47:20,615:INFO:Uploading model into container now
2024-11-13 18:47:20,616:INFO:_master_model_container: 17
2024-11-13 18:47:20,616:INFO:_display_container: 2
2024-11-13 18:47:20,617:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:47:20,617:INFO:create_model() successfully completed......................................
2024-11-13 18:47:20,793:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:20,793:INFO:Creating metrics dataframe
2024-11-13 18:47:20,806:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:47:20,807:INFO:Total runtime is 0.4523066401481628 minutes
2024-11-13 18:47:20,810:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:20,810:INFO:Initializing create_model()
2024-11-13 18:47:20,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:20,810:INFO:Checking exceptions
2024-11-13 18:47:20,810:INFO:Importing libraries
2024-11-13 18:47:20,810:INFO:Copying training dataset
2024-11-13 18:47:20,818:INFO:Defining folds
2024-11-13 18:47:20,818:INFO:Declaring metric variables
2024-11-13 18:47:20,821:INFO:Importing untrained model
2024-11-13 18:47:20,825:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:47:20,831:INFO:Starting cross validation
2024-11-13 18:47:20,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:08,840:INFO:Calculating mean and std
2024-11-13 18:54:08,846:INFO:Creating metrics dataframe
2024-11-13 18:54:08,854:INFO:Uploading results into container
2024-11-13 18:54:08,854:INFO:Uploading model into container now
2024-11-13 18:54:08,855:INFO:_master_model_container: 18
2024-11-13 18:54:08,855:INFO:_display_container: 2
2024-11-13 18:54:08,856:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:54:08,856:INFO:create_model() successfully completed......................................
2024-11-13 18:54:09,090:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:09,090:INFO:Creating metrics dataframe
2024-11-13 18:54:09,104:INFO:Initializing CatBoost Regressor
2024-11-13 18:54:09,104:INFO:Total runtime is 7.257263306776682 minutes
2024-11-13 18:54:09,107:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:09,108:INFO:Initializing create_model()
2024-11-13 18:54:09,108:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:09,108:INFO:Checking exceptions
2024-11-13 18:54:09,108:INFO:Importing libraries
2024-11-13 18:54:09,108:INFO:Copying training dataset
2024-11-13 18:54:09,116:INFO:Defining folds
2024-11-13 18:54:09,116:INFO:Declaring metric variables
2024-11-13 18:54:09,120:INFO:Importing untrained model
2024-11-13 18:54:09,123:INFO:CatBoost Regressor Imported successfully
2024-11-13 18:54:09,129:INFO:Starting cross validation
2024-11-13 18:54:09,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:22,230:INFO:Calculating mean and std
2024-11-13 18:54:22,234:INFO:Creating metrics dataframe
2024-11-13 18:54:22,241:INFO:Uploading results into container
2024-11-13 18:54:22,242:INFO:Uploading model into container now
2024-11-13 18:54:22,243:INFO:_master_model_container: 19
2024-11-13 18:54:22,243:INFO:_display_container: 2
2024-11-13 18:54:22,243:INFO:<catboost.core.CatBoostRegressor object at 0x7ff4bc221310>
2024-11-13 18:54:22,243:INFO:create_model() successfully completed......................................
2024-11-13 18:54:22,480:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:22,480:INFO:Creating metrics dataframe
2024-11-13 18:54:22,495:INFO:Initializing Dummy Regressor
2024-11-13 18:54:22,496:INFO:Total runtime is 7.4804585536321 minutes
2024-11-13 18:54:22,499:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:22,500:INFO:Initializing create_model()
2024-11-13 18:54:22,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:22,500:INFO:Checking exceptions
2024-11-13 18:54:22,500:INFO:Importing libraries
2024-11-13 18:54:22,500:INFO:Copying training dataset
2024-11-13 18:54:22,509:INFO:Defining folds
2024-11-13 18:54:22,509:INFO:Declaring metric variables
2024-11-13 18:54:22,513:INFO:Importing untrained model
2024-11-13 18:54:22,517:INFO:Dummy Regressor Imported successfully
2024-11-13 18:54:22,523:INFO:Starting cross validation
2024-11-13 18:54:22,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:25,563:INFO:Calculating mean and std
2024-11-13 18:54:25,568:INFO:Creating metrics dataframe
2024-11-13 18:54:25,574:INFO:Uploading results into container
2024-11-13 18:54:25,575:INFO:Uploading model into container now
2024-11-13 18:54:25,576:INFO:_master_model_container: 20
2024-11-13 18:54:25,576:INFO:_display_container: 2
2024-11-13 18:54:25,576:INFO:DummyRegressor()
2024-11-13 18:54:25,576:INFO:create_model() successfully completed......................................
2024-11-13 18:54:25,785:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:25,786:INFO:Creating metrics dataframe
2024-11-13 18:54:25,809:INFO:Initializing create_model()
2024-11-13 18:54:25,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:25,810:INFO:Checking exceptions
2024-11-13 18:54:25,812:INFO:Importing libraries
2024-11-13 18:54:25,812:INFO:Copying training dataset
2024-11-13 18:54:25,818:INFO:Defining folds
2024-11-13 18:54:25,818:INFO:Declaring metric variables
2024-11-13 18:54:25,818:INFO:Importing untrained model
2024-11-13 18:54:25,818:INFO:Declaring custom model
2024-11-13 18:54:25,819:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:54:25,820:INFO:Cross validation set to False
2024-11-13 18:54:25,820:INFO:Fitting Model
2024-11-13 18:54:26,076:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:54:26,076:INFO:create_model() successfully completed......................................
2024-11-13 18:54:26,366:INFO:_master_model_container: 20
2024-11-13 18:54:26,367:INFO:_display_container: 2
2024-11-13 18:54:26,368:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:54:26,368:INFO:compare_models() successfully completed......................................
2024-11-13 18:54:26,433:INFO:PyCaret RegressionExperiment
2024-11-13 18:54:26,433:INFO:Logging name: reg-default-name
2024-11-13 18:54:26,433:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:54:26,433:INFO:version 3.2.0
2024-11-13 18:54:26,433:INFO:Initializing setup()
2024-11-13 18:54:26,433:INFO:self.USI: e41e
2024-11-13 18:54:26,433:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:54:26,433:INFO:Checking environment
2024-11-13 18:54:26,433:INFO:python_version: 3.8.13
2024-11-13 18:54:26,434:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:54:26,434:INFO:machine: x86_64
2024-11-13 18:54:26,434:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:54:26,434:INFO:Memory: svmem(total=270355722240, available=213611134976, percent=21.0, used=54676021248, free=51250532352, active=11658366976, inactive=147092914176, buffers=8888320, cached=164420280320, shared=187604992, slab=25030275072)
2024-11-13 18:54:26,437:INFO:Physical Core: 28
2024-11-13 18:54:26,438:INFO:Logical Core: 56
2024-11-13 18:54:26,438:INFO:Checking libraries
2024-11-13 18:54:26,438:INFO:System:
2024-11-13 18:54:26,438:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:54:26,438:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:54:26,438:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:54:26,438:INFO:PyCaret required dependencies:
2024-11-13 18:54:26,438:INFO:                 pip: 22.2.2
2024-11-13 18:54:26,438:INFO:          setuptools: 63.4.2
2024-11-13 18:54:26,438:INFO:             pycaret: 3.2.0
2024-11-13 18:54:26,438:INFO:             IPython: 8.12.2
2024-11-13 18:54:26,438:INFO:          ipywidgets: 7.7.1
2024-11-13 18:54:26,438:INFO:                tqdm: 4.64.1
2024-11-13 18:54:26,438:INFO:               numpy: 1.23.5
2024-11-13 18:54:26,438:INFO:              pandas: 1.5.3
2024-11-13 18:54:26,438:INFO:              jinja2: 3.1.2
2024-11-13 18:54:26,438:INFO:               scipy: 1.10.1
2024-11-13 18:54:26,438:INFO:              joblib: 1.3.0
2024-11-13 18:54:26,438:INFO:             sklearn: 1.1.2
2024-11-13 18:54:26,438:INFO:                pyod: 2.0.2
2024-11-13 18:54:26,438:INFO:            imblearn: 0.12.4
2024-11-13 18:54:26,439:INFO:   category_encoders: 2.6.4
2024-11-13 18:54:26,439:INFO:            lightgbm: 4.5.0
2024-11-13 18:54:26,439:INFO:               numba: 0.57.1
2024-11-13 18:54:26,439:INFO:            requests: 2.28.1
2024-11-13 18:54:26,439:INFO:          matplotlib: 3.5.1
2024-11-13 18:54:26,439:INFO:          scikitplot: 0.3.7
2024-11-13 18:54:26,439:INFO:         yellowbrick: 1.5
2024-11-13 18:54:26,439:INFO:              plotly: 5.24.1
2024-11-13 18:54:26,439:INFO:    plotly-resampler: Not installed
2024-11-13 18:54:26,439:INFO:             kaleido: 0.2.1
2024-11-13 18:54:26,439:INFO:           schemdraw: 0.15
2024-11-13 18:54:26,439:INFO:         statsmodels: 0.13.2
2024-11-13 18:54:26,439:INFO:              sktime: 0.21.1
2024-11-13 18:54:26,439:INFO:               tbats: 1.1.3
2024-11-13 18:54:26,439:INFO:            pmdarima: 2.0.4
2024-11-13 18:54:26,439:INFO:              psutil: 5.9.1
2024-11-13 18:54:26,439:INFO:          markupsafe: 2.1.1
2024-11-13 18:54:26,439:INFO:             pickle5: Not installed
2024-11-13 18:54:26,439:INFO:         cloudpickle: 2.1.0
2024-11-13 18:54:26,439:INFO:         deprecation: 2.1.0
2024-11-13 18:54:26,439:INFO:              xxhash: 3.5.0
2024-11-13 18:54:26,439:INFO:           wurlitzer: 3.1.1
2024-11-13 18:54:26,439:INFO:PyCaret optional dependencies:
2024-11-13 18:54:26,439:INFO:                shap: 0.44.1
2024-11-13 18:54:26,439:INFO:           interpret: 0.6.5
2024-11-13 18:54:26,439:INFO:                umap: 0.5.7
2024-11-13 18:54:26,439:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:54:26,439:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:54:26,439:INFO:             autoviz: Not installed
2024-11-13 18:54:26,439:INFO:           fairlearn: 0.7.0
2024-11-13 18:54:26,439:INFO:          deepchecks: Not installed
2024-11-13 18:54:26,439:INFO:             xgboost: 2.1.1
2024-11-13 18:54:26,440:INFO:            catboost: 1.2.7
2024-11-13 18:54:26,440:INFO:              kmodes: 0.12.2
2024-11-13 18:54:26,440:INFO:             mlxtend: 0.23.1
2024-11-13 18:54:26,440:INFO:       statsforecast: 1.5.0
2024-11-13 18:54:26,440:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:54:26,440:INFO:                 ray: 2.10.0
2024-11-13 18:54:26,440:INFO:            hyperopt: 0.2.7
2024-11-13 18:54:26,440:INFO:              optuna: 4.1.0
2024-11-13 18:54:26,440:INFO:               skopt: 0.10.2
2024-11-13 18:54:26,440:INFO:              mlflow: 1.30.1
2024-11-13 18:54:26,440:INFO:              gradio: 3.50.2
2024-11-13 18:54:26,440:INFO:             fastapi: 0.115.5
2024-11-13 18:54:26,440:INFO:             uvicorn: 0.32.0
2024-11-13 18:54:26,440:INFO:              m2cgen: 0.10.0
2024-11-13 18:54:26,440:INFO:           evidently: 0.2.8
2024-11-13 18:54:26,440:INFO:               fugue: 0.8.6
2024-11-13 18:54:26,440:INFO:           streamlit: Not installed
2024-11-13 18:54:26,440:INFO:             prophet: Not installed
2024-11-13 18:54:26,440:INFO:None
2024-11-13 18:54:26,440:INFO:Set up data.
2024-11-13 18:54:26,451:INFO:Set up folding strategy.
2024-11-13 18:54:26,451:INFO:Set up train/test split.
2024-11-13 18:54:26,455:INFO:Set up index.
2024-11-13 18:54:26,457:INFO:Assigning column types.
2024-11-13 18:54:26,460:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:54:26,461:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,465:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,468:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,517:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,554:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:26,556:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:26,557:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,560:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,564:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,648:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:26,651:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:26,651:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:54:26,655:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,659:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,706:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,745:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:26,747:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:26,752:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,755:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,842:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:26,844:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:26,844:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:54:26,852:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,899:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,936:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:26,938:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:26,946:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,032:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,034:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,034:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:54:27,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,126:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,128:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,183:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,220:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,222:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,222:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:54:27,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,314:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,316:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,411:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,413:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,414:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:54:27,506:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,508:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,604:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,606:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,607:INFO:Preparing preprocessing pipeline...
2024-11-13 18:54:27,607:INFO:Set up simple imputation.
2024-11-13 18:54:27,622:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:54:27,626:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['USA_WSPD', 'MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:54:27,626:INFO:Creating final display dataframe.
2024-11-13 18:54:27,684:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 8)
4        Transformed data shape        (31316, 8)
5   Transformed train set shape        (21921, 8)
6    Transformed test set shape         (9395, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              e41e
2024-11-13 18:54:27,786:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,788:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,879:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,882:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,882:INFO:setup() successfully completed in 1.45s...............
2024-11-13 18:54:27,940:INFO:Initializing compare_models()
2024-11-13 18:54:27,940:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:54:27,941:INFO:Checking exceptions
2024-11-13 18:54:27,946:INFO:Preparing display monitor
2024-11-13 18:54:27,982:INFO:Initializing Linear Regression
2024-11-13 18:54:27,982:INFO:Total runtime is 2.47955322265625e-06 minutes
2024-11-13 18:54:27,985:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:27,985:INFO:Initializing create_model()
2024-11-13 18:54:27,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:27,986:INFO:Checking exceptions
2024-11-13 18:54:27,986:INFO:Importing libraries
2024-11-13 18:54:27,986:INFO:Copying training dataset
2024-11-13 18:54:27,991:INFO:Defining folds
2024-11-13 18:54:27,991:INFO:Declaring metric variables
2024-11-13 18:54:27,994:INFO:Importing untrained model
2024-11-13 18:54:27,997:INFO:Linear Regression Imported successfully
2024-11-13 18:54:28,004:INFO:Starting cross validation
2024-11-13 18:54:28,005:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:30,957:INFO:Calculating mean and std
2024-11-13 18:54:30,961:INFO:Creating metrics dataframe
2024-11-13 18:54:30,970:INFO:Uploading results into container
2024-11-13 18:54:30,971:INFO:Uploading model into container now
2024-11-13 18:54:30,971:INFO:_master_model_container: 1
2024-11-13 18:54:30,972:INFO:_display_container: 2
2024-11-13 18:54:30,972:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:54:30,972:INFO:create_model() successfully completed......................................
2024-11-13 18:54:31,217:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:31,217:INFO:Creating metrics dataframe
2024-11-13 18:54:31,227:INFO:Initializing Lasso Regression
2024-11-13 18:54:31,227:INFO:Total runtime is 0.0540927251180013 minutes
2024-11-13 18:54:31,231:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:31,231:INFO:Initializing create_model()
2024-11-13 18:54:31,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:31,232:INFO:Checking exceptions
2024-11-13 18:54:31,232:INFO:Importing libraries
2024-11-13 18:54:31,232:INFO:Copying training dataset
2024-11-13 18:54:31,241:INFO:Defining folds
2024-11-13 18:54:31,241:INFO:Declaring metric variables
2024-11-13 18:54:31,245:INFO:Importing untrained model
2024-11-13 18:54:31,248:INFO:Lasso Regression Imported successfully
2024-11-13 18:54:31,255:INFO:Starting cross validation
2024-11-13 18:54:31,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:34,117:INFO:Calculating mean and std
2024-11-13 18:54:34,121:INFO:Creating metrics dataframe
2024-11-13 18:54:34,128:INFO:Uploading results into container
2024-11-13 18:54:34,129:INFO:Uploading model into container now
2024-11-13 18:54:34,129:INFO:_master_model_container: 2
2024-11-13 18:54:34,129:INFO:_display_container: 2
2024-11-13 18:54:34,130:INFO:Lasso(random_state=123)
2024-11-13 18:54:34,130:INFO:create_model() successfully completed......................................
2024-11-13 18:54:34,315:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:34,315:INFO:Creating metrics dataframe
2024-11-13 18:54:34,325:INFO:Initializing Ridge Regression
2024-11-13 18:54:34,326:INFO:Total runtime is 0.10572757720947265 minutes
2024-11-13 18:54:34,329:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:34,329:INFO:Initializing create_model()
2024-11-13 18:54:34,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:34,330:INFO:Checking exceptions
2024-11-13 18:54:34,330:INFO:Importing libraries
2024-11-13 18:54:34,330:INFO:Copying training dataset
2024-11-13 18:54:34,336:INFO:Defining folds
2024-11-13 18:54:34,337:INFO:Declaring metric variables
2024-11-13 18:54:34,340:INFO:Importing untrained model
2024-11-13 18:54:34,344:INFO:Ridge Regression Imported successfully
2024-11-13 18:54:34,350:INFO:Starting cross validation
2024-11-13 18:54:34,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:37,172:INFO:Calculating mean and std
2024-11-13 18:54:37,175:INFO:Creating metrics dataframe
2024-11-13 18:54:37,183:INFO:Uploading results into container
2024-11-13 18:54:37,183:INFO:Uploading model into container now
2024-11-13 18:54:37,184:INFO:_master_model_container: 3
2024-11-13 18:54:37,184:INFO:_display_container: 2
2024-11-13 18:54:37,184:INFO:Ridge(random_state=123)
2024-11-13 18:54:37,184:INFO:create_model() successfully completed......................................
2024-11-13 18:54:37,401:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:37,401:INFO:Creating metrics dataframe
2024-11-13 18:54:37,412:INFO:Initializing Elastic Net
2024-11-13 18:54:37,413:INFO:Total runtime is 0.1571786602338155 minutes
2024-11-13 18:54:37,416:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:37,416:INFO:Initializing create_model()
2024-11-13 18:54:37,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:37,417:INFO:Checking exceptions
2024-11-13 18:54:37,417:INFO:Importing libraries
2024-11-13 18:54:37,417:INFO:Copying training dataset
2024-11-13 18:54:37,424:INFO:Defining folds
2024-11-13 18:54:37,424:INFO:Declaring metric variables
2024-11-13 18:54:37,427:INFO:Importing untrained model
2024-11-13 18:54:37,431:INFO:Elastic Net Imported successfully
2024-11-13 18:54:37,437:INFO:Starting cross validation
2024-11-13 18:54:37,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:40,676:INFO:Calculating mean and std
2024-11-13 18:54:40,679:INFO:Creating metrics dataframe
2024-11-13 18:54:40,686:INFO:Uploading results into container
2024-11-13 18:54:40,687:INFO:Uploading model into container now
2024-11-13 18:54:40,688:INFO:_master_model_container: 4
2024-11-13 18:54:40,688:INFO:_display_container: 2
2024-11-13 18:54:40,688:INFO:ElasticNet(random_state=123)
2024-11-13 18:54:40,688:INFO:create_model() successfully completed......................................
2024-11-13 18:54:40,866:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:40,866:INFO:Creating metrics dataframe
2024-11-13 18:54:40,877:INFO:Initializing Least Angle Regression
2024-11-13 18:54:40,877:INFO:Total runtime is 0.21492094596227007 minutes
2024-11-13 18:54:40,880:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:40,881:INFO:Initializing create_model()
2024-11-13 18:54:40,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:40,881:INFO:Checking exceptions
2024-11-13 18:54:40,881:INFO:Importing libraries
2024-11-13 18:54:40,881:INFO:Copying training dataset
2024-11-13 18:54:40,888:INFO:Defining folds
2024-11-13 18:54:40,888:INFO:Declaring metric variables
2024-11-13 18:54:40,891:INFO:Importing untrained model
2024-11-13 18:54:40,895:INFO:Least Angle Regression Imported successfully
2024-11-13 18:54:40,901:INFO:Starting cross validation
2024-11-13 18:54:40,902:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:40,971:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:40,975:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.407e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:54:40,979:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:40,981:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:40,990:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:40,994:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.478e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:54:40,996:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:41,000:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:41,000:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.949e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:54:41,000:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.974e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:54:43,429:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:43,429:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:43,444:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:43,445:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:43,461:INFO:Calculating mean and std
2024-11-13 18:54:43,465:INFO:Creating metrics dataframe
2024-11-13 18:54:43,472:INFO:Uploading results into container
2024-11-13 18:54:43,472:INFO:Uploading model into container now
2024-11-13 18:54:43,473:INFO:_master_model_container: 5
2024-11-13 18:54:43,473:INFO:_display_container: 2
2024-11-13 18:54:43,474:INFO:Lars(random_state=123)
2024-11-13 18:54:43,474:INFO:create_model() successfully completed......................................
2024-11-13 18:54:43,701:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:43,701:INFO:Creating metrics dataframe
2024-11-13 18:54:43,712:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:54:43,712:INFO:Total runtime is 0.2621651212374369 minutes
2024-11-13 18:54:43,715:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:43,715:INFO:Initializing create_model()
2024-11-13 18:54:43,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:43,716:INFO:Checking exceptions
2024-11-13 18:54:43,716:INFO:Importing libraries
2024-11-13 18:54:43,716:INFO:Copying training dataset
2024-11-13 18:54:43,722:INFO:Defining folds
2024-11-13 18:54:43,722:INFO:Declaring metric variables
2024-11-13 18:54:43,726:INFO:Importing untrained model
2024-11-13 18:54:43,729:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:54:43,736:INFO:Starting cross validation
2024-11-13 18:54:43,736:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:43,771:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,777:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,783:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,793:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,809:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,818:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,823:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,823:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:46,157:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:46,157:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:46,172:INFO:Calculating mean and std
2024-11-13 18:54:46,175:INFO:Creating metrics dataframe
2024-11-13 18:54:46,181:INFO:Uploading results into container
2024-11-13 18:54:46,182:INFO:Uploading model into container now
2024-11-13 18:54:46,182:INFO:_master_model_container: 6
2024-11-13 18:54:46,182:INFO:_display_container: 2
2024-11-13 18:54:46,183:INFO:LassoLars(random_state=123)
2024-11-13 18:54:46,183:INFO:create_model() successfully completed......................................
2024-11-13 18:54:46,365:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:46,366:INFO:Creating metrics dataframe
2024-11-13 18:54:46,379:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:54:46,379:INFO:Total runtime is 0.3066184083620707 minutes
2024-11-13 18:54:46,382:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:46,383:INFO:Initializing create_model()
2024-11-13 18:54:46,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:46,383:INFO:Checking exceptions
2024-11-13 18:54:46,383:INFO:Importing libraries
2024-11-13 18:54:46,383:INFO:Copying training dataset
2024-11-13 18:54:46,391:INFO:Defining folds
2024-11-13 18:54:46,391:INFO:Declaring metric variables
2024-11-13 18:54:46,394:INFO:Importing untrained model
2024-11-13 18:54:46,398:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:54:46,404:INFO:Starting cross validation
2024-11-13 18:54:46,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:46,441:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,447:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,451:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,455:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,473:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,477:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,487:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,492:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,501:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,503:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,520:INFO:Calculating mean and std
2024-11-13 18:54:46,524:INFO:Creating metrics dataframe
2024-11-13 18:54:46,531:INFO:Uploading results into container
2024-11-13 18:54:46,532:INFO:Uploading model into container now
2024-11-13 18:54:46,532:INFO:_master_model_container: 7
2024-11-13 18:54:46,532:INFO:_display_container: 2
2024-11-13 18:54:46,532:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:54:46,533:INFO:create_model() successfully completed......................................
2024-11-13 18:54:46,705:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:46,705:INFO:Creating metrics dataframe
2024-11-13 18:54:46,716:INFO:Initializing Bayesian Ridge
2024-11-13 18:54:46,716:INFO:Total runtime is 0.31223843097686765 minutes
2024-11-13 18:54:46,720:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:46,720:INFO:Initializing create_model()
2024-11-13 18:54:46,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:46,720:INFO:Checking exceptions
2024-11-13 18:54:46,720:INFO:Importing libraries
2024-11-13 18:54:46,720:INFO:Copying training dataset
2024-11-13 18:54:46,727:INFO:Defining folds
2024-11-13 18:54:46,727:INFO:Declaring metric variables
2024-11-13 18:54:46,731:INFO:Importing untrained model
2024-11-13 18:54:46,734:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:54:46,741:INFO:Starting cross validation
2024-11-13 18:54:46,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:46,893:INFO:Calculating mean and std
2024-11-13 18:54:46,897:INFO:Creating metrics dataframe
2024-11-13 18:54:46,904:INFO:Uploading results into container
2024-11-13 18:54:46,905:INFO:Uploading model into container now
2024-11-13 18:54:46,905:INFO:_master_model_container: 8
2024-11-13 18:54:46,905:INFO:_display_container: 2
2024-11-13 18:54:46,906:INFO:BayesianRidge()
2024-11-13 18:54:46,906:INFO:create_model() successfully completed......................................
2024-11-13 18:54:47,120:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:47,120:INFO:Creating metrics dataframe
2024-11-13 18:54:47,132:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:54:47,132:INFO:Total runtime is 0.319174579779307 minutes
2024-11-13 18:54:47,136:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:47,136:INFO:Initializing create_model()
2024-11-13 18:54:47,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:47,136:INFO:Checking exceptions
2024-11-13 18:54:47,136:INFO:Importing libraries
2024-11-13 18:54:47,137:INFO:Copying training dataset
2024-11-13 18:54:47,143:INFO:Defining folds
2024-11-13 18:54:47,144:INFO:Declaring metric variables
2024-11-13 18:54:47,147:INFO:Importing untrained model
2024-11-13 18:54:47,150:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:54:47,157:INFO:Starting cross validation
2024-11-13 18:54:47,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:47,315:INFO:Calculating mean and std
2024-11-13 18:54:47,320:INFO:Creating metrics dataframe
2024-11-13 18:54:47,327:INFO:Uploading results into container
2024-11-13 18:54:47,327:INFO:Uploading model into container now
2024-11-13 18:54:47,328:INFO:_master_model_container: 9
2024-11-13 18:54:47,328:INFO:_display_container: 2
2024-11-13 18:54:47,329:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:54:47,329:INFO:create_model() successfully completed......................................
2024-11-13 18:54:47,552:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:47,552:INFO:Creating metrics dataframe
2024-11-13 18:54:47,563:INFO:Initializing Huber Regressor
2024-11-13 18:54:47,564:INFO:Total runtime is 0.32636140982309975 minutes
2024-11-13 18:54:47,567:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:47,567:INFO:Initializing create_model()
2024-11-13 18:54:47,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:47,568:INFO:Checking exceptions
2024-11-13 18:54:47,568:INFO:Importing libraries
2024-11-13 18:54:47,568:INFO:Copying training dataset
2024-11-13 18:54:47,574:INFO:Defining folds
2024-11-13 18:54:47,575:INFO:Declaring metric variables
2024-11-13 18:54:47,578:INFO:Importing untrained model
2024-11-13 18:54:47,582:INFO:Huber Regressor Imported successfully
2024-11-13 18:54:47,588:INFO:Starting cross validation
2024-11-13 18:54:47,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:47,862:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,863:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,892:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,897:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,898:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,950:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,976:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:48,019:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:48,026:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:48,044:INFO:Calculating mean and std
2024-11-13 18:54:48,047:INFO:Creating metrics dataframe
2024-11-13 18:54:48,055:INFO:Uploading results into container
2024-11-13 18:54:48,055:INFO:Uploading model into container now
2024-11-13 18:54:48,056:INFO:_master_model_container: 10
2024-11-13 18:54:48,056:INFO:_display_container: 2
2024-11-13 18:54:48,056:INFO:HuberRegressor()
2024-11-13 18:54:48,056:INFO:create_model() successfully completed......................................
2024-11-13 18:54:48,220:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:48,220:INFO:Creating metrics dataframe
2024-11-13 18:54:48,232:INFO:Initializing K Neighbors Regressor
2024-11-13 18:54:48,232:INFO:Total runtime is 0.33750462134679154 minutes
2024-11-13 18:54:48,235:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:48,236:INFO:Initializing create_model()
2024-11-13 18:54:48,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:48,236:INFO:Checking exceptions
2024-11-13 18:54:48,236:INFO:Importing libraries
2024-11-13 18:54:48,236:INFO:Copying training dataset
2024-11-13 18:54:48,243:INFO:Defining folds
2024-11-13 18:54:48,243:INFO:Declaring metric variables
2024-11-13 18:54:48,246:INFO:Importing untrained model
2024-11-13 18:54:48,250:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:54:48,256:INFO:Starting cross validation
2024-11-13 18:54:48,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:48,482:INFO:Calculating mean and std
2024-11-13 18:54:48,485:INFO:Creating metrics dataframe
2024-11-13 18:54:48,491:INFO:Uploading results into container
2024-11-13 18:54:48,492:INFO:Uploading model into container now
2024-11-13 18:54:48,492:INFO:_master_model_container: 11
2024-11-13 18:54:48,492:INFO:_display_container: 2
2024-11-13 18:54:48,493:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:54:48,493:INFO:create_model() successfully completed......................................
2024-11-13 18:54:48,681:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:48,682:INFO:Creating metrics dataframe
2024-11-13 18:54:48,696:INFO:Initializing Decision Tree Regressor
2024-11-13 18:54:48,697:INFO:Total runtime is 0.3452465017636617 minutes
2024-11-13 18:54:48,701:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:48,701:INFO:Initializing create_model()
2024-11-13 18:54:48,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:48,702:INFO:Checking exceptions
2024-11-13 18:54:48,702:INFO:Importing libraries
2024-11-13 18:54:48,702:INFO:Copying training dataset
2024-11-13 18:54:48,710:INFO:Defining folds
2024-11-13 18:54:48,710:INFO:Declaring metric variables
2024-11-13 18:54:48,714:INFO:Importing untrained model
2024-11-13 18:54:48,719:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:54:48,726:INFO:Starting cross validation
2024-11-13 18:54:48,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:48,871:INFO:Calculating mean and std
2024-11-13 18:54:48,875:INFO:Creating metrics dataframe
2024-11-13 18:54:48,883:INFO:Uploading results into container
2024-11-13 18:54:48,884:INFO:Uploading model into container now
2024-11-13 18:54:48,885:INFO:_master_model_container: 12
2024-11-13 18:54:48,885:INFO:_display_container: 2
2024-11-13 18:54:48,885:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:54:48,885:INFO:create_model() successfully completed......................................
2024-11-13 18:54:49,050:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:49,050:INFO:Creating metrics dataframe
2024-11-13 18:54:49,062:INFO:Initializing Random Forest Regressor
2024-11-13 18:54:49,062:INFO:Total runtime is 0.35134084224700923 minutes
2024-11-13 18:54:49,066:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:49,066:INFO:Initializing create_model()
2024-11-13 18:54:49,066:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:49,066:INFO:Checking exceptions
2024-11-13 18:54:49,066:INFO:Importing libraries
2024-11-13 18:54:49,067:INFO:Copying training dataset
2024-11-13 18:54:49,073:INFO:Defining folds
2024-11-13 18:54:49,073:INFO:Declaring metric variables
2024-11-13 18:54:49,077:INFO:Importing untrained model
2024-11-13 18:54:49,080:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:54:49,087:INFO:Starting cross validation
2024-11-13 18:54:49,088:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:50,016:INFO:Calculating mean and std
2024-11-13 18:54:50,019:INFO:Creating metrics dataframe
2024-11-13 18:54:50,024:INFO:Uploading results into container
2024-11-13 18:54:50,025:INFO:Uploading model into container now
2024-11-13 18:54:50,025:INFO:_master_model_container: 13
2024-11-13 18:54:50,026:INFO:_display_container: 2
2024-11-13 18:54:50,026:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:54:50,026:INFO:create_model() successfully completed......................................
2024-11-13 18:54:50,196:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:50,196:INFO:Creating metrics dataframe
2024-11-13 18:54:50,208:INFO:Initializing Extra Trees Regressor
2024-11-13 18:54:50,209:INFO:Total runtime is 0.37044362227121985 minutes
2024-11-13 18:54:50,212:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:50,212:INFO:Initializing create_model()
2024-11-13 18:54:50,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:50,212:INFO:Checking exceptions
2024-11-13 18:54:50,213:INFO:Importing libraries
2024-11-13 18:54:50,213:INFO:Copying training dataset
2024-11-13 18:54:50,219:INFO:Defining folds
2024-11-13 18:54:50,220:INFO:Declaring metric variables
2024-11-13 18:54:50,223:INFO:Importing untrained model
2024-11-13 18:54:50,227:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:54:50,233:INFO:Starting cross validation
2024-11-13 18:54:50,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:50,753:INFO:Calculating mean and std
2024-11-13 18:54:50,757:INFO:Creating metrics dataframe
2024-11-13 18:54:50,762:INFO:Uploading results into container
2024-11-13 18:54:50,763:INFO:Uploading model into container now
2024-11-13 18:54:50,763:INFO:_master_model_container: 14
2024-11-13 18:54:50,764:INFO:_display_container: 2
2024-11-13 18:54:50,764:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:54:50,765:INFO:create_model() successfully completed......................................
2024-11-13 18:54:50,958:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:50,959:INFO:Creating metrics dataframe
2024-11-13 18:54:50,974:INFO:Initializing AdaBoost Regressor
2024-11-13 18:54:50,974:INFO:Total runtime is 0.38320453961690265 minutes
2024-11-13 18:54:50,978:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:50,979:INFO:Initializing create_model()
2024-11-13 18:54:50,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:50,979:INFO:Checking exceptions
2024-11-13 18:54:50,979:INFO:Importing libraries
2024-11-13 18:54:50,979:INFO:Copying training dataset
2024-11-13 18:54:50,988:INFO:Defining folds
2024-11-13 18:54:50,988:INFO:Declaring metric variables
2024-11-13 18:54:50,992:INFO:Importing untrained model
2024-11-13 18:54:50,996:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:54:51,004:INFO:Starting cross validation
2024-11-13 18:54:51,005:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:51,655:INFO:Calculating mean and std
2024-11-13 18:54:51,659:INFO:Creating metrics dataframe
2024-11-13 18:54:51,666:INFO:Uploading results into container
2024-11-13 18:54:51,667:INFO:Uploading model into container now
2024-11-13 18:54:51,668:INFO:_master_model_container: 15
2024-11-13 18:54:51,668:INFO:_display_container: 2
2024-11-13 18:54:51,668:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:54:51,668:INFO:create_model() successfully completed......................................
2024-11-13 18:54:51,886:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:51,887:INFO:Creating metrics dataframe
2024-11-13 18:54:51,900:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:54:51,900:INFO:Total runtime is 0.3986332535743713 minutes
2024-11-13 18:54:51,903:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:51,904:INFO:Initializing create_model()
2024-11-13 18:54:51,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:51,904:INFO:Checking exceptions
2024-11-13 18:54:51,904:INFO:Importing libraries
2024-11-13 18:54:51,904:INFO:Copying training dataset
2024-11-13 18:54:51,911:INFO:Defining folds
2024-11-13 18:54:51,911:INFO:Declaring metric variables
2024-11-13 18:54:51,915:INFO:Importing untrained model
2024-11-13 18:54:51,918:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:54:51,924:INFO:Starting cross validation
2024-11-13 18:54:51,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:54,293:INFO:Calculating mean and std
2024-11-13 18:54:54,296:INFO:Creating metrics dataframe
2024-11-13 18:54:54,303:INFO:Uploading results into container
2024-11-13 18:54:54,304:INFO:Uploading model into container now
2024-11-13 18:54:54,304:INFO:_master_model_container: 16
2024-11-13 18:54:54,304:INFO:_display_container: 2
2024-11-13 18:54:54,305:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:54:54,305:INFO:create_model() successfully completed......................................
2024-11-13 18:54:54,481:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:54,481:INFO:Creating metrics dataframe
2024-11-13 18:54:54,494:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:54:54,494:INFO:Total runtime is 0.44187271595001215 minutes
2024-11-13 18:54:54,497:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:54,498:INFO:Initializing create_model()
2024-11-13 18:54:54,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:54,498:INFO:Checking exceptions
2024-11-13 18:54:54,498:INFO:Importing libraries
2024-11-13 18:54:54,498:INFO:Copying training dataset
2024-11-13 18:54:54,505:INFO:Defining folds
2024-11-13 18:54:54,505:INFO:Declaring metric variables
2024-11-13 18:54:54,508:INFO:Importing untrained model
2024-11-13 18:54:54,512:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:54:54,518:INFO:Starting cross validation
2024-11-13 18:54:54,519:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:54,911:INFO:Calculating mean and std
2024-11-13 18:54:54,915:INFO:Creating metrics dataframe
2024-11-13 18:54:54,922:INFO:Uploading results into container
2024-11-13 18:54:54,923:INFO:Uploading model into container now
2024-11-13 18:54:54,923:INFO:_master_model_container: 17
2024-11-13 18:54:54,924:INFO:_display_container: 2
2024-11-13 18:54:54,924:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:54:54,925:INFO:create_model() successfully completed......................................
2024-11-13 18:54:55,105:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:55,105:INFO:Creating metrics dataframe
2024-11-13 18:54:55,118:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:54:55,118:INFO:Total runtime is 0.4522675911585489 minutes
2024-11-13 18:54:55,121:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:55,121:INFO:Initializing create_model()
2024-11-13 18:54:55,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:55,122:INFO:Checking exceptions
2024-11-13 18:54:55,122:INFO:Importing libraries
2024-11-13 18:54:55,122:INFO:Copying training dataset
2024-11-13 18:54:55,128:INFO:Defining folds
2024-11-13 18:54:55,129:INFO:Declaring metric variables
2024-11-13 18:54:55,132:INFO:Importing untrained model
2024-11-13 18:54:55,136:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:54:55,142:INFO:Starting cross validation
2024-11-13 18:54:55,143:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 19:01:47,907:INFO:Calculating mean and std
2024-11-13 19:01:47,910:INFO:Creating metrics dataframe
2024-11-13 19:01:47,917:INFO:Uploading results into container
2024-11-13 19:01:47,917:INFO:Uploading model into container now
2024-11-13 19:01:47,918:INFO:_master_model_container: 18
2024-11-13 19:01:47,918:INFO:_display_container: 2
2024-11-13 19:01:47,919:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 19:01:47,919:INFO:create_model() successfully completed......................................
2024-11-13 19:01:48,122:INFO:SubProcess create_model() end ==================================
2024-11-13 19:01:48,122:INFO:Creating metrics dataframe
2024-11-13 19:01:48,135:INFO:Initializing CatBoost Regressor
2024-11-13 19:01:48,136:INFO:Total runtime is 7.335893412431081 minutes
2024-11-13 19:01:48,139:INFO:SubProcess create_model() called ==================================
2024-11-13 19:01:48,139:INFO:Initializing create_model()
2024-11-13 19:01:48,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 19:01:48,139:INFO:Checking exceptions
2024-11-13 19:01:48,139:INFO:Importing libraries
2024-11-13 19:01:48,140:INFO:Copying training dataset
2024-11-13 19:01:48,148:INFO:Defining folds
2024-11-13 19:01:48,148:INFO:Declaring metric variables
2024-11-13 19:01:48,151:INFO:Importing untrained model
2024-11-13 19:01:48,155:INFO:CatBoost Regressor Imported successfully
2024-11-13 19:01:48,161:INFO:Starting cross validation
2024-11-13 19:01:48,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 19:01:59,434:INFO:Calculating mean and std
2024-11-13 19:01:59,438:INFO:Creating metrics dataframe
2024-11-13 19:01:59,445:INFO:Uploading results into container
2024-11-13 19:01:59,446:INFO:Uploading model into container now
2024-11-13 19:01:59,447:INFO:_master_model_container: 19
2024-11-13 19:01:59,447:INFO:_display_container: 2
2024-11-13 19:01:59,447:INFO:<catboost.core.CatBoostRegressor object at 0x7ff6871760a0>
2024-11-13 19:01:59,447:INFO:create_model() successfully completed......................................
2024-11-13 19:01:59,637:INFO:SubProcess create_model() end ==================================
2024-11-13 19:01:59,637:INFO:Creating metrics dataframe
2024-11-13 19:01:59,652:INFO:Initializing Dummy Regressor
2024-11-13 19:01:59,652:INFO:Total runtime is 7.527840868631999 minutes
2024-11-13 19:01:59,656:INFO:SubProcess create_model() called ==================================
2024-11-13 19:01:59,656:INFO:Initializing create_model()
2024-11-13 19:01:59,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 19:01:59,656:INFO:Checking exceptions
2024-11-13 19:01:59,656:INFO:Importing libraries
2024-11-13 19:01:59,656:INFO:Copying training dataset
2024-11-13 19:01:59,668:INFO:Defining folds
2024-11-13 19:01:59,668:INFO:Declaring metric variables
2024-11-13 19:01:59,672:INFO:Importing untrained model
2024-11-13 19:01:59,676:INFO:Dummy Regressor Imported successfully
2024-11-13 19:01:59,683:INFO:Starting cross validation
2024-11-13 19:01:59,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 19:02:02,853:INFO:Calculating mean and std
2024-11-13 19:02:02,858:INFO:Creating metrics dataframe
2024-11-13 19:02:02,866:INFO:Uploading results into container
2024-11-13 19:02:02,866:INFO:Uploading model into container now
2024-11-13 19:02:02,867:INFO:_master_model_container: 20
2024-11-13 19:02:02,867:INFO:_display_container: 2
2024-11-13 19:02:02,868:INFO:DummyRegressor()
2024-11-13 19:02:02,868:INFO:create_model() successfully completed......................................
2024-11-13 19:02:03,105:INFO:SubProcess create_model() end ==================================
2024-11-13 19:02:03,105:INFO:Creating metrics dataframe
2024-11-13 19:02:03,130:INFO:Initializing create_model()
2024-11-13 19:02:03,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 19:02:03,130:INFO:Checking exceptions
2024-11-13 19:02:03,132:INFO:Importing libraries
2024-11-13 19:02:03,132:INFO:Copying training dataset
2024-11-13 19:02:03,138:INFO:Defining folds
2024-11-13 19:02:03,138:INFO:Declaring metric variables
2024-11-13 19:02:03,138:INFO:Importing untrained model
2024-11-13 19:02:03,138:INFO:Declaring custom model
2024-11-13 19:02:03,139:INFO:Linear Regression Imported successfully
2024-11-13 19:02:03,139:INFO:Cross validation set to False
2024-11-13 19:02:03,140:INFO:Fitting Model
2024-11-13 19:02:03,157:INFO:LinearRegression(n_jobs=-1)
2024-11-13 19:02:03,157:INFO:create_model() successfully completed......................................
2024-11-13 19:02:03,425:INFO:_master_model_container: 20
2024-11-13 19:02:03,425:INFO:_display_container: 2
2024-11-13 19:02:03,425:INFO:LinearRegression(n_jobs=-1)
2024-11-13 19:02:03,425:INFO:compare_models() successfully completed......................................
2024-11-13 19:15:10,938:INFO:Initializing plot_model()
2024-11-13 19:15:10,938:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, system=True)
2024-11-13 19:15:10,938:INFO:Checking exceptions
2024-11-13 19:15:11,008:INFO:Preloading libraries
2024-11-13 19:15:11,177:INFO:Copying training dataset
2024-11-13 19:15:11,178:INFO:Plot type: residuals
2024-11-13 19:15:11,256:INFO:Fitting Model
2024-11-13 19:15:11,256:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-13 19:15:11,256:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- MSLP
- Mid_Level_RH
- USA_PRES
- USA_WSPD
- Vert_Vel
Feature names seen at fit time, yet now missing:
- Longitude
- STORM_DIR

  warnings.warn(message, FutureWarning)

2024-11-13 19:15:38,909:INFO:Initializing plot_model()
2024-11-13 19:15:38,909:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, system=True)
2024-11-13 19:15:38,909:INFO:Checking exceptions
2024-11-13 19:15:38,975:INFO:Preloading libraries
2024-11-13 19:15:39,127:INFO:Copying training dataset
2024-11-13 19:15:39,127:INFO:Plot type: residuals
2024-11-13 19:15:39,210:INFO:Fitting Model
2024-11-13 19:15:39,211:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-13 19:15:39,211:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- MSLP
- Mid_Level_RH
- USA_PRES
- USA_WSPD
- Vert_Vel
Feature names seen at fit time, yet now missing:
- Latitude
- STORM_DIR

  warnings.warn(message, FutureWarning)

2024-11-14 09:09:10,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-14 09:09:10,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-14 09:09:10,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-14 09:09:10,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-14 09:10:43,311:INFO:PyCaret RegressionExperiment
2024-11-14 09:10:43,311:INFO:Logging name: reg-default-name
2024-11-14 09:10:43,311:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 09:10:43,311:INFO:version 3.2.0
2024-11-14 09:10:43,311:INFO:Initializing setup()
2024-11-14 09:10:43,311:INFO:self.USI: d379
2024-11-14 09:10:43,311:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'fold_generator', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'memory', 'data', 'fold_groups_param', 'X', 'transform_target_param', 'target_param', 'y_test', 'X_train', 'seed', 'pipeline', 'html_param', 'exp_name_log', 'USI', 'log_plots_param', 'gpu_param', 'n_jobs_param', 'exp_id', '_available_plots', 'logging_param', 'y_train'}
2024-11-14 09:10:43,311:INFO:Checking environment
2024-11-14 09:10:43,312:INFO:python_version: 3.8.13
2024-11-14 09:10:43,312:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 09:10:43,312:INFO:machine: x86_64
2024-11-14 09:10:43,348:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 09:10:43,348:INFO:Memory: svmem(total=270355722240, available=224949596160, percent=16.8, used=43324637184, free=79091494912, active=71671537664, inactive=59491532800, buffers=10100736, cached=147929489408, shared=187387904, slab=25124335616)
2024-11-14 09:10:43,351:INFO:Physical Core: 28
2024-11-14 09:10:43,351:INFO:Logical Core: 56
2024-11-14 09:10:43,351:INFO:Checking libraries
2024-11-14 09:10:43,351:INFO:System:
2024-11-14 09:10:43,351:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 09:10:43,351:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 09:10:43,352:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 09:10:43,352:INFO:PyCaret required dependencies:
2024-11-14 09:10:43,544:INFO:                 pip: 22.2.2
2024-11-14 09:10:43,544:INFO:          setuptools: 63.4.2
2024-11-14 09:10:43,544:INFO:             pycaret: 3.2.0
2024-11-14 09:10:43,544:INFO:             IPython: 8.12.2
2024-11-14 09:10:43,544:INFO:          ipywidgets: 7.7.1
2024-11-14 09:10:43,544:INFO:                tqdm: 4.64.1
2024-11-14 09:10:43,544:INFO:               numpy: 1.23.5
2024-11-14 09:10:43,544:INFO:              pandas: 1.5.3
2024-11-14 09:10:43,544:INFO:              jinja2: 3.1.2
2024-11-14 09:10:43,544:INFO:               scipy: 1.10.1
2024-11-14 09:10:43,544:INFO:              joblib: 1.3.0
2024-11-14 09:10:43,544:INFO:             sklearn: 1.1.2
2024-11-14 09:10:43,544:INFO:                pyod: 2.0.2
2024-11-14 09:10:43,544:INFO:            imblearn: 0.12.4
2024-11-14 09:10:43,544:INFO:   category_encoders: 2.6.4
2024-11-14 09:10:43,544:INFO:            lightgbm: 4.5.0
2024-11-14 09:10:43,544:INFO:               numba: 0.57.1
2024-11-14 09:10:43,545:INFO:            requests: 2.28.1
2024-11-14 09:10:43,545:INFO:          matplotlib: 3.5.1
2024-11-14 09:10:43,545:INFO:          scikitplot: 0.3.7
2024-11-14 09:10:43,545:INFO:         yellowbrick: 1.5
2024-11-14 09:10:43,545:INFO:              plotly: 5.24.1
2024-11-14 09:10:43,545:INFO:    plotly-resampler: Not installed
2024-11-14 09:10:43,545:INFO:             kaleido: 0.2.1
2024-11-14 09:10:43,545:INFO:           schemdraw: 0.15
2024-11-14 09:10:43,545:INFO:         statsmodels: 0.13.2
2024-11-14 09:10:43,545:INFO:              sktime: 0.21.1
2024-11-14 09:10:43,545:INFO:               tbats: 1.1.3
2024-11-14 09:10:43,545:INFO:            pmdarima: 2.0.4
2024-11-14 09:10:43,545:INFO:              psutil: 5.9.1
2024-11-14 09:10:43,545:INFO:          markupsafe: 2.1.1
2024-11-14 09:10:43,545:INFO:             pickle5: Not installed
2024-11-14 09:10:43,545:INFO:         cloudpickle: 2.1.0
2024-11-14 09:10:43,545:INFO:         deprecation: 2.1.0
2024-11-14 09:10:43,545:INFO:              xxhash: 3.5.0
2024-11-14 09:10:43,545:INFO:           wurlitzer: 3.1.1
2024-11-14 09:10:43,545:INFO:PyCaret optional dependencies:
2024-11-14 09:10:47,962:INFO:                shap: 0.44.1
2024-11-14 09:10:47,963:INFO:           interpret: 0.6.5
2024-11-14 09:10:47,963:INFO:                umap: 0.5.7
2024-11-14 09:10:47,963:INFO:     ydata_profiling: 4.6.0
2024-11-14 09:10:47,963:INFO:  explainerdashboard: 0.4.7
2024-11-14 09:10:47,963:INFO:             autoviz: Not installed
2024-11-14 09:10:47,963:INFO:           fairlearn: 0.7.0
2024-11-14 09:10:47,963:INFO:          deepchecks: Not installed
2024-11-14 09:10:47,963:INFO:             xgboost: 2.1.1
2024-11-14 09:10:47,963:INFO:            catboost: 1.2.7
2024-11-14 09:10:47,963:INFO:              kmodes: 0.12.2
2024-11-14 09:10:47,963:INFO:             mlxtend: 0.23.1
2024-11-14 09:10:47,963:INFO:       statsforecast: 1.5.0
2024-11-14 09:10:47,963:INFO:        tune_sklearn: 0.5.0
2024-11-14 09:10:47,963:INFO:                 ray: 2.10.0
2024-11-14 09:10:47,963:INFO:            hyperopt: 0.2.7
2024-11-14 09:10:47,963:INFO:              optuna: 4.1.0
2024-11-14 09:10:47,963:INFO:               skopt: 0.10.2
2024-11-14 09:10:47,963:INFO:              mlflow: 1.30.1
2024-11-14 09:10:47,963:INFO:              gradio: 3.50.2
2024-11-14 09:10:47,963:INFO:             fastapi: 0.115.5
2024-11-14 09:10:47,963:INFO:             uvicorn: 0.32.0
2024-11-14 09:10:47,963:INFO:              m2cgen: 0.10.0
2024-11-14 09:10:47,963:INFO:           evidently: 0.2.8
2024-11-14 09:10:47,963:INFO:               fugue: 0.8.6
2024-11-14 09:10:47,963:INFO:           streamlit: Not installed
2024-11-14 09:10:47,963:INFO:             prophet: Not installed
2024-11-14 09:10:47,964:INFO:None
2024-11-14 09:10:47,964:INFO:Set up data.
2024-11-14 09:12:41,795:INFO:PyCaret RegressionExperiment
2024-11-14 09:12:41,795:INFO:Logging name: reg-default-name
2024-11-14 09:12:41,796:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 09:12:41,796:INFO:version 3.2.0
2024-11-14 09:12:41,796:INFO:Initializing setup()
2024-11-14 09:12:41,796:INFO:self.USI: a7fe
2024-11-14 09:12:41,796:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'fold_generator', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'memory', 'data', 'fold_groups_param', 'X', 'transform_target_param', 'target_param', 'y_test', 'X_train', 'seed', 'pipeline', 'html_param', 'exp_name_log', 'USI', 'log_plots_param', 'gpu_param', 'n_jobs_param', 'exp_id', '_available_plots', 'logging_param', 'y_train'}
2024-11-14 09:12:41,796:INFO:Checking environment
2024-11-14 09:12:41,796:INFO:python_version: 3.8.13
2024-11-14 09:12:41,796:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 09:12:41,796:INFO:machine: x86_64
2024-11-14 09:12:41,796:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 09:12:41,796:INFO:Memory: svmem(total=270355722240, available=225077796864, percent=16.7, used=43196420096, free=79248089088, active=71692062720, inactive=59310542848, buffers=10100736, cached=147901112320, shared=187387904, slab=25124253696)
2024-11-14 09:12:41,798:INFO:Physical Core: 28
2024-11-14 09:12:41,798:INFO:Logical Core: 56
2024-11-14 09:12:41,798:INFO:Checking libraries
2024-11-14 09:12:41,799:INFO:System:
2024-11-14 09:12:41,799:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 09:12:41,799:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 09:12:41,799:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 09:12:41,799:INFO:PyCaret required dependencies:
2024-11-14 09:12:41,799:INFO:                 pip: 22.2.2
2024-11-14 09:12:41,799:INFO:          setuptools: 63.4.2
2024-11-14 09:12:41,799:INFO:             pycaret: 3.2.0
2024-11-14 09:12:41,799:INFO:             IPython: 8.12.2
2024-11-14 09:12:41,799:INFO:          ipywidgets: 7.7.1
2024-11-14 09:12:41,799:INFO:                tqdm: 4.64.1
2024-11-14 09:12:41,799:INFO:               numpy: 1.23.5
2024-11-14 09:12:41,799:INFO:              pandas: 1.5.3
2024-11-14 09:12:41,799:INFO:              jinja2: 3.1.2
2024-11-14 09:12:41,799:INFO:               scipy: 1.10.1
2024-11-14 09:12:41,799:INFO:              joblib: 1.3.0
2024-11-14 09:12:41,799:INFO:             sklearn: 1.1.2
2024-11-14 09:12:41,799:INFO:                pyod: 2.0.2
2024-11-14 09:12:41,799:INFO:            imblearn: 0.12.4
2024-11-14 09:12:41,799:INFO:   category_encoders: 2.6.4
2024-11-14 09:12:41,799:INFO:            lightgbm: 4.5.0
2024-11-14 09:12:41,799:INFO:               numba: 0.57.1
2024-11-14 09:12:41,799:INFO:            requests: 2.28.1
2024-11-14 09:12:41,799:INFO:          matplotlib: 3.5.1
2024-11-14 09:12:41,799:INFO:          scikitplot: 0.3.7
2024-11-14 09:12:41,799:INFO:         yellowbrick: 1.5
2024-11-14 09:12:41,799:INFO:              plotly: 5.24.1
2024-11-14 09:12:41,800:INFO:    plotly-resampler: Not installed
2024-11-14 09:12:41,800:INFO:             kaleido: 0.2.1
2024-11-14 09:12:41,800:INFO:           schemdraw: 0.15
2024-11-14 09:12:41,800:INFO:         statsmodels: 0.13.2
2024-11-14 09:12:41,800:INFO:              sktime: 0.21.1
2024-11-14 09:12:41,800:INFO:               tbats: 1.1.3
2024-11-14 09:12:41,800:INFO:            pmdarima: 2.0.4
2024-11-14 09:12:41,800:INFO:              psutil: 5.9.1
2024-11-14 09:12:41,800:INFO:          markupsafe: 2.1.1
2024-11-14 09:12:41,800:INFO:             pickle5: Not installed
2024-11-14 09:12:41,800:INFO:         cloudpickle: 2.1.0
2024-11-14 09:12:41,800:INFO:         deprecation: 2.1.0
2024-11-14 09:12:41,800:INFO:              xxhash: 3.5.0
2024-11-14 09:12:41,800:INFO:           wurlitzer: 3.1.1
2024-11-14 09:12:41,800:INFO:PyCaret optional dependencies:
2024-11-14 09:12:41,800:INFO:                shap: 0.44.1
2024-11-14 09:12:41,800:INFO:           interpret: 0.6.5
2024-11-14 09:12:41,800:INFO:                umap: 0.5.7
2024-11-14 09:12:41,800:INFO:     ydata_profiling: 4.6.0
2024-11-14 09:12:41,800:INFO:  explainerdashboard: 0.4.7
2024-11-14 09:12:41,800:INFO:             autoviz: Not installed
2024-11-14 09:12:41,800:INFO:           fairlearn: 0.7.0
2024-11-14 09:12:41,800:INFO:          deepchecks: Not installed
2024-11-14 09:12:41,800:INFO:             xgboost: 2.1.1
2024-11-14 09:12:41,800:INFO:            catboost: 1.2.7
2024-11-14 09:12:41,800:INFO:              kmodes: 0.12.2
2024-11-14 09:12:41,800:INFO:             mlxtend: 0.23.1
2024-11-14 09:12:41,800:INFO:       statsforecast: 1.5.0
2024-11-14 09:12:41,800:INFO:        tune_sklearn: 0.5.0
2024-11-14 09:12:41,801:INFO:                 ray: 2.10.0
2024-11-14 09:12:41,801:INFO:            hyperopt: 0.2.7
2024-11-14 09:12:41,801:INFO:              optuna: 4.1.0
2024-11-14 09:12:41,801:INFO:               skopt: 0.10.2
2024-11-14 09:12:41,801:INFO:              mlflow: 1.30.1
2024-11-14 09:12:41,801:INFO:              gradio: 3.50.2
2024-11-14 09:12:41,801:INFO:             fastapi: 0.115.5
2024-11-14 09:12:41,801:INFO:             uvicorn: 0.32.0
2024-11-14 09:12:41,801:INFO:              m2cgen: 0.10.0
2024-11-14 09:12:41,801:INFO:           evidently: 0.2.8
2024-11-14 09:12:41,801:INFO:               fugue: 0.8.6
2024-11-14 09:12:41,801:INFO:           streamlit: Not installed
2024-11-14 09:12:41,801:INFO:             prophet: Not installed
2024-11-14 09:12:41,801:INFO:None
2024-11-14 09:12:41,801:INFO:Set up data.
2024-11-14 09:12:41,813:INFO:Set up folding strategy.
2024-11-14 09:12:41,813:INFO:Set up train/test split.
2024-11-14 09:12:41,818:INFO:Set up index.
2024-11-14 09:12:41,819:INFO:Assigning column types.
2024-11-14 09:12:41,824:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 09:12:41,825:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 09:12:41,831:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:12:41,837:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:12:41,900:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:12:41,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:12:41,937:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:41,940:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:42,034:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,038:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,042:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,091:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,128:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:42,130:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:42,131:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 09:12:42,135:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,139:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,225:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:42,227:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:42,231:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,235:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,321:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,321:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:42,323:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:42,324:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 09:12:42,332:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,380:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,416:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,417:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:42,419:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:42,427:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,476:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,512:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,513:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:42,515:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:42,515:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 09:12:42,576:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,613:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,614:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:42,616:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:42,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,710:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:42,713:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:42,713:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 09:12:42,771:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,808:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:42,810:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:42,867:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:12:42,904:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:42,906:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:42,907:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 09:12:43,000:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:43,002:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:43,095:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:43,097:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:43,099:INFO:Preparing preprocessing pipeline...
2024-11-14 09:12:43,099:INFO:Set up simple imputation.
2024-11-14 09:12:43,118:INFO:Finished creating preprocessing pipeline.
2024-11-14 09:12:43,151:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 09:12:43,151:INFO:Creating final display dataframe.
2024-11-14 09:12:43,249:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a7fe
2024-11-14 09:12:43,384:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:43,387:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:43,484:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:12:43,486:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:12:43,487:INFO:setup() successfully completed in 1.69s...............
2024-11-14 09:13:46,882:INFO:Initializing compare_models()
2024-11-14 09:13:46,882:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 09:13:46,882:INFO:Checking exceptions
2024-11-14 09:13:46,889:INFO:Preparing display monitor
2024-11-14 09:13:46,933:INFO:Initializing Linear Regression
2024-11-14 09:13:46,933:INFO:Total runtime is 2.7060508728027343e-06 minutes
2024-11-14 09:13:46,937:INFO:SubProcess create_model() called ==================================
2024-11-14 09:13:46,937:INFO:Initializing create_model()
2024-11-14 09:13:46,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:13:46,937:INFO:Checking exceptions
2024-11-14 09:13:46,937:INFO:Importing libraries
2024-11-14 09:13:46,937:INFO:Copying training dataset
2024-11-14 09:13:46,944:INFO:Defining folds
2024-11-14 09:13:46,944:INFO:Declaring metric variables
2024-11-14 09:13:46,947:INFO:Importing untrained model
2024-11-14 09:13:46,951:INFO:Linear Regression Imported successfully
2024-11-14 09:13:46,959:INFO:Starting cross validation
2024-11-14 09:13:46,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:13:50,693:INFO:Calculating mean and std
2024-11-14 09:13:50,698:INFO:Creating metrics dataframe
2024-11-14 09:13:50,705:INFO:Uploading results into container
2024-11-14 09:13:50,706:INFO:Uploading model into container now
2024-11-14 09:13:50,706:INFO:_master_model_container: 1
2024-11-14 09:13:50,706:INFO:_display_container: 2
2024-11-14 09:13:50,707:INFO:LinearRegression(n_jobs=-1)
2024-11-14 09:13:50,707:INFO:create_model() successfully completed......................................
2024-11-14 09:13:50,906:INFO:SubProcess create_model() end ==================================
2024-11-14 09:13:50,906:INFO:Creating metrics dataframe
2024-11-14 09:13:50,916:INFO:Initializing Lasso Regression
2024-11-14 09:13:50,916:INFO:Total runtime is 0.06639446417490641 minutes
2024-11-14 09:13:50,920:INFO:SubProcess create_model() called ==================================
2024-11-14 09:13:50,920:INFO:Initializing create_model()
2024-11-14 09:13:50,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:13:50,920:INFO:Checking exceptions
2024-11-14 09:13:50,921:INFO:Importing libraries
2024-11-14 09:13:50,921:INFO:Copying training dataset
2024-11-14 09:13:50,928:INFO:Defining folds
2024-11-14 09:13:50,928:INFO:Declaring metric variables
2024-11-14 09:13:50,932:INFO:Importing untrained model
2024-11-14 09:13:50,935:INFO:Lasso Regression Imported successfully
2024-11-14 09:13:50,941:INFO:Starting cross validation
2024-11-14 09:13:50,942:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:13:53,870:INFO:Calculating mean and std
2024-11-14 09:13:53,873:INFO:Creating metrics dataframe
2024-11-14 09:13:53,880:INFO:Uploading results into container
2024-11-14 09:13:53,881:INFO:Uploading model into container now
2024-11-14 09:13:53,882:INFO:_master_model_container: 2
2024-11-14 09:13:53,882:INFO:_display_container: 2
2024-11-14 09:13:53,882:INFO:Lasso(random_state=123)
2024-11-14 09:13:53,883:INFO:create_model() successfully completed......................................
2024-11-14 09:13:54,062:INFO:SubProcess create_model() end ==================================
2024-11-14 09:13:54,062:INFO:Creating metrics dataframe
2024-11-14 09:13:54,074:INFO:Initializing Ridge Regression
2024-11-14 09:13:54,074:INFO:Total runtime is 0.11901885271072388 minutes
2024-11-14 09:13:54,077:INFO:SubProcess create_model() called ==================================
2024-11-14 09:13:54,078:INFO:Initializing create_model()
2024-11-14 09:13:54,078:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:13:54,078:INFO:Checking exceptions
2024-11-14 09:13:54,078:INFO:Importing libraries
2024-11-14 09:13:54,078:INFO:Copying training dataset
2024-11-14 09:13:54,086:INFO:Defining folds
2024-11-14 09:13:54,086:INFO:Declaring metric variables
2024-11-14 09:13:54,089:INFO:Importing untrained model
2024-11-14 09:13:54,093:INFO:Ridge Regression Imported successfully
2024-11-14 09:13:54,100:INFO:Starting cross validation
2024-11-14 09:13:54,102:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:13:56,871:INFO:Calculating mean and std
2024-11-14 09:13:56,875:INFO:Creating metrics dataframe
2024-11-14 09:13:56,880:INFO:Uploading results into container
2024-11-14 09:13:56,881:INFO:Uploading model into container now
2024-11-14 09:13:56,881:INFO:_master_model_container: 3
2024-11-14 09:13:56,882:INFO:_display_container: 2
2024-11-14 09:13:56,882:INFO:Ridge(random_state=123)
2024-11-14 09:13:56,882:INFO:create_model() successfully completed......................................
2024-11-14 09:13:57,064:INFO:SubProcess create_model() end ==================================
2024-11-14 09:13:57,064:INFO:Creating metrics dataframe
2024-11-14 09:13:57,076:INFO:Initializing Elastic Net
2024-11-14 09:13:57,076:INFO:Total runtime is 0.16906256675720216 minutes
2024-11-14 09:13:57,080:INFO:SubProcess create_model() called ==================================
2024-11-14 09:13:57,080:INFO:Initializing create_model()
2024-11-14 09:13:57,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:13:57,081:INFO:Checking exceptions
2024-11-14 09:13:57,081:INFO:Importing libraries
2024-11-14 09:13:57,081:INFO:Copying training dataset
2024-11-14 09:13:57,088:INFO:Defining folds
2024-11-14 09:13:57,088:INFO:Declaring metric variables
2024-11-14 09:13:57,091:INFO:Importing untrained model
2024-11-14 09:13:57,095:INFO:Elastic Net Imported successfully
2024-11-14 09:13:57,101:INFO:Starting cross validation
2024-11-14 09:13:57,102:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:13:59,958:INFO:Calculating mean and std
2024-11-14 09:13:59,962:INFO:Creating metrics dataframe
2024-11-14 09:13:59,967:INFO:Uploading results into container
2024-11-14 09:13:59,968:INFO:Uploading model into container now
2024-11-14 09:13:59,969:INFO:_master_model_container: 4
2024-11-14 09:13:59,969:INFO:_display_container: 2
2024-11-14 09:13:59,969:INFO:ElasticNet(random_state=123)
2024-11-14 09:13:59,969:INFO:create_model() successfully completed......................................
2024-11-14 09:14:00,128:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:00,128:INFO:Creating metrics dataframe
2024-11-14 09:14:00,138:INFO:Initializing Least Angle Regression
2024-11-14 09:14:00,138:INFO:Total runtime is 0.22009501457214356 minutes
2024-11-14 09:14:00,142:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:00,142:INFO:Initializing create_model()
2024-11-14 09:14:00,142:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:00,142:INFO:Checking exceptions
2024-11-14 09:14:00,142:INFO:Importing libraries
2024-11-14 09:14:00,143:INFO:Copying training dataset
2024-11-14 09:14:00,150:INFO:Defining folds
2024-11-14 09:14:00,150:INFO:Declaring metric variables
2024-11-14 09:14:00,153:INFO:Importing untrained model
2024-11-14 09:14:00,157:INFO:Least Angle Regression Imported successfully
2024-11-14 09:14:00,163:INFO:Starting cross validation
2024-11-14 09:14:00,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:02,719:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:02,740:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:02,767:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:02,811:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:02,848:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:02,893:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:02,903:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:02,921:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:02,959:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:03,014:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:03,034:INFO:Calculating mean and std
2024-11-14 09:14:03,037:INFO:Creating metrics dataframe
2024-11-14 09:14:03,042:INFO:Uploading results into container
2024-11-14 09:14:03,043:INFO:Uploading model into container now
2024-11-14 09:14:03,044:INFO:_master_model_container: 5
2024-11-14 09:14:03,044:INFO:_display_container: 2
2024-11-14 09:14:03,045:INFO:Lars(random_state=123)
2024-11-14 09:14:03,045:INFO:create_model() successfully completed......................................
2024-11-14 09:14:03,227:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:03,227:INFO:Creating metrics dataframe
2024-11-14 09:14:03,237:INFO:Initializing Lasso Least Angle Regression
2024-11-14 09:14:03,237:INFO:Total runtime is 0.27174580097198486 minutes
2024-11-14 09:14:03,241:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:03,241:INFO:Initializing create_model()
2024-11-14 09:14:03,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:03,241:INFO:Checking exceptions
2024-11-14 09:14:03,242:INFO:Importing libraries
2024-11-14 09:14:03,242:INFO:Copying training dataset
2024-11-14 09:14:03,249:INFO:Defining folds
2024-11-14 09:14:03,249:INFO:Declaring metric variables
2024-11-14 09:14:03,252:INFO:Importing untrained model
2024-11-14 09:14:03,255:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 09:14:03,263:INFO:Starting cross validation
2024-11-14 09:14:03,263:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:03,337:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:14:03,340:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:14:03,347:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:14:03,363:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:14:05,782:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:14:05,805:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:14:05,857:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:14:05,917:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:14:06,003:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:14:06,115:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:14:06,126:INFO:Calculating mean and std
2024-11-14 09:14:06,130:INFO:Creating metrics dataframe
2024-11-14 09:14:06,136:INFO:Uploading results into container
2024-11-14 09:14:06,137:INFO:Uploading model into container now
2024-11-14 09:14:06,137:INFO:_master_model_container: 6
2024-11-14 09:14:06,137:INFO:_display_container: 2
2024-11-14 09:14:06,138:INFO:LassoLars(random_state=123)
2024-11-14 09:14:06,138:INFO:create_model() successfully completed......................................
2024-11-14 09:14:06,330:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:06,331:INFO:Creating metrics dataframe
2024-11-14 09:14:06,342:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 09:14:06,342:INFO:Total runtime is 0.32349501848220824 minutes
2024-11-14 09:14:06,346:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:06,346:INFO:Initializing create_model()
2024-11-14 09:14:06,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:06,346:INFO:Checking exceptions
2024-11-14 09:14:06,346:INFO:Importing libraries
2024-11-14 09:14:06,347:INFO:Copying training dataset
2024-11-14 09:14:06,353:INFO:Defining folds
2024-11-14 09:14:06,354:INFO:Declaring metric variables
2024-11-14 09:14:06,357:INFO:Importing untrained model
2024-11-14 09:14:06,360:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 09:14:06,367:INFO:Starting cross validation
2024-11-14 09:14:06,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:06,399:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:06,407:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:06,417:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:06,425:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:06,436:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:06,441:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:06,443:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:06,444:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:06,449:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:06,454:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:14:06,467:INFO:Calculating mean and std
2024-11-14 09:14:06,471:INFO:Creating metrics dataframe
2024-11-14 09:14:06,478:INFO:Uploading results into container
2024-11-14 09:14:06,479:INFO:Uploading model into container now
2024-11-14 09:14:06,479:INFO:_master_model_container: 7
2024-11-14 09:14:06,479:INFO:_display_container: 2
2024-11-14 09:14:06,479:INFO:OrthogonalMatchingPursuit()
2024-11-14 09:14:06,480:INFO:create_model() successfully completed......................................
2024-11-14 09:14:06,621:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:06,621:INFO:Creating metrics dataframe
2024-11-14 09:14:06,633:INFO:Initializing Bayesian Ridge
2024-11-14 09:14:06,633:INFO:Total runtime is 0.3283329089482625 minutes
2024-11-14 09:14:06,636:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:06,636:INFO:Initializing create_model()
2024-11-14 09:14:06,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:06,636:INFO:Checking exceptions
2024-11-14 09:14:06,636:INFO:Importing libraries
2024-11-14 09:14:06,637:INFO:Copying training dataset
2024-11-14 09:14:06,643:INFO:Defining folds
2024-11-14 09:14:06,643:INFO:Declaring metric variables
2024-11-14 09:14:06,647:INFO:Importing untrained model
2024-11-14 09:14:06,650:INFO:Bayesian Ridge Imported successfully
2024-11-14 09:14:06,656:INFO:Starting cross validation
2024-11-14 09:14:06,657:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:06,760:INFO:Calculating mean and std
2024-11-14 09:14:06,764:INFO:Creating metrics dataframe
2024-11-14 09:14:06,771:INFO:Uploading results into container
2024-11-14 09:14:06,772:INFO:Uploading model into container now
2024-11-14 09:14:06,772:INFO:_master_model_container: 8
2024-11-14 09:14:06,772:INFO:_display_container: 2
2024-11-14 09:14:06,773:INFO:BayesianRidge()
2024-11-14 09:14:06,773:INFO:create_model() successfully completed......................................
2024-11-14 09:14:06,926:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:06,926:INFO:Creating metrics dataframe
2024-11-14 09:14:06,937:INFO:Initializing Passive Aggressive Regressor
2024-11-14 09:14:06,937:INFO:Total runtime is 0.3334125121434529 minutes
2024-11-14 09:14:06,941:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:06,941:INFO:Initializing create_model()
2024-11-14 09:14:06,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:06,941:INFO:Checking exceptions
2024-11-14 09:14:06,941:INFO:Importing libraries
2024-11-14 09:14:06,941:INFO:Copying training dataset
2024-11-14 09:14:06,948:INFO:Defining folds
2024-11-14 09:14:06,949:INFO:Declaring metric variables
2024-11-14 09:14:06,952:INFO:Importing untrained model
2024-11-14 09:14:06,955:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 09:14:06,962:INFO:Starting cross validation
2024-11-14 09:14:06,963:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:07,167:INFO:Calculating mean and std
2024-11-14 09:14:07,171:INFO:Creating metrics dataframe
2024-11-14 09:14:07,178:INFO:Uploading results into container
2024-11-14 09:14:07,179:INFO:Uploading model into container now
2024-11-14 09:14:07,179:INFO:_master_model_container: 9
2024-11-14 09:14:07,179:INFO:_display_container: 2
2024-11-14 09:14:07,180:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-14 09:14:07,180:INFO:create_model() successfully completed......................................
2024-11-14 09:14:07,320:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:07,320:INFO:Creating metrics dataframe
2024-11-14 09:14:07,332:INFO:Initializing Huber Regressor
2024-11-14 09:14:07,332:INFO:Total runtime is 0.33999195496241247 minutes
2024-11-14 09:14:07,335:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:07,336:INFO:Initializing create_model()
2024-11-14 09:14:07,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:07,336:INFO:Checking exceptions
2024-11-14 09:14:07,336:INFO:Importing libraries
2024-11-14 09:14:07,336:INFO:Copying training dataset
2024-11-14 09:14:07,343:INFO:Defining folds
2024-11-14 09:14:07,343:INFO:Declaring metric variables
2024-11-14 09:14:07,347:INFO:Importing untrained model
2024-11-14 09:14:07,350:INFO:Huber Regressor Imported successfully
2024-11-14 09:14:07,357:INFO:Starting cross validation
2024-11-14 09:14:07,358:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:07,627:INFO:Calculating mean and std
2024-11-14 09:14:07,631:INFO:Creating metrics dataframe
2024-11-14 09:14:07,638:INFO:Uploading results into container
2024-11-14 09:14:07,639:INFO:Uploading model into container now
2024-11-14 09:14:07,639:INFO:_master_model_container: 10
2024-11-14 09:14:07,639:INFO:_display_container: 2
2024-11-14 09:14:07,640:INFO:HuberRegressor()
2024-11-14 09:14:07,640:INFO:create_model() successfully completed......................................
2024-11-14 09:14:07,781:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:07,781:INFO:Creating metrics dataframe
2024-11-14 09:14:07,793:INFO:Initializing K Neighbors Regressor
2024-11-14 09:14:07,793:INFO:Total runtime is 0.34767777125040683 minutes
2024-11-14 09:14:07,797:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:07,797:INFO:Initializing create_model()
2024-11-14 09:14:07,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:07,797:INFO:Checking exceptions
2024-11-14 09:14:07,797:INFO:Importing libraries
2024-11-14 09:14:07,798:INFO:Copying training dataset
2024-11-14 09:14:07,804:INFO:Defining folds
2024-11-14 09:14:07,805:INFO:Declaring metric variables
2024-11-14 09:14:07,808:INFO:Importing untrained model
2024-11-14 09:14:07,811:INFO:K Neighbors Regressor Imported successfully
2024-11-14 09:14:07,817:INFO:Starting cross validation
2024-11-14 09:14:07,818:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:08,014:INFO:Calculating mean and std
2024-11-14 09:14:08,018:INFO:Creating metrics dataframe
2024-11-14 09:14:08,024:INFO:Uploading results into container
2024-11-14 09:14:08,025:INFO:Uploading model into container now
2024-11-14 09:14:08,026:INFO:_master_model_container: 11
2024-11-14 09:14:08,026:INFO:_display_container: 2
2024-11-14 09:14:08,026:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 09:14:08,026:INFO:create_model() successfully completed......................................
2024-11-14 09:14:08,215:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:08,216:INFO:Creating metrics dataframe
2024-11-14 09:14:08,229:INFO:Initializing Decision Tree Regressor
2024-11-14 09:14:08,229:INFO:Total runtime is 0.3549398779869079 minutes
2024-11-14 09:14:08,232:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:08,233:INFO:Initializing create_model()
2024-11-14 09:14:08,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:08,233:INFO:Checking exceptions
2024-11-14 09:14:08,233:INFO:Importing libraries
2024-11-14 09:14:08,233:INFO:Copying training dataset
2024-11-14 09:14:08,241:INFO:Defining folds
2024-11-14 09:14:08,241:INFO:Declaring metric variables
2024-11-14 09:14:08,244:INFO:Importing untrained model
2024-11-14 09:14:08,247:INFO:Decision Tree Regressor Imported successfully
2024-11-14 09:14:08,254:INFO:Starting cross validation
2024-11-14 09:14:08,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:08,418:INFO:Calculating mean and std
2024-11-14 09:14:08,419:INFO:Creating metrics dataframe
2024-11-14 09:14:08,426:INFO:Uploading results into container
2024-11-14 09:14:08,426:INFO:Uploading model into container now
2024-11-14 09:14:08,427:INFO:_master_model_container: 12
2024-11-14 09:14:08,427:INFO:_display_container: 2
2024-11-14 09:14:08,428:INFO:DecisionTreeRegressor(random_state=123)
2024-11-14 09:14:08,428:INFO:create_model() successfully completed......................................
2024-11-14 09:14:08,593:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:08,594:INFO:Creating metrics dataframe
2024-11-14 09:14:08,608:INFO:Initializing Random Forest Regressor
2024-11-14 09:14:08,608:INFO:Total runtime is 0.36126066843668614 minutes
2024-11-14 09:14:08,612:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:08,613:INFO:Initializing create_model()
2024-11-14 09:14:08,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:08,613:INFO:Checking exceptions
2024-11-14 09:14:08,613:INFO:Importing libraries
2024-11-14 09:14:08,613:INFO:Copying training dataset
2024-11-14 09:14:08,621:INFO:Defining folds
2024-11-14 09:14:08,622:INFO:Declaring metric variables
2024-11-14 09:14:08,625:INFO:Importing untrained model
2024-11-14 09:14:08,630:INFO:Random Forest Regressor Imported successfully
2024-11-14 09:14:08,637:INFO:Starting cross validation
2024-11-14 09:14:08,638:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:10,226:INFO:Calculating mean and std
2024-11-14 09:14:10,230:INFO:Creating metrics dataframe
2024-11-14 09:14:10,234:INFO:Uploading results into container
2024-11-14 09:14:10,235:INFO:Uploading model into container now
2024-11-14 09:14:10,236:INFO:_master_model_container: 13
2024-11-14 09:14:10,236:INFO:_display_container: 2
2024-11-14 09:14:10,237:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:14:10,237:INFO:create_model() successfully completed......................................
2024-11-14 09:14:10,376:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:10,376:INFO:Creating metrics dataframe
2024-11-14 09:14:10,388:INFO:Initializing Extra Trees Regressor
2024-11-14 09:14:10,389:INFO:Total runtime is 0.3909329175949096 minutes
2024-11-14 09:14:10,392:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:10,392:INFO:Initializing create_model()
2024-11-14 09:14:10,392:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:10,392:INFO:Checking exceptions
2024-11-14 09:14:10,393:INFO:Importing libraries
2024-11-14 09:14:10,393:INFO:Copying training dataset
2024-11-14 09:14:10,400:INFO:Defining folds
2024-11-14 09:14:10,400:INFO:Declaring metric variables
2024-11-14 09:14:10,403:INFO:Importing untrained model
2024-11-14 09:14:10,407:INFO:Extra Trees Regressor Imported successfully
2024-11-14 09:14:10,413:INFO:Starting cross validation
2024-11-14 09:14:10,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:11,257:INFO:Calculating mean and std
2024-11-14 09:14:11,260:INFO:Creating metrics dataframe
2024-11-14 09:14:11,267:INFO:Uploading results into container
2024-11-14 09:14:11,267:INFO:Uploading model into container now
2024-11-14 09:14:11,268:INFO:_master_model_container: 14
2024-11-14 09:14:11,268:INFO:_display_container: 2
2024-11-14 09:14:11,269:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:14:11,269:INFO:create_model() successfully completed......................................
2024-11-14 09:14:11,410:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:11,410:INFO:Creating metrics dataframe
2024-11-14 09:14:11,423:INFO:Initializing AdaBoost Regressor
2024-11-14 09:14:11,423:INFO:Total runtime is 0.40817873477935784 minutes
2024-11-14 09:14:11,431:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:11,431:INFO:Initializing create_model()
2024-11-14 09:14:11,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:11,432:INFO:Checking exceptions
2024-11-14 09:14:11,432:INFO:Importing libraries
2024-11-14 09:14:11,432:INFO:Copying training dataset
2024-11-14 09:14:11,440:INFO:Defining folds
2024-11-14 09:14:11,440:INFO:Declaring metric variables
2024-11-14 09:14:11,443:INFO:Importing untrained model
2024-11-14 09:14:11,446:INFO:AdaBoost Regressor Imported successfully
2024-11-14 09:14:11,453:INFO:Starting cross validation
2024-11-14 09:14:11,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:12,413:INFO:Calculating mean and std
2024-11-14 09:14:12,416:INFO:Creating metrics dataframe
2024-11-14 09:14:12,423:INFO:Uploading results into container
2024-11-14 09:14:12,424:INFO:Uploading model into container now
2024-11-14 09:14:12,424:INFO:_master_model_container: 15
2024-11-14 09:14:12,424:INFO:_display_container: 2
2024-11-14 09:14:12,424:INFO:AdaBoostRegressor(random_state=123)
2024-11-14 09:14:12,424:INFO:create_model() successfully completed......................................
2024-11-14 09:14:12,562:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:12,563:INFO:Creating metrics dataframe
2024-11-14 09:14:12,575:INFO:Initializing Gradient Boosting Regressor
2024-11-14 09:14:12,575:INFO:Total runtime is 0.42737795511881504 minutes
2024-11-14 09:14:12,578:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:12,579:INFO:Initializing create_model()
2024-11-14 09:14:12,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:12,579:INFO:Checking exceptions
2024-11-14 09:14:12,579:INFO:Importing libraries
2024-11-14 09:14:12,579:INFO:Copying training dataset
2024-11-14 09:14:12,586:INFO:Defining folds
2024-11-14 09:14:12,586:INFO:Declaring metric variables
2024-11-14 09:14:12,589:INFO:Importing untrained model
2024-11-14 09:14:12,592:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 09:14:12,599:INFO:Starting cross validation
2024-11-14 09:14:12,599:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:13,944:INFO:Calculating mean and std
2024-11-14 09:14:13,948:INFO:Creating metrics dataframe
2024-11-14 09:14:13,955:INFO:Uploading results into container
2024-11-14 09:14:13,956:INFO:Uploading model into container now
2024-11-14 09:14:13,956:INFO:_master_model_container: 16
2024-11-14 09:14:13,956:INFO:_display_container: 2
2024-11-14 09:14:13,957:INFO:GradientBoostingRegressor(random_state=123)
2024-11-14 09:14:13,957:INFO:create_model() successfully completed......................................
2024-11-14 09:14:14,146:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:14,147:INFO:Creating metrics dataframe
2024-11-14 09:14:14,160:INFO:Initializing Extreme Gradient Boosting
2024-11-14 09:14:14,160:INFO:Total runtime is 0.453785216808319 minutes
2024-11-14 09:14:14,163:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:14,163:INFO:Initializing create_model()
2024-11-14 09:14:14,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:14,164:INFO:Checking exceptions
2024-11-14 09:14:14,164:INFO:Importing libraries
2024-11-14 09:14:14,164:INFO:Copying training dataset
2024-11-14 09:14:14,171:INFO:Defining folds
2024-11-14 09:14:14,171:INFO:Declaring metric variables
2024-11-14 09:14:14,174:INFO:Importing untrained model
2024-11-14 09:14:14,178:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 09:14:14,184:INFO:Starting cross validation
2024-11-14 09:14:14,185:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:14:14,497:INFO:Calculating mean and std
2024-11-14 09:14:14,501:INFO:Creating metrics dataframe
2024-11-14 09:14:14,507:INFO:Uploading results into container
2024-11-14 09:14:14,508:INFO:Uploading model into container now
2024-11-14 09:14:14,509:INFO:_master_model_container: 17
2024-11-14 09:14:14,509:INFO:_display_container: 2
2024-11-14 09:14:14,510:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-14 09:14:14,510:INFO:create_model() successfully completed......................................
2024-11-14 09:14:14,653:INFO:SubProcess create_model() end ==================================
2024-11-14 09:14:14,654:INFO:Creating metrics dataframe
2024-11-14 09:14:14,666:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 09:14:14,666:INFO:Total runtime is 0.46222756703694656 minutes
2024-11-14 09:14:14,670:INFO:SubProcess create_model() called ==================================
2024-11-14 09:14:14,670:INFO:Initializing create_model()
2024-11-14 09:14:14,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7754769790>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7566205310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:14:14,670:INFO:Checking exceptions
2024-11-14 09:14:14,670:INFO:Importing libraries
2024-11-14 09:14:14,670:INFO:Copying training dataset
2024-11-14 09:14:14,677:INFO:Defining folds
2024-11-14 09:14:14,677:INFO:Declaring metric variables
2024-11-14 09:14:14,681:INFO:Importing untrained model
2024-11-14 09:14:14,684:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 09:14:14,690:INFO:Starting cross validation
2024-11-14 09:14:14,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:12,473:INFO:PyCaret RegressionExperiment
2024-11-14 09:15:12,473:INFO:Logging name: reg-default-name
2024-11-14 09:15:12,473:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 09:15:12,473:INFO:version 3.2.0
2024-11-14 09:15:12,473:INFO:Initializing setup()
2024-11-14 09:15:12,473:INFO:self.USI: 5606
2024-11-14 09:15:12,473:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'fold_generator', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'memory', 'data', 'fold_groups_param', 'X', 'transform_target_param', 'target_param', 'y_test', 'X_train', 'seed', 'pipeline', 'html_param', 'exp_name_log', 'USI', 'log_plots_param', 'gpu_param', 'n_jobs_param', 'exp_id', '_available_plots', 'logging_param', 'y_train'}
2024-11-14 09:15:12,473:INFO:Checking environment
2024-11-14 09:15:12,473:INFO:python_version: 3.8.13
2024-11-14 09:15:12,474:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 09:15:12,476:INFO:machine: x86_64
2024-11-14 09:15:12,476:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 09:15:12,477:INFO:Memory: svmem(total=270355722240, available=224959352832, percent=16.8, used=43314393088, free=79118204928, active=71694618624, inactive=59346059264, buffers=9031680, cached=147914092544, shared=187392000, slab=25137573888)
2024-11-14 09:15:12,481:INFO:Physical Core: 28
2024-11-14 09:15:12,482:INFO:Logical Core: 56
2024-11-14 09:15:12,482:INFO:Checking libraries
2024-11-14 09:15:12,482:INFO:System:
2024-11-14 09:15:12,482:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 09:15:12,482:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 09:15:12,482:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 09:15:12,482:INFO:PyCaret required dependencies:
2024-11-14 09:15:12,483:INFO:                 pip: 22.2.2
2024-11-14 09:15:12,483:INFO:          setuptools: 63.4.2
2024-11-14 09:15:12,483:INFO:             pycaret: 3.2.0
2024-11-14 09:15:12,483:INFO:             IPython: 8.12.2
2024-11-14 09:15:12,483:INFO:          ipywidgets: 7.7.1
2024-11-14 09:15:12,483:INFO:                tqdm: 4.64.1
2024-11-14 09:15:12,483:INFO:               numpy: 1.23.5
2024-11-14 09:15:12,483:INFO:              pandas: 1.5.3
2024-11-14 09:15:12,483:INFO:              jinja2: 3.1.2
2024-11-14 09:15:12,483:INFO:               scipy: 1.10.1
2024-11-14 09:15:12,483:INFO:              joblib: 1.3.0
2024-11-14 09:15:12,483:INFO:             sklearn: 1.1.2
2024-11-14 09:15:12,483:INFO:                pyod: 2.0.2
2024-11-14 09:15:12,483:INFO:            imblearn: 0.12.4
2024-11-14 09:15:12,483:INFO:   category_encoders: 2.6.4
2024-11-14 09:15:12,484:INFO:            lightgbm: 4.5.0
2024-11-14 09:15:12,484:INFO:               numba: 0.57.1
2024-11-14 09:15:12,484:INFO:            requests: 2.28.1
2024-11-14 09:15:12,484:INFO:          matplotlib: 3.5.1
2024-11-14 09:15:12,484:INFO:          scikitplot: 0.3.7
2024-11-14 09:15:12,484:INFO:         yellowbrick: 1.5
2024-11-14 09:15:12,484:INFO:              plotly: 5.24.1
2024-11-14 09:15:12,484:INFO:    plotly-resampler: Not installed
2024-11-14 09:15:12,484:INFO:             kaleido: 0.2.1
2024-11-14 09:15:12,484:INFO:           schemdraw: 0.15
2024-11-14 09:15:12,484:INFO:         statsmodels: 0.13.2
2024-11-14 09:15:12,484:INFO:              sktime: 0.21.1
2024-11-14 09:15:12,484:INFO:               tbats: 1.1.3
2024-11-14 09:15:12,484:INFO:            pmdarima: 2.0.4
2024-11-14 09:15:12,484:INFO:              psutil: 5.9.1
2024-11-14 09:15:12,485:INFO:          markupsafe: 2.1.1
2024-11-14 09:15:12,485:INFO:             pickle5: Not installed
2024-11-14 09:15:12,485:INFO:         cloudpickle: 2.1.0
2024-11-14 09:15:12,485:INFO:         deprecation: 2.1.0
2024-11-14 09:15:12,485:INFO:              xxhash: 3.5.0
2024-11-14 09:15:12,485:INFO:           wurlitzer: 3.1.1
2024-11-14 09:15:12,485:INFO:PyCaret optional dependencies:
2024-11-14 09:15:12,485:INFO:                shap: 0.44.1
2024-11-14 09:15:12,485:INFO:           interpret: 0.6.5
2024-11-14 09:15:12,485:INFO:                umap: 0.5.7
2024-11-14 09:15:12,485:INFO:     ydata_profiling: 4.6.0
2024-11-14 09:15:12,486:INFO:  explainerdashboard: 0.4.7
2024-11-14 09:15:12,486:INFO:             autoviz: Not installed
2024-11-14 09:15:12,486:INFO:           fairlearn: 0.7.0
2024-11-14 09:15:12,486:INFO:          deepchecks: Not installed
2024-11-14 09:15:12,486:INFO:             xgboost: 2.1.1
2024-11-14 09:15:12,486:INFO:            catboost: 1.2.7
2024-11-14 09:15:12,486:INFO:              kmodes: 0.12.2
2024-11-14 09:15:12,486:INFO:             mlxtend: 0.23.1
2024-11-14 09:15:12,486:INFO:       statsforecast: 1.5.0
2024-11-14 09:15:12,486:INFO:        tune_sklearn: 0.5.0
2024-11-14 09:15:12,486:INFO:                 ray: 2.10.0
2024-11-14 09:15:12,486:INFO:            hyperopt: 0.2.7
2024-11-14 09:15:12,486:INFO:              optuna: 4.1.0
2024-11-14 09:15:12,486:INFO:               skopt: 0.10.2
2024-11-14 09:15:12,486:INFO:              mlflow: 1.30.1
2024-11-14 09:15:12,486:INFO:              gradio: 3.50.2
2024-11-14 09:15:12,486:INFO:             fastapi: 0.115.5
2024-11-14 09:15:12,486:INFO:             uvicorn: 0.32.0
2024-11-14 09:15:12,486:INFO:              m2cgen: 0.10.0
2024-11-14 09:15:12,486:INFO:           evidently: 0.2.8
2024-11-14 09:15:12,486:INFO:               fugue: 0.8.6
2024-11-14 09:15:12,486:INFO:           streamlit: Not installed
2024-11-14 09:15:12,486:INFO:             prophet: Not installed
2024-11-14 09:15:12,486:INFO:None
2024-11-14 09:15:12,487:INFO:Set up data.
2024-11-14 09:15:12,500:INFO:Set up folding strategy.
2024-11-14 09:15:12,500:INFO:Set up train/test split.
2024-11-14 09:15:12,510:INFO:Set up index.
2024-11-14 09:15:12,513:INFO:Assigning column types.
2024-11-14 09:15:12,518:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 09:15:12,519:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,528:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,534:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,661:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:12,665:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:12,669:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,674:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,679:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,797:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,797:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:12,800:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:12,801:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 09:15:12,805:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,907:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:12,910:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:12,915:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,919:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:15:12,974:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,016:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:13,019:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:13,019:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 09:15:13,028:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,126:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:13,129:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:13,138:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,234:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,235:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:13,238:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:13,238:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 09:15:13,301:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,346:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:13,348:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:13,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,478:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,479:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:13,482:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:13,483:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 09:15:13,566:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,607:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:13,610:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:13,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:15:13,716:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:13,718:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:13,719:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 09:15:13,825:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:13,828:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:13,933:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:13,936:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:13,943:INFO:Preparing preprocessing pipeline...
2024-11-14 09:15:13,943:INFO:Set up simple imputation.
2024-11-14 09:15:13,961:INFO:Finished creating preprocessing pipeline.
2024-11-14 09:15:13,965:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 09:15:13,965:INFO:Creating final display dataframe.
2024-11-14 09:15:14,021:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5606
2024-11-14 09:15:14,136:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:14,138:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:14,245:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:15:14,248:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:15:14,248:INFO:setup() successfully completed in 1.78s...............
2024-11-14 09:15:16,540:INFO:Initializing compare_models()
2024-11-14 09:15:16,540:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 09:15:16,540:INFO:Checking exceptions
2024-11-14 09:15:16,546:INFO:Preparing display monitor
2024-11-14 09:15:16,595:INFO:Initializing Linear Regression
2024-11-14 09:15:16,595:INFO:Total runtime is 2.781550089518229e-06 minutes
2024-11-14 09:15:16,599:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:16,599:INFO:Initializing create_model()
2024-11-14 09:15:16,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:16,600:INFO:Checking exceptions
2024-11-14 09:15:16,600:INFO:Importing libraries
2024-11-14 09:15:16,600:INFO:Copying training dataset
2024-11-14 09:15:16,607:INFO:Defining folds
2024-11-14 09:15:16,607:INFO:Declaring metric variables
2024-11-14 09:15:16,611:INFO:Importing untrained model
2024-11-14 09:15:16,615:INFO:Linear Regression Imported successfully
2024-11-14 09:15:16,624:INFO:Starting cross validation
2024-11-14 09:15:16,625:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:20,603:INFO:Calculating mean and std
2024-11-14 09:15:20,609:INFO:Creating metrics dataframe
2024-11-14 09:15:20,615:INFO:Uploading results into container
2024-11-14 09:15:20,615:INFO:Uploading model into container now
2024-11-14 09:15:20,616:INFO:_master_model_container: 1
2024-11-14 09:15:20,616:INFO:_display_container: 2
2024-11-14 09:15:20,617:INFO:LinearRegression(n_jobs=-1)
2024-11-14 09:15:20,617:INFO:create_model() successfully completed......................................
2024-11-14 09:15:20,887:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:20,887:INFO:Creating metrics dataframe
2024-11-14 09:15:20,897:INFO:Initializing Lasso Regression
2024-11-14 09:15:20,897:INFO:Total runtime is 0.07171188592910767 minutes
2024-11-14 09:15:20,901:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:20,901:INFO:Initializing create_model()
2024-11-14 09:15:20,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:20,901:INFO:Checking exceptions
2024-11-14 09:15:20,902:INFO:Importing libraries
2024-11-14 09:15:20,902:INFO:Copying training dataset
2024-11-14 09:15:20,911:INFO:Defining folds
2024-11-14 09:15:20,911:INFO:Declaring metric variables
2024-11-14 09:15:20,915:INFO:Importing untrained model
2024-11-14 09:15:20,918:INFO:Lasso Regression Imported successfully
2024-11-14 09:15:20,925:INFO:Starting cross validation
2024-11-14 09:15:20,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:23,709:INFO:Calculating mean and std
2024-11-14 09:15:23,713:INFO:Creating metrics dataframe
2024-11-14 09:15:23,720:INFO:Uploading results into container
2024-11-14 09:15:23,721:INFO:Uploading model into container now
2024-11-14 09:15:23,721:INFO:_master_model_container: 2
2024-11-14 09:15:23,722:INFO:_display_container: 2
2024-11-14 09:15:23,722:INFO:Lasso(random_state=123)
2024-11-14 09:15:23,722:INFO:create_model() successfully completed......................................
2024-11-14 09:15:23,934:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:23,934:INFO:Creating metrics dataframe
2024-11-14 09:15:23,944:INFO:Initializing Ridge Regression
2024-11-14 09:15:23,944:INFO:Total runtime is 0.1224936604499817 minutes
2024-11-14 09:15:23,947:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:23,948:INFO:Initializing create_model()
2024-11-14 09:15:23,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:23,948:INFO:Checking exceptions
2024-11-14 09:15:23,948:INFO:Importing libraries
2024-11-14 09:15:23,948:INFO:Copying training dataset
2024-11-14 09:15:23,955:INFO:Defining folds
2024-11-14 09:15:23,956:INFO:Declaring metric variables
2024-11-14 09:15:23,959:INFO:Importing untrained model
2024-11-14 09:15:23,962:INFO:Ridge Regression Imported successfully
2024-11-14 09:15:23,969:INFO:Starting cross validation
2024-11-14 09:15:23,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:26,742:INFO:Calculating mean and std
2024-11-14 09:15:26,746:INFO:Creating metrics dataframe
2024-11-14 09:15:26,753:INFO:Uploading results into container
2024-11-14 09:15:26,754:INFO:Uploading model into container now
2024-11-14 09:15:26,755:INFO:_master_model_container: 3
2024-11-14 09:15:26,755:INFO:_display_container: 2
2024-11-14 09:15:26,755:INFO:Ridge(random_state=123)
2024-11-14 09:15:26,755:INFO:create_model() successfully completed......................................
2024-11-14 09:15:26,942:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:26,943:INFO:Creating metrics dataframe
2024-11-14 09:15:26,952:INFO:Initializing Elastic Net
2024-11-14 09:15:26,953:INFO:Total runtime is 0.1726361870765686 minutes
2024-11-14 09:15:26,956:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:26,956:INFO:Initializing create_model()
2024-11-14 09:15:26,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:26,956:INFO:Checking exceptions
2024-11-14 09:15:26,957:INFO:Importing libraries
2024-11-14 09:15:26,957:INFO:Copying training dataset
2024-11-14 09:15:26,964:INFO:Defining folds
2024-11-14 09:15:26,964:INFO:Declaring metric variables
2024-11-14 09:15:26,967:INFO:Importing untrained model
2024-11-14 09:15:26,971:INFO:Elastic Net Imported successfully
2024-11-14 09:15:26,977:INFO:Starting cross validation
2024-11-14 09:15:26,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:29,941:INFO:Calculating mean and std
2024-11-14 09:15:29,945:INFO:Creating metrics dataframe
2024-11-14 09:15:29,951:INFO:Uploading results into container
2024-11-14 09:15:29,952:INFO:Uploading model into container now
2024-11-14 09:15:29,952:INFO:_master_model_container: 4
2024-11-14 09:15:29,952:INFO:_display_container: 2
2024-11-14 09:15:29,953:INFO:ElasticNet(random_state=123)
2024-11-14 09:15:29,953:INFO:create_model() successfully completed......................................
2024-11-14 09:15:30,159:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:30,159:INFO:Creating metrics dataframe
2024-11-14 09:15:30,171:INFO:Initializing Least Angle Regression
2024-11-14 09:15:30,171:INFO:Total runtime is 0.22627538442611694 minutes
2024-11-14 09:15:30,174:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:30,175:INFO:Initializing create_model()
2024-11-14 09:15:30,175:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:30,175:INFO:Checking exceptions
2024-11-14 09:15:30,175:INFO:Importing libraries
2024-11-14 09:15:30,175:INFO:Copying training dataset
2024-11-14 09:15:30,183:INFO:Defining folds
2024-11-14 09:15:30,183:INFO:Declaring metric variables
2024-11-14 09:15:30,186:INFO:Importing untrained model
2024-11-14 09:15:30,190:INFO:Least Angle Regression Imported successfully
2024-11-14 09:15:30,197:INFO:Starting cross validation
2024-11-14 09:15:30,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:32,751:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:32,766:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:32,825:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:32,874:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:32,880:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:32,928:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:32,937:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:32,939:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:32,954:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:33,071:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:33,085:INFO:Calculating mean and std
2024-11-14 09:15:33,089:INFO:Creating metrics dataframe
2024-11-14 09:15:33,095:INFO:Uploading results into container
2024-11-14 09:15:33,096:INFO:Uploading model into container now
2024-11-14 09:15:33,097:INFO:_master_model_container: 5
2024-11-14 09:15:33,097:INFO:_display_container: 2
2024-11-14 09:15:33,097:INFO:Lars(random_state=123)
2024-11-14 09:15:33,097:INFO:create_model() successfully completed......................................
2024-11-14 09:15:33,284:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:33,285:INFO:Creating metrics dataframe
2024-11-14 09:15:33,296:INFO:Initializing Lasso Least Angle Regression
2024-11-14 09:15:33,296:INFO:Total runtime is 0.27835903962453207 minutes
2024-11-14 09:15:33,299:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:33,300:INFO:Initializing create_model()
2024-11-14 09:15:33,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:33,300:INFO:Checking exceptions
2024-11-14 09:15:33,300:INFO:Importing libraries
2024-11-14 09:15:33,300:INFO:Copying training dataset
2024-11-14 09:15:33,308:INFO:Defining folds
2024-11-14 09:15:33,308:INFO:Declaring metric variables
2024-11-14 09:15:33,311:INFO:Importing untrained model
2024-11-14 09:15:33,315:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 09:15:33,321:INFO:Starting cross validation
2024-11-14 09:15:33,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:33,401:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:15:33,404:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:15:33,413:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:15:33,419:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:15:35,773:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:15:35,888:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:15:35,918:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:15:35,956:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:15:35,976:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:15:36,002:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:15:36,021:INFO:Calculating mean and std
2024-11-14 09:15:36,024:INFO:Creating metrics dataframe
2024-11-14 09:15:36,030:INFO:Uploading results into container
2024-11-14 09:15:36,031:INFO:Uploading model into container now
2024-11-14 09:15:36,032:INFO:_master_model_container: 6
2024-11-14 09:15:36,032:INFO:_display_container: 2
2024-11-14 09:15:36,032:INFO:LassoLars(random_state=123)
2024-11-14 09:15:36,032:INFO:create_model() successfully completed......................................
2024-11-14 09:15:36,223:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:36,223:INFO:Creating metrics dataframe
2024-11-14 09:15:36,234:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 09:15:36,234:INFO:Total runtime is 0.3273259123166402 minutes
2024-11-14 09:15:36,237:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:36,238:INFO:Initializing create_model()
2024-11-14 09:15:36,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:36,238:INFO:Checking exceptions
2024-11-14 09:15:36,238:INFO:Importing libraries
2024-11-14 09:15:36,238:INFO:Copying training dataset
2024-11-14 09:15:36,245:INFO:Defining folds
2024-11-14 09:15:36,246:INFO:Declaring metric variables
2024-11-14 09:15:36,249:INFO:Importing untrained model
2024-11-14 09:15:36,253:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 09:15:36,259:INFO:Starting cross validation
2024-11-14 09:15:36,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:36,296:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:36,301:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:36,309:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:36,313:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:36,321:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:36,327:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:36,329:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:36,335:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:36,344:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:36,348:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:15:36,365:INFO:Calculating mean and std
2024-11-14 09:15:36,369:INFO:Creating metrics dataframe
2024-11-14 09:15:36,375:INFO:Uploading results into container
2024-11-14 09:15:36,376:INFO:Uploading model into container now
2024-11-14 09:15:36,376:INFO:_master_model_container: 7
2024-11-14 09:15:36,377:INFO:_display_container: 2
2024-11-14 09:15:36,377:INFO:OrthogonalMatchingPursuit()
2024-11-14 09:15:36,377:INFO:create_model() successfully completed......................................
2024-11-14 09:15:36,548:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:36,548:INFO:Creating metrics dataframe
2024-11-14 09:15:36,559:INFO:Initializing Bayesian Ridge
2024-11-14 09:15:36,559:INFO:Total runtime is 0.33274556398391725 minutes
2024-11-14 09:15:36,562:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:36,563:INFO:Initializing create_model()
2024-11-14 09:15:36,563:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:36,563:INFO:Checking exceptions
2024-11-14 09:15:36,563:INFO:Importing libraries
2024-11-14 09:15:36,563:INFO:Copying training dataset
2024-11-14 09:15:36,570:INFO:Defining folds
2024-11-14 09:15:36,571:INFO:Declaring metric variables
2024-11-14 09:15:36,574:INFO:Importing untrained model
2024-11-14 09:15:36,577:INFO:Bayesian Ridge Imported successfully
2024-11-14 09:15:36,584:INFO:Starting cross validation
2024-11-14 09:15:36,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:36,685:INFO:Calculating mean and std
2024-11-14 09:15:36,689:INFO:Creating metrics dataframe
2024-11-14 09:15:36,695:INFO:Uploading results into container
2024-11-14 09:15:36,696:INFO:Uploading model into container now
2024-11-14 09:15:36,697:INFO:_master_model_container: 8
2024-11-14 09:15:36,697:INFO:_display_container: 2
2024-11-14 09:15:36,697:INFO:BayesianRidge()
2024-11-14 09:15:36,697:INFO:create_model() successfully completed......................................
2024-11-14 09:15:36,908:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:36,908:INFO:Creating metrics dataframe
2024-11-14 09:15:36,919:INFO:Initializing Passive Aggressive Regressor
2024-11-14 09:15:36,919:INFO:Total runtime is 0.3387428561846415 minutes
2024-11-14 09:15:36,922:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:36,923:INFO:Initializing create_model()
2024-11-14 09:15:36,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:36,923:INFO:Checking exceptions
2024-11-14 09:15:36,923:INFO:Importing libraries
2024-11-14 09:15:36,923:INFO:Copying training dataset
2024-11-14 09:15:36,931:INFO:Defining folds
2024-11-14 09:15:36,932:INFO:Declaring metric variables
2024-11-14 09:15:36,935:INFO:Importing untrained model
2024-11-14 09:15:36,938:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 09:15:36,945:INFO:Starting cross validation
2024-11-14 09:15:36,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:37,165:INFO:Calculating mean and std
2024-11-14 09:15:37,168:INFO:Creating metrics dataframe
2024-11-14 09:15:37,176:INFO:Uploading results into container
2024-11-14 09:15:37,177:INFO:Uploading model into container now
2024-11-14 09:15:37,178:INFO:_master_model_container: 9
2024-11-14 09:15:37,178:INFO:_display_container: 2
2024-11-14 09:15:37,179:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-14 09:15:37,180:INFO:create_model() successfully completed......................................
2024-11-14 09:15:37,347:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:37,348:INFO:Creating metrics dataframe
2024-11-14 09:15:37,359:INFO:Initializing Huber Regressor
2024-11-14 09:15:37,359:INFO:Total runtime is 0.3460708459218343 minutes
2024-11-14 09:15:37,362:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:37,362:INFO:Initializing create_model()
2024-11-14 09:15:37,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:37,362:INFO:Checking exceptions
2024-11-14 09:15:37,363:INFO:Importing libraries
2024-11-14 09:15:37,363:INFO:Copying training dataset
2024-11-14 09:15:37,370:INFO:Defining folds
2024-11-14 09:15:37,370:INFO:Declaring metric variables
2024-11-14 09:15:37,374:INFO:Importing untrained model
2024-11-14 09:15:37,377:INFO:Huber Regressor Imported successfully
2024-11-14 09:15:37,383:INFO:Starting cross validation
2024-11-14 09:15:37,384:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:37,663:INFO:Calculating mean and std
2024-11-14 09:15:37,667:INFO:Creating metrics dataframe
2024-11-14 09:15:37,674:INFO:Uploading results into container
2024-11-14 09:15:37,675:INFO:Uploading model into container now
2024-11-14 09:15:37,676:INFO:_master_model_container: 10
2024-11-14 09:15:37,676:INFO:_display_container: 2
2024-11-14 09:15:37,676:INFO:HuberRegressor()
2024-11-14 09:15:37,676:INFO:create_model() successfully completed......................................
2024-11-14 09:15:37,829:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:37,830:INFO:Creating metrics dataframe
2024-11-14 09:15:37,842:INFO:Initializing K Neighbors Regressor
2024-11-14 09:15:37,842:INFO:Total runtime is 0.3541201949119568 minutes
2024-11-14 09:15:37,845:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:37,845:INFO:Initializing create_model()
2024-11-14 09:15:37,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:37,845:INFO:Checking exceptions
2024-11-14 09:15:37,846:INFO:Importing libraries
2024-11-14 09:15:37,846:INFO:Copying training dataset
2024-11-14 09:15:37,853:INFO:Defining folds
2024-11-14 09:15:37,853:INFO:Declaring metric variables
2024-11-14 09:15:37,856:INFO:Importing untrained model
2024-11-14 09:15:37,860:INFO:K Neighbors Regressor Imported successfully
2024-11-14 09:15:37,866:INFO:Starting cross validation
2024-11-14 09:15:37,866:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:38,025:INFO:Calculating mean and std
2024-11-14 09:15:38,029:INFO:Creating metrics dataframe
2024-11-14 09:15:38,033:INFO:Uploading results into container
2024-11-14 09:15:38,034:INFO:Uploading model into container now
2024-11-14 09:15:38,035:INFO:_master_model_container: 11
2024-11-14 09:15:38,035:INFO:_display_container: 2
2024-11-14 09:15:38,035:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 09:15:38,035:INFO:create_model() successfully completed......................................
2024-11-14 09:15:38,191:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:38,191:INFO:Creating metrics dataframe
2024-11-14 09:15:38,202:INFO:Initializing Decision Tree Regressor
2024-11-14 09:15:38,203:INFO:Total runtime is 0.36013479232788087 minutes
2024-11-14 09:15:38,206:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:38,206:INFO:Initializing create_model()
2024-11-14 09:15:38,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:38,207:INFO:Checking exceptions
2024-11-14 09:15:38,207:INFO:Importing libraries
2024-11-14 09:15:38,207:INFO:Copying training dataset
2024-11-14 09:15:38,214:INFO:Defining folds
2024-11-14 09:15:38,214:INFO:Declaring metric variables
2024-11-14 09:15:38,217:INFO:Importing untrained model
2024-11-14 09:15:38,221:INFO:Decision Tree Regressor Imported successfully
2024-11-14 09:15:38,227:INFO:Starting cross validation
2024-11-14 09:15:38,228:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:38,395:INFO:Calculating mean and std
2024-11-14 09:15:38,400:INFO:Creating metrics dataframe
2024-11-14 09:15:38,406:INFO:Uploading results into container
2024-11-14 09:15:38,407:INFO:Uploading model into container now
2024-11-14 09:15:38,408:INFO:_master_model_container: 12
2024-11-14 09:15:38,408:INFO:_display_container: 2
2024-11-14 09:15:38,409:INFO:DecisionTreeRegressor(random_state=123)
2024-11-14 09:15:38,409:INFO:create_model() successfully completed......................................
2024-11-14 09:15:38,599:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:38,599:INFO:Creating metrics dataframe
2024-11-14 09:15:38,611:INFO:Initializing Random Forest Regressor
2024-11-14 09:15:38,611:INFO:Total runtime is 0.366939119497935 minutes
2024-11-14 09:15:38,614:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:38,614:INFO:Initializing create_model()
2024-11-14 09:15:38,615:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:38,615:INFO:Checking exceptions
2024-11-14 09:15:38,615:INFO:Importing libraries
2024-11-14 09:15:38,615:INFO:Copying training dataset
2024-11-14 09:15:38,622:INFO:Defining folds
2024-11-14 09:15:38,623:INFO:Declaring metric variables
2024-11-14 09:15:38,626:INFO:Importing untrained model
2024-11-14 09:15:38,629:INFO:Random Forest Regressor Imported successfully
2024-11-14 09:15:38,636:INFO:Starting cross validation
2024-11-14 09:15:38,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:40,177:INFO:Calculating mean and std
2024-11-14 09:15:40,180:INFO:Creating metrics dataframe
2024-11-14 09:15:40,187:INFO:Uploading results into container
2024-11-14 09:15:40,188:INFO:Uploading model into container now
2024-11-14 09:15:40,188:INFO:_master_model_container: 13
2024-11-14 09:15:40,188:INFO:_display_container: 2
2024-11-14 09:15:40,188:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:15:40,189:INFO:create_model() successfully completed......................................
2024-11-14 09:15:40,344:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:40,344:INFO:Creating metrics dataframe
2024-11-14 09:15:40,356:INFO:Initializing Extra Trees Regressor
2024-11-14 09:15:40,356:INFO:Total runtime is 0.3960283160209656 minutes
2024-11-14 09:15:40,359:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:40,360:INFO:Initializing create_model()
2024-11-14 09:15:40,360:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:40,360:INFO:Checking exceptions
2024-11-14 09:15:40,360:INFO:Importing libraries
2024-11-14 09:15:40,360:INFO:Copying training dataset
2024-11-14 09:15:40,368:INFO:Defining folds
2024-11-14 09:15:40,368:INFO:Declaring metric variables
2024-11-14 09:15:40,371:INFO:Importing untrained model
2024-11-14 09:15:40,374:INFO:Extra Trees Regressor Imported successfully
2024-11-14 09:15:40,381:INFO:Starting cross validation
2024-11-14 09:15:40,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:41,219:INFO:Calculating mean and std
2024-11-14 09:15:41,223:INFO:Creating metrics dataframe
2024-11-14 09:15:41,230:INFO:Uploading results into container
2024-11-14 09:15:41,231:INFO:Uploading model into container now
2024-11-14 09:15:41,231:INFO:_master_model_container: 14
2024-11-14 09:15:41,232:INFO:_display_container: 2
2024-11-14 09:15:41,232:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:15:41,232:INFO:create_model() successfully completed......................................
2024-11-14 09:15:41,391:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:41,391:INFO:Creating metrics dataframe
2024-11-14 09:15:41,404:INFO:Initializing AdaBoost Regressor
2024-11-14 09:15:41,404:INFO:Total runtime is 0.4134933670361837 minutes
2024-11-14 09:15:41,407:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:41,408:INFO:Initializing create_model()
2024-11-14 09:15:41,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:41,408:INFO:Checking exceptions
2024-11-14 09:15:41,408:INFO:Importing libraries
2024-11-14 09:15:41,408:INFO:Copying training dataset
2024-11-14 09:15:41,416:INFO:Defining folds
2024-11-14 09:15:41,416:INFO:Declaring metric variables
2024-11-14 09:15:41,419:INFO:Importing untrained model
2024-11-14 09:15:41,423:INFO:AdaBoost Regressor Imported successfully
2024-11-14 09:15:41,429:INFO:Starting cross validation
2024-11-14 09:15:41,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:42,576:INFO:Calculating mean and std
2024-11-14 09:15:42,579:INFO:Creating metrics dataframe
2024-11-14 09:15:42,586:INFO:Uploading results into container
2024-11-14 09:15:42,587:INFO:Uploading model into container now
2024-11-14 09:15:42,588:INFO:_master_model_container: 15
2024-11-14 09:15:42,588:INFO:_display_container: 2
2024-11-14 09:15:42,588:INFO:AdaBoostRegressor(random_state=123)
2024-11-14 09:15:42,588:INFO:create_model() successfully completed......................................
2024-11-14 09:15:42,748:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:42,748:INFO:Creating metrics dataframe
2024-11-14 09:15:42,760:INFO:Initializing Gradient Boosting Regressor
2024-11-14 09:15:42,761:INFO:Total runtime is 0.4361012736956279 minutes
2024-11-14 09:15:42,764:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:42,764:INFO:Initializing create_model()
2024-11-14 09:15:42,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:42,764:INFO:Checking exceptions
2024-11-14 09:15:42,765:INFO:Importing libraries
2024-11-14 09:15:42,765:INFO:Copying training dataset
2024-11-14 09:15:42,772:INFO:Defining folds
2024-11-14 09:15:42,772:INFO:Declaring metric variables
2024-11-14 09:15:42,776:INFO:Importing untrained model
2024-11-14 09:15:42,779:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 09:15:42,786:INFO:Starting cross validation
2024-11-14 09:15:42,786:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:44,198:INFO:Calculating mean and std
2024-11-14 09:15:44,201:INFO:Creating metrics dataframe
2024-11-14 09:15:44,208:INFO:Uploading results into container
2024-11-14 09:15:44,209:INFO:Uploading model into container now
2024-11-14 09:15:44,210:INFO:_master_model_container: 16
2024-11-14 09:15:44,210:INFO:_display_container: 2
2024-11-14 09:15:44,210:INFO:GradientBoostingRegressor(random_state=123)
2024-11-14 09:15:44,210:INFO:create_model() successfully completed......................................
2024-11-14 09:15:44,369:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:44,369:INFO:Creating metrics dataframe
2024-11-14 09:15:44,382:INFO:Initializing Extreme Gradient Boosting
2024-11-14 09:15:44,382:INFO:Total runtime is 0.46313025951385506 minutes
2024-11-14 09:15:44,386:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:44,386:INFO:Initializing create_model()
2024-11-14 09:15:44,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:44,386:INFO:Checking exceptions
2024-11-14 09:15:44,386:INFO:Importing libraries
2024-11-14 09:15:44,387:INFO:Copying training dataset
2024-11-14 09:15:44,394:INFO:Defining folds
2024-11-14 09:15:44,394:INFO:Declaring metric variables
2024-11-14 09:15:44,398:INFO:Importing untrained model
2024-11-14 09:15:44,401:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 09:15:44,408:INFO:Starting cross validation
2024-11-14 09:15:44,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:15:44,836:INFO:Calculating mean and std
2024-11-14 09:15:44,840:INFO:Creating metrics dataframe
2024-11-14 09:15:44,847:INFO:Uploading results into container
2024-11-14 09:15:44,848:INFO:Uploading model into container now
2024-11-14 09:15:44,848:INFO:_master_model_container: 17
2024-11-14 09:15:44,849:INFO:_display_container: 2
2024-11-14 09:15:44,850:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-14 09:15:44,850:INFO:create_model() successfully completed......................................
2024-11-14 09:15:45,045:INFO:SubProcess create_model() end ==================================
2024-11-14 09:15:45,045:INFO:Creating metrics dataframe
2024-11-14 09:15:45,059:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 09:15:45,060:INFO:Total runtime is 0.47441858053207403 minutes
2024-11-14 09:15:45,063:INFO:SubProcess create_model() called ==================================
2024-11-14 09:15:45,064:INFO:Initializing create_model()
2024-11-14 09:15:45,064:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:15:45,064:INFO:Checking exceptions
2024-11-14 09:15:45,064:INFO:Importing libraries
2024-11-14 09:15:45,064:INFO:Copying training dataset
2024-11-14 09:15:45,072:INFO:Defining folds
2024-11-14 09:15:45,073:INFO:Declaring metric variables
2024-11-14 09:15:45,076:INFO:Importing untrained model
2024-11-14 09:15:45,080:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 09:15:45,087:INFO:Starting cross validation
2024-11-14 09:15:45,087:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:22:35,368:INFO:Calculating mean and std
2024-11-14 09:22:35,373:INFO:Creating metrics dataframe
2024-11-14 09:22:35,381:INFO:Uploading results into container
2024-11-14 09:22:35,381:INFO:Uploading model into container now
2024-11-14 09:22:35,382:INFO:_master_model_container: 18
2024-11-14 09:22:35,382:INFO:_display_container: 2
2024-11-14 09:22:35,383:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:22:35,383:INFO:create_model() successfully completed......................................
2024-11-14 09:22:35,580:INFO:SubProcess create_model() end ==================================
2024-11-14 09:22:35,580:INFO:Creating metrics dataframe
2024-11-14 09:22:35,592:INFO:Initializing CatBoost Regressor
2024-11-14 09:22:35,592:INFO:Total runtime is 7.316632743676504 minutes
2024-11-14 09:22:35,596:INFO:SubProcess create_model() called ==================================
2024-11-14 09:22:35,596:INFO:Initializing create_model()
2024-11-14 09:22:35,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:22:35,596:INFO:Checking exceptions
2024-11-14 09:22:35,596:INFO:Importing libraries
2024-11-14 09:22:35,596:INFO:Copying training dataset
2024-11-14 09:22:35,604:INFO:Defining folds
2024-11-14 09:22:35,604:INFO:Declaring metric variables
2024-11-14 09:22:35,607:INFO:Importing untrained model
2024-11-14 09:22:35,610:INFO:CatBoost Regressor Imported successfully
2024-11-14 09:22:35,616:INFO:Starting cross validation
2024-11-14 09:22:35,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:22:49,172:INFO:Calculating mean and std
2024-11-14 09:22:49,178:INFO:Creating metrics dataframe
2024-11-14 09:22:49,185:INFO:Uploading results into container
2024-11-14 09:22:49,186:INFO:Uploading model into container now
2024-11-14 09:22:49,186:INFO:_master_model_container: 19
2024-11-14 09:22:49,187:INFO:_display_container: 2
2024-11-14 09:22:49,187:INFO:<catboost.core.CatBoostRegressor object at 0x7f772b52ffd0>
2024-11-14 09:22:49,187:INFO:create_model() successfully completed......................................
2024-11-14 09:22:49,424:INFO:SubProcess create_model() end ==================================
2024-11-14 09:22:49,424:INFO:Creating metrics dataframe
2024-11-14 09:22:49,439:INFO:Initializing Dummy Regressor
2024-11-14 09:22:49,439:INFO:Total runtime is 7.547403566042583 minutes
2024-11-14 09:22:49,442:INFO:SubProcess create_model() called ==================================
2024-11-14 09:22:49,443:INFO:Initializing create_model()
2024-11-14 09:22:49,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7567de8820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:22:49,443:INFO:Checking exceptions
2024-11-14 09:22:49,443:INFO:Importing libraries
2024-11-14 09:22:49,443:INFO:Copying training dataset
2024-11-14 09:22:49,452:INFO:Defining folds
2024-11-14 09:22:49,453:INFO:Declaring metric variables
2024-11-14 09:22:49,456:INFO:Importing untrained model
2024-11-14 09:22:49,460:INFO:Dummy Regressor Imported successfully
2024-11-14 09:22:49,466:INFO:Starting cross validation
2024-11-14 09:22:49,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:22:52,466:INFO:Calculating mean and std
2024-11-14 09:22:52,471:INFO:Creating metrics dataframe
2024-11-14 09:22:52,477:INFO:Uploading results into container
2024-11-14 09:22:52,478:INFO:Uploading model into container now
2024-11-14 09:22:52,479:INFO:_master_model_container: 20
2024-11-14 09:22:52,479:INFO:_display_container: 2
2024-11-14 09:22:52,479:INFO:DummyRegressor()
2024-11-14 09:22:52,479:INFO:create_model() successfully completed......................................
2024-11-14 09:22:52,673:INFO:SubProcess create_model() end ==================================
2024-11-14 09:22:52,674:INFO:Creating metrics dataframe
2024-11-14 09:22:52,698:INFO:Initializing create_model()
2024-11-14 09:22:52,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772af77730>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:22:52,698:INFO:Checking exceptions
2024-11-14 09:22:52,700:INFO:Importing libraries
2024-11-14 09:22:52,700:INFO:Copying training dataset
2024-11-14 09:22:52,707:INFO:Defining folds
2024-11-14 09:22:52,707:INFO:Declaring metric variables
2024-11-14 09:22:52,707:INFO:Importing untrained model
2024-11-14 09:22:52,707:INFO:Declaring custom model
2024-11-14 09:22:52,708:INFO:Extra Trees Regressor Imported successfully
2024-11-14 09:22:52,709:INFO:Cross validation set to False
2024-11-14 09:22:52,709:INFO:Fitting Model
2024-11-14 09:22:52,936:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:22:52,937:INFO:create_model() successfully completed......................................
2024-11-14 09:22:53,180:INFO:_master_model_container: 20
2024-11-14 09:22:53,181:INFO:_display_container: 2
2024-11-14 09:22:53,181:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:22:53,181:INFO:compare_models() successfully completed......................................
2024-11-14 09:25:02,928:INFO:Initializing save_model()
2024-11-14 09:25:02,928:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=123), model_name=lat_predictor_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2024-11-14 09:25:02,928:INFO:Adding model into prep_pipe
2024-11-14 09:25:03,031:INFO:lat_predictor_pipeline.pkl saved in current working directory
2024-11-14 09:25:03,038:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2024-11-14 09:25:03,038:INFO:save_model() successfully completed......................................
2024-11-14 09:26:19,048:INFO:PyCaret RegressionExperiment
2024-11-14 09:26:19,048:INFO:Logging name: reg-default-name
2024-11-14 09:26:19,048:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 09:26:19,048:INFO:version 3.2.0
2024-11-14 09:26:19,048:INFO:Initializing setup()
2024-11-14 09:26:19,048:INFO:self.USI: 5868
2024-11-14 09:26:19,048:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'fold_generator', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'memory', 'data', 'fold_groups_param', 'X', 'transform_target_param', 'target_param', 'y_test', 'X_train', 'seed', 'pipeline', 'html_param', 'exp_name_log', 'USI', 'log_plots_param', 'gpu_param', 'n_jobs_param', 'exp_id', '_available_plots', 'logging_param', 'y_train'}
2024-11-14 09:26:19,048:INFO:Checking environment
2024-11-14 09:26:19,049:INFO:python_version: 3.8.13
2024-11-14 09:26:19,049:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 09:26:19,049:INFO:machine: x86_64
2024-11-14 09:26:19,049:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 09:26:19,049:INFO:Memory: svmem(total=270355722240, available=220252807168, percent=18.5, used=48034115584, free=74242465792, active=71697448960, inactive=64230535168, buffers=10100736, cached=148069040128, shared=187645952, slab=25151623168)
2024-11-14 09:26:19,052:INFO:Physical Core: 28
2024-11-14 09:26:19,052:INFO:Logical Core: 56
2024-11-14 09:26:19,052:INFO:Checking libraries
2024-11-14 09:26:19,052:INFO:System:
2024-11-14 09:26:19,052:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 09:26:19,052:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 09:26:19,052:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 09:26:19,052:INFO:PyCaret required dependencies:
2024-11-14 09:26:19,052:INFO:                 pip: 22.2.2
2024-11-14 09:26:19,052:INFO:          setuptools: 63.4.2
2024-11-14 09:26:19,052:INFO:             pycaret: 3.2.0
2024-11-14 09:26:19,052:INFO:             IPython: 8.12.2
2024-11-14 09:26:19,052:INFO:          ipywidgets: 7.7.1
2024-11-14 09:26:19,052:INFO:                tqdm: 4.64.1
2024-11-14 09:26:19,052:INFO:               numpy: 1.23.5
2024-11-14 09:26:19,052:INFO:              pandas: 1.5.3
2024-11-14 09:26:19,052:INFO:              jinja2: 3.1.2
2024-11-14 09:26:19,052:INFO:               scipy: 1.10.1
2024-11-14 09:26:19,052:INFO:              joblib: 1.3.0
2024-11-14 09:26:19,053:INFO:             sklearn: 1.1.2
2024-11-14 09:26:19,053:INFO:                pyod: 2.0.2
2024-11-14 09:26:19,053:INFO:            imblearn: 0.12.4
2024-11-14 09:26:19,053:INFO:   category_encoders: 2.6.4
2024-11-14 09:26:19,053:INFO:            lightgbm: 4.5.0
2024-11-14 09:26:19,053:INFO:               numba: 0.57.1
2024-11-14 09:26:19,053:INFO:            requests: 2.28.1
2024-11-14 09:26:19,053:INFO:          matplotlib: 3.5.1
2024-11-14 09:26:19,053:INFO:          scikitplot: 0.3.7
2024-11-14 09:26:19,053:INFO:         yellowbrick: 1.5
2024-11-14 09:26:19,053:INFO:              plotly: 5.24.1
2024-11-14 09:26:19,053:INFO:    plotly-resampler: Not installed
2024-11-14 09:26:19,053:INFO:             kaleido: 0.2.1
2024-11-14 09:26:19,053:INFO:           schemdraw: 0.15
2024-11-14 09:26:19,053:INFO:         statsmodels: 0.13.2
2024-11-14 09:26:19,053:INFO:              sktime: 0.21.1
2024-11-14 09:26:19,053:INFO:               tbats: 1.1.3
2024-11-14 09:26:19,053:INFO:            pmdarima: 2.0.4
2024-11-14 09:26:19,053:INFO:              psutil: 5.9.1
2024-11-14 09:26:19,053:INFO:          markupsafe: 2.1.1
2024-11-14 09:26:19,053:INFO:             pickle5: Not installed
2024-11-14 09:26:19,053:INFO:         cloudpickle: 2.1.0
2024-11-14 09:26:19,053:INFO:         deprecation: 2.1.0
2024-11-14 09:26:19,053:INFO:              xxhash: 3.5.0
2024-11-14 09:26:19,053:INFO:           wurlitzer: 3.1.1
2024-11-14 09:26:19,053:INFO:PyCaret optional dependencies:
2024-11-14 09:26:19,053:INFO:                shap: 0.44.1
2024-11-14 09:26:19,053:INFO:           interpret: 0.6.5
2024-11-14 09:26:19,053:INFO:                umap: 0.5.7
2024-11-14 09:26:19,054:INFO:     ydata_profiling: 4.6.0
2024-11-14 09:26:19,054:INFO:  explainerdashboard: 0.4.7
2024-11-14 09:26:19,054:INFO:             autoviz: Not installed
2024-11-14 09:26:19,054:INFO:           fairlearn: 0.7.0
2024-11-14 09:26:19,054:INFO:          deepchecks: Not installed
2024-11-14 09:26:19,054:INFO:             xgboost: 2.1.1
2024-11-14 09:26:19,054:INFO:            catboost: 1.2.7
2024-11-14 09:26:19,054:INFO:              kmodes: 0.12.2
2024-11-14 09:26:19,054:INFO:             mlxtend: 0.23.1
2024-11-14 09:26:19,054:INFO:       statsforecast: 1.5.0
2024-11-14 09:26:19,054:INFO:        tune_sklearn: 0.5.0
2024-11-14 09:26:19,054:INFO:                 ray: 2.10.0
2024-11-14 09:26:19,054:INFO:            hyperopt: 0.2.7
2024-11-14 09:26:19,054:INFO:              optuna: 4.1.0
2024-11-14 09:26:19,054:INFO:               skopt: 0.10.2
2024-11-14 09:26:19,054:INFO:              mlflow: 1.30.1
2024-11-14 09:26:19,054:INFO:              gradio: 3.50.2
2024-11-14 09:26:19,054:INFO:             fastapi: 0.115.5
2024-11-14 09:26:19,054:INFO:             uvicorn: 0.32.0
2024-11-14 09:26:19,054:INFO:              m2cgen: 0.10.0
2024-11-14 09:26:19,054:INFO:           evidently: 0.2.8
2024-11-14 09:26:19,054:INFO:               fugue: 0.8.6
2024-11-14 09:26:19,054:INFO:           streamlit: Not installed
2024-11-14 09:26:19,054:INFO:             prophet: Not installed
2024-11-14 09:26:19,054:INFO:None
2024-11-14 09:26:19,054:INFO:Set up data.
2024-11-14 09:26:19,064:INFO:Set up folding strategy.
2024-11-14 09:26:19,064:INFO:Set up train/test split.
2024-11-14 09:26:19,069:INFO:Set up index.
2024-11-14 09:26:19,071:INFO:Assigning column types.
2024-11-14 09:26:19,076:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 09:26:19,076:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,081:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,087:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,144:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,182:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,182:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:19,185:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:19,185:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,189:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,193:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,281:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,282:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:19,284:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:19,285:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 09:26:19,289:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,293:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,344:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,382:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,383:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:19,385:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:19,389:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,393:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,480:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,480:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:19,482:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:19,483:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 09:26:19,490:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,540:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,582:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:19,585:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:19,593:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,678:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:19,680:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:19,681:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 09:26:19,735:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,772:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:19,774:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:19,829:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,865:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:19,867:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:19,868:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 09:26:19,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:26:19,959:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:19,961:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:20,016:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 09:26:20,053:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:20,055:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:20,056:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 09:26:20,147:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:20,149:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:20,241:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:20,243:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:20,244:INFO:Preparing preprocessing pipeline...
2024-11-14 09:26:20,244:INFO:Set up simple imputation.
2024-11-14 09:26:20,267:INFO:Finished creating preprocessing pipeline.
2024-11-14 09:26:20,270:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Latitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 09:26:20,270:INFO:Creating final display dataframe.
2024-11-14 09:26:20,324:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Longitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5868
2024-11-14 09:26:20,423:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:20,425:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:20,515:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 09:26:20,517:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 09:26:20,518:INFO:setup() successfully completed in 1.47s...............
2024-11-14 09:26:20,518:INFO:Initializing compare_models()
2024-11-14 09:26:20,519:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 09:26:20,519:INFO:Checking exceptions
2024-11-14 09:26:20,520:INFO:Preparing display monitor
2024-11-14 09:26:20,553:INFO:Initializing Linear Regression
2024-11-14 09:26:20,553:INFO:Total runtime is 2.157688140869141e-06 minutes
2024-11-14 09:26:20,556:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:20,557:INFO:Initializing create_model()
2024-11-14 09:26:20,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:20,557:INFO:Checking exceptions
2024-11-14 09:26:20,557:INFO:Importing libraries
2024-11-14 09:26:20,557:INFO:Copying training dataset
2024-11-14 09:26:20,563:INFO:Defining folds
2024-11-14 09:26:20,563:INFO:Declaring metric variables
2024-11-14 09:26:20,567:INFO:Importing untrained model
2024-11-14 09:26:20,570:INFO:Linear Regression Imported successfully
2024-11-14 09:26:20,576:INFO:Starting cross validation
2024-11-14 09:26:20,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:23,353:INFO:Calculating mean and std
2024-11-14 09:26:23,356:INFO:Creating metrics dataframe
2024-11-14 09:26:23,362:INFO:Uploading results into container
2024-11-14 09:26:23,363:INFO:Uploading model into container now
2024-11-14 09:26:23,363:INFO:_master_model_container: 1
2024-11-14 09:26:23,364:INFO:_display_container: 2
2024-11-14 09:26:23,364:INFO:LinearRegression(n_jobs=-1)
2024-11-14 09:26:23,364:INFO:create_model() successfully completed......................................
2024-11-14 09:26:23,582:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:23,582:INFO:Creating metrics dataframe
2024-11-14 09:26:23,591:INFO:Initializing Lasso Regression
2024-11-14 09:26:23,591:INFO:Total runtime is 0.050632508595784505 minutes
2024-11-14 09:26:23,594:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:23,594:INFO:Initializing create_model()
2024-11-14 09:26:23,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:23,595:INFO:Checking exceptions
2024-11-14 09:26:23,595:INFO:Importing libraries
2024-11-14 09:26:23,595:INFO:Copying training dataset
2024-11-14 09:26:23,602:INFO:Defining folds
2024-11-14 09:26:23,602:INFO:Declaring metric variables
2024-11-14 09:26:23,605:INFO:Importing untrained model
2024-11-14 09:26:23,609:INFO:Lasso Regression Imported successfully
2024-11-14 09:26:23,615:INFO:Starting cross validation
2024-11-14 09:26:23,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:26,421:INFO:Calculating mean and std
2024-11-14 09:26:26,425:INFO:Creating metrics dataframe
2024-11-14 09:26:26,432:INFO:Uploading results into container
2024-11-14 09:26:26,432:INFO:Uploading model into container now
2024-11-14 09:26:26,433:INFO:_master_model_container: 2
2024-11-14 09:26:26,433:INFO:_display_container: 2
2024-11-14 09:26:26,434:INFO:Lasso(random_state=123)
2024-11-14 09:26:26,434:INFO:create_model() successfully completed......................................
2024-11-14 09:26:26,627:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:26,627:INFO:Creating metrics dataframe
2024-11-14 09:26:26,637:INFO:Initializing Ridge Regression
2024-11-14 09:26:26,637:INFO:Total runtime is 0.10140404701232911 minutes
2024-11-14 09:26:26,640:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:26,641:INFO:Initializing create_model()
2024-11-14 09:26:26,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:26,641:INFO:Checking exceptions
2024-11-14 09:26:26,641:INFO:Importing libraries
2024-11-14 09:26:26,641:INFO:Copying training dataset
2024-11-14 09:26:26,649:INFO:Defining folds
2024-11-14 09:26:26,649:INFO:Declaring metric variables
2024-11-14 09:26:26,652:INFO:Importing untrained model
2024-11-14 09:26:26,656:INFO:Ridge Regression Imported successfully
2024-11-14 09:26:26,662:INFO:Starting cross validation
2024-11-14 09:26:26,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:29,480:INFO:Calculating mean and std
2024-11-14 09:26:29,484:INFO:Creating metrics dataframe
2024-11-14 09:26:29,491:INFO:Uploading results into container
2024-11-14 09:26:29,492:INFO:Uploading model into container now
2024-11-14 09:26:29,492:INFO:_master_model_container: 3
2024-11-14 09:26:29,492:INFO:_display_container: 2
2024-11-14 09:26:29,493:INFO:Ridge(random_state=123)
2024-11-14 09:26:29,493:INFO:create_model() successfully completed......................................
2024-11-14 09:26:29,666:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:29,666:INFO:Creating metrics dataframe
2024-11-14 09:26:29,677:INFO:Initializing Elastic Net
2024-11-14 09:26:29,677:INFO:Total runtime is 0.15206860303878783 minutes
2024-11-14 09:26:29,680:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:29,681:INFO:Initializing create_model()
2024-11-14 09:26:29,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:29,681:INFO:Checking exceptions
2024-11-14 09:26:29,681:INFO:Importing libraries
2024-11-14 09:26:29,681:INFO:Copying training dataset
2024-11-14 09:26:29,688:INFO:Defining folds
2024-11-14 09:26:29,688:INFO:Declaring metric variables
2024-11-14 09:26:29,691:INFO:Importing untrained model
2024-11-14 09:26:29,695:INFO:Elastic Net Imported successfully
2024-11-14 09:26:29,701:INFO:Starting cross validation
2024-11-14 09:26:29,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:32,770:INFO:Calculating mean and std
2024-11-14 09:26:32,774:INFO:Creating metrics dataframe
2024-11-14 09:26:32,780:INFO:Uploading results into container
2024-11-14 09:26:32,781:INFO:Uploading model into container now
2024-11-14 09:26:32,781:INFO:_master_model_container: 4
2024-11-14 09:26:32,781:INFO:_display_container: 2
2024-11-14 09:26:32,782:INFO:ElasticNet(random_state=123)
2024-11-14 09:26:32,782:INFO:create_model() successfully completed......................................
2024-11-14 09:26:32,950:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:32,950:INFO:Creating metrics dataframe
2024-11-14 09:26:32,960:INFO:Initializing Least Angle Regression
2024-11-14 09:26:32,960:INFO:Total runtime is 0.20678615967432656 minutes
2024-11-14 09:26:32,963:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:32,964:INFO:Initializing create_model()
2024-11-14 09:26:32,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:32,964:INFO:Checking exceptions
2024-11-14 09:26:32,964:INFO:Importing libraries
2024-11-14 09:26:32,964:INFO:Copying training dataset
2024-11-14 09:26:32,971:INFO:Defining folds
2024-11-14 09:26:32,971:INFO:Declaring metric variables
2024-11-14 09:26:32,974:INFO:Importing untrained model
2024-11-14 09:26:32,977:INFO:Least Angle Regression Imported successfully
2024-11-14 09:26:32,984:INFO:Starting cross validation
2024-11-14 09:26:32,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:33,022:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:33,064:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:33,072:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:33,076:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:33,081:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:35,476:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:35,478:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:35,509:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:35,678:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:35,744:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:35,762:INFO:Calculating mean and std
2024-11-14 09:26:35,765:INFO:Creating metrics dataframe
2024-11-14 09:26:35,772:INFO:Uploading results into container
2024-11-14 09:26:35,772:INFO:Uploading model into container now
2024-11-14 09:26:35,773:INFO:_master_model_container: 5
2024-11-14 09:26:35,773:INFO:_display_container: 2
2024-11-14 09:26:35,774:INFO:Lars(random_state=123)
2024-11-14 09:26:35,774:INFO:create_model() successfully completed......................................
2024-11-14 09:26:35,987:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:35,987:INFO:Creating metrics dataframe
2024-11-14 09:26:35,998:INFO:Initializing Lasso Least Angle Regression
2024-11-14 09:26:35,998:INFO:Total runtime is 0.2574247320493062 minutes
2024-11-14 09:26:36,002:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:36,002:INFO:Initializing create_model()
2024-11-14 09:26:36,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:36,002:INFO:Checking exceptions
2024-11-14 09:26:36,003:INFO:Importing libraries
2024-11-14 09:26:36,003:INFO:Copying training dataset
2024-11-14 09:26:36,009:INFO:Defining folds
2024-11-14 09:26:36,009:INFO:Declaring metric variables
2024-11-14 09:26:36,013:INFO:Importing untrained model
2024-11-14 09:26:36,016:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 09:26:36,023:INFO:Starting cross validation
2024-11-14 09:26:36,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:36,058:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:26:36,064:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:26:36,068:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:26:36,078:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:26:36,079:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:26:36,082:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:26:36,092:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:26:36,093:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:26:36,100:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:26:36,105:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 09:26:36,124:INFO:Calculating mean and std
2024-11-14 09:26:36,128:INFO:Creating metrics dataframe
2024-11-14 09:26:36,135:INFO:Uploading results into container
2024-11-14 09:26:36,135:INFO:Uploading model into container now
2024-11-14 09:26:36,136:INFO:_master_model_container: 6
2024-11-14 09:26:36,136:INFO:_display_container: 2
2024-11-14 09:26:36,137:INFO:LassoLars(random_state=123)
2024-11-14 09:26:36,137:INFO:create_model() successfully completed......................................
2024-11-14 09:26:36,313:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:36,313:INFO:Creating metrics dataframe
2024-11-14 09:26:36,324:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 09:26:36,324:INFO:Total runtime is 0.26285618146260575 minutes
2024-11-14 09:26:36,328:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:36,328:INFO:Initializing create_model()
2024-11-14 09:26:36,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:36,328:INFO:Checking exceptions
2024-11-14 09:26:36,328:INFO:Importing libraries
2024-11-14 09:26:36,328:INFO:Copying training dataset
2024-11-14 09:26:36,335:INFO:Defining folds
2024-11-14 09:26:36,335:INFO:Declaring metric variables
2024-11-14 09:26:36,339:INFO:Importing untrained model
2024-11-14 09:26:36,342:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 09:26:36,348:INFO:Starting cross validation
2024-11-14 09:26:36,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:36,385:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:36,392:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:36,395:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:36,398:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:36,404:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:36,413:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:36,416:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:36,422:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:36,430:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:36,435:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 09:26:36,456:INFO:Calculating mean and std
2024-11-14 09:26:36,459:INFO:Creating metrics dataframe
2024-11-14 09:26:36,466:INFO:Uploading results into container
2024-11-14 09:26:36,467:INFO:Uploading model into container now
2024-11-14 09:26:36,467:INFO:_master_model_container: 7
2024-11-14 09:26:36,467:INFO:_display_container: 2
2024-11-14 09:26:36,468:INFO:OrthogonalMatchingPursuit()
2024-11-14 09:26:36,468:INFO:create_model() successfully completed......................................
2024-11-14 09:26:36,640:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:36,640:INFO:Creating metrics dataframe
2024-11-14 09:26:36,652:INFO:Initializing Bayesian Ridge
2024-11-14 09:26:36,652:INFO:Total runtime is 0.26831466754277544 minutes
2024-11-14 09:26:36,655:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:36,656:INFO:Initializing create_model()
2024-11-14 09:26:36,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:36,656:INFO:Checking exceptions
2024-11-14 09:26:36,656:INFO:Importing libraries
2024-11-14 09:26:36,656:INFO:Copying training dataset
2024-11-14 09:26:36,663:INFO:Defining folds
2024-11-14 09:26:36,663:INFO:Declaring metric variables
2024-11-14 09:26:36,666:INFO:Importing untrained model
2024-11-14 09:26:36,670:INFO:Bayesian Ridge Imported successfully
2024-11-14 09:26:36,676:INFO:Starting cross validation
2024-11-14 09:26:36,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:36,794:INFO:Calculating mean and std
2024-11-14 09:26:36,798:INFO:Creating metrics dataframe
2024-11-14 09:26:36,803:INFO:Uploading results into container
2024-11-14 09:26:36,804:INFO:Uploading model into container now
2024-11-14 09:26:36,805:INFO:_master_model_container: 8
2024-11-14 09:26:36,805:INFO:_display_container: 2
2024-11-14 09:26:36,805:INFO:BayesianRidge()
2024-11-14 09:26:36,805:INFO:create_model() successfully completed......................................
2024-11-14 09:26:36,977:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:36,977:INFO:Creating metrics dataframe
2024-11-14 09:26:36,988:INFO:Initializing Passive Aggressive Regressor
2024-11-14 09:26:36,988:INFO:Total runtime is 0.2739217877388 minutes
2024-11-14 09:26:36,991:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:36,992:INFO:Initializing create_model()
2024-11-14 09:26:36,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:36,992:INFO:Checking exceptions
2024-11-14 09:26:36,992:INFO:Importing libraries
2024-11-14 09:26:36,992:INFO:Copying training dataset
2024-11-14 09:26:36,999:INFO:Defining folds
2024-11-14 09:26:37,000:INFO:Declaring metric variables
2024-11-14 09:26:37,003:INFO:Importing untrained model
2024-11-14 09:26:37,007:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 09:26:37,013:INFO:Starting cross validation
2024-11-14 09:26:37,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:37,140:INFO:Calculating mean and std
2024-11-14 09:26:37,144:INFO:Creating metrics dataframe
2024-11-14 09:26:37,151:INFO:Uploading results into container
2024-11-14 09:26:37,151:INFO:Uploading model into container now
2024-11-14 09:26:37,152:INFO:_master_model_container: 9
2024-11-14 09:26:37,152:INFO:_display_container: 2
2024-11-14 09:26:37,152:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-14 09:26:37,152:INFO:create_model() successfully completed......................................
2024-11-14 09:26:37,312:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:37,312:INFO:Creating metrics dataframe
2024-11-14 09:26:37,324:INFO:Initializing Huber Regressor
2024-11-14 09:26:37,324:INFO:Total runtime is 0.2795147498448689 minutes
2024-11-14 09:26:37,327:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:37,327:INFO:Initializing create_model()
2024-11-14 09:26:37,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:37,328:INFO:Checking exceptions
2024-11-14 09:26:37,328:INFO:Importing libraries
2024-11-14 09:26:37,328:INFO:Copying training dataset
2024-11-14 09:26:37,335:INFO:Defining folds
2024-11-14 09:26:37,335:INFO:Declaring metric variables
2024-11-14 09:26:37,338:INFO:Importing untrained model
2024-11-14 09:26:37,341:INFO:Huber Regressor Imported successfully
2024-11-14 09:26:37,348:INFO:Starting cross validation
2024-11-14 09:26:37,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:37,602:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 09:26:37,604:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 09:26:37,624:INFO:Calculating mean and std
2024-11-14 09:26:37,628:INFO:Creating metrics dataframe
2024-11-14 09:26:37,635:INFO:Uploading results into container
2024-11-14 09:26:37,635:INFO:Uploading model into container now
2024-11-14 09:26:37,636:INFO:_master_model_container: 10
2024-11-14 09:26:37,636:INFO:_display_container: 2
2024-11-14 09:26:37,637:INFO:HuberRegressor()
2024-11-14 09:26:37,637:INFO:create_model() successfully completed......................................
2024-11-14 09:26:37,807:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:37,807:INFO:Creating metrics dataframe
2024-11-14 09:26:37,818:INFO:Initializing K Neighbors Regressor
2024-11-14 09:26:37,818:INFO:Total runtime is 0.2877588669459024 minutes
2024-11-14 09:26:37,822:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:37,822:INFO:Initializing create_model()
2024-11-14 09:26:37,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:37,822:INFO:Checking exceptions
2024-11-14 09:26:37,822:INFO:Importing libraries
2024-11-14 09:26:37,822:INFO:Copying training dataset
2024-11-14 09:26:37,829:INFO:Defining folds
2024-11-14 09:26:37,830:INFO:Declaring metric variables
2024-11-14 09:26:37,833:INFO:Importing untrained model
2024-11-14 09:26:37,836:INFO:K Neighbors Regressor Imported successfully
2024-11-14 09:26:37,842:INFO:Starting cross validation
2024-11-14 09:26:37,843:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:38,011:INFO:Calculating mean and std
2024-11-14 09:26:38,014:INFO:Creating metrics dataframe
2024-11-14 09:26:38,020:INFO:Uploading results into container
2024-11-14 09:26:38,020:INFO:Uploading model into container now
2024-11-14 09:26:38,021:INFO:_master_model_container: 11
2024-11-14 09:26:38,021:INFO:_display_container: 2
2024-11-14 09:26:38,022:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 09:26:38,022:INFO:create_model() successfully completed......................................
2024-11-14 09:26:38,187:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:38,187:INFO:Creating metrics dataframe
2024-11-14 09:26:38,199:INFO:Initializing Decision Tree Regressor
2024-11-14 09:26:38,199:INFO:Total runtime is 0.2940980593363443 minutes
2024-11-14 09:26:38,202:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:38,202:INFO:Initializing create_model()
2024-11-14 09:26:38,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:38,203:INFO:Checking exceptions
2024-11-14 09:26:38,203:INFO:Importing libraries
2024-11-14 09:26:38,203:INFO:Copying training dataset
2024-11-14 09:26:38,210:INFO:Defining folds
2024-11-14 09:26:38,210:INFO:Declaring metric variables
2024-11-14 09:26:38,213:INFO:Importing untrained model
2024-11-14 09:26:38,217:INFO:Decision Tree Regressor Imported successfully
2024-11-14 09:26:38,223:INFO:Starting cross validation
2024-11-14 09:26:38,224:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:38,369:INFO:Calculating mean and std
2024-11-14 09:26:38,373:INFO:Creating metrics dataframe
2024-11-14 09:26:38,379:INFO:Uploading results into container
2024-11-14 09:26:38,380:INFO:Uploading model into container now
2024-11-14 09:26:38,380:INFO:_master_model_container: 12
2024-11-14 09:26:38,380:INFO:_display_container: 2
2024-11-14 09:26:38,381:INFO:DecisionTreeRegressor(random_state=123)
2024-11-14 09:26:38,381:INFO:create_model() successfully completed......................................
2024-11-14 09:26:38,589:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:38,590:INFO:Creating metrics dataframe
2024-11-14 09:26:38,602:INFO:Initializing Random Forest Regressor
2024-11-14 09:26:38,602:INFO:Total runtime is 0.3008202672004699 minutes
2024-11-14 09:26:38,605:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:38,606:INFO:Initializing create_model()
2024-11-14 09:26:38,606:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:38,606:INFO:Checking exceptions
2024-11-14 09:26:38,606:INFO:Importing libraries
2024-11-14 09:26:38,606:INFO:Copying training dataset
2024-11-14 09:26:38,614:INFO:Defining folds
2024-11-14 09:26:38,615:INFO:Declaring metric variables
2024-11-14 09:26:38,618:INFO:Importing untrained model
2024-11-14 09:26:38,621:INFO:Random Forest Regressor Imported successfully
2024-11-14 09:26:38,628:INFO:Starting cross validation
2024-11-14 09:26:38,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:40,164:INFO:Calculating mean and std
2024-11-14 09:26:40,168:INFO:Creating metrics dataframe
2024-11-14 09:26:40,173:INFO:Uploading results into container
2024-11-14 09:26:40,174:INFO:Uploading model into container now
2024-11-14 09:26:40,174:INFO:_master_model_container: 13
2024-11-14 09:26:40,175:INFO:_display_container: 2
2024-11-14 09:26:40,175:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:26:40,175:INFO:create_model() successfully completed......................................
2024-11-14 09:26:40,338:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:40,338:INFO:Creating metrics dataframe
2024-11-14 09:26:40,350:INFO:Initializing Extra Trees Regressor
2024-11-14 09:26:40,350:INFO:Total runtime is 0.3299567103385925 minutes
2024-11-14 09:26:40,354:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:40,354:INFO:Initializing create_model()
2024-11-14 09:26:40,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:40,354:INFO:Checking exceptions
2024-11-14 09:26:40,354:INFO:Importing libraries
2024-11-14 09:26:40,354:INFO:Copying training dataset
2024-11-14 09:26:40,361:INFO:Defining folds
2024-11-14 09:26:40,362:INFO:Declaring metric variables
2024-11-14 09:26:40,365:INFO:Importing untrained model
2024-11-14 09:26:40,368:INFO:Extra Trees Regressor Imported successfully
2024-11-14 09:26:40,375:INFO:Starting cross validation
2024-11-14 09:26:40,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:41,260:INFO:Calculating mean and std
2024-11-14 09:26:41,262:INFO:Creating metrics dataframe
2024-11-14 09:26:41,266:INFO:Uploading results into container
2024-11-14 09:26:41,267:INFO:Uploading model into container now
2024-11-14 09:26:41,267:INFO:_master_model_container: 14
2024-11-14 09:26:41,267:INFO:_display_container: 2
2024-11-14 09:26:41,268:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:26:41,268:INFO:create_model() successfully completed......................................
2024-11-14 09:26:41,425:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:41,425:INFO:Creating metrics dataframe
2024-11-14 09:26:41,438:INFO:Initializing AdaBoost Regressor
2024-11-14 09:26:41,438:INFO:Total runtime is 0.34808034499486284 minutes
2024-11-14 09:26:41,441:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:41,441:INFO:Initializing create_model()
2024-11-14 09:26:41,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:41,442:INFO:Checking exceptions
2024-11-14 09:26:41,442:INFO:Importing libraries
2024-11-14 09:26:41,442:INFO:Copying training dataset
2024-11-14 09:26:41,449:INFO:Defining folds
2024-11-14 09:26:41,449:INFO:Declaring metric variables
2024-11-14 09:26:41,452:INFO:Importing untrained model
2024-11-14 09:26:41,456:INFO:AdaBoost Regressor Imported successfully
2024-11-14 09:26:41,462:INFO:Starting cross validation
2024-11-14 09:26:41,463:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:42,250:INFO:Calculating mean and std
2024-11-14 09:26:42,254:INFO:Creating metrics dataframe
2024-11-14 09:26:42,260:INFO:Uploading results into container
2024-11-14 09:26:42,260:INFO:Uploading model into container now
2024-11-14 09:26:42,261:INFO:_master_model_container: 15
2024-11-14 09:26:42,261:INFO:_display_container: 2
2024-11-14 09:26:42,261:INFO:AdaBoostRegressor(random_state=123)
2024-11-14 09:26:42,261:INFO:create_model() successfully completed......................................
2024-11-14 09:26:42,422:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:42,423:INFO:Creating metrics dataframe
2024-11-14 09:26:42,436:INFO:Initializing Gradient Boosting Regressor
2024-11-14 09:26:42,436:INFO:Total runtime is 0.3647217909495036 minutes
2024-11-14 09:26:42,439:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:42,440:INFO:Initializing create_model()
2024-11-14 09:26:42,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:42,440:INFO:Checking exceptions
2024-11-14 09:26:42,440:INFO:Importing libraries
2024-11-14 09:26:42,440:INFO:Copying training dataset
2024-11-14 09:26:42,447:INFO:Defining folds
2024-11-14 09:26:42,448:INFO:Declaring metric variables
2024-11-14 09:26:42,451:INFO:Importing untrained model
2024-11-14 09:26:42,455:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 09:26:42,461:INFO:Starting cross validation
2024-11-14 09:26:42,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:43,800:INFO:Calculating mean and std
2024-11-14 09:26:43,805:INFO:Creating metrics dataframe
2024-11-14 09:26:43,813:INFO:Uploading results into container
2024-11-14 09:26:43,813:INFO:Uploading model into container now
2024-11-14 09:26:43,814:INFO:_master_model_container: 16
2024-11-14 09:26:43,814:INFO:_display_container: 2
2024-11-14 09:26:43,815:INFO:GradientBoostingRegressor(random_state=123)
2024-11-14 09:26:43,815:INFO:create_model() successfully completed......................................
2024-11-14 09:26:44,021:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:44,021:INFO:Creating metrics dataframe
2024-11-14 09:26:44,035:INFO:Initializing Extreme Gradient Boosting
2024-11-14 09:26:44,035:INFO:Total runtime is 0.3913641095161438 minutes
2024-11-14 09:26:44,038:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:44,038:INFO:Initializing create_model()
2024-11-14 09:26:44,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:44,039:INFO:Checking exceptions
2024-11-14 09:26:44,039:INFO:Importing libraries
2024-11-14 09:26:44,039:INFO:Copying training dataset
2024-11-14 09:26:44,046:INFO:Defining folds
2024-11-14 09:26:44,046:INFO:Declaring metric variables
2024-11-14 09:26:44,049:INFO:Importing untrained model
2024-11-14 09:26:44,053:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 09:26:44,060:INFO:Starting cross validation
2024-11-14 09:26:44,060:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:26:44,407:INFO:Calculating mean and std
2024-11-14 09:26:44,411:INFO:Creating metrics dataframe
2024-11-14 09:26:44,418:INFO:Uploading results into container
2024-11-14 09:26:44,419:INFO:Uploading model into container now
2024-11-14 09:26:44,419:INFO:_master_model_container: 17
2024-11-14 09:26:44,420:INFO:_display_container: 2
2024-11-14 09:26:44,420:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-14 09:26:44,421:INFO:create_model() successfully completed......................................
2024-11-14 09:26:44,602:INFO:SubProcess create_model() end ==================================
2024-11-14 09:26:44,603:INFO:Creating metrics dataframe
2024-11-14 09:26:44,616:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 09:26:44,616:INFO:Total runtime is 0.4010587851206462 minutes
2024-11-14 09:26:44,620:INFO:SubProcess create_model() called ==================================
2024-11-14 09:26:44,620:INFO:Initializing create_model()
2024-11-14 09:26:44,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:26:44,620:INFO:Checking exceptions
2024-11-14 09:26:44,620:INFO:Importing libraries
2024-11-14 09:26:44,621:INFO:Copying training dataset
2024-11-14 09:26:44,628:INFO:Defining folds
2024-11-14 09:26:44,628:INFO:Declaring metric variables
2024-11-14 09:26:44,632:INFO:Importing untrained model
2024-11-14 09:26:44,635:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 09:26:44,641:INFO:Starting cross validation
2024-11-14 09:26:44,642:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:33:29,371:INFO:Calculating mean and std
2024-11-14 09:33:29,376:INFO:Creating metrics dataframe
2024-11-14 09:33:29,383:INFO:Uploading results into container
2024-11-14 09:33:29,385:INFO:Uploading model into container now
2024-11-14 09:33:29,385:INFO:_master_model_container: 18
2024-11-14 09:33:29,385:INFO:_display_container: 2
2024-11-14 09:33:29,386:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:33:29,386:INFO:create_model() successfully completed......................................
2024-11-14 09:33:29,603:INFO:SubProcess create_model() end ==================================
2024-11-14 09:33:29,603:INFO:Creating metrics dataframe
2024-11-14 09:33:29,617:INFO:Initializing CatBoost Regressor
2024-11-14 09:33:29,617:INFO:Total runtime is 7.151062937577565 minutes
2024-11-14 09:33:29,620:INFO:SubProcess create_model() called ==================================
2024-11-14 09:33:29,620:INFO:Initializing create_model()
2024-11-14 09:33:29,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:33:29,621:INFO:Checking exceptions
2024-11-14 09:33:29,621:INFO:Importing libraries
2024-11-14 09:33:29,621:INFO:Copying training dataset
2024-11-14 09:33:29,628:INFO:Defining folds
2024-11-14 09:33:29,629:INFO:Declaring metric variables
2024-11-14 09:33:29,632:INFO:Importing untrained model
2024-11-14 09:33:29,635:INFO:CatBoost Regressor Imported successfully
2024-11-14 09:33:29,641:INFO:Starting cross validation
2024-11-14 09:33:29,642:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:33:42,546:INFO:Calculating mean and std
2024-11-14 09:33:42,552:INFO:Creating metrics dataframe
2024-11-14 09:33:42,558:INFO:Uploading results into container
2024-11-14 09:33:42,559:INFO:Uploading model into container now
2024-11-14 09:33:42,559:INFO:_master_model_container: 19
2024-11-14 09:33:42,559:INFO:_display_container: 2
2024-11-14 09:33:42,559:INFO:<catboost.core.CatBoostRegressor object at 0x7f772ad4e6d0>
2024-11-14 09:33:42,559:INFO:create_model() successfully completed......................................
2024-11-14 09:33:42,767:INFO:SubProcess create_model() end ==================================
2024-11-14 09:33:42,767:INFO:Creating metrics dataframe
2024-11-14 09:33:42,781:INFO:Initializing Dummy Regressor
2024-11-14 09:33:42,782:INFO:Total runtime is 7.370479516188303 minutes
2024-11-14 09:33:42,785:INFO:SubProcess create_model() called ==================================
2024-11-14 09:33:42,786:INFO:Initializing create_model()
2024-11-14 09:33:42,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772a686b80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:33:42,786:INFO:Checking exceptions
2024-11-14 09:33:42,786:INFO:Importing libraries
2024-11-14 09:33:42,786:INFO:Copying training dataset
2024-11-14 09:33:42,794:INFO:Defining folds
2024-11-14 09:33:42,795:INFO:Declaring metric variables
2024-11-14 09:33:42,798:INFO:Importing untrained model
2024-11-14 09:33:42,801:INFO:Dummy Regressor Imported successfully
2024-11-14 09:33:42,808:INFO:Starting cross validation
2024-11-14 09:33:42,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 09:33:42,911:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-11-14 09:33:45,762:INFO:Calculating mean and std
2024-11-14 09:33:45,767:INFO:Creating metrics dataframe
2024-11-14 09:33:45,774:INFO:Uploading results into container
2024-11-14 09:33:45,775:INFO:Uploading model into container now
2024-11-14 09:33:45,775:INFO:_master_model_container: 20
2024-11-14 09:33:45,776:INFO:_display_container: 2
2024-11-14 09:33:45,776:INFO:DummyRegressor()
2024-11-14 09:33:45,776:INFO:create_model() successfully completed......................................
2024-11-14 09:33:45,973:INFO:SubProcess create_model() end ==================================
2024-11-14 09:33:45,973:INFO:Creating metrics dataframe
2024-11-14 09:33:45,996:INFO:Initializing create_model()
2024-11-14 09:33:45,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 09:33:45,996:INFO:Checking exceptions
2024-11-14 09:33:45,998:INFO:Importing libraries
2024-11-14 09:33:45,998:INFO:Copying training dataset
2024-11-14 09:33:46,004:INFO:Defining folds
2024-11-14 09:33:46,004:INFO:Declaring metric variables
2024-11-14 09:33:46,005:INFO:Importing untrained model
2024-11-14 09:33:46,005:INFO:Declaring custom model
2024-11-14 09:33:46,005:INFO:Extra Trees Regressor Imported successfully
2024-11-14 09:33:46,006:INFO:Cross validation set to False
2024-11-14 09:33:46,006:INFO:Fitting Model
2024-11-14 09:33:46,251:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:33:46,251:INFO:create_model() successfully completed......................................
2024-11-14 09:33:46,503:INFO:_master_model_container: 20
2024-11-14 09:33:46,504:INFO:_display_container: 2
2024-11-14 09:33:46,504:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 09:33:46,504:INFO:compare_models() successfully completed......................................
2024-11-14 09:34:31,486:INFO:Initializing plot_model()
2024-11-14 09:34:31,486:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, system=True)
2024-11-14 09:34:31,486:INFO:Checking exceptions
2024-11-14 09:34:31,555:INFO:Preloading libraries
2024-11-14 09:34:31,742:INFO:Copying training dataset
2024-11-14 09:34:31,742:INFO:Plot type: residuals
2024-11-14 09:34:31,954:INFO:Fitting Model
2024-11-14 09:34:31,955:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-14 09:34:31,955:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- Latitude
Feature names seen at fit time, yet now missing:
- Longitude

  warnings.warn(message, FutureWarning)

2024-11-14 09:34:32,006:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- Latitude
Feature names seen at fit time, yet now missing:
- Longitude

  warnings.warn(message, FutureWarning)

2024-11-14 09:34:32,101:INFO:Scoring test/hold-out set
2024-11-14 09:34:32,101:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- Latitude
Feature names seen at fit time, yet now missing:
- Longitude

  warnings.warn(message, FutureWarning)

2024-11-14 09:34:32,152:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- Latitude
Feature names seen at fit time, yet now missing:
- Longitude

  warnings.warn(message, FutureWarning)

2024-11-14 09:34:33,143:INFO:Visual Rendered Successfully
2024-11-14 09:34:33,382:INFO:plot_model() successfully completed......................................
2024-11-14 09:37:14,148:INFO:Initializing plot_model()
2024-11-14 09:37:14,148:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, system=True)
2024-11-14 09:37:14,148:INFO:Checking exceptions
2024-11-14 09:37:14,201:INFO:Preloading libraries
2024-11-14 09:37:14,342:INFO:Copying training dataset
2024-11-14 09:37:14,342:INFO:Plot type: residuals
2024-11-14 09:37:14,425:INFO:Fitting Model
2024-11-14 09:37:14,425:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-14 09:37:14,425:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- Latitude
Feature names seen at fit time, yet now missing:
- Longitude

  warnings.warn(message, FutureWarning)

2024-11-14 09:37:14,477:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- Latitude
Feature names seen at fit time, yet now missing:
- Longitude

  warnings.warn(message, FutureWarning)

2024-11-14 09:37:14,569:INFO:Scoring test/hold-out set
2024-11-14 09:37:14,569:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- Latitude
Feature names seen at fit time, yet now missing:
- Longitude

  warnings.warn(message, FutureWarning)

2024-11-14 09:37:14,621:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- Latitude
Feature names seen at fit time, yet now missing:
- Longitude

  warnings.warn(message, FutureWarning)

2024-11-14 09:37:15,313:INFO:Visual Rendered Successfully
2024-11-14 09:37:15,576:INFO:plot_model() successfully completed......................................
2024-11-14 09:37:15,580:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- Latitude

  warnings.warn(message, FutureWarning)

2024-11-14 09:37:41,146:INFO:Initializing plot_model()
2024-11-14 09:37:41,146:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, system=True)
2024-11-14 09:37:41,147:INFO:Checking exceptions
2024-11-14 09:37:41,201:INFO:Preloading libraries
2024-11-14 09:37:41,398:INFO:Copying training dataset
2024-11-14 09:37:41,399:INFO:Plot type: residuals
2024-11-14 09:37:41,495:INFO:Fitting Model
2024-11-14 09:37:41,495:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-14 09:37:41,650:INFO:Scoring test/hold-out set
2024-11-14 09:37:42,360:INFO:Visual Rendered Successfully
2024-11-14 09:37:42,591:INFO:plot_model() successfully completed......................................
2024-11-14 09:42:56,416:INFO:Initializing plot_model()
2024-11-14 09:42:56,416:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, system=True)
2024-11-14 09:42:56,416:INFO:Checking exceptions
2024-11-14 09:42:56,467:INFO:Preloading libraries
2024-11-14 09:42:56,600:INFO:Copying training dataset
2024-11-14 09:42:56,600:INFO:Plot type: error
2024-11-14 09:42:56,663:INFO:Fitting Model
2024-11-14 09:42:56,664:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-14 09:42:56,664:INFO:Scoring test/hold-out set
2024-11-14 09:42:57,093:INFO:Visual Rendered Successfully
2024-11-14 09:42:57,307:INFO:plot_model() successfully completed......................................
2024-11-14 09:46:24,158:INFO:Initializing plot_model()
2024-11-14 09:46:24,159:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, system=True)
2024-11-14 09:46:24,159:INFO:Checking exceptions
2024-11-14 09:46:24,216:INFO:Preloading libraries
2024-11-14 09:46:24,365:INFO:Copying training dataset
2024-11-14 09:46:24,365:INFO:Plot type: residuals
2024-11-14 09:46:24,444:INFO:Fitting Model
2024-11-14 09:46:24,444:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-14 09:46:24,865:INFO:Scoring test/hold-out set
2024-11-14 09:46:25,583:INFO:Visual Rendered Successfully
2024-11-14 09:46:25,811:INFO:plot_model() successfully completed......................................
2024-11-14 09:46:25,814:INFO:Initializing plot_model()
2024-11-14 09:46:25,814:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, system=True)
2024-11-14 09:46:25,814:INFO:Checking exceptions
2024-11-14 09:46:25,868:INFO:Preloading libraries
2024-11-14 09:46:25,983:INFO:Copying training dataset
2024-11-14 09:46:25,983:INFO:Plot type: error
2024-11-14 09:46:26,038:INFO:Fitting Model
2024-11-14 09:46:26,038:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-14 09:46:26,038:INFO:Scoring test/hold-out set
2024-11-14 09:46:26,442:INFO:Visual Rendered Successfully
2024-11-14 09:46:26,631:INFO:plot_model() successfully completed......................................
2024-11-14 10:06:59,506:INFO:Initializing create_model()
2024-11-14 10:06:59,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f773c5299d0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:06:59,507:INFO:Checking exceptions
2024-11-14 10:06:59,540:INFO:Importing libraries
2024-11-14 10:06:59,540:INFO:Copying training dataset
2024-11-14 10:06:59,549:INFO:Defining folds
2024-11-14 10:06:59,549:INFO:Declaring metric variables
2024-11-14 10:06:59,553:INFO:Importing untrained model
2024-11-14 10:06:59,557:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:06:59,564:INFO:Starting cross validation
2024-11-14 10:06:59,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:04,383:INFO:Calculating mean and std
2024-11-14 10:07:04,388:INFO:Creating metrics dataframe
2024-11-14 10:07:04,396:INFO:Finalizing model
2024-11-14 10:07:04,657:INFO:Uploading results into container
2024-11-14 10:07:04,658:INFO:Uploading model into container now
2024-11-14 10:07:04,669:INFO:_master_model_container: 21
2024-11-14 10:07:04,669:INFO:_display_container: 3
2024-11-14 10:07:04,670:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:07:04,670:INFO:create_model() successfully completed......................................
2024-11-14 10:07:39,094:INFO:PyCaret RegressionExperiment
2024-11-14 10:07:39,094:INFO:Logging name: reg-default-name
2024-11-14 10:07:39,094:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 10:07:39,094:INFO:version 3.2.0
2024-11-14 10:07:39,094:INFO:Initializing setup()
2024-11-14 10:07:39,095:INFO:self.USI: c8de
2024-11-14 10:07:39,095:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'fold_generator', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'memory', 'data', 'fold_groups_param', 'X', 'transform_target_param', 'target_param', 'y_test', 'X_train', 'seed', 'pipeline', 'html_param', 'exp_name_log', 'USI', 'log_plots_param', 'gpu_param', 'n_jobs_param', 'exp_id', '_available_plots', 'logging_param', 'y_train'}
2024-11-14 10:07:39,095:INFO:Checking environment
2024-11-14 10:07:39,095:INFO:python_version: 3.8.13
2024-11-14 10:07:39,095:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 10:07:39,095:INFO:machine: x86_64
2024-11-14 10:07:39,095:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 10:07:39,095:INFO:Memory: svmem(total=270355722240, available=218826534912, percent=19.1, used=49447411712, free=72005763072, active=71714992128, inactive=66431533056, buffers=10100736, cached=148892446720, shared=187678720, slab=25146716160)
2024-11-14 10:07:39,099:INFO:Physical Core: 28
2024-11-14 10:07:39,099:INFO:Logical Core: 56
2024-11-14 10:07:39,099:INFO:Checking libraries
2024-11-14 10:07:39,099:INFO:System:
2024-11-14 10:07:39,099:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 10:07:39,099:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 10:07:39,099:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 10:07:39,099:INFO:PyCaret required dependencies:
2024-11-14 10:07:39,099:INFO:                 pip: 22.2.2
2024-11-14 10:07:39,099:INFO:          setuptools: 63.4.2
2024-11-14 10:07:39,099:INFO:             pycaret: 3.2.0
2024-11-14 10:07:39,099:INFO:             IPython: 8.12.2
2024-11-14 10:07:39,099:INFO:          ipywidgets: 7.7.1
2024-11-14 10:07:39,099:INFO:                tqdm: 4.64.1
2024-11-14 10:07:39,099:INFO:               numpy: 1.23.5
2024-11-14 10:07:39,099:INFO:              pandas: 1.5.3
2024-11-14 10:07:39,099:INFO:              jinja2: 3.1.2
2024-11-14 10:07:39,100:INFO:               scipy: 1.10.1
2024-11-14 10:07:39,100:INFO:              joblib: 1.3.0
2024-11-14 10:07:39,100:INFO:             sklearn: 1.1.2
2024-11-14 10:07:39,100:INFO:                pyod: 2.0.2
2024-11-14 10:07:39,100:INFO:            imblearn: 0.12.4
2024-11-14 10:07:39,100:INFO:   category_encoders: 2.6.4
2024-11-14 10:07:39,100:INFO:            lightgbm: 4.5.0
2024-11-14 10:07:39,100:INFO:               numba: 0.57.1
2024-11-14 10:07:39,100:INFO:            requests: 2.28.1
2024-11-14 10:07:39,100:INFO:          matplotlib: 3.5.1
2024-11-14 10:07:39,100:INFO:          scikitplot: 0.3.7
2024-11-14 10:07:39,100:INFO:         yellowbrick: 1.5
2024-11-14 10:07:39,100:INFO:              plotly: 5.24.1
2024-11-14 10:07:39,100:INFO:    plotly-resampler: Not installed
2024-11-14 10:07:39,100:INFO:             kaleido: 0.2.1
2024-11-14 10:07:39,100:INFO:           schemdraw: 0.15
2024-11-14 10:07:39,100:INFO:         statsmodels: 0.13.2
2024-11-14 10:07:39,100:INFO:              sktime: 0.21.1
2024-11-14 10:07:39,100:INFO:               tbats: 1.1.3
2024-11-14 10:07:39,100:INFO:            pmdarima: 2.0.4
2024-11-14 10:07:39,100:INFO:              psutil: 5.9.1
2024-11-14 10:07:39,100:INFO:          markupsafe: 2.1.1
2024-11-14 10:07:39,100:INFO:             pickle5: Not installed
2024-11-14 10:07:39,100:INFO:         cloudpickle: 2.1.0
2024-11-14 10:07:39,100:INFO:         deprecation: 2.1.0
2024-11-14 10:07:39,100:INFO:              xxhash: 3.5.0
2024-11-14 10:07:39,100:INFO:           wurlitzer: 3.1.1
2024-11-14 10:07:39,100:INFO:PyCaret optional dependencies:
2024-11-14 10:07:39,101:INFO:                shap: 0.44.1
2024-11-14 10:07:39,101:INFO:           interpret: 0.6.5
2024-11-14 10:07:39,101:INFO:                umap: 0.5.7
2024-11-14 10:07:39,101:INFO:     ydata_profiling: 4.6.0
2024-11-14 10:07:39,101:INFO:  explainerdashboard: 0.4.7
2024-11-14 10:07:39,101:INFO:             autoviz: Not installed
2024-11-14 10:07:39,101:INFO:           fairlearn: 0.7.0
2024-11-14 10:07:39,101:INFO:          deepchecks: Not installed
2024-11-14 10:07:39,101:INFO:             xgboost: 2.1.1
2024-11-14 10:07:39,101:INFO:            catboost: 1.2.7
2024-11-14 10:07:39,101:INFO:              kmodes: 0.12.2
2024-11-14 10:07:39,101:INFO:             mlxtend: 0.23.1
2024-11-14 10:07:39,101:INFO:       statsforecast: 1.5.0
2024-11-14 10:07:39,101:INFO:        tune_sklearn: 0.5.0
2024-11-14 10:07:39,101:INFO:                 ray: 2.10.0
2024-11-14 10:07:39,101:INFO:            hyperopt: 0.2.7
2024-11-14 10:07:39,101:INFO:              optuna: 4.1.0
2024-11-14 10:07:39,101:INFO:               skopt: 0.10.2
2024-11-14 10:07:39,101:INFO:              mlflow: 1.30.1
2024-11-14 10:07:39,101:INFO:              gradio: 3.50.2
2024-11-14 10:07:39,101:INFO:             fastapi: 0.115.5
2024-11-14 10:07:39,101:INFO:             uvicorn: 0.32.0
2024-11-14 10:07:39,101:INFO:              m2cgen: 0.10.0
2024-11-14 10:07:39,101:INFO:           evidently: 0.2.8
2024-11-14 10:07:39,101:INFO:               fugue: 0.8.6
2024-11-14 10:07:39,101:INFO:           streamlit: Not installed
2024-11-14 10:07:39,101:INFO:             prophet: Not installed
2024-11-14 10:07:39,101:INFO:None
2024-11-14 10:07:39,101:INFO:Set up data.
2024-11-14 10:07:39,111:INFO:Set up folding strategy.
2024-11-14 10:07:39,111:INFO:Set up train/test split.
2024-11-14 10:07:39,117:INFO:Set up index.
2024-11-14 10:07:39,118:INFO:Assigning column types.
2024-11-14 10:07:39,123:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 10:07:39,123:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,128:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,133:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,236:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:39,239:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:39,240:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,244:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,248:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,297:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,335:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:39,337:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:39,337:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 10:07:39,341:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,345:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,393:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,430:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,430:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:39,432:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:39,436:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,440:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,488:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,526:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:39,528:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:39,528:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 10:07:39,537:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,585:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,622:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:39,624:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:39,632:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,681:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,718:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:39,720:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:39,721:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 10:07:39,777:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,814:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,814:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:39,816:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:39,873:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:07:39,912:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:39,914:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:39,915:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 10:07:39,972:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:07:40,009:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:40,011:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:40,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:07:40,105:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:40,107:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:40,107:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 10:07:40,201:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:40,203:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:40,298:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:40,300:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:40,301:INFO:Preparing preprocessing pipeline...
2024-11-14 10:07:40,302:INFO:Set up simple imputation.
2024-11-14 10:07:40,320:INFO:Finished creating preprocessing pipeline.
2024-11-14 10:07:40,324:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 10:07:40,324:INFO:Creating final display dataframe.
2024-11-14 10:07:40,385:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              c8de
2024-11-14 10:07:40,489:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:40,491:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:40,585:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:07:40,587:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:07:40,588:INFO:setup() successfully completed in 1.5s...............
2024-11-14 10:07:40,589:INFO:Initializing compare_models()
2024-11-14 10:07:40,589:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 10:07:40,589:INFO:Checking exceptions
2024-11-14 10:07:40,592:INFO:Preparing display monitor
2024-11-14 10:07:40,624:INFO:Initializing Linear Regression
2024-11-14 10:07:40,626:INFO:Total runtime is 3.617207209269206e-05 minutes
2024-11-14 10:07:40,629:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:40,630:INFO:Initializing create_model()
2024-11-14 10:07:40,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:40,630:INFO:Checking exceptions
2024-11-14 10:07:40,630:INFO:Importing libraries
2024-11-14 10:07:40,630:INFO:Copying training dataset
2024-11-14 10:07:40,636:INFO:Defining folds
2024-11-14 10:07:40,636:INFO:Declaring metric variables
2024-11-14 10:07:40,639:INFO:Importing untrained model
2024-11-14 10:07:40,642:INFO:Linear Regression Imported successfully
2024-11-14 10:07:40,649:INFO:Starting cross validation
2024-11-14 10:07:40,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:43,426:INFO:Calculating mean and std
2024-11-14 10:07:43,430:INFO:Creating metrics dataframe
2024-11-14 10:07:43,436:INFO:Uploading results into container
2024-11-14 10:07:43,437:INFO:Uploading model into container now
2024-11-14 10:07:43,438:INFO:_master_model_container: 1
2024-11-14 10:07:43,438:INFO:_display_container: 2
2024-11-14 10:07:43,439:INFO:LinearRegression(n_jobs=-1)
2024-11-14 10:07:43,439:INFO:create_model() successfully completed......................................
2024-11-14 10:07:43,673:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:43,673:INFO:Creating metrics dataframe
2024-11-14 10:07:43,682:INFO:Initializing Lasso Regression
2024-11-14 10:07:43,682:INFO:Total runtime is 0.050967621803283694 minutes
2024-11-14 10:07:43,685:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:43,686:INFO:Initializing create_model()
2024-11-14 10:07:43,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:43,686:INFO:Checking exceptions
2024-11-14 10:07:43,686:INFO:Importing libraries
2024-11-14 10:07:43,686:INFO:Copying training dataset
2024-11-14 10:07:43,693:INFO:Defining folds
2024-11-14 10:07:43,693:INFO:Declaring metric variables
2024-11-14 10:07:43,696:INFO:Importing untrained model
2024-11-14 10:07:43,700:INFO:Lasso Regression Imported successfully
2024-11-14 10:07:43,706:INFO:Starting cross validation
2024-11-14 10:07:43,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:46,541:INFO:Calculating mean and std
2024-11-14 10:07:46,545:INFO:Creating metrics dataframe
2024-11-14 10:07:46,552:INFO:Uploading results into container
2024-11-14 10:07:46,552:INFO:Uploading model into container now
2024-11-14 10:07:46,553:INFO:_master_model_container: 2
2024-11-14 10:07:46,553:INFO:_display_container: 2
2024-11-14 10:07:46,554:INFO:Lasso(random_state=123)
2024-11-14 10:07:46,554:INFO:create_model() successfully completed......................................
2024-11-14 10:07:46,763:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:46,763:INFO:Creating metrics dataframe
2024-11-14 10:07:46,773:INFO:Initializing Ridge Regression
2024-11-14 10:07:46,773:INFO:Total runtime is 0.10247821807861329 minutes
2024-11-14 10:07:46,776:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:46,777:INFO:Initializing create_model()
2024-11-14 10:07:46,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:46,777:INFO:Checking exceptions
2024-11-14 10:07:46,777:INFO:Importing libraries
2024-11-14 10:07:46,777:INFO:Copying training dataset
2024-11-14 10:07:46,784:INFO:Defining folds
2024-11-14 10:07:46,784:INFO:Declaring metric variables
2024-11-14 10:07:46,787:INFO:Importing untrained model
2024-11-14 10:07:46,790:INFO:Ridge Regression Imported successfully
2024-11-14 10:07:46,796:INFO:Starting cross validation
2024-11-14 10:07:46,797:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:49,772:INFO:Calculating mean and std
2024-11-14 10:07:49,776:INFO:Creating metrics dataframe
2024-11-14 10:07:49,783:INFO:Uploading results into container
2024-11-14 10:07:49,784:INFO:Uploading model into container now
2024-11-14 10:07:49,784:INFO:_master_model_container: 3
2024-11-14 10:07:49,784:INFO:_display_container: 2
2024-11-14 10:07:49,785:INFO:Ridge(random_state=123)
2024-11-14 10:07:49,785:INFO:create_model() successfully completed......................................
2024-11-14 10:07:49,952:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:49,952:INFO:Creating metrics dataframe
2024-11-14 10:07:49,965:INFO:Initializing Elastic Net
2024-11-14 10:07:49,965:INFO:Total runtime is 0.1556787967681885 minutes
2024-11-14 10:07:49,968:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:49,969:INFO:Initializing create_model()
2024-11-14 10:07:49,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:49,969:INFO:Checking exceptions
2024-11-14 10:07:49,969:INFO:Importing libraries
2024-11-14 10:07:49,969:INFO:Copying training dataset
2024-11-14 10:07:49,977:INFO:Defining folds
2024-11-14 10:07:49,977:INFO:Declaring metric variables
2024-11-14 10:07:49,981:INFO:Importing untrained model
2024-11-14 10:07:49,984:INFO:Elastic Net Imported successfully
2024-11-14 10:07:49,991:INFO:Starting cross validation
2024-11-14 10:07:49,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:53,310:INFO:Calculating mean and std
2024-11-14 10:07:53,313:INFO:Creating metrics dataframe
2024-11-14 10:07:53,320:INFO:Uploading results into container
2024-11-14 10:07:53,321:INFO:Uploading model into container now
2024-11-14 10:07:53,321:INFO:_master_model_container: 4
2024-11-14 10:07:53,321:INFO:_display_container: 2
2024-11-14 10:07:53,322:INFO:ElasticNet(random_state=123)
2024-11-14 10:07:53,322:INFO:create_model() successfully completed......................................
2024-11-14 10:07:53,519:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:53,519:INFO:Creating metrics dataframe
2024-11-14 10:07:53,530:INFO:Initializing Least Angle Regression
2024-11-14 10:07:53,530:INFO:Total runtime is 0.21509549220403038 minutes
2024-11-14 10:07:53,533:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:53,533:INFO:Initializing create_model()
2024-11-14 10:07:53,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:53,534:INFO:Checking exceptions
2024-11-14 10:07:53,534:INFO:Importing libraries
2024-11-14 10:07:53,534:INFO:Copying training dataset
2024-11-14 10:07:53,541:INFO:Defining folds
2024-11-14 10:07:53,541:INFO:Declaring metric variables
2024-11-14 10:07:53,545:INFO:Importing untrained model
2024-11-14 10:07:53,548:INFO:Least Angle Regression Imported successfully
2024-11-14 10:07:53,554:INFO:Starting cross validation
2024-11-14 10:07:53,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:53,634:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:53,638:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:53,648:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:53,653:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:56,066:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:56,081:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:56,221:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:56,262:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:56,311:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:56,463:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:56,479:INFO:Calculating mean and std
2024-11-14 10:07:56,483:INFO:Creating metrics dataframe
2024-11-14 10:07:56,491:INFO:Uploading results into container
2024-11-14 10:07:56,491:INFO:Uploading model into container now
2024-11-14 10:07:56,492:INFO:_master_model_container: 5
2024-11-14 10:07:56,492:INFO:_display_container: 2
2024-11-14 10:07:56,492:INFO:Lars(random_state=123)
2024-11-14 10:07:56,492:INFO:create_model() successfully completed......................................
2024-11-14 10:07:56,690:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:56,690:INFO:Creating metrics dataframe
2024-11-14 10:07:56,701:INFO:Initializing Lasso Least Angle Regression
2024-11-14 10:07:56,702:INFO:Total runtime is 0.2679585893948873 minutes
2024-11-14 10:07:56,705:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:56,705:INFO:Initializing create_model()
2024-11-14 10:07:56,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:56,706:INFO:Checking exceptions
2024-11-14 10:07:56,706:INFO:Importing libraries
2024-11-14 10:07:56,706:INFO:Copying training dataset
2024-11-14 10:07:56,713:INFO:Defining folds
2024-11-14 10:07:56,713:INFO:Declaring metric variables
2024-11-14 10:07:56,716:INFO:Importing untrained model
2024-11-14 10:07:56,719:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 10:07:56,726:INFO:Starting cross validation
2024-11-14 10:07:56,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:56,759:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 10:07:56,771:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 10:07:56,782:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 10:07:56,791:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 10:07:56,798:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 10:07:56,805:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 10:07:56,810:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 10:07:56,816:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 10:07:56,822:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 10:07:56,822:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 10:07:56,840:INFO:Calculating mean and std
2024-11-14 10:07:56,844:INFO:Creating metrics dataframe
2024-11-14 10:07:56,851:INFO:Uploading results into container
2024-11-14 10:07:56,851:INFO:Uploading model into container now
2024-11-14 10:07:56,852:INFO:_master_model_container: 6
2024-11-14 10:07:56,852:INFO:_display_container: 2
2024-11-14 10:07:56,852:INFO:LassoLars(random_state=123)
2024-11-14 10:07:56,852:INFO:create_model() successfully completed......................................
2024-11-14 10:07:57,029:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:57,029:INFO:Creating metrics dataframe
2024-11-14 10:07:57,040:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 10:07:57,040:INFO:Total runtime is 0.27359196742375697 minutes
2024-11-14 10:07:57,043:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:57,043:INFO:Initializing create_model()
2024-11-14 10:07:57,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:57,044:INFO:Checking exceptions
2024-11-14 10:07:57,044:INFO:Importing libraries
2024-11-14 10:07:57,044:INFO:Copying training dataset
2024-11-14 10:07:57,051:INFO:Defining folds
2024-11-14 10:07:57,051:INFO:Declaring metric variables
2024-11-14 10:07:57,054:INFO:Importing untrained model
2024-11-14 10:07:57,057:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 10:07:57,064:INFO:Starting cross validation
2024-11-14 10:07:57,064:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:57,092:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:57,097:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:57,107:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:57,110:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:57,112:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:57,116:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:57,123:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:57,126:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:57,132:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:57,140:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 10:07:57,154:INFO:Calculating mean and std
2024-11-14 10:07:57,158:INFO:Creating metrics dataframe
2024-11-14 10:07:57,163:INFO:Uploading results into container
2024-11-14 10:07:57,164:INFO:Uploading model into container now
2024-11-14 10:07:57,165:INFO:_master_model_container: 7
2024-11-14 10:07:57,165:INFO:_display_container: 2
2024-11-14 10:07:57,165:INFO:OrthogonalMatchingPursuit()
2024-11-14 10:07:57,165:INFO:create_model() successfully completed......................................
2024-11-14 10:07:57,378:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:57,379:INFO:Creating metrics dataframe
2024-11-14 10:07:57,390:INFO:Initializing Bayesian Ridge
2024-11-14 10:07:57,390:INFO:Total runtime is 0.27943085829416914 minutes
2024-11-14 10:07:57,393:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:57,394:INFO:Initializing create_model()
2024-11-14 10:07:57,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:57,394:INFO:Checking exceptions
2024-11-14 10:07:57,394:INFO:Importing libraries
2024-11-14 10:07:57,394:INFO:Copying training dataset
2024-11-14 10:07:57,402:INFO:Defining folds
2024-11-14 10:07:57,402:INFO:Declaring metric variables
2024-11-14 10:07:57,405:INFO:Importing untrained model
2024-11-14 10:07:57,408:INFO:Bayesian Ridge Imported successfully
2024-11-14 10:07:57,415:INFO:Starting cross validation
2024-11-14 10:07:57,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:57,506:INFO:Calculating mean and std
2024-11-14 10:07:57,510:INFO:Creating metrics dataframe
2024-11-14 10:07:57,516:INFO:Uploading results into container
2024-11-14 10:07:57,516:INFO:Uploading model into container now
2024-11-14 10:07:57,517:INFO:_master_model_container: 8
2024-11-14 10:07:57,517:INFO:_display_container: 2
2024-11-14 10:07:57,517:INFO:BayesianRidge()
2024-11-14 10:07:57,517:INFO:create_model() successfully completed......................................
2024-11-14 10:07:57,713:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:57,713:INFO:Creating metrics dataframe
2024-11-14 10:07:57,724:INFO:Initializing Passive Aggressive Regressor
2024-11-14 10:07:57,725:INFO:Total runtime is 0.28500583966573084 minutes
2024-11-14 10:07:57,728:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:57,728:INFO:Initializing create_model()
2024-11-14 10:07:57,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:57,728:INFO:Checking exceptions
2024-11-14 10:07:57,729:INFO:Importing libraries
2024-11-14 10:07:57,729:INFO:Copying training dataset
2024-11-14 10:07:57,736:INFO:Defining folds
2024-11-14 10:07:57,736:INFO:Declaring metric variables
2024-11-14 10:07:57,739:INFO:Importing untrained model
2024-11-14 10:07:57,742:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 10:07:57,748:INFO:Starting cross validation
2024-11-14 10:07:57,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:57,951:INFO:Calculating mean and std
2024-11-14 10:07:57,957:INFO:Creating metrics dataframe
2024-11-14 10:07:57,964:INFO:Uploading results into container
2024-11-14 10:07:57,965:INFO:Uploading model into container now
2024-11-14 10:07:57,965:INFO:_master_model_container: 9
2024-11-14 10:07:57,965:INFO:_display_container: 2
2024-11-14 10:07:57,966:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-14 10:07:57,966:INFO:create_model() successfully completed......................................
2024-11-14 10:07:58,166:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:58,166:INFO:Creating metrics dataframe
2024-11-14 10:07:58,178:INFO:Initializing Huber Regressor
2024-11-14 10:07:58,178:INFO:Total runtime is 0.2925687630971273 minutes
2024-11-14 10:07:58,181:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:58,182:INFO:Initializing create_model()
2024-11-14 10:07:58,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:58,182:INFO:Checking exceptions
2024-11-14 10:07:58,183:INFO:Importing libraries
2024-11-14 10:07:58,183:INFO:Copying training dataset
2024-11-14 10:07:58,190:INFO:Defining folds
2024-11-14 10:07:58,190:INFO:Declaring metric variables
2024-11-14 10:07:58,193:INFO:Importing untrained model
2024-11-14 10:07:58,196:INFO:Huber Regressor Imported successfully
2024-11-14 10:07:58,203:INFO:Starting cross validation
2024-11-14 10:07:58,203:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:58,490:INFO:Calculating mean and std
2024-11-14 10:07:58,494:INFO:Creating metrics dataframe
2024-11-14 10:07:58,500:INFO:Uploading results into container
2024-11-14 10:07:58,500:INFO:Uploading model into container now
2024-11-14 10:07:58,501:INFO:_master_model_container: 10
2024-11-14 10:07:58,501:INFO:_display_container: 2
2024-11-14 10:07:58,501:INFO:HuberRegressor()
2024-11-14 10:07:58,501:INFO:create_model() successfully completed......................................
2024-11-14 10:07:58,673:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:58,673:INFO:Creating metrics dataframe
2024-11-14 10:07:58,684:INFO:Initializing K Neighbors Regressor
2024-11-14 10:07:58,685:INFO:Total runtime is 0.30100657542546594 minutes
2024-11-14 10:07:58,688:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:58,688:INFO:Initializing create_model()
2024-11-14 10:07:58,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:58,688:INFO:Checking exceptions
2024-11-14 10:07:58,689:INFO:Importing libraries
2024-11-14 10:07:58,689:INFO:Copying training dataset
2024-11-14 10:07:58,696:INFO:Defining folds
2024-11-14 10:07:58,696:INFO:Declaring metric variables
2024-11-14 10:07:58,699:INFO:Importing untrained model
2024-11-14 10:07:58,702:INFO:K Neighbors Regressor Imported successfully
2024-11-14 10:07:58,708:INFO:Starting cross validation
2024-11-14 10:07:58,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:58,860:INFO:Calculating mean and std
2024-11-14 10:07:58,864:INFO:Creating metrics dataframe
2024-11-14 10:07:58,869:INFO:Uploading results into container
2024-11-14 10:07:58,870:INFO:Uploading model into container now
2024-11-14 10:07:58,871:INFO:_master_model_container: 11
2024-11-14 10:07:58,871:INFO:_display_container: 2
2024-11-14 10:07:58,871:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 10:07:58,871:INFO:create_model() successfully completed......................................
2024-11-14 10:07:59,056:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:59,056:INFO:Creating metrics dataframe
2024-11-14 10:07:59,068:INFO:Initializing Decision Tree Regressor
2024-11-14 10:07:59,068:INFO:Total runtime is 0.3074007948239645 minutes
2024-11-14 10:07:59,071:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:59,072:INFO:Initializing create_model()
2024-11-14 10:07:59,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:59,072:INFO:Checking exceptions
2024-11-14 10:07:59,072:INFO:Importing libraries
2024-11-14 10:07:59,072:INFO:Copying training dataset
2024-11-14 10:07:59,080:INFO:Defining folds
2024-11-14 10:07:59,081:INFO:Declaring metric variables
2024-11-14 10:07:59,084:INFO:Importing untrained model
2024-11-14 10:07:59,087:INFO:Decision Tree Regressor Imported successfully
2024-11-14 10:07:59,094:INFO:Starting cross validation
2024-11-14 10:07:59,095:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:07:59,261:INFO:Calculating mean and std
2024-11-14 10:07:59,265:INFO:Creating metrics dataframe
2024-11-14 10:07:59,271:INFO:Uploading results into container
2024-11-14 10:07:59,272:INFO:Uploading model into container now
2024-11-14 10:07:59,273:INFO:_master_model_container: 12
2024-11-14 10:07:59,273:INFO:_display_container: 2
2024-11-14 10:07:59,273:INFO:DecisionTreeRegressor(random_state=123)
2024-11-14 10:07:59,273:INFO:create_model() successfully completed......................................
2024-11-14 10:07:59,443:INFO:SubProcess create_model() end ==================================
2024-11-14 10:07:59,443:INFO:Creating metrics dataframe
2024-11-14 10:07:59,455:INFO:Initializing Random Forest Regressor
2024-11-14 10:07:59,455:INFO:Total runtime is 0.3138489166895549 minutes
2024-11-14 10:07:59,458:INFO:SubProcess create_model() called ==================================
2024-11-14 10:07:59,459:INFO:Initializing create_model()
2024-11-14 10:07:59,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:07:59,459:INFO:Checking exceptions
2024-11-14 10:07:59,459:INFO:Importing libraries
2024-11-14 10:07:59,459:INFO:Copying training dataset
2024-11-14 10:07:59,466:INFO:Defining folds
2024-11-14 10:07:59,466:INFO:Declaring metric variables
2024-11-14 10:07:59,469:INFO:Importing untrained model
2024-11-14 10:07:59,473:INFO:Random Forest Regressor Imported successfully
2024-11-14 10:07:59,479:INFO:Starting cross validation
2024-11-14 10:07:59,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:08:01,022:INFO:Calculating mean and std
2024-11-14 10:08:01,026:INFO:Creating metrics dataframe
2024-11-14 10:08:01,034:INFO:Uploading results into container
2024-11-14 10:08:01,035:INFO:Uploading model into container now
2024-11-14 10:08:01,036:INFO:_master_model_container: 13
2024-11-14 10:08:01,036:INFO:_display_container: 2
2024-11-14 10:08:01,036:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:08:01,037:INFO:create_model() successfully completed......................................
2024-11-14 10:08:01,208:INFO:SubProcess create_model() end ==================================
2024-11-14 10:08:01,208:INFO:Creating metrics dataframe
2024-11-14 10:08:01,220:INFO:Initializing Extra Trees Regressor
2024-11-14 10:08:01,221:INFO:Total runtime is 0.34327306747436526 minutes
2024-11-14 10:08:01,224:INFO:SubProcess create_model() called ==================================
2024-11-14 10:08:01,224:INFO:Initializing create_model()
2024-11-14 10:08:01,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:08:01,224:INFO:Checking exceptions
2024-11-14 10:08:01,224:INFO:Importing libraries
2024-11-14 10:08:01,225:INFO:Copying training dataset
2024-11-14 10:08:01,232:INFO:Defining folds
2024-11-14 10:08:01,232:INFO:Declaring metric variables
2024-11-14 10:08:01,235:INFO:Importing untrained model
2024-11-14 10:08:01,239:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:08:01,245:INFO:Starting cross validation
2024-11-14 10:08:01,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:08:02,091:INFO:Calculating mean and std
2024-11-14 10:08:02,094:INFO:Creating metrics dataframe
2024-11-14 10:08:02,099:INFO:Uploading results into container
2024-11-14 10:08:02,100:INFO:Uploading model into container now
2024-11-14 10:08:02,100:INFO:_master_model_container: 14
2024-11-14 10:08:02,100:INFO:_display_container: 2
2024-11-14 10:08:02,101:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:08:02,101:INFO:create_model() successfully completed......................................
2024-11-14 10:08:02,285:INFO:SubProcess create_model() end ==================================
2024-11-14 10:08:02,285:INFO:Creating metrics dataframe
2024-11-14 10:08:02,300:INFO:Initializing AdaBoost Regressor
2024-11-14 10:08:02,300:INFO:Total runtime is 0.36126271088918055 minutes
2024-11-14 10:08:02,304:INFO:SubProcess create_model() called ==================================
2024-11-14 10:08:02,304:INFO:Initializing create_model()
2024-11-14 10:08:02,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:08:02,304:INFO:Checking exceptions
2024-11-14 10:08:02,304:INFO:Importing libraries
2024-11-14 10:08:02,304:INFO:Copying training dataset
2024-11-14 10:08:02,312:INFO:Defining folds
2024-11-14 10:08:02,312:INFO:Declaring metric variables
2024-11-14 10:08:02,316:INFO:Importing untrained model
2024-11-14 10:08:02,320:INFO:AdaBoost Regressor Imported successfully
2024-11-14 10:08:02,326:INFO:Starting cross validation
2024-11-14 10:08:02,327:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:08:03,325:INFO:Calculating mean and std
2024-11-14 10:08:03,329:INFO:Creating metrics dataframe
2024-11-14 10:08:03,335:INFO:Uploading results into container
2024-11-14 10:08:03,336:INFO:Uploading model into container now
2024-11-14 10:08:03,336:INFO:_master_model_container: 15
2024-11-14 10:08:03,337:INFO:_display_container: 2
2024-11-14 10:08:03,337:INFO:AdaBoostRegressor(random_state=123)
2024-11-14 10:08:03,337:INFO:create_model() successfully completed......................................
2024-11-14 10:08:03,568:INFO:SubProcess create_model() end ==================================
2024-11-14 10:08:03,568:INFO:Creating metrics dataframe
2024-11-14 10:08:03,582:INFO:Initializing Gradient Boosting Regressor
2024-11-14 10:08:03,582:INFO:Total runtime is 0.3826324542363485 minutes
2024-11-14 10:08:03,585:INFO:SubProcess create_model() called ==================================
2024-11-14 10:08:03,586:INFO:Initializing create_model()
2024-11-14 10:08:03,586:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:08:03,586:INFO:Checking exceptions
2024-11-14 10:08:03,586:INFO:Importing libraries
2024-11-14 10:08:03,586:INFO:Copying training dataset
2024-11-14 10:08:03,594:INFO:Defining folds
2024-11-14 10:08:03,595:INFO:Declaring metric variables
2024-11-14 10:08:03,598:INFO:Importing untrained model
2024-11-14 10:08:03,602:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 10:08:03,608:INFO:Starting cross validation
2024-11-14 10:08:03,609:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:08:04,944:INFO:Calculating mean and std
2024-11-14 10:08:04,947:INFO:Creating metrics dataframe
2024-11-14 10:08:04,954:INFO:Uploading results into container
2024-11-14 10:08:04,954:INFO:Uploading model into container now
2024-11-14 10:08:04,955:INFO:_master_model_container: 16
2024-11-14 10:08:04,955:INFO:_display_container: 2
2024-11-14 10:08:04,956:INFO:GradientBoostingRegressor(random_state=123)
2024-11-14 10:08:04,956:INFO:create_model() successfully completed......................................
2024-11-14 10:08:05,160:INFO:SubProcess create_model() end ==================================
2024-11-14 10:08:05,160:INFO:Creating metrics dataframe
2024-11-14 10:08:05,173:INFO:Initializing Extreme Gradient Boosting
2024-11-14 10:08:05,173:INFO:Total runtime is 0.4091464440027873 minutes
2024-11-14 10:08:05,176:INFO:SubProcess create_model() called ==================================
2024-11-14 10:08:05,177:INFO:Initializing create_model()
2024-11-14 10:08:05,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:08:05,177:INFO:Checking exceptions
2024-11-14 10:08:05,177:INFO:Importing libraries
2024-11-14 10:08:05,177:INFO:Copying training dataset
2024-11-14 10:08:05,185:INFO:Defining folds
2024-11-14 10:08:05,185:INFO:Declaring metric variables
2024-11-14 10:08:05,189:INFO:Importing untrained model
2024-11-14 10:08:05,193:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 10:08:05,199:INFO:Starting cross validation
2024-11-14 10:08:05,200:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:08:05,528:INFO:Calculating mean and std
2024-11-14 10:08:05,531:INFO:Creating metrics dataframe
2024-11-14 10:08:05,539:INFO:Uploading results into container
2024-11-14 10:08:05,539:INFO:Uploading model into container now
2024-11-14 10:08:05,540:INFO:_master_model_container: 17
2024-11-14 10:08:05,540:INFO:_display_container: 2
2024-11-14 10:08:05,541:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-14 10:08:05,541:INFO:create_model() successfully completed......................................
2024-11-14 10:08:05,767:INFO:SubProcess create_model() end ==================================
2024-11-14 10:08:05,767:INFO:Creating metrics dataframe
2024-11-14 10:08:05,781:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 10:08:05,781:INFO:Total runtime is 0.4192763169606527 minutes
2024-11-14 10:08:05,784:INFO:SubProcess create_model() called ==================================
2024-11-14 10:08:05,785:INFO:Initializing create_model()
2024-11-14 10:08:05,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:08:05,785:INFO:Checking exceptions
2024-11-14 10:08:05,785:INFO:Importing libraries
2024-11-14 10:08:05,785:INFO:Copying training dataset
2024-11-14 10:08:05,792:INFO:Defining folds
2024-11-14 10:08:05,793:INFO:Declaring metric variables
2024-11-14 10:08:05,796:INFO:Importing untrained model
2024-11-14 10:08:05,800:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 10:08:05,806:INFO:Starting cross validation
2024-11-14 10:08:05,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:14:53,029:INFO:Calculating mean and std
2024-11-14 10:14:53,033:INFO:Creating metrics dataframe
2024-11-14 10:14:53,040:INFO:Uploading results into container
2024-11-14 10:14:53,041:INFO:Uploading model into container now
2024-11-14 10:14:53,042:INFO:_master_model_container: 18
2024-11-14 10:14:53,042:INFO:_display_container: 2
2024-11-14 10:14:53,042:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:14:53,043:INFO:create_model() successfully completed......................................
2024-11-14 10:14:53,305:INFO:SubProcess create_model() end ==================================
2024-11-14 10:14:53,305:INFO:Creating metrics dataframe
2024-11-14 10:14:53,319:INFO:Initializing CatBoost Regressor
2024-11-14 10:14:53,319:INFO:Total runtime is 7.211581492424011 minutes
2024-11-14 10:14:53,322:INFO:SubProcess create_model() called ==================================
2024-11-14 10:14:53,323:INFO:Initializing create_model()
2024-11-14 10:14:53,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:14:53,323:INFO:Checking exceptions
2024-11-14 10:14:53,323:INFO:Importing libraries
2024-11-14 10:14:53,323:INFO:Copying training dataset
2024-11-14 10:14:53,332:INFO:Defining folds
2024-11-14 10:14:53,332:INFO:Declaring metric variables
2024-11-14 10:14:53,335:INFO:Importing untrained model
2024-11-14 10:14:53,339:INFO:CatBoost Regressor Imported successfully
2024-11-14 10:14:53,345:INFO:Starting cross validation
2024-11-14 10:14:53,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:15:06,661:INFO:Calculating mean and std
2024-11-14 10:15:06,667:INFO:Creating metrics dataframe
2024-11-14 10:15:06,677:INFO:Uploading results into container
2024-11-14 10:15:06,678:INFO:Uploading model into container now
2024-11-14 10:15:06,679:INFO:_master_model_container: 19
2024-11-14 10:15:06,679:INFO:_display_container: 2
2024-11-14 10:15:06,679:INFO:<catboost.core.CatBoostRegressor object at 0x7f772ae860a0>
2024-11-14 10:15:06,679:INFO:create_model() successfully completed......................................
2024-11-14 10:15:06,919:INFO:SubProcess create_model() end ==================================
2024-11-14 10:15:06,920:INFO:Creating metrics dataframe
2024-11-14 10:15:06,935:INFO:Initializing Dummy Regressor
2024-11-14 10:15:06,935:INFO:Total runtime is 7.4385095000267025 minutes
2024-11-14 10:15:06,938:INFO:SubProcess create_model() called ==================================
2024-11-14 10:15:06,939:INFO:Initializing create_model()
2024-11-14 10:15:06,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75706167c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:15:06,939:INFO:Checking exceptions
2024-11-14 10:15:06,939:INFO:Importing libraries
2024-11-14 10:15:06,940:INFO:Copying training dataset
2024-11-14 10:15:06,949:INFO:Defining folds
2024-11-14 10:15:06,949:INFO:Declaring metric variables
2024-11-14 10:15:06,953:INFO:Importing untrained model
2024-11-14 10:15:06,956:INFO:Dummy Regressor Imported successfully
2024-11-14 10:15:06,963:INFO:Starting cross validation
2024-11-14 10:15:06,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:15:07,019:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-11-14 10:15:10,361:INFO:Calculating mean and std
2024-11-14 10:15:10,367:INFO:Creating metrics dataframe
2024-11-14 10:15:10,374:INFO:Uploading results into container
2024-11-14 10:15:10,375:INFO:Uploading model into container now
2024-11-14 10:15:10,375:INFO:_master_model_container: 20
2024-11-14 10:15:10,376:INFO:_display_container: 2
2024-11-14 10:15:10,376:INFO:DummyRegressor()
2024-11-14 10:15:10,376:INFO:create_model() successfully completed......................................
2024-11-14 10:15:10,582:INFO:SubProcess create_model() end ==================================
2024-11-14 10:15:10,582:INFO:Creating metrics dataframe
2024-11-14 10:15:10,607:INFO:Initializing create_model()
2024-11-14 10:15:10,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:15:10,607:INFO:Checking exceptions
2024-11-14 10:15:10,609:INFO:Importing libraries
2024-11-14 10:15:10,609:INFO:Copying training dataset
2024-11-14 10:15:10,615:INFO:Defining folds
2024-11-14 10:15:10,615:INFO:Declaring metric variables
2024-11-14 10:15:10,615:INFO:Importing untrained model
2024-11-14 10:15:10,615:INFO:Declaring custom model
2024-11-14 10:15:10,616:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:15:10,617:INFO:Cross validation set to False
2024-11-14 10:15:10,617:INFO:Fitting Model
2024-11-14 10:15:10,873:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:15:10,873:INFO:create_model() successfully completed......................................
2024-11-14 10:15:11,220:INFO:_master_model_container: 20
2024-11-14 10:15:11,221:INFO:_display_container: 2
2024-11-14 10:15:11,221:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:15:11,221:INFO:compare_models() successfully completed......................................
2024-11-14 10:15:18,940:INFO:Initializing create_model()
2024-11-14 10:15:18,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:15:18,941:INFO:Checking exceptions
2024-11-14 10:15:18,979:INFO:Importing libraries
2024-11-14 10:15:18,979:INFO:Copying training dataset
2024-11-14 10:15:18,991:INFO:Defining folds
2024-11-14 10:15:18,991:INFO:Declaring metric variables
2024-11-14 10:15:18,995:INFO:Importing untrained model
2024-11-14 10:15:18,999:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:15:19,006:INFO:Starting cross validation
2024-11-14 10:15:19,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:15:22,712:INFO:Calculating mean and std
2024-11-14 10:15:22,717:INFO:Creating metrics dataframe
2024-11-14 10:15:22,727:INFO:Finalizing model
2024-11-14 10:15:22,985:INFO:Uploading results into container
2024-11-14 10:15:22,986:INFO:Uploading model into container now
2024-11-14 10:15:23,003:INFO:_master_model_container: 21
2024-11-14 10:15:23,003:INFO:_display_container: 3
2024-11-14 10:15:23,004:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:15:23,004:INFO:create_model() successfully completed......................................
2024-11-14 10:18:39,780:INFO:Initializing create_model()
2024-11-14 10:18:39,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:18:39,780:INFO:Checking exceptions
2024-11-14 10:18:39,823:INFO:Importing libraries
2024-11-14 10:18:39,824:INFO:Copying training dataset
2024-11-14 10:18:39,833:INFO:Defining folds
2024-11-14 10:18:39,834:INFO:Declaring metric variables
2024-11-14 10:18:39,838:INFO:Importing untrained model
2024-11-14 10:18:39,842:INFO:Random Forest Regressor Imported successfully
2024-11-14 10:18:39,850:INFO:Starting cross validation
2024-11-14 10:18:39,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:18:43,997:INFO:Calculating mean and std
2024-11-14 10:18:44,000:INFO:Creating metrics dataframe
2024-11-14 10:18:44,009:INFO:Finalizing model
2024-11-14 10:18:44,400:INFO:Uploading results into container
2024-11-14 10:18:44,401:INFO:Uploading model into container now
2024-11-14 10:18:44,411:INFO:_master_model_container: 22
2024-11-14 10:18:44,411:INFO:_display_container: 4
2024-11-14 10:18:44,411:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:18:44,411:INFO:create_model() successfully completed......................................
2024-11-14 10:21:50,328:INFO:Initializing tune_model()
2024-11-14 10:21:50,328:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>)
2024-11-14 10:21:50,329:INFO:Checking exceptions
2024-11-14 10:21:50,368:INFO:Copying training dataset
2024-11-14 10:21:50,374:INFO:Checking base model
2024-11-14 10:21:50,375:INFO:Base model : Random Forest Regressor
2024-11-14 10:21:50,379:INFO:Declaring metric variables
2024-11-14 10:21:50,382:INFO:Defining Hyperparameters
2024-11-14 10:21:50,596:INFO:Tuning with n_jobs=-1
2024-11-14 10:21:50,596:INFO:Initializing RandomizedSearchCV
2024-11-14 10:22:05,823:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:05,824:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:05,834:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:05,869:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:05,875:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:05,887:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:05,954:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:05,964:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:06,075:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:06,449:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:06,545:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:06,804:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:06,820:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:06,898:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:22:06,967:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:25:06,172:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-11-14 10:25:06,177:INFO:Hyperparameter search completed
2024-11-14 10:25:06,178:INFO:SubProcess create_model() called ==================================
2024-11-14 10:25:06,178:INFO:Initializing create_model()
2024-11-14 10:25:06,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f772afccb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'squared_error', 'bootstrap': False})
2024-11-14 10:25:06,179:INFO:Checking exceptions
2024-11-14 10:25:06,179:INFO:Importing libraries
2024-11-14 10:25:06,179:INFO:Copying training dataset
2024-11-14 10:25:06,187:INFO:Defining folds
2024-11-14 10:25:06,187:INFO:Declaring metric variables
2024-11-14 10:25:06,191:INFO:Importing untrained model
2024-11-14 10:25:06,191:INFO:Declaring custom model
2024-11-14 10:25:06,195:INFO:Random Forest Regressor Imported successfully
2024-11-14 10:25:06,201:INFO:Starting cross validation
2024-11-14 10:25:06,202:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:25:07,905:INFO:Calculating mean and std
2024-11-14 10:25:07,915:INFO:Creating metrics dataframe
2024-11-14 10:25:07,925:INFO:Finalizing model
2024-11-14 10:25:08,344:INFO:Uploading results into container
2024-11-14 10:25:08,345:INFO:Uploading model into container now
2024-11-14 10:25:08,346:INFO:_master_model_container: 23
2024-11-14 10:25:08,346:INFO:_display_container: 5
2024-11-14 10:25:08,347:INFO:RandomForestRegressor(bootstrap=False, max_depth=11, max_features='sqrt',
                      min_impurity_decrease=0.0002, min_samples_leaf=5,
                      min_samples_split=7, n_estimators=200, n_jobs=-1,
                      random_state=123)
2024-11-14 10:25:08,347:INFO:create_model() successfully completed......................................
2024-11-14 10:25:08,599:INFO:SubProcess create_model() end ==================================
2024-11-14 10:25:08,600:INFO:choose_better activated
2024-11-14 10:25:08,604:INFO:SubProcess create_model() called ==================================
2024-11-14 10:25:08,605:INFO:Initializing create_model()
2024-11-14 10:25:08,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:25:08,605:INFO:Checking exceptions
2024-11-14 10:25:08,607:INFO:Importing libraries
2024-11-14 10:25:08,607:INFO:Copying training dataset
2024-11-14 10:25:08,614:INFO:Defining folds
2024-11-14 10:25:08,614:INFO:Declaring metric variables
2024-11-14 10:25:08,614:INFO:Importing untrained model
2024-11-14 10:25:08,614:INFO:Declaring custom model
2024-11-14 10:25:08,615:INFO:Random Forest Regressor Imported successfully
2024-11-14 10:25:08,615:INFO:Starting cross validation
2024-11-14 10:25:08,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:25:10,253:INFO:Calculating mean and std
2024-11-14 10:25:10,254:INFO:Creating metrics dataframe
2024-11-14 10:25:10,258:INFO:Finalizing model
2024-11-14 10:25:10,627:INFO:Uploading results into container
2024-11-14 10:25:10,628:INFO:Uploading model into container now
2024-11-14 10:25:10,628:INFO:_master_model_container: 24
2024-11-14 10:25:10,628:INFO:_display_container: 6
2024-11-14 10:25:10,629:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:25:10,629:INFO:create_model() successfully completed......................................
2024-11-14 10:25:10,800:INFO:SubProcess create_model() end ==================================
2024-11-14 10:25:10,801:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for R2 is 0.973
2024-11-14 10:25:10,802:INFO:RandomForestRegressor(bootstrap=False, max_depth=11, max_features='sqrt',
                      min_impurity_decrease=0.0002, min_samples_leaf=5,
                      min_samples_split=7, n_estimators=200, n_jobs=-1,
                      random_state=123) result for R2 is 0.8686
2024-11-14 10:25:10,802:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) is best model
2024-11-14 10:25:10,802:INFO:choose_better completed
2024-11-14 10:25:10,802:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-11-14 10:25:10,813:INFO:_master_model_container: 24
2024-11-14 10:25:10,813:INFO:_display_container: 5
2024-11-14 10:25:10,814:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:25:10,814:INFO:tune_model() successfully completed......................................
2024-11-14 10:28:26,972:INFO:Initializing create_model()
2024-11-14 10:28:26,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:28:26,973:INFO:Checking exceptions
2024-11-14 10:28:27,006:INFO:Importing libraries
2024-11-14 10:28:27,006:INFO:Copying training dataset
2024-11-14 10:28:27,015:INFO:Defining folds
2024-11-14 10:28:27,015:INFO:Declaring metric variables
2024-11-14 10:28:27,019:INFO:Importing untrained model
2024-11-14 10:28:27,023:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:28:27,030:INFO:Starting cross validation
2024-11-14 10:28:27,031:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:28:28,499:INFO:Calculating mean and std
2024-11-14 10:28:28,505:INFO:Creating metrics dataframe
2024-11-14 10:28:28,514:INFO:Finalizing model
2024-11-14 10:28:28,789:INFO:Uploading results into container
2024-11-14 10:28:28,789:INFO:Uploading model into container now
2024-11-14 10:28:28,803:INFO:_master_model_container: 25
2024-11-14 10:28:28,803:INFO:_display_container: 6
2024-11-14 10:28:28,803:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:28:28,804:INFO:create_model() successfully completed......................................
2024-11-14 10:32:11,703:INFO:Initializing create_model()
2024-11-14 10:32:11,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772ac80460>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:32:11,704:INFO:Checking exceptions
2024-11-14 10:32:11,748:INFO:Importing libraries
2024-11-14 10:32:11,748:INFO:Copying training dataset
2024-11-14 10:32:11,757:INFO:Defining folds
2024-11-14 10:32:11,757:INFO:Declaring metric variables
2024-11-14 10:32:11,761:INFO:Importing untrained model
2024-11-14 10:32:11,766:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:32:11,774:INFO:Starting cross validation
2024-11-14 10:32:11,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:32:16,327:INFO:Calculating mean and std
2024-11-14 10:32:16,332:INFO:Creating metrics dataframe
2024-11-14 10:32:16,345:INFO:Finalizing model
2024-11-14 10:32:16,593:INFO:Uploading results into container
2024-11-14 10:32:16,594:INFO:Uploading model into container now
2024-11-14 10:32:16,606:INFO:_master_model_container: 26
2024-11-14 10:32:16,606:INFO:_display_container: 7
2024-11-14 10:32:16,606:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:32:16,606:INFO:create_model() successfully completed......................................
2024-11-14 10:42:47,164:INFO:PyCaret RegressionExperiment
2024-11-14 10:42:47,164:INFO:Logging name: reg-default-name
2024-11-14 10:42:47,165:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 10:42:47,165:INFO:version 3.2.0
2024-11-14 10:42:47,165:INFO:Initializing setup()
2024-11-14 10:42:47,165:INFO:self.USI: d027
2024-11-14 10:42:47,165:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'y', 'fold_generator', 'X_test', '_ml_usecase', 'gpu_n_jobs_param', 'memory', 'data', 'fold_groups_param', 'X', 'transform_target_param', 'target_param', 'y_test', 'X_train', 'seed', 'pipeline', 'html_param', 'exp_name_log', 'USI', 'log_plots_param', 'gpu_param', 'n_jobs_param', 'exp_id', '_available_plots', 'logging_param', 'y_train'}
2024-11-14 10:42:47,165:INFO:Checking environment
2024-11-14 10:42:47,165:INFO:python_version: 3.8.13
2024-11-14 10:42:47,165:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 10:42:47,165:INFO:machine: x86_64
2024-11-14 10:42:47,165:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 10:42:47,166:INFO:Memory: svmem(total=270355722240, available=221224370176, percent=18.2, used=47041380352, free=74079727616, active=71775244288, inactive=64177369088, buffers=10100736, cached=149224513536, shared=195850240, slab=25238470656)
2024-11-14 10:42:47,171:INFO:Physical Core: 28
2024-11-14 10:42:47,172:INFO:Logical Core: 56
2024-11-14 10:42:47,172:INFO:Checking libraries
2024-11-14 10:42:47,172:INFO:System:
2024-11-14 10:42:47,172:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 10:42:47,172:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 10:42:47,172:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 10:42:47,172:INFO:PyCaret required dependencies:
2024-11-14 10:42:47,172:INFO:                 pip: 22.2.2
2024-11-14 10:42:47,172:INFO:          setuptools: 63.4.2
2024-11-14 10:42:47,172:INFO:             pycaret: 3.2.0
2024-11-14 10:42:47,173:INFO:             IPython: 8.12.2
2024-11-14 10:42:47,173:INFO:          ipywidgets: 7.7.1
2024-11-14 10:42:47,173:INFO:                tqdm: 4.64.1
2024-11-14 10:42:47,173:INFO:               numpy: 1.23.5
2024-11-14 10:42:47,173:INFO:              pandas: 1.5.3
2024-11-14 10:42:47,173:INFO:              jinja2: 3.1.2
2024-11-14 10:42:47,173:INFO:               scipy: 1.10.1
2024-11-14 10:42:47,173:INFO:              joblib: 1.3.0
2024-11-14 10:42:47,173:INFO:             sklearn: 1.1.2
2024-11-14 10:42:47,173:INFO:                pyod: 2.0.2
2024-11-14 10:42:47,173:INFO:            imblearn: 0.12.4
2024-11-14 10:42:47,173:INFO:   category_encoders: 2.6.4
2024-11-14 10:42:47,173:INFO:            lightgbm: 4.5.0
2024-11-14 10:42:47,173:INFO:               numba: 0.57.1
2024-11-14 10:42:47,173:INFO:            requests: 2.28.1
2024-11-14 10:42:47,173:INFO:          matplotlib: 3.5.1
2024-11-14 10:42:47,173:INFO:          scikitplot: 0.3.7
2024-11-14 10:42:47,174:INFO:         yellowbrick: 1.5
2024-11-14 10:42:47,174:INFO:              plotly: 5.24.1
2024-11-14 10:42:47,174:INFO:    plotly-resampler: Not installed
2024-11-14 10:42:47,174:INFO:             kaleido: 0.2.1
2024-11-14 10:42:47,174:INFO:           schemdraw: 0.15
2024-11-14 10:42:47,174:INFO:         statsmodels: 0.13.2
2024-11-14 10:42:47,174:INFO:              sktime: 0.21.1
2024-11-14 10:42:47,174:INFO:               tbats: 1.1.3
2024-11-14 10:42:47,174:INFO:            pmdarima: 2.0.4
2024-11-14 10:42:47,174:INFO:              psutil: 5.9.1
2024-11-14 10:42:47,174:INFO:          markupsafe: 2.1.1
2024-11-14 10:42:47,174:INFO:             pickle5: Not installed
2024-11-14 10:42:47,174:INFO:         cloudpickle: 2.1.0
2024-11-14 10:42:47,174:INFO:         deprecation: 2.1.0
2024-11-14 10:42:47,174:INFO:              xxhash: 3.5.0
2024-11-14 10:42:47,174:INFO:           wurlitzer: 3.1.1
2024-11-14 10:42:47,175:INFO:PyCaret optional dependencies:
2024-11-14 10:42:47,175:INFO:                shap: 0.44.1
2024-11-14 10:42:47,175:INFO:           interpret: 0.6.5
2024-11-14 10:42:47,175:INFO:                umap: 0.5.7
2024-11-14 10:42:47,175:INFO:     ydata_profiling: 4.6.0
2024-11-14 10:42:47,175:INFO:  explainerdashboard: 0.4.7
2024-11-14 10:42:47,175:INFO:             autoviz: Not installed
2024-11-14 10:42:47,175:INFO:           fairlearn: 0.7.0
2024-11-14 10:42:47,175:INFO:          deepchecks: Not installed
2024-11-14 10:42:47,175:INFO:             xgboost: 2.1.1
2024-11-14 10:42:47,175:INFO:            catboost: 1.2.7
2024-11-14 10:42:47,175:INFO:              kmodes: 0.12.2
2024-11-14 10:42:47,175:INFO:             mlxtend: 0.23.1
2024-11-14 10:42:47,175:INFO:       statsforecast: 1.5.0
2024-11-14 10:42:47,175:INFO:        tune_sklearn: 0.5.0
2024-11-14 10:42:47,175:INFO:                 ray: 2.10.0
2024-11-14 10:42:47,176:INFO:            hyperopt: 0.2.7
2024-11-14 10:42:47,176:INFO:              optuna: 4.1.0
2024-11-14 10:42:47,176:INFO:               skopt: 0.10.2
2024-11-14 10:42:47,176:INFO:              mlflow: 1.30.1
2024-11-14 10:42:47,176:INFO:              gradio: 3.50.2
2024-11-14 10:42:47,176:INFO:             fastapi: 0.115.5
2024-11-14 10:42:47,176:INFO:             uvicorn: 0.32.0
2024-11-14 10:42:47,176:INFO:              m2cgen: 0.10.0
2024-11-14 10:42:47,176:INFO:           evidently: 0.2.8
2024-11-14 10:42:47,176:INFO:               fugue: 0.8.6
2024-11-14 10:42:47,176:INFO:           streamlit: Not installed
2024-11-14 10:42:47,176:INFO:             prophet: Not installed
2024-11-14 10:42:47,176:INFO:None
2024-11-14 10:42:47,176:INFO:Set up data.
2024-11-14 10:42:47,186:INFO:Set up folding strategy.
2024-11-14 10:42:47,187:INFO:Set up train/test split.
2024-11-14 10:42:47,193:INFO:Set up index.
2024-11-14 10:42:47,194:INFO:Assigning column types.
2024-11-14 10:42:47,199:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 10:42:47,199:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,205:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,211:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,324:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,325:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:47,328:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:47,329:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,333:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,338:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,392:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,435:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:47,438:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:47,438:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 10:42:47,442:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,447:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,518:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,567:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,568:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:47,571:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:47,578:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,583:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,639:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,676:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,676:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:47,679:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:47,679:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 10:42:47,687:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,775:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:47,779:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:47,787:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,875:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:47,878:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:47,878:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 10:42:47,935:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,972:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:42:47,973:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:47,975:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:48,033:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:42:48,070:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:42:48,071:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:48,073:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:48,074:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 10:42:48,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:42:48,169:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:48,171:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:48,229:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:42:48,272:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:48,275:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:48,275:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 10:42:48,370:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:48,372:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:48,468:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:48,471:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:48,472:INFO:Preparing preprocessing pipeline...
2024-11-14 10:42:48,472:INFO:Set up simple imputation.
2024-11-14 10:42:48,491:INFO:Finished creating preprocessing pipeline.
2024-11-14 10:42:48,495:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 10:42:48,495:INFO:Creating final display dataframe.
2024-11-14 10:42:48,553:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d027
2024-11-14 10:42:48,647:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:48,650:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:48,742:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:42:48,745:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:42:48,746:INFO:setup() successfully completed in 1.58s...............
2024-11-14 10:42:48,752:INFO:Initializing compare_models()
2024-11-14 10:42:48,752:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772a601940>, include=['et', 'rf', 'dt', 'knn', 'catboost', 'lightgbm'], fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f772a601940>, 'include': ['et', 'rf', 'dt', 'knn', 'catboost', 'lightgbm'], 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 10:42:48,752:INFO:Checking exceptions
2024-11-14 10:42:48,755:INFO:Preparing display monitor
2024-11-14 10:42:48,792:INFO:Initializing Extra Trees Regressor
2024-11-14 10:42:48,792:INFO:Total runtime is 1.8676122029622395e-06 minutes
2024-11-14 10:42:48,796:INFO:SubProcess create_model() called ==================================
2024-11-14 10:42:48,796:INFO:Initializing create_model()
2024-11-14 10:42:48,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772a601940>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f773c288c10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:42:48,796:INFO:Checking exceptions
2024-11-14 10:42:48,796:INFO:Importing libraries
2024-11-14 10:42:48,796:INFO:Copying training dataset
2024-11-14 10:42:48,802:INFO:Defining folds
2024-11-14 10:42:48,802:INFO:Declaring metric variables
2024-11-14 10:42:48,805:INFO:Importing untrained model
2024-11-14 10:42:48,809:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:42:48,815:INFO:Starting cross validation
2024-11-14 10:42:48,816:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:42:53,818:INFO:Calculating mean and std
2024-11-14 10:42:53,823:INFO:Creating metrics dataframe
2024-11-14 10:42:53,830:INFO:Uploading results into container
2024-11-14 10:42:53,831:INFO:Uploading model into container now
2024-11-14 10:42:53,831:INFO:_master_model_container: 1
2024-11-14 10:42:53,831:INFO:_display_container: 2
2024-11-14 10:42:53,832:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:42:53,832:INFO:create_model() successfully completed......................................
2024-11-14 10:42:54,081:INFO:SubProcess create_model() end ==================================
2024-11-14 10:42:54,081:INFO:Creating metrics dataframe
2024-11-14 10:42:54,091:INFO:Initializing Random Forest Regressor
2024-11-14 10:42:54,091:INFO:Total runtime is 0.0883111556371053 minutes
2024-11-14 10:42:54,094:INFO:SubProcess create_model() called ==================================
2024-11-14 10:42:54,095:INFO:Initializing create_model()
2024-11-14 10:42:54,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772a601940>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f773c288c10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:42:54,095:INFO:Checking exceptions
2024-11-14 10:42:54,095:INFO:Importing libraries
2024-11-14 10:42:54,095:INFO:Copying training dataset
2024-11-14 10:42:54,102:INFO:Defining folds
2024-11-14 10:42:54,103:INFO:Declaring metric variables
2024-11-14 10:42:54,106:INFO:Importing untrained model
2024-11-14 10:42:54,109:INFO:Random Forest Regressor Imported successfully
2024-11-14 10:42:54,116:INFO:Starting cross validation
2024-11-14 10:42:54,117:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:42:57,552:INFO:Calculating mean and std
2024-11-14 10:42:57,555:INFO:Creating metrics dataframe
2024-11-14 10:42:57,562:INFO:Uploading results into container
2024-11-14 10:42:57,563:INFO:Uploading model into container now
2024-11-14 10:42:57,564:INFO:_master_model_container: 2
2024-11-14 10:42:57,564:INFO:_display_container: 2
2024-11-14 10:42:57,564:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:42:57,565:INFO:create_model() successfully completed......................................
2024-11-14 10:42:57,820:INFO:SubProcess create_model() end ==================================
2024-11-14 10:42:57,820:INFO:Creating metrics dataframe
2024-11-14 10:42:57,832:INFO:Initializing Decision Tree Regressor
2024-11-14 10:42:57,832:INFO:Total runtime is 0.15066770712534586 minutes
2024-11-14 10:42:57,836:INFO:SubProcess create_model() called ==================================
2024-11-14 10:42:57,836:INFO:Initializing create_model()
2024-11-14 10:42:57,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772a601940>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f773c288c10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:42:57,837:INFO:Checking exceptions
2024-11-14 10:42:57,837:INFO:Importing libraries
2024-11-14 10:42:57,837:INFO:Copying training dataset
2024-11-14 10:42:57,845:INFO:Defining folds
2024-11-14 10:42:57,845:INFO:Declaring metric variables
2024-11-14 10:42:57,849:INFO:Importing untrained model
2024-11-14 10:42:57,853:INFO:Decision Tree Regressor Imported successfully
2024-11-14 10:42:57,867:INFO:Starting cross validation
2024-11-14 10:42:57,868:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:43:00,642:INFO:Calculating mean and std
2024-11-14 10:43:00,645:INFO:Creating metrics dataframe
2024-11-14 10:43:00,651:INFO:Uploading results into container
2024-11-14 10:43:00,652:INFO:Uploading model into container now
2024-11-14 10:43:00,653:INFO:_master_model_container: 3
2024-11-14 10:43:00,653:INFO:_display_container: 2
2024-11-14 10:43:00,654:INFO:DecisionTreeRegressor(random_state=123)
2024-11-14 10:43:00,654:INFO:create_model() successfully completed......................................
2024-11-14 10:43:00,875:INFO:SubProcess create_model() end ==================================
2024-11-14 10:43:00,875:INFO:Creating metrics dataframe
2024-11-14 10:43:00,885:INFO:Initializing K Neighbors Regressor
2024-11-14 10:43:00,886:INFO:Total runtime is 0.20155382951100667 minutes
2024-11-14 10:43:00,889:INFO:SubProcess create_model() called ==================================
2024-11-14 10:43:00,889:INFO:Initializing create_model()
2024-11-14 10:43:00,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772a601940>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f773c288c10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:43:00,889:INFO:Checking exceptions
2024-11-14 10:43:00,889:INFO:Importing libraries
2024-11-14 10:43:00,890:INFO:Copying training dataset
2024-11-14 10:43:00,896:INFO:Defining folds
2024-11-14 10:43:00,897:INFO:Declaring metric variables
2024-11-14 10:43:00,900:INFO:Importing untrained model
2024-11-14 10:43:00,903:INFO:K Neighbors Regressor Imported successfully
2024-11-14 10:43:00,909:INFO:Starting cross validation
2024-11-14 10:43:00,910:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:43:03,674:INFO:Calculating mean and std
2024-11-14 10:43:03,677:INFO:Creating metrics dataframe
2024-11-14 10:43:03,687:INFO:Uploading results into container
2024-11-14 10:43:03,688:INFO:Uploading model into container now
2024-11-14 10:43:03,689:INFO:_master_model_container: 4
2024-11-14 10:43:03,689:INFO:_display_container: 2
2024-11-14 10:43:03,689:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 10:43:03,690:INFO:create_model() successfully completed......................................
2024-11-14 10:43:03,897:INFO:SubProcess create_model() end ==================================
2024-11-14 10:43:03,897:INFO:Creating metrics dataframe
2024-11-14 10:43:03,910:INFO:Initializing CatBoost Regressor
2024-11-14 10:43:03,911:INFO:Total runtime is 0.25197031497955324 minutes
2024-11-14 10:43:03,914:INFO:SubProcess create_model() called ==================================
2024-11-14 10:43:03,915:INFO:Initializing create_model()
2024-11-14 10:43:03,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772a601940>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f773c288c10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:43:03,915:INFO:Checking exceptions
2024-11-14 10:43:03,915:INFO:Importing libraries
2024-11-14 10:43:03,915:INFO:Copying training dataset
2024-11-14 10:43:03,925:INFO:Defining folds
2024-11-14 10:43:03,925:INFO:Declaring metric variables
2024-11-14 10:43:03,929:INFO:Importing untrained model
2024-11-14 10:43:03,933:INFO:CatBoost Regressor Imported successfully
2024-11-14 10:43:03,941:INFO:Starting cross validation
2024-11-14 10:43:03,942:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:43:13,506:INFO:Calculating mean and std
2024-11-14 10:43:13,509:INFO:Creating metrics dataframe
2024-11-14 10:43:13,516:INFO:Uploading results into container
2024-11-14 10:43:13,517:INFO:Uploading model into container now
2024-11-14 10:43:13,517:INFO:_master_model_container: 5
2024-11-14 10:43:13,517:INFO:_display_container: 2
2024-11-14 10:43:13,518:INFO:<catboost.core.CatBoostRegressor object at 0x7f772a867670>
2024-11-14 10:43:13,518:INFO:create_model() successfully completed......................................
2024-11-14 10:43:13,738:INFO:SubProcess create_model() end ==================================
2024-11-14 10:43:13,739:INFO:Creating metrics dataframe
2024-11-14 10:43:13,749:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 10:43:13,749:INFO:Total runtime is 0.41595301230748494 minutes
2024-11-14 10:43:13,753:INFO:SubProcess create_model() called ==================================
2024-11-14 10:43:13,753:INFO:Initializing create_model()
2024-11-14 10:43:13,753:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772a601940>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f773c288c10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:43:13,754:INFO:Checking exceptions
2024-11-14 10:43:13,754:INFO:Importing libraries
2024-11-14 10:43:13,754:INFO:Copying training dataset
2024-11-14 10:43:13,761:INFO:Defining folds
2024-11-14 10:43:13,761:INFO:Declaring metric variables
2024-11-14 10:43:13,765:INFO:Importing untrained model
2024-11-14 10:43:13,768:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 10:43:13,775:INFO:Starting cross validation
2024-11-14 10:43:13,776:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:46:43,628:INFO:Calculating mean and std
2024-11-14 10:46:43,631:INFO:Creating metrics dataframe
2024-11-14 10:46:43,637:INFO:Uploading results into container
2024-11-14 10:46:43,638:INFO:Uploading model into container now
2024-11-14 10:46:43,639:INFO:_master_model_container: 6
2024-11-14 10:46:43,639:INFO:_display_container: 2
2024-11-14 10:46:43,640:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:46:43,640:INFO:create_model() successfully completed......................................
2024-11-14 10:46:43,846:INFO:SubProcess create_model() end ==================================
2024-11-14 10:46:43,846:INFO:Creating metrics dataframe
2024-11-14 10:46:43,867:INFO:Initializing create_model()
2024-11-14 10:46:43,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772a601940>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:46:43,867:INFO:Checking exceptions
2024-11-14 10:46:43,869:INFO:Importing libraries
2024-11-14 10:46:43,869:INFO:Copying training dataset
2024-11-14 10:46:43,876:INFO:Defining folds
2024-11-14 10:46:43,876:INFO:Declaring metric variables
2024-11-14 10:46:43,876:INFO:Importing untrained model
2024-11-14 10:46:43,876:INFO:Declaring custom model
2024-11-14 10:46:43,877:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:46:43,878:INFO:Cross validation set to False
2024-11-14 10:46:43,878:INFO:Fitting Model
2024-11-14 10:46:44,118:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:46:44,119:INFO:create_model() successfully completed......................................
2024-11-14 10:46:44,379:INFO:_master_model_container: 6
2024-11-14 10:46:44,379:INFO:_display_container: 2
2024-11-14 10:46:44,380:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:46:44,380:INFO:compare_models() successfully completed......................................
2024-11-14 10:48:16,591:INFO:Initializing tune_model()
2024-11-14 10:48:16,592:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f772a601940>)
2024-11-14 10:48:16,592:INFO:Checking exceptions
2024-11-14 10:48:16,628:INFO:Copying training dataset
2024-11-14 10:48:16,633:INFO:Checking base model
2024-11-14 10:48:16,633:INFO:Base model : Extra Trees Regressor
2024-11-14 10:48:16,636:INFO:Declaring metric variables
2024-11-14 10:48:16,640:INFO:Defining Hyperparameters
2024-11-14 10:48:16,823:INFO:Tuning with n_jobs=-1
2024-11-14 10:48:16,823:INFO:Initializing RandomizedSearchCV
2024-11-14 10:48:29,261:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,282:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,291:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,389:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,424:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,434:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,434:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,441:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,443:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,462:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,579:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,684:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,685:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,688:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,688:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,697:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,760:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,780:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:48:29,945:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 10:49:42,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-14 10:49:42,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-14 10:49:42,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-14 10:49:42,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-14 10:49:43,267:INFO:PyCaret RegressionExperiment
2024-11-14 10:49:43,267:INFO:Logging name: reg-default-name
2024-11-14 10:49:43,267:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 10:49:43,267:INFO:version 3.2.0
2024-11-14 10:49:43,268:INFO:Initializing setup()
2024-11-14 10:49:43,268:INFO:self.USI: 0a04
2024-11-14 10:49:43,268:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 10:49:43,268:INFO:Checking environment
2024-11-14 10:49:43,268:INFO:python_version: 3.8.13
2024-11-14 10:49:43,268:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 10:49:43,268:INFO:machine: x86_64
2024-11-14 10:49:43,300:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 10:49:43,300:INFO:Memory: svmem(total=270355722240, available=222516785152, percent=17.7, used=45748948992, free=75270758400, active=71781896192, inactive=62944530432, buffers=10100736, cached=149325914112, shared=195821568, slab=25251028992)
2024-11-14 10:49:43,302:INFO:Physical Core: 28
2024-11-14 10:49:43,302:INFO:Logical Core: 56
2024-11-14 10:49:43,302:INFO:Checking libraries
2024-11-14 10:49:43,302:INFO:System:
2024-11-14 10:49:43,302:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 10:49:43,302:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 10:49:43,302:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 10:49:43,302:INFO:PyCaret required dependencies:
2024-11-14 10:49:43,449:INFO:                 pip: 22.2.2
2024-11-14 10:49:43,449:INFO:          setuptools: 63.4.2
2024-11-14 10:49:43,449:INFO:             pycaret: 3.2.0
2024-11-14 10:49:43,449:INFO:             IPython: 8.12.2
2024-11-14 10:49:43,449:INFO:          ipywidgets: 7.7.1
2024-11-14 10:49:43,449:INFO:                tqdm: 4.64.1
2024-11-14 10:49:43,449:INFO:               numpy: 1.23.5
2024-11-14 10:49:43,449:INFO:              pandas: 1.5.3
2024-11-14 10:49:43,449:INFO:              jinja2: 3.1.2
2024-11-14 10:49:43,449:INFO:               scipy: 1.10.1
2024-11-14 10:49:43,449:INFO:              joblib: 1.3.0
2024-11-14 10:49:43,449:INFO:             sklearn: 1.1.2
2024-11-14 10:49:43,449:INFO:                pyod: 2.0.2
2024-11-14 10:49:43,449:INFO:            imblearn: 0.12.4
2024-11-14 10:49:43,450:INFO:   category_encoders: 2.6.4
2024-11-14 10:49:43,450:INFO:            lightgbm: 4.5.0
2024-11-14 10:49:43,450:INFO:               numba: 0.57.1
2024-11-14 10:49:43,450:INFO:            requests: 2.28.1
2024-11-14 10:49:43,450:INFO:          matplotlib: 3.5.1
2024-11-14 10:49:43,450:INFO:          scikitplot: 0.3.7
2024-11-14 10:49:43,450:INFO:         yellowbrick: 1.5
2024-11-14 10:49:43,450:INFO:              plotly: 5.24.1
2024-11-14 10:49:43,450:INFO:    plotly-resampler: Not installed
2024-11-14 10:49:43,450:INFO:             kaleido: 0.2.1
2024-11-14 10:49:43,450:INFO:           schemdraw: 0.15
2024-11-14 10:49:43,450:INFO:         statsmodels: 0.13.2
2024-11-14 10:49:43,450:INFO:              sktime: 0.21.1
2024-11-14 10:49:43,450:INFO:               tbats: 1.1.3
2024-11-14 10:49:43,450:INFO:            pmdarima: 2.0.4
2024-11-14 10:49:43,450:INFO:              psutil: 5.9.1
2024-11-14 10:49:43,450:INFO:          markupsafe: 2.1.1
2024-11-14 10:49:43,450:INFO:             pickle5: Not installed
2024-11-14 10:49:43,450:INFO:         cloudpickle: 2.1.0
2024-11-14 10:49:43,450:INFO:         deprecation: 2.1.0
2024-11-14 10:49:43,450:INFO:              xxhash: 3.5.0
2024-11-14 10:49:43,450:INFO:           wurlitzer: 3.1.1
2024-11-14 10:49:43,450:INFO:PyCaret optional dependencies:
2024-11-14 10:49:44,408:INFO:                shap: 0.44.1
2024-11-14 10:49:44,408:INFO:           interpret: 0.6.5
2024-11-14 10:49:44,408:INFO:                umap: 0.5.7
2024-11-14 10:49:44,408:INFO:     ydata_profiling: 4.6.0
2024-11-14 10:49:44,408:INFO:  explainerdashboard: 0.4.7
2024-11-14 10:49:44,408:INFO:             autoviz: Not installed
2024-11-14 10:49:44,408:INFO:           fairlearn: 0.7.0
2024-11-14 10:49:44,408:INFO:          deepchecks: Not installed
2024-11-14 10:49:44,408:INFO:             xgboost: 2.1.1
2024-11-14 10:49:44,408:INFO:            catboost: 1.2.7
2024-11-14 10:49:44,408:INFO:              kmodes: 0.12.2
2024-11-14 10:49:44,408:INFO:             mlxtend: 0.23.1
2024-11-14 10:49:44,408:INFO:       statsforecast: 1.5.0
2024-11-14 10:49:44,409:INFO:        tune_sklearn: 0.5.0
2024-11-14 10:49:44,409:INFO:                 ray: 2.10.0
2024-11-14 10:49:44,409:INFO:            hyperopt: 0.2.7
2024-11-14 10:49:44,409:INFO:              optuna: 4.1.0
2024-11-14 10:49:44,409:INFO:               skopt: 0.10.2
2024-11-14 10:49:44,409:INFO:              mlflow: 1.30.1
2024-11-14 10:49:44,409:INFO:              gradio: 3.50.2
2024-11-14 10:49:44,409:INFO:             fastapi: 0.115.5
2024-11-14 10:49:44,409:INFO:             uvicorn: 0.32.0
2024-11-14 10:49:44,409:INFO:              m2cgen: 0.10.0
2024-11-14 10:49:44,409:INFO:           evidently: 0.2.8
2024-11-14 10:49:44,409:INFO:               fugue: 0.8.6
2024-11-14 10:49:44,409:INFO:           streamlit: Not installed
2024-11-14 10:49:44,409:INFO:             prophet: Not installed
2024-11-14 10:49:44,409:INFO:None
2024-11-14 10:49:44,409:INFO:Set up data.
2024-11-14 10:49:44,419:INFO:Set up folding strategy.
2024-11-14 10:49:44,419:INFO:Set up train/test split.
2024-11-14 10:49:44,424:INFO:Set up index.
2024-11-14 10:49:44,425:INFO:Assigning column types.
2024-11-14 10:49:44,429:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 10:49:44,429:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,433:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,437:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,488:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,527:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:44,529:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:44,541:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,545:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,549:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,637:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,638:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:44,640:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:44,640:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 10:49:44,644:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,648:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,737:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:44,739:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:44,744:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,748:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,798:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,837:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:44,839:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:44,839:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 10:49:44,847:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,898:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,938:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:44,940:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:44,948:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 10:49:44,999:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:49:45,036:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:49:45,037:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:45,039:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:45,040:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 10:49:45,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:49:45,135:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:49:45,135:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:45,138:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:45,196:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:49:45,234:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 10:49:45,234:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:45,237:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:45,237:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 10:49:45,295:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:49:45,333:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:45,335:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:45,394:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 10:49:45,433:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:45,435:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:45,435:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 10:49:45,533:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:45,535:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:45,632:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:45,634:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:45,636:INFO:Preparing preprocessing pipeline...
2024-11-14 10:49:45,636:INFO:Set up simple imputation.
2024-11-14 10:49:45,656:INFO:Finished creating preprocessing pipeline.
2024-11-14 10:49:45,659:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 10:49:45,659:INFO:Creating final display dataframe.
2024-11-14 10:49:45,713:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              0a04
2024-11-14 10:49:45,811:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:45,813:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:45,911:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 10:49:45,913:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 10:49:45,914:INFO:setup() successfully completed in 2.65s...............
2024-11-14 10:49:45,914:INFO:Initializing compare_models()
2024-11-14 10:49:45,914:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, include=['et', 'rf', 'dt', 'knn', 'catboost', 'lightgbm'], fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, 'include': ['et', 'rf', 'dt', 'knn', 'catboost', 'lightgbm'], 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 10:49:45,914:INFO:Checking exceptions
2024-11-14 10:49:45,916:INFO:Preparing display monitor
2024-11-14 10:49:45,951:INFO:Initializing Extra Trees Regressor
2024-11-14 10:49:45,951:INFO:Total runtime is 2.2649765014648438e-06 minutes
2024-11-14 10:49:45,954:INFO:SubProcess create_model() called ==================================
2024-11-14 10:49:45,955:INFO:Initializing create_model()
2024-11-14 10:49:45,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4ccc1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:49:45,955:INFO:Checking exceptions
2024-11-14 10:49:45,956:INFO:Importing libraries
2024-11-14 10:49:45,957:INFO:Copying training dataset
2024-11-14 10:49:45,962:INFO:Defining folds
2024-11-14 10:49:45,962:INFO:Declaring metric variables
2024-11-14 10:49:45,965:INFO:Importing untrained model
2024-11-14 10:49:45,969:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:49:45,975:INFO:Starting cross validation
2024-11-14 10:49:45,978:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:49:49,908:INFO:Calculating mean and std
2024-11-14 10:49:49,913:INFO:Creating metrics dataframe
2024-11-14 10:49:49,921:INFO:Uploading results into container
2024-11-14 10:49:49,922:INFO:Uploading model into container now
2024-11-14 10:49:49,922:INFO:_master_model_container: 1
2024-11-14 10:49:49,922:INFO:_display_container: 2
2024-11-14 10:49:49,923:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:49:49,923:INFO:create_model() successfully completed......................................
2024-11-14 10:49:50,082:INFO:SubProcess create_model() end ==================================
2024-11-14 10:49:50,082:INFO:Creating metrics dataframe
2024-11-14 10:49:50,092:INFO:Initializing Random Forest Regressor
2024-11-14 10:49:50,092:INFO:Total runtime is 0.06901750961939494 minutes
2024-11-14 10:49:50,095:INFO:SubProcess create_model() called ==================================
2024-11-14 10:49:50,096:INFO:Initializing create_model()
2024-11-14 10:49:50,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4ccc1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:49:50,096:INFO:Checking exceptions
2024-11-14 10:49:50,096:INFO:Importing libraries
2024-11-14 10:49:50,096:INFO:Copying training dataset
2024-11-14 10:49:50,103:INFO:Defining folds
2024-11-14 10:49:50,104:INFO:Declaring metric variables
2024-11-14 10:49:50,107:INFO:Importing untrained model
2024-11-14 10:49:50,111:INFO:Random Forest Regressor Imported successfully
2024-11-14 10:49:50,117:INFO:Starting cross validation
2024-11-14 10:49:50,118:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:49:53,599:INFO:Calculating mean and std
2024-11-14 10:49:53,603:INFO:Creating metrics dataframe
2024-11-14 10:49:53,611:INFO:Uploading results into container
2024-11-14 10:49:53,611:INFO:Uploading model into container now
2024-11-14 10:49:53,612:INFO:_master_model_container: 2
2024-11-14 10:49:53,612:INFO:_display_container: 2
2024-11-14 10:49:53,612:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:49:53,613:INFO:create_model() successfully completed......................................
2024-11-14 10:49:53,751:INFO:SubProcess create_model() end ==================================
2024-11-14 10:49:53,751:INFO:Creating metrics dataframe
2024-11-14 10:49:53,761:INFO:Initializing Decision Tree Regressor
2024-11-14 10:49:53,761:INFO:Total runtime is 0.1301777442296346 minutes
2024-11-14 10:49:53,765:INFO:SubProcess create_model() called ==================================
2024-11-14 10:49:53,765:INFO:Initializing create_model()
2024-11-14 10:49:53,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4ccc1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:49:53,765:INFO:Checking exceptions
2024-11-14 10:49:53,765:INFO:Importing libraries
2024-11-14 10:49:53,766:INFO:Copying training dataset
2024-11-14 10:49:53,773:INFO:Defining folds
2024-11-14 10:49:53,773:INFO:Declaring metric variables
2024-11-14 10:49:53,776:INFO:Importing untrained model
2024-11-14 10:49:53,780:INFO:Decision Tree Regressor Imported successfully
2024-11-14 10:49:53,787:INFO:Starting cross validation
2024-11-14 10:49:53,788:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:49:56,548:INFO:Calculating mean and std
2024-11-14 10:49:56,552:INFO:Creating metrics dataframe
2024-11-14 10:49:56,559:INFO:Uploading results into container
2024-11-14 10:49:56,560:INFO:Uploading model into container now
2024-11-14 10:49:56,561:INFO:_master_model_container: 3
2024-11-14 10:49:56,561:INFO:_display_container: 2
2024-11-14 10:49:56,561:INFO:DecisionTreeRegressor(random_state=123)
2024-11-14 10:49:56,561:INFO:create_model() successfully completed......................................
2024-11-14 10:49:56,695:INFO:SubProcess create_model() end ==================================
2024-11-14 10:49:56,695:INFO:Creating metrics dataframe
2024-11-14 10:49:56,705:INFO:Initializing K Neighbors Regressor
2024-11-14 10:49:56,705:INFO:Total runtime is 0.17924276987711588 minutes
2024-11-14 10:49:56,709:INFO:SubProcess create_model() called ==================================
2024-11-14 10:49:56,709:INFO:Initializing create_model()
2024-11-14 10:49:56,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4ccc1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:49:56,709:INFO:Checking exceptions
2024-11-14 10:49:56,709:INFO:Importing libraries
2024-11-14 10:49:56,709:INFO:Copying training dataset
2024-11-14 10:49:56,716:INFO:Defining folds
2024-11-14 10:49:56,717:INFO:Declaring metric variables
2024-11-14 10:49:56,720:INFO:Importing untrained model
2024-11-14 10:49:56,724:INFO:K Neighbors Regressor Imported successfully
2024-11-14 10:49:56,730:INFO:Starting cross validation
2024-11-14 10:49:56,731:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:49:59,568:INFO:Calculating mean and std
2024-11-14 10:49:59,571:INFO:Creating metrics dataframe
2024-11-14 10:49:59,576:INFO:Uploading results into container
2024-11-14 10:49:59,577:INFO:Uploading model into container now
2024-11-14 10:49:59,578:INFO:_master_model_container: 4
2024-11-14 10:49:59,578:INFO:_display_container: 2
2024-11-14 10:49:59,578:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 10:49:59,578:INFO:create_model() successfully completed......................................
2024-11-14 10:49:59,718:INFO:SubProcess create_model() end ==================================
2024-11-14 10:49:59,719:INFO:Creating metrics dataframe
2024-11-14 10:49:59,731:INFO:Initializing CatBoost Regressor
2024-11-14 10:49:59,731:INFO:Total runtime is 0.2296778599421183 minutes
2024-11-14 10:49:59,735:INFO:SubProcess create_model() called ==================================
2024-11-14 10:49:59,736:INFO:Initializing create_model()
2024-11-14 10:49:59,736:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4ccc1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:49:59,736:INFO:Checking exceptions
2024-11-14 10:49:59,736:INFO:Importing libraries
2024-11-14 10:49:59,736:INFO:Copying training dataset
2024-11-14 10:49:59,745:INFO:Defining folds
2024-11-14 10:49:59,745:INFO:Declaring metric variables
2024-11-14 10:49:59,749:INFO:Importing untrained model
2024-11-14 10:49:59,752:INFO:CatBoost Regressor Imported successfully
2024-11-14 10:49:59,759:INFO:Starting cross validation
2024-11-14 10:49:59,760:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:50:12,238:INFO:Calculating mean and std
2024-11-14 10:50:12,241:INFO:Creating metrics dataframe
2024-11-14 10:50:12,247:INFO:Uploading results into container
2024-11-14 10:50:12,248:INFO:Uploading model into container now
2024-11-14 10:50:12,248:INFO:_master_model_container: 5
2024-11-14 10:50:12,249:INFO:_display_container: 2
2024-11-14 10:50:12,249:INFO:<catboost.core.CatBoostRegressor object at 0x7fc1c5075280>
2024-11-14 10:50:12,249:INFO:create_model() successfully completed......................................
2024-11-14 10:50:12,388:INFO:SubProcess create_model() end ==================================
2024-11-14 10:50:12,389:INFO:Creating metrics dataframe
2024-11-14 10:50:12,399:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 10:50:12,399:INFO:Total runtime is 0.44081064065297443 minutes
2024-11-14 10:50:12,403:INFO:SubProcess create_model() called ==================================
2024-11-14 10:50:12,403:INFO:Initializing create_model()
2024-11-14 10:50:12,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4ccc1c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:50:12,403:INFO:Checking exceptions
2024-11-14 10:50:12,403:INFO:Importing libraries
2024-11-14 10:50:12,403:INFO:Copying training dataset
2024-11-14 10:50:12,410:INFO:Defining folds
2024-11-14 10:50:12,411:INFO:Declaring metric variables
2024-11-14 10:50:12,414:INFO:Importing untrained model
2024-11-14 10:50:12,417:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 10:50:12,423:INFO:Starting cross validation
2024-11-14 10:50:12,424:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:53:37,343:INFO:Calculating mean and std
2024-11-14 10:53:37,347:INFO:Creating metrics dataframe
2024-11-14 10:53:37,356:INFO:Uploading results into container
2024-11-14 10:53:37,357:INFO:Uploading model into container now
2024-11-14 10:53:37,357:INFO:_master_model_container: 6
2024-11-14 10:53:37,357:INFO:_display_container: 2
2024-11-14 10:53:37,358:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:53:37,358:INFO:create_model() successfully completed......................................
2024-11-14 10:53:37,536:INFO:SubProcess create_model() end ==================================
2024-11-14 10:53:37,537:INFO:Creating metrics dataframe
2024-11-14 10:53:37,557:INFO:Initializing create_model()
2024-11-14 10:53:37,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:53:37,557:INFO:Checking exceptions
2024-11-14 10:53:37,559:INFO:Importing libraries
2024-11-14 10:53:37,559:INFO:Copying training dataset
2024-11-14 10:53:37,566:INFO:Defining folds
2024-11-14 10:53:37,566:INFO:Declaring metric variables
2024-11-14 10:53:37,566:INFO:Importing untrained model
2024-11-14 10:53:37,566:INFO:Declaring custom model
2024-11-14 10:53:37,567:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:53:37,568:INFO:Cross validation set to False
2024-11-14 10:53:37,568:INFO:Fitting Model
2024-11-14 10:53:37,780:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:53:37,780:INFO:create_model() successfully completed......................................
2024-11-14 10:53:37,957:INFO:_master_model_container: 6
2024-11-14 10:53:37,957:INFO:_display_container: 2
2024-11-14 10:53:37,957:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:53:37,958:INFO:compare_models() successfully completed......................................
2024-11-14 10:54:26,433:INFO:Initializing tune_model()
2024-11-14 10:54:26,433:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>)
2024-11-14 10:54:26,434:INFO:Checking exceptions
2024-11-14 10:54:26,470:INFO:Copying training dataset
2024-11-14 10:54:26,475:INFO:Checking base model
2024-11-14 10:54:26,475:INFO:Base model : Extra Trees Regressor
2024-11-14 10:54:26,479:INFO:Declaring metric variables
2024-11-14 10:54:26,483:INFO:Defining Hyperparameters
2024-11-14 10:54:26,675:INFO:Tuning with n_jobs=-1
2024-11-14 10:54:26,675:INFO:Initializing RandomizedSearchCV
2024-11-14 10:56:12,946:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-11-14 10:56:12,950:INFO:Hyperparameter search completed
2024-11-14 10:56:12,950:INFO:SubProcess create_model() called ==================================
2024-11-14 10:56:12,951:INFO:Initializing create_model()
2024-11-14 10:56:12,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dc0b7370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'squared_error', 'bootstrap': False})
2024-11-14 10:56:12,951:INFO:Checking exceptions
2024-11-14 10:56:12,952:INFO:Importing libraries
2024-11-14 10:56:12,952:INFO:Copying training dataset
2024-11-14 10:56:12,958:INFO:Defining folds
2024-11-14 10:56:12,959:INFO:Declaring metric variables
2024-11-14 10:56:12,962:INFO:Importing untrained model
2024-11-14 10:56:12,962:INFO:Declaring custom model
2024-11-14 10:56:12,966:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:56:12,973:INFO:Starting cross validation
2024-11-14 10:56:12,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:56:13,677:INFO:Calculating mean and std
2024-11-14 10:56:13,681:INFO:Creating metrics dataframe
2024-11-14 10:56:13,692:INFO:Finalizing model
2024-11-14 10:56:14,043:INFO:Uploading results into container
2024-11-14 10:56:14,044:INFO:Uploading model into container now
2024-11-14 10:56:14,044:INFO:_master_model_container: 7
2024-11-14 10:56:14,044:INFO:_display_container: 3
2024-11-14 10:56:14,045:INFO:ExtraTreesRegressor(max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123)
2024-11-14 10:56:14,045:INFO:create_model() successfully completed......................................
2024-11-14 10:56:14,209:INFO:SubProcess create_model() end ==================================
2024-11-14 10:56:14,209:INFO:choose_better activated
2024-11-14 10:56:14,215:INFO:SubProcess create_model() called ==================================
2024-11-14 10:56:14,216:INFO:Initializing create_model()
2024-11-14 10:56:14,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 10:56:14,217:INFO:Checking exceptions
2024-11-14 10:56:14,220:INFO:Importing libraries
2024-11-14 10:56:14,220:INFO:Copying training dataset
2024-11-14 10:56:14,230:INFO:Defining folds
2024-11-14 10:56:14,230:INFO:Declaring metric variables
2024-11-14 10:56:14,230:INFO:Importing untrained model
2024-11-14 10:56:14,230:INFO:Declaring custom model
2024-11-14 10:56:14,231:INFO:Extra Trees Regressor Imported successfully
2024-11-14 10:56:14,231:INFO:Starting cross validation
2024-11-14 10:56:14,232:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 10:56:15,168:INFO:Calculating mean and std
2024-11-14 10:56:15,168:INFO:Creating metrics dataframe
2024-11-14 10:56:15,172:INFO:Finalizing model
2024-11-14 10:56:15,404:INFO:Uploading results into container
2024-11-14 10:56:15,405:INFO:Uploading model into container now
2024-11-14 10:56:15,406:INFO:_master_model_container: 8
2024-11-14 10:56:15,406:INFO:_display_container: 4
2024-11-14 10:56:15,407:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:56:15,407:INFO:create_model() successfully completed......................................
2024-11-14 10:56:15,574:INFO:SubProcess create_model() end ==================================
2024-11-14 10:56:15,575:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9809
2024-11-14 10:56:15,576:INFO:ExtraTreesRegressor(max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123) result for R2 is 0.7478
2024-11-14 10:56:15,576:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-11-14 10:56:15,576:INFO:choose_better completed
2024-11-14 10:56:15,576:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-11-14 10:56:15,589:INFO:_master_model_container: 8
2024-11-14 10:56:15,589:INFO:_display_container: 3
2024-11-14 10:56:15,590:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 10:56:15,590:INFO:tune_model() successfully completed......................................
2024-11-14 11:20:51,650:INFO:Initializing create_model()
2024-11-14 11:20:51,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:20:51,651:INFO:Checking exceptions
2024-11-14 11:20:51,686:INFO:Importing libraries
2024-11-14 11:20:51,686:INFO:Copying training dataset
2024-11-14 11:20:51,694:INFO:Defining folds
2024-11-14 11:20:51,694:INFO:Declaring metric variables
2024-11-14 11:20:51,698:INFO:Importing untrained model
2024-11-14 11:20:51,702:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 11:20:51,710:INFO:Starting cross validation
2024-11-14 11:20:51,711:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:20:54,651:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015029 seconds.
2024-11-14 11:20:54,652:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-14 11:20:54,653:INFO:[LightGBM] [Info] Total Bins 855
2024-11-14 11:20:54,655:INFO:[LightGBM] [Info] Number of data points in the train set: 19728, number of used features: 4
2024-11-14 11:20:54,664:INFO:[LightGBM] [Info] Start training from score 22.226485
2024-11-14 11:20:55,523:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044292 seconds.
2024-11-14 11:20:55,524:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-14 11:20:55,524:INFO:[LightGBM] [Info] Total Bins 857
2024-11-14 11:20:55,534:INFO:[LightGBM] [Info] Number of data points in the train set: 19729, number of used features: 4
2024-11-14 11:20:55,557:INFO:[LightGBM] [Info] Start training from score 22.285260
2024-11-14 11:20:55,557:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043295 seconds.
2024-11-14 11:20:55,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-14 11:20:55,558:INFO:[LightGBM] [Info] Total Bins 859
2024-11-14 11:20:55,567:INFO:[LightGBM] [Info] Number of data points in the train set: 19729, number of used features: 4
2024-11-14 11:20:55,589:INFO:[LightGBM] [Info] Start training from score 22.235760
2024-11-14 11:20:55,733:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066768 seconds.
2024-11-14 11:20:55,733:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-14 11:20:55,733:INFO:[LightGBM] [Info] Total Bins 858
2024-11-14 11:20:55,751:INFO:[LightGBM] [Info] Number of data points in the train set: 19729, number of used features: 4
2024-11-14 11:20:55,769:INFO:[LightGBM] [Info] Start training from score 22.251959
2024-11-14 11:20:56,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077234 seconds.
2024-11-14 11:20:56,043:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-14 11:20:56,043:INFO:[LightGBM] [Info] Total Bins 858
2024-11-14 11:20:56,071:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078355 seconds.
2024-11-14 11:20:56,071:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-14 11:20:56,071:INFO:[LightGBM] [Info] Total Bins 860
2024-11-14 11:20:56,082:INFO:[LightGBM] [Info] Number of data points in the train set: 19729, number of used features: 4
2024-11-14 11:20:56,099:INFO:[LightGBM] [Info] Number of data points in the train set: 19729, number of used features: 4
2024-11-14 11:20:56,140:INFO:[LightGBM] [Info] Start training from score 22.245202
2024-11-14 11:20:56,150:INFO:[LightGBM] [Info] Start training from score 22.299442
2024-11-14 11:20:56,172:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109334 seconds.
2024-11-14 11:20:56,172:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-14 11:20:56,173:INFO:[LightGBM] [Info] Total Bins 860
2024-11-14 11:20:56,194:INFO:[LightGBM] [Info] Number of data points in the train set: 19729, number of used features: 4
2024-11-14 11:20:56,258:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097361 seconds.
2024-11-14 11:20:56,259:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-14 11:20:56,259:INFO:[LightGBM] [Info] Total Bins 858
2024-11-14 11:20:56,266:INFO:[LightGBM] [Info] Start training from score 22.283106
2024-11-14 11:20:56,291:INFO:[LightGBM] [Info] Number of data points in the train set: 19729, number of used features: 4
2024-11-14 11:20:56,355:INFO:[LightGBM] [Info] Start training from score 22.282427
2024-11-14 11:20:56,387:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101164 seconds.
2024-11-14 11:20:56,387:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-11-14 11:20:56,387:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-11-14 11:20:56,387:INFO:[LightGBM] [Info] Total Bins 858
2024-11-14 11:20:56,415:INFO:[LightGBM] [Info] Number of data points in the train set: 19729, number of used features: 4
2024-11-14 11:20:56,467:INFO:[LightGBM] [Info] Start training from score 22.294947
2024-11-14 11:20:57,174:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070949 seconds.
2024-11-14 11:20:57,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-14 11:20:57,175:INFO:[LightGBM] [Info] Total Bins 857
2024-11-14 11:20:57,191:INFO:[LightGBM] [Info] Number of data points in the train set: 19729, number of used features: 4
2024-11-14 11:20:57,245:INFO:[LightGBM] [Info] Start training from score 22.296244
2024-11-14 11:27:53,095:INFO:Calculating mean and std
2024-11-14 11:27:53,098:INFO:Creating metrics dataframe
2024-11-14 11:27:53,109:INFO:Finalizing model
2024-11-14 11:27:53,152:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012134 seconds.
2024-11-14 11:27:53,152:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-14 11:27:53,152:INFO:[LightGBM] [Info] Total Bins 858
2024-11-14 11:27:53,155:INFO:[LightGBM] [Info] Number of data points in the train set: 21921, number of used features: 4
2024-11-14 11:27:53,162:INFO:[LightGBM] [Info] Start training from score 22.270083
2024-11-14 11:28:10,433:INFO:Uploading results into container
2024-11-14 11:28:10,435:INFO:Uploading model into container now
2024-11-14 11:28:10,443:INFO:_master_model_container: 9
2024-11-14 11:28:10,443:INFO:_display_container: 4
2024-11-14 11:28:10,444:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-14 11:28:10,444:INFO:create_model() successfully completed......................................
2024-11-14 11:30:56,743:INFO:Initializing create_model()
2024-11-14 11:30:56,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd8156250>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:30:56,744:INFO:Checking exceptions
2024-11-14 11:30:56,778:INFO:Importing libraries
2024-11-14 11:30:56,778:INFO:Copying training dataset
2024-11-14 11:30:56,787:INFO:Defining folds
2024-11-14 11:30:56,788:INFO:Declaring metric variables
2024-11-14 11:30:56,791:INFO:Importing untrained model
2024-11-14 11:30:56,795:INFO:Extra Trees Regressor Imported successfully
2024-11-14 11:30:56,803:INFO:Starting cross validation
2024-11-14 11:30:56,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:31:00,675:INFO:Calculating mean and std
2024-11-14 11:31:00,681:INFO:Creating metrics dataframe
2024-11-14 11:31:00,690:INFO:Finalizing model
2024-11-14 11:31:00,935:INFO:Uploading results into container
2024-11-14 11:31:00,936:INFO:Uploading model into container now
2024-11-14 11:31:00,948:INFO:_master_model_container: 10
2024-11-14 11:31:00,948:INFO:_display_container: 5
2024-11-14 11:31:00,949:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 11:31:00,949:INFO:create_model() successfully completed......................................
2024-11-14 11:32:13,560:INFO:PyCaret RegressionExperiment
2024-11-14 11:32:13,560:INFO:Logging name: reg-default-name
2024-11-14 11:32:13,560:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 11:32:13,560:INFO:version 3.2.0
2024-11-14 11:32:13,560:INFO:Initializing setup()
2024-11-14 11:32:13,560:INFO:self.USI: 1cc4
2024-11-14 11:32:13,560:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 11:32:13,560:INFO:Checking environment
2024-11-14 11:32:13,561:INFO:python_version: 3.8.13
2024-11-14 11:32:13,561:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 11:32:13,561:INFO:machine: x86_64
2024-11-14 11:32:13,561:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 11:32:13,561:INFO:Memory: svmem(total=270355722240, available=217890918400, percent=19.4, used=50374610944, free=70424924160, active=71812816896, inactive=67729293312, buffers=10100736, cached=149546086400, shared=196083712, slab=25262632960)
2024-11-14 11:32:13,565:INFO:Physical Core: 28
2024-11-14 11:32:13,565:INFO:Logical Core: 56
2024-11-14 11:32:13,565:INFO:Checking libraries
2024-11-14 11:32:13,566:INFO:System:
2024-11-14 11:32:13,566:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 11:32:13,566:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 11:32:13,566:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 11:32:13,566:INFO:PyCaret required dependencies:
2024-11-14 11:32:13,566:INFO:                 pip: 22.2.2
2024-11-14 11:32:13,566:INFO:          setuptools: 63.4.2
2024-11-14 11:32:13,566:INFO:             pycaret: 3.2.0
2024-11-14 11:32:13,566:INFO:             IPython: 8.12.2
2024-11-14 11:32:13,566:INFO:          ipywidgets: 7.7.1
2024-11-14 11:32:13,566:INFO:                tqdm: 4.64.1
2024-11-14 11:32:13,566:INFO:               numpy: 1.23.5
2024-11-14 11:32:13,566:INFO:              pandas: 1.5.3
2024-11-14 11:32:13,566:INFO:              jinja2: 3.1.2
2024-11-14 11:32:13,566:INFO:               scipy: 1.10.1
2024-11-14 11:32:13,566:INFO:              joblib: 1.3.0
2024-11-14 11:32:13,566:INFO:             sklearn: 1.1.2
2024-11-14 11:32:13,567:INFO:                pyod: 2.0.2
2024-11-14 11:32:13,567:INFO:            imblearn: 0.12.4
2024-11-14 11:32:13,567:INFO:   category_encoders: 2.6.4
2024-11-14 11:32:13,567:INFO:            lightgbm: 4.5.0
2024-11-14 11:32:13,567:INFO:               numba: 0.57.1
2024-11-14 11:32:13,567:INFO:            requests: 2.28.1
2024-11-14 11:32:13,567:INFO:          matplotlib: 3.5.1
2024-11-14 11:32:13,567:INFO:          scikitplot: 0.3.7
2024-11-14 11:32:13,567:INFO:         yellowbrick: 1.5
2024-11-14 11:32:13,567:INFO:              plotly: 5.24.1
2024-11-14 11:32:13,567:INFO:    plotly-resampler: Not installed
2024-11-14 11:32:13,567:INFO:             kaleido: 0.2.1
2024-11-14 11:32:13,567:INFO:           schemdraw: 0.15
2024-11-14 11:32:13,567:INFO:         statsmodels: 0.13.2
2024-11-14 11:32:13,567:INFO:              sktime: 0.21.1
2024-11-14 11:32:13,567:INFO:               tbats: 1.1.3
2024-11-14 11:32:13,567:INFO:            pmdarima: 2.0.4
2024-11-14 11:32:13,567:INFO:              psutil: 5.9.1
2024-11-14 11:32:13,567:INFO:          markupsafe: 2.1.1
2024-11-14 11:32:13,567:INFO:             pickle5: Not installed
2024-11-14 11:32:13,567:INFO:         cloudpickle: 2.1.0
2024-11-14 11:32:13,567:INFO:         deprecation: 2.1.0
2024-11-14 11:32:13,567:INFO:              xxhash: 3.5.0
2024-11-14 11:32:13,567:INFO:           wurlitzer: 3.1.1
2024-11-14 11:32:13,567:INFO:PyCaret optional dependencies:
2024-11-14 11:32:13,567:INFO:                shap: 0.44.1
2024-11-14 11:32:13,567:INFO:           interpret: 0.6.5
2024-11-14 11:32:13,567:INFO:                umap: 0.5.7
2024-11-14 11:32:13,567:INFO:     ydata_profiling: 4.6.0
2024-11-14 11:32:13,567:INFO:  explainerdashboard: 0.4.7
2024-11-14 11:32:13,568:INFO:             autoviz: Not installed
2024-11-14 11:32:13,568:INFO:           fairlearn: 0.7.0
2024-11-14 11:32:13,568:INFO:          deepchecks: Not installed
2024-11-14 11:32:13,568:INFO:             xgboost: 2.1.1
2024-11-14 11:32:13,568:INFO:            catboost: 1.2.7
2024-11-14 11:32:13,568:INFO:              kmodes: 0.12.2
2024-11-14 11:32:13,568:INFO:             mlxtend: 0.23.1
2024-11-14 11:32:13,568:INFO:       statsforecast: 1.5.0
2024-11-14 11:32:13,568:INFO:        tune_sklearn: 0.5.0
2024-11-14 11:32:13,568:INFO:                 ray: 2.10.0
2024-11-14 11:32:13,568:INFO:            hyperopt: 0.2.7
2024-11-14 11:32:13,568:INFO:              optuna: 4.1.0
2024-11-14 11:32:13,568:INFO:               skopt: 0.10.2
2024-11-14 11:32:13,568:INFO:              mlflow: 1.30.1
2024-11-14 11:32:13,568:INFO:              gradio: 3.50.2
2024-11-14 11:32:13,568:INFO:             fastapi: 0.115.5
2024-11-14 11:32:13,568:INFO:             uvicorn: 0.32.0
2024-11-14 11:32:13,568:INFO:              m2cgen: 0.10.0
2024-11-14 11:32:13,568:INFO:           evidently: 0.2.8
2024-11-14 11:32:13,568:INFO:               fugue: 0.8.6
2024-11-14 11:32:13,568:INFO:           streamlit: Not installed
2024-11-14 11:32:13,568:INFO:             prophet: Not installed
2024-11-14 11:32:13,568:INFO:None
2024-11-14 11:32:13,568:INFO:Set up data.
2024-11-14 11:32:13,578:INFO:Set up folding strategy.
2024-11-14 11:32:13,579:INFO:Set up train/test split.
2024-11-14 11:32:13,584:INFO:Set up index.
2024-11-14 11:32:13,585:INFO:Assigning column types.
2024-11-14 11:32:13,590:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 11:32:13,591:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,596:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,601:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,669:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,710:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:13,713:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:13,713:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,717:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,721:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,813:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:13,816:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:13,817:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 11:32:13,821:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,825:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,915:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,916:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:13,918:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:13,923:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,927:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 11:32:13,978:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,017:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,017:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:14,020:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:14,020:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 11:32:14,028:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,118:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:14,120:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:14,129:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,183:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,223:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:14,225:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:14,226:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 11:32:14,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,324:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,325:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:14,327:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:14,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,427:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:14,430:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:14,430:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 11:32:14,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,530:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:14,532:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:14,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 11:32:14,632:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:14,634:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:14,635:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 11:32:14,733:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:14,736:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:14,837:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:14,841:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:14,843:INFO:Preparing preprocessing pipeline...
2024-11-14 11:32:14,843:INFO:Set up simple imputation.
2024-11-14 11:32:14,869:INFO:Finished creating preprocessing pipeline.
2024-11-14 11:32:14,873:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 11:32:14,873:INFO:Creating final display dataframe.
2024-11-14 11:32:14,928:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              1cc4
2024-11-14 11:32:15,026:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:15,029:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:15,127:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 11:32:15,130:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 11:32:15,131:INFO:setup() successfully completed in 1.57s...............
2024-11-14 11:32:15,135:INFO:Initializing compare_models()
2024-11-14 11:32:15,135:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 11:32:15,135:INFO:Checking exceptions
2024-11-14 11:32:15,138:INFO:Preparing display monitor
2024-11-14 11:32:15,173:INFO:Initializing Linear Regression
2024-11-14 11:32:15,173:INFO:Total runtime is 2.3881594340006512e-06 minutes
2024-11-14 11:32:15,176:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:15,176:INFO:Initializing create_model()
2024-11-14 11:32:15,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:15,176:INFO:Checking exceptions
2024-11-14 11:32:15,177:INFO:Importing libraries
2024-11-14 11:32:15,177:INFO:Copying training dataset
2024-11-14 11:32:15,182:INFO:Defining folds
2024-11-14 11:32:15,182:INFO:Declaring metric variables
2024-11-14 11:32:15,185:INFO:Importing untrained model
2024-11-14 11:32:15,189:INFO:Linear Regression Imported successfully
2024-11-14 11:32:15,195:INFO:Starting cross validation
2024-11-14 11:32:15,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:18,007:INFO:Calculating mean and std
2024-11-14 11:32:18,011:INFO:Creating metrics dataframe
2024-11-14 11:32:18,018:INFO:Uploading results into container
2024-11-14 11:32:18,019:INFO:Uploading model into container now
2024-11-14 11:32:18,020:INFO:_master_model_container: 1
2024-11-14 11:32:18,020:INFO:_display_container: 2
2024-11-14 11:32:18,021:INFO:LinearRegression(n_jobs=-1)
2024-11-14 11:32:18,021:INFO:create_model() successfully completed......................................
2024-11-14 11:32:18,208:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:18,209:INFO:Creating metrics dataframe
2024-11-14 11:32:18,218:INFO:Initializing Lasso Regression
2024-11-14 11:32:18,218:INFO:Total runtime is 0.050760217507680255 minutes
2024-11-14 11:32:18,222:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:18,222:INFO:Initializing create_model()
2024-11-14 11:32:18,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:18,222:INFO:Checking exceptions
2024-11-14 11:32:18,222:INFO:Importing libraries
2024-11-14 11:32:18,222:INFO:Copying training dataset
2024-11-14 11:32:18,231:INFO:Defining folds
2024-11-14 11:32:18,231:INFO:Declaring metric variables
2024-11-14 11:32:18,234:INFO:Importing untrained model
2024-11-14 11:32:18,238:INFO:Lasso Regression Imported successfully
2024-11-14 11:32:18,244:INFO:Starting cross validation
2024-11-14 11:32:18,245:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:21,235:INFO:Calculating mean and std
2024-11-14 11:32:21,239:INFO:Creating metrics dataframe
2024-11-14 11:32:21,247:INFO:Uploading results into container
2024-11-14 11:32:21,248:INFO:Uploading model into container now
2024-11-14 11:32:21,248:INFO:_master_model_container: 2
2024-11-14 11:32:21,249:INFO:_display_container: 2
2024-11-14 11:32:21,249:INFO:Lasso(random_state=123)
2024-11-14 11:32:21,249:INFO:create_model() successfully completed......................................
2024-11-14 11:32:21,409:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:21,409:INFO:Creating metrics dataframe
2024-11-14 11:32:21,419:INFO:Initializing Ridge Regression
2024-11-14 11:32:21,419:INFO:Total runtime is 0.10411022504170736 minutes
2024-11-14 11:32:21,422:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:21,423:INFO:Initializing create_model()
2024-11-14 11:32:21,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:21,423:INFO:Checking exceptions
2024-11-14 11:32:21,423:INFO:Importing libraries
2024-11-14 11:32:21,423:INFO:Copying training dataset
2024-11-14 11:32:21,430:INFO:Defining folds
2024-11-14 11:32:21,431:INFO:Declaring metric variables
2024-11-14 11:32:21,434:INFO:Importing untrained model
2024-11-14 11:32:21,437:INFO:Ridge Regression Imported successfully
2024-11-14 11:32:21,444:INFO:Starting cross validation
2024-11-14 11:32:21,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:24,304:INFO:Calculating mean and std
2024-11-14 11:32:24,310:INFO:Creating metrics dataframe
2024-11-14 11:32:24,318:INFO:Uploading results into container
2024-11-14 11:32:24,319:INFO:Uploading model into container now
2024-11-14 11:32:24,320:INFO:_master_model_container: 3
2024-11-14 11:32:24,320:INFO:_display_container: 2
2024-11-14 11:32:24,321:INFO:Ridge(random_state=123)
2024-11-14 11:32:24,321:INFO:create_model() successfully completed......................................
2024-11-14 11:32:24,492:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:24,492:INFO:Creating metrics dataframe
2024-11-14 11:32:24,503:INFO:Initializing Elastic Net
2024-11-14 11:32:24,503:INFO:Total runtime is 0.15550367037455243 minutes
2024-11-14 11:32:24,506:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:24,506:INFO:Initializing create_model()
2024-11-14 11:32:24,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:24,507:INFO:Checking exceptions
2024-11-14 11:32:24,507:INFO:Importing libraries
2024-11-14 11:32:24,507:INFO:Copying training dataset
2024-11-14 11:32:24,514:INFO:Defining folds
2024-11-14 11:32:24,514:INFO:Declaring metric variables
2024-11-14 11:32:24,517:INFO:Importing untrained model
2024-11-14 11:32:24,521:INFO:Elastic Net Imported successfully
2024-11-14 11:32:24,528:INFO:Starting cross validation
2024-11-14 11:32:24,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:27,424:INFO:Calculating mean and std
2024-11-14 11:32:27,428:INFO:Creating metrics dataframe
2024-11-14 11:32:27,436:INFO:Uploading results into container
2024-11-14 11:32:27,437:INFO:Uploading model into container now
2024-11-14 11:32:27,439:INFO:_master_model_container: 4
2024-11-14 11:32:27,439:INFO:_display_container: 2
2024-11-14 11:32:27,440:INFO:ElasticNet(random_state=123)
2024-11-14 11:32:27,440:INFO:create_model() successfully completed......................................
2024-11-14 11:32:27,599:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:27,599:INFO:Creating metrics dataframe
2024-11-14 11:32:27,610:INFO:Initializing Least Angle Regression
2024-11-14 11:32:27,610:INFO:Total runtime is 0.20729172627131146 minutes
2024-11-14 11:32:27,613:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:27,614:INFO:Initializing create_model()
2024-11-14 11:32:27,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:27,614:INFO:Checking exceptions
2024-11-14 11:32:27,614:INFO:Importing libraries
2024-11-14 11:32:27,614:INFO:Copying training dataset
2024-11-14 11:32:27,622:INFO:Defining folds
2024-11-14 11:32:27,623:INFO:Declaring metric variables
2024-11-14 11:32:27,626:INFO:Importing untrained model
2024-11-14 11:32:27,630:INFO:Least Angle Regression Imported successfully
2024-11-14 11:32:27,636:INFO:Starting cross validation
2024-11-14 11:32:27,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:27,724:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:27,732:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:27,736:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:30,117:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:30,124:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:30,139:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:30,362:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:30,371:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:30,397:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:30,398:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:30,413:INFO:Calculating mean and std
2024-11-14 11:32:30,417:INFO:Creating metrics dataframe
2024-11-14 11:32:30,424:INFO:Uploading results into container
2024-11-14 11:32:30,425:INFO:Uploading model into container now
2024-11-14 11:32:30,425:INFO:_master_model_container: 5
2024-11-14 11:32:30,426:INFO:_display_container: 2
2024-11-14 11:32:30,426:INFO:Lars(random_state=123)
2024-11-14 11:32:30,426:INFO:create_model() successfully completed......................................
2024-11-14 11:32:30,571:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:30,571:INFO:Creating metrics dataframe
2024-11-14 11:32:30,583:INFO:Initializing Lasso Least Angle Regression
2024-11-14 11:32:30,584:INFO:Total runtime is 0.2568505922953288 minutes
2024-11-14 11:32:30,588:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:30,588:INFO:Initializing create_model()
2024-11-14 11:32:30,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:30,588:INFO:Checking exceptions
2024-11-14 11:32:30,588:INFO:Importing libraries
2024-11-14 11:32:30,588:INFO:Copying training dataset
2024-11-14 11:32:30,597:INFO:Defining folds
2024-11-14 11:32:30,597:INFO:Declaring metric variables
2024-11-14 11:32:30,601:INFO:Importing untrained model
2024-11-14 11:32:30,605:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 11:32:30,612:INFO:Starting cross validation
2024-11-14 11:32:30,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:30,652:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 11:32:30,655:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 11:32:30,665:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 11:32:30,673:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 11:32:30,681:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 11:32:30,690:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 11:32:30,690:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 11:32:30,699:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 11:32:30,700:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 11:32:30,703:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 11:32:30,722:INFO:Calculating mean and std
2024-11-14 11:32:30,725:INFO:Creating metrics dataframe
2024-11-14 11:32:30,732:INFO:Uploading results into container
2024-11-14 11:32:30,732:INFO:Uploading model into container now
2024-11-14 11:32:30,733:INFO:_master_model_container: 6
2024-11-14 11:32:30,733:INFO:_display_container: 2
2024-11-14 11:32:30,733:INFO:LassoLars(random_state=123)
2024-11-14 11:32:30,734:INFO:create_model() successfully completed......................................
2024-11-14 11:32:30,909:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:30,910:INFO:Creating metrics dataframe
2024-11-14 11:32:30,921:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 11:32:30,921:INFO:Total runtime is 0.26247995694478354 minutes
2024-11-14 11:32:30,925:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:30,925:INFO:Initializing create_model()
2024-11-14 11:32:30,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:30,925:INFO:Checking exceptions
2024-11-14 11:32:30,926:INFO:Importing libraries
2024-11-14 11:32:30,926:INFO:Copying training dataset
2024-11-14 11:32:30,933:INFO:Defining folds
2024-11-14 11:32:30,933:INFO:Declaring metric variables
2024-11-14 11:32:30,936:INFO:Importing untrained model
2024-11-14 11:32:30,940:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 11:32:30,947:INFO:Starting cross validation
2024-11-14 11:32:30,948:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:30,985:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:30,989:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:30,993:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:31,000:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:31,002:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:31,006:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:31,010:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:31,013:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:31,023:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:31,028:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 11:32:31,044:INFO:Calculating mean and std
2024-11-14 11:32:31,047:INFO:Creating metrics dataframe
2024-11-14 11:32:31,054:INFO:Uploading results into container
2024-11-14 11:32:31,055:INFO:Uploading model into container now
2024-11-14 11:32:31,056:INFO:_master_model_container: 7
2024-11-14 11:32:31,056:INFO:_display_container: 2
2024-11-14 11:32:31,056:INFO:OrthogonalMatchingPursuit()
2024-11-14 11:32:31,056:INFO:create_model() successfully completed......................................
2024-11-14 11:32:31,213:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:31,213:INFO:Creating metrics dataframe
2024-11-14 11:32:31,227:INFO:Initializing Bayesian Ridge
2024-11-14 11:32:31,227:INFO:Total runtime is 0.2675734281539917 minutes
2024-11-14 11:32:31,231:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:31,231:INFO:Initializing create_model()
2024-11-14 11:32:31,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:31,232:INFO:Checking exceptions
2024-11-14 11:32:31,232:INFO:Importing libraries
2024-11-14 11:32:31,232:INFO:Copying training dataset
2024-11-14 11:32:31,240:INFO:Defining folds
2024-11-14 11:32:31,240:INFO:Declaring metric variables
2024-11-14 11:32:31,244:INFO:Importing untrained model
2024-11-14 11:32:31,248:INFO:Bayesian Ridge Imported successfully
2024-11-14 11:32:31,256:INFO:Starting cross validation
2024-11-14 11:32:31,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:31,362:INFO:Calculating mean and std
2024-11-14 11:32:31,366:INFO:Creating metrics dataframe
2024-11-14 11:32:31,371:INFO:Uploading results into container
2024-11-14 11:32:31,372:INFO:Uploading model into container now
2024-11-14 11:32:31,373:INFO:_master_model_container: 8
2024-11-14 11:32:31,373:INFO:_display_container: 2
2024-11-14 11:32:31,373:INFO:BayesianRidge()
2024-11-14 11:32:31,373:INFO:create_model() successfully completed......................................
2024-11-14 11:32:31,521:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:31,521:INFO:Creating metrics dataframe
2024-11-14 11:32:31,533:INFO:Initializing Passive Aggressive Regressor
2024-11-14 11:32:31,533:INFO:Total runtime is 0.27267892758051554 minutes
2024-11-14 11:32:31,537:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:31,537:INFO:Initializing create_model()
2024-11-14 11:32:31,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:31,537:INFO:Checking exceptions
2024-11-14 11:32:31,537:INFO:Importing libraries
2024-11-14 11:32:31,537:INFO:Copying training dataset
2024-11-14 11:32:31,544:INFO:Defining folds
2024-11-14 11:32:31,545:INFO:Declaring metric variables
2024-11-14 11:32:31,548:INFO:Importing untrained model
2024-11-14 11:32:31,551:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 11:32:31,558:INFO:Starting cross validation
2024-11-14 11:32:31,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:31,744:INFO:Calculating mean and std
2024-11-14 11:32:31,748:INFO:Creating metrics dataframe
2024-11-14 11:32:31,755:INFO:Uploading results into container
2024-11-14 11:32:31,755:INFO:Uploading model into container now
2024-11-14 11:32:31,756:INFO:_master_model_container: 9
2024-11-14 11:32:31,756:INFO:_display_container: 2
2024-11-14 11:32:31,756:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-14 11:32:31,756:INFO:create_model() successfully completed......................................
2024-11-14 11:32:31,884:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:31,884:INFO:Creating metrics dataframe
2024-11-14 11:32:31,895:INFO:Initializing Huber Regressor
2024-11-14 11:32:31,896:INFO:Total runtime is 0.2787180701891581 minutes
2024-11-14 11:32:31,899:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:31,899:INFO:Initializing create_model()
2024-11-14 11:32:31,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:31,900:INFO:Checking exceptions
2024-11-14 11:32:31,900:INFO:Importing libraries
2024-11-14 11:32:31,900:INFO:Copying training dataset
2024-11-14 11:32:31,907:INFO:Defining folds
2024-11-14 11:32:31,907:INFO:Declaring metric variables
2024-11-14 11:32:31,911:INFO:Importing untrained model
2024-11-14 11:32:31,914:INFO:Huber Regressor Imported successfully
2024-11-14 11:32:31,921:INFO:Starting cross validation
2024-11-14 11:32:31,922:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:32,209:INFO:Calculating mean and std
2024-11-14 11:32:32,213:INFO:Creating metrics dataframe
2024-11-14 11:32:32,219:INFO:Uploading results into container
2024-11-14 11:32:32,220:INFO:Uploading model into container now
2024-11-14 11:32:32,221:INFO:_master_model_container: 10
2024-11-14 11:32:32,221:INFO:_display_container: 2
2024-11-14 11:32:32,221:INFO:HuberRegressor()
2024-11-14 11:32:32,221:INFO:create_model() successfully completed......................................
2024-11-14 11:32:32,357:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:32,357:INFO:Creating metrics dataframe
2024-11-14 11:32:32,369:INFO:Initializing K Neighbors Regressor
2024-11-14 11:32:32,369:INFO:Total runtime is 0.28661028544108075 minutes
2024-11-14 11:32:32,372:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:32,373:INFO:Initializing create_model()
2024-11-14 11:32:32,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:32,373:INFO:Checking exceptions
2024-11-14 11:32:32,373:INFO:Importing libraries
2024-11-14 11:32:32,373:INFO:Copying training dataset
2024-11-14 11:32:32,380:INFO:Defining folds
2024-11-14 11:32:32,380:INFO:Declaring metric variables
2024-11-14 11:32:32,384:INFO:Importing untrained model
2024-11-14 11:32:32,388:INFO:K Neighbors Regressor Imported successfully
2024-11-14 11:32:32,394:INFO:Starting cross validation
2024-11-14 11:32:32,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:32,556:INFO:Calculating mean and std
2024-11-14 11:32:32,559:INFO:Creating metrics dataframe
2024-11-14 11:32:32,565:INFO:Uploading results into container
2024-11-14 11:32:32,566:INFO:Uploading model into container now
2024-11-14 11:32:32,567:INFO:_master_model_container: 11
2024-11-14 11:32:32,567:INFO:_display_container: 2
2024-11-14 11:32:32,568:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 11:32:32,568:INFO:create_model() successfully completed......................................
2024-11-14 11:32:32,703:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:32,703:INFO:Creating metrics dataframe
2024-11-14 11:32:32,715:INFO:Initializing Decision Tree Regressor
2024-11-14 11:32:32,715:INFO:Total runtime is 0.2923725207646688 minutes
2024-11-14 11:32:32,718:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:32,718:INFO:Initializing create_model()
2024-11-14 11:32:32,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:32,719:INFO:Checking exceptions
2024-11-14 11:32:32,719:INFO:Importing libraries
2024-11-14 11:32:32,719:INFO:Copying training dataset
2024-11-14 11:32:32,726:INFO:Defining folds
2024-11-14 11:32:32,727:INFO:Declaring metric variables
2024-11-14 11:32:32,730:INFO:Importing untrained model
2024-11-14 11:32:32,733:INFO:Decision Tree Regressor Imported successfully
2024-11-14 11:32:32,739:INFO:Starting cross validation
2024-11-14 11:32:32,740:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:32,927:INFO:Calculating mean and std
2024-11-14 11:32:32,931:INFO:Creating metrics dataframe
2024-11-14 11:32:32,939:INFO:Uploading results into container
2024-11-14 11:32:32,939:INFO:Uploading model into container now
2024-11-14 11:32:32,940:INFO:_master_model_container: 12
2024-11-14 11:32:32,940:INFO:_display_container: 2
2024-11-14 11:32:32,940:INFO:DecisionTreeRegressor(random_state=123)
2024-11-14 11:32:32,940:INFO:create_model() successfully completed......................................
2024-11-14 11:32:33,067:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:33,067:INFO:Creating metrics dataframe
2024-11-14 11:32:33,079:INFO:Initializing Random Forest Regressor
2024-11-14 11:32:33,079:INFO:Total runtime is 0.2984394470850627 minutes
2024-11-14 11:32:33,082:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:33,082:INFO:Initializing create_model()
2024-11-14 11:32:33,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:33,083:INFO:Checking exceptions
2024-11-14 11:32:33,083:INFO:Importing libraries
2024-11-14 11:32:33,083:INFO:Copying training dataset
2024-11-14 11:32:33,089:INFO:Defining folds
2024-11-14 11:32:33,090:INFO:Declaring metric variables
2024-11-14 11:32:33,093:INFO:Importing untrained model
2024-11-14 11:32:33,096:INFO:Random Forest Regressor Imported successfully
2024-11-14 11:32:33,103:INFO:Starting cross validation
2024-11-14 11:32:33,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:34,626:INFO:Calculating mean and std
2024-11-14 11:32:34,629:INFO:Creating metrics dataframe
2024-11-14 11:32:34,635:INFO:Uploading results into container
2024-11-14 11:32:34,636:INFO:Uploading model into container now
2024-11-14 11:32:34,636:INFO:_master_model_container: 13
2024-11-14 11:32:34,636:INFO:_display_container: 2
2024-11-14 11:32:34,637:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 11:32:34,637:INFO:create_model() successfully completed......................................
2024-11-14 11:32:34,766:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:34,767:INFO:Creating metrics dataframe
2024-11-14 11:32:34,779:INFO:Initializing Extra Trees Regressor
2024-11-14 11:32:34,779:INFO:Total runtime is 0.3267713348070781 minutes
2024-11-14 11:32:34,782:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:34,783:INFO:Initializing create_model()
2024-11-14 11:32:34,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:34,783:INFO:Checking exceptions
2024-11-14 11:32:34,783:INFO:Importing libraries
2024-11-14 11:32:34,783:INFO:Copying training dataset
2024-11-14 11:32:34,790:INFO:Defining folds
2024-11-14 11:32:34,790:INFO:Declaring metric variables
2024-11-14 11:32:34,793:INFO:Importing untrained model
2024-11-14 11:32:34,797:INFO:Extra Trees Regressor Imported successfully
2024-11-14 11:32:34,804:INFO:Starting cross validation
2024-11-14 11:32:34,805:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:35,652:INFO:Calculating mean and std
2024-11-14 11:32:35,654:INFO:Creating metrics dataframe
2024-11-14 11:32:35,659:INFO:Uploading results into container
2024-11-14 11:32:35,660:INFO:Uploading model into container now
2024-11-14 11:32:35,660:INFO:_master_model_container: 14
2024-11-14 11:32:35,661:INFO:_display_container: 2
2024-11-14 11:32:35,661:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 11:32:35,661:INFO:create_model() successfully completed......................................
2024-11-14 11:32:35,817:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:35,817:INFO:Creating metrics dataframe
2024-11-14 11:32:35,830:INFO:Initializing AdaBoost Regressor
2024-11-14 11:32:35,830:INFO:Total runtime is 0.3442862391471863 minutes
2024-11-14 11:32:35,833:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:35,834:INFO:Initializing create_model()
2024-11-14 11:32:35,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:35,834:INFO:Checking exceptions
2024-11-14 11:32:35,834:INFO:Importing libraries
2024-11-14 11:32:35,834:INFO:Copying training dataset
2024-11-14 11:32:35,841:INFO:Defining folds
2024-11-14 11:32:35,841:INFO:Declaring metric variables
2024-11-14 11:32:35,845:INFO:Importing untrained model
2024-11-14 11:32:35,848:INFO:AdaBoost Regressor Imported successfully
2024-11-14 11:32:35,854:INFO:Starting cross validation
2024-11-14 11:32:35,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:36,962:INFO:Calculating mean and std
2024-11-14 11:32:36,966:INFO:Creating metrics dataframe
2024-11-14 11:32:36,970:INFO:Uploading results into container
2024-11-14 11:32:36,970:INFO:Uploading model into container now
2024-11-14 11:32:36,971:INFO:_master_model_container: 15
2024-11-14 11:32:36,971:INFO:_display_container: 2
2024-11-14 11:32:36,971:INFO:AdaBoostRegressor(random_state=123)
2024-11-14 11:32:36,971:INFO:create_model() successfully completed......................................
2024-11-14 11:32:37,105:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:37,105:INFO:Creating metrics dataframe
2024-11-14 11:32:37,117:INFO:Initializing Gradient Boosting Regressor
2024-11-14 11:32:37,117:INFO:Total runtime is 0.36574256420135504 minutes
2024-11-14 11:32:37,120:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:37,121:INFO:Initializing create_model()
2024-11-14 11:32:37,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:37,121:INFO:Checking exceptions
2024-11-14 11:32:37,121:INFO:Importing libraries
2024-11-14 11:32:37,121:INFO:Copying training dataset
2024-11-14 11:32:37,128:INFO:Defining folds
2024-11-14 11:32:37,128:INFO:Declaring metric variables
2024-11-14 11:32:37,131:INFO:Importing untrained model
2024-11-14 11:32:37,134:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 11:32:37,140:INFO:Starting cross validation
2024-11-14 11:32:37,141:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:38,973:INFO:Calculating mean and std
2024-11-14 11:32:38,977:INFO:Creating metrics dataframe
2024-11-14 11:32:38,983:INFO:Uploading results into container
2024-11-14 11:32:38,984:INFO:Uploading model into container now
2024-11-14 11:32:38,984:INFO:_master_model_container: 16
2024-11-14 11:32:38,984:INFO:_display_container: 2
2024-11-14 11:32:38,985:INFO:GradientBoostingRegressor(random_state=123)
2024-11-14 11:32:38,985:INFO:create_model() successfully completed......................................
2024-11-14 11:32:39,127:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:39,128:INFO:Creating metrics dataframe
2024-11-14 11:32:39,140:INFO:Initializing Extreme Gradient Boosting
2024-11-14 11:32:39,141:INFO:Total runtime is 0.3994677623112997 minutes
2024-11-14 11:32:39,144:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:39,144:INFO:Initializing create_model()
2024-11-14 11:32:39,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:39,145:INFO:Checking exceptions
2024-11-14 11:32:39,145:INFO:Importing libraries
2024-11-14 11:32:39,145:INFO:Copying training dataset
2024-11-14 11:32:39,152:INFO:Defining folds
2024-11-14 11:32:39,152:INFO:Declaring metric variables
2024-11-14 11:32:39,156:INFO:Importing untrained model
2024-11-14 11:32:39,159:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 11:32:39,166:INFO:Starting cross validation
2024-11-14 11:32:39,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:32:39,486:INFO:Calculating mean and std
2024-11-14 11:32:39,490:INFO:Creating metrics dataframe
2024-11-14 11:32:39,496:INFO:Uploading results into container
2024-11-14 11:32:39,496:INFO:Uploading model into container now
2024-11-14 11:32:39,497:INFO:_master_model_container: 17
2024-11-14 11:32:39,497:INFO:_display_container: 2
2024-11-14 11:32:39,498:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-14 11:32:39,498:INFO:create_model() successfully completed......................................
2024-11-14 11:32:39,645:INFO:SubProcess create_model() end ==================================
2024-11-14 11:32:39,645:INFO:Creating metrics dataframe
2024-11-14 11:32:39,659:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 11:32:39,659:INFO:Total runtime is 0.4081079562505087 minutes
2024-11-14 11:32:39,662:INFO:SubProcess create_model() called ==================================
2024-11-14 11:32:39,663:INFO:Initializing create_model()
2024-11-14 11:32:39,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:32:39,663:INFO:Checking exceptions
2024-11-14 11:32:39,663:INFO:Importing libraries
2024-11-14 11:32:39,663:INFO:Copying training dataset
2024-11-14 11:32:39,671:INFO:Defining folds
2024-11-14 11:32:39,671:INFO:Declaring metric variables
2024-11-14 11:32:39,675:INFO:Importing untrained model
2024-11-14 11:32:39,678:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 11:32:39,685:INFO:Starting cross validation
2024-11-14 11:32:39,686:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:39:32,942:INFO:Calculating mean and std
2024-11-14 11:39:32,946:INFO:Creating metrics dataframe
2024-11-14 11:39:32,953:INFO:Uploading results into container
2024-11-14 11:39:32,954:INFO:Uploading model into container now
2024-11-14 11:39:32,955:INFO:_master_model_container: 18
2024-11-14 11:39:32,955:INFO:_display_container: 2
2024-11-14 11:39:32,956:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-14 11:39:32,956:INFO:create_model() successfully completed......................................
2024-11-14 11:39:33,146:INFO:SubProcess create_model() end ==================================
2024-11-14 11:39:33,146:INFO:Creating metrics dataframe
2024-11-14 11:39:33,159:INFO:Initializing CatBoost Regressor
2024-11-14 11:39:33,159:INFO:Total runtime is 7.2997801025708515 minutes
2024-11-14 11:39:33,163:INFO:SubProcess create_model() called ==================================
2024-11-14 11:39:33,163:INFO:Initializing create_model()
2024-11-14 11:39:33,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:39:33,163:INFO:Checking exceptions
2024-11-14 11:39:33,163:INFO:Importing libraries
2024-11-14 11:39:33,164:INFO:Copying training dataset
2024-11-14 11:39:33,172:INFO:Defining folds
2024-11-14 11:39:33,172:INFO:Declaring metric variables
2024-11-14 11:39:33,176:INFO:Importing untrained model
2024-11-14 11:39:33,179:INFO:CatBoost Regressor Imported successfully
2024-11-14 11:39:33,186:INFO:Starting cross validation
2024-11-14 11:39:33,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:39:47,287:INFO:Calculating mean and std
2024-11-14 11:39:47,292:INFO:Creating metrics dataframe
2024-11-14 11:39:47,298:INFO:Uploading results into container
2024-11-14 11:39:47,298:INFO:Uploading model into container now
2024-11-14 11:39:47,299:INFO:_master_model_container: 19
2024-11-14 11:39:47,300:INFO:_display_container: 2
2024-11-14 11:39:47,300:INFO:<catboost.core.CatBoostRegressor object at 0x7fc1c4c46b20>
2024-11-14 11:39:47,300:INFO:create_model() successfully completed......................................
2024-11-14 11:39:47,482:INFO:SubProcess create_model() end ==================================
2024-11-14 11:39:47,482:INFO:Creating metrics dataframe
2024-11-14 11:39:47,496:INFO:Initializing Dummy Regressor
2024-11-14 11:39:47,496:INFO:Total runtime is 7.538729957739512 minutes
2024-11-14 11:39:47,500:INFO:SubProcess create_model() called ==================================
2024-11-14 11:39:47,500:INFO:Initializing create_model()
2024-11-14 11:39:47,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4af9070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:39:47,500:INFO:Checking exceptions
2024-11-14 11:39:47,500:INFO:Importing libraries
2024-11-14 11:39:47,500:INFO:Copying training dataset
2024-11-14 11:39:47,509:INFO:Defining folds
2024-11-14 11:39:47,509:INFO:Declaring metric variables
2024-11-14 11:39:47,512:INFO:Importing untrained model
2024-11-14 11:39:47,516:INFO:Dummy Regressor Imported successfully
2024-11-14 11:39:47,522:INFO:Starting cross validation
2024-11-14 11:39:47,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:39:50,712:INFO:Calculating mean and std
2024-11-14 11:39:50,717:INFO:Creating metrics dataframe
2024-11-14 11:39:50,724:INFO:Uploading results into container
2024-11-14 11:39:50,725:INFO:Uploading model into container now
2024-11-14 11:39:50,726:INFO:_master_model_container: 20
2024-11-14 11:39:50,726:INFO:_display_container: 2
2024-11-14 11:39:50,727:INFO:DummyRegressor()
2024-11-14 11:39:50,727:INFO:create_model() successfully completed......................................
2024-11-14 11:39:50,890:INFO:SubProcess create_model() end ==================================
2024-11-14 11:39:50,890:INFO:Creating metrics dataframe
2024-11-14 11:39:50,913:INFO:Initializing create_model()
2024-11-14 11:39:50,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:39:50,913:INFO:Checking exceptions
2024-11-14 11:39:50,915:INFO:Importing libraries
2024-11-14 11:39:50,915:INFO:Copying training dataset
2024-11-14 11:39:50,922:INFO:Defining folds
2024-11-14 11:39:50,922:INFO:Declaring metric variables
2024-11-14 11:39:50,922:INFO:Importing untrained model
2024-11-14 11:39:50,922:INFO:Declaring custom model
2024-11-14 11:39:50,923:INFO:Extra Trees Regressor Imported successfully
2024-11-14 11:39:50,923:INFO:Cross validation set to False
2024-11-14 11:39:50,924:INFO:Fitting Model
2024-11-14 11:39:51,161:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 11:39:51,161:INFO:create_model() successfully completed......................................
2024-11-14 11:39:51,357:INFO:_master_model_container: 20
2024-11-14 11:39:51,357:INFO:_display_container: 2
2024-11-14 11:39:51,358:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 11:39:51,358:INFO:compare_models() successfully completed......................................
2024-11-14 11:43:32,914:INFO:Initializing create_model()
2024-11-14 11:43:32,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:43:32,914:INFO:Checking exceptions
2024-11-14 11:43:32,950:INFO:Importing libraries
2024-11-14 11:43:32,950:INFO:Copying training dataset
2024-11-14 11:43:32,959:INFO:Defining folds
2024-11-14 11:43:32,959:INFO:Declaring metric variables
2024-11-14 11:43:32,963:INFO:Importing untrained model
2024-11-14 11:43:32,967:INFO:Extra Trees Regressor Imported successfully
2024-11-14 11:43:32,974:INFO:Starting cross validation
2024-11-14 11:43:32,975:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:43:36,575:INFO:Calculating mean and std
2024-11-14 11:43:36,579:INFO:Creating metrics dataframe
2024-11-14 11:43:36,587:INFO:Finalizing model
2024-11-14 11:43:36,831:INFO:Uploading results into container
2024-11-14 11:43:36,832:INFO:Uploading model into container now
2024-11-14 11:43:36,845:INFO:_master_model_container: 21
2024-11-14 11:43:36,845:INFO:_display_container: 3
2024-11-14 11:43:36,848:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 11:43:36,848:INFO:create_model() successfully completed......................................
2024-11-14 11:44:25,228:INFO:Initializing tune_model()
2024-11-14 11:44:25,228:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>)
2024-11-14 11:44:25,228:INFO:Checking exceptions
2024-11-14 11:44:25,263:INFO:Copying training dataset
2024-11-14 11:44:25,268:INFO:Checking base model
2024-11-14 11:44:25,268:INFO:Base model : Extra Trees Regressor
2024-11-14 11:44:25,272:INFO:Declaring metric variables
2024-11-14 11:44:25,276:INFO:Defining Hyperparameters
2024-11-14 11:44:25,420:INFO:Tuning with n_jobs=-1
2024-11-14 11:44:25,420:INFO:Initializing RandomizedSearchCV
2024-11-14 11:44:48,561:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-11-14 11:45:32,730:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 11:45:32,823:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 11:45:33,238:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 11:45:33,631:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 11:45:33,749:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 11:45:34,644:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 11:46:12,343:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-11-14 11:46:12,347:INFO:Hyperparameter search completed
2024-11-14 11:46:12,348:INFO:SubProcess create_model() called ==================================
2024-11-14 11:46:12,349:INFO:Initializing create_model()
2024-11-14 11:46:12,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c55acdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'squared_error', 'bootstrap': False})
2024-11-14 11:46:12,349:INFO:Checking exceptions
2024-11-14 11:46:12,349:INFO:Importing libraries
2024-11-14 11:46:12,349:INFO:Copying training dataset
2024-11-14 11:46:12,358:INFO:Defining folds
2024-11-14 11:46:12,358:INFO:Declaring metric variables
2024-11-14 11:46:12,363:INFO:Importing untrained model
2024-11-14 11:46:12,363:INFO:Declaring custom model
2024-11-14 11:46:12,366:INFO:Extra Trees Regressor Imported successfully
2024-11-14 11:46:12,373:INFO:Starting cross validation
2024-11-14 11:46:12,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:46:13,098:INFO:Calculating mean and std
2024-11-14 11:46:13,101:INFO:Creating metrics dataframe
2024-11-14 11:46:13,110:INFO:Finalizing model
2024-11-14 11:46:13,491:INFO:Uploading results into container
2024-11-14 11:46:13,492:INFO:Uploading model into container now
2024-11-14 11:46:13,493:INFO:_master_model_container: 22
2024-11-14 11:46:13,493:INFO:_display_container: 4
2024-11-14 11:46:13,494:INFO:ExtraTreesRegressor(max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123)
2024-11-14 11:46:13,494:INFO:create_model() successfully completed......................................
2024-11-14 11:46:13,721:INFO:SubProcess create_model() end ==================================
2024-11-14 11:46:13,721:INFO:choose_better activated
2024-11-14 11:46:13,726:INFO:SubProcess create_model() called ==================================
2024-11-14 11:46:13,726:INFO:Initializing create_model()
2024-11-14 11:46:13,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 11:46:13,726:INFO:Checking exceptions
2024-11-14 11:46:13,729:INFO:Importing libraries
2024-11-14 11:46:13,729:INFO:Copying training dataset
2024-11-14 11:46:13,736:INFO:Defining folds
2024-11-14 11:46:13,736:INFO:Declaring metric variables
2024-11-14 11:46:13,736:INFO:Importing untrained model
2024-11-14 11:46:13,736:INFO:Declaring custom model
2024-11-14 11:46:13,737:INFO:Extra Trees Regressor Imported successfully
2024-11-14 11:46:13,737:INFO:Starting cross validation
2024-11-14 11:46:13,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 11:46:14,690:INFO:Calculating mean and std
2024-11-14 11:46:14,691:INFO:Creating metrics dataframe
2024-11-14 11:46:14,695:INFO:Finalizing model
2024-11-14 11:46:14,950:INFO:Uploading results into container
2024-11-14 11:46:14,951:INFO:Uploading model into container now
2024-11-14 11:46:14,952:INFO:_master_model_container: 23
2024-11-14 11:46:14,952:INFO:_display_container: 5
2024-11-14 11:46:14,953:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 11:46:14,953:INFO:create_model() successfully completed......................................
2024-11-14 11:46:15,094:INFO:SubProcess create_model() end ==================================
2024-11-14 11:46:15,094:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9809
2024-11-14 11:46:15,095:INFO:ExtraTreesRegressor(max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123) result for R2 is 0.7478
2024-11-14 11:46:15,095:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-11-14 11:46:15,095:INFO:choose_better completed
2024-11-14 11:46:15,096:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-11-14 11:46:15,108:INFO:_master_model_container: 23
2024-11-14 11:46:15,108:INFO:_display_container: 4
2024-11-14 11:46:15,109:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 11:46:15,109:INFO:tune_model() successfully completed......................................
2024-11-14 12:00:10,438:INFO:Initializing get_config()
2024-11-14 12:00:10,438:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ef66a0>, variable=None)
2024-11-14 12:17:44,632:WARNING:<ipython-input-28-b51a3270d8a6>:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  get_metrics().corr()

2024-11-14 12:19:29,331:INFO:PyCaret RegressionExperiment
2024-11-14 12:19:29,331:INFO:Logging name: reg-default-name
2024-11-14 12:19:29,331:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 12:19:29,331:INFO:version 3.2.0
2024-11-14 12:19:29,331:INFO:Initializing setup()
2024-11-14 12:19:29,331:INFO:self.USI: 0626
2024-11-14 12:19:29,331:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 12:19:29,331:INFO:Checking environment
2024-11-14 12:19:29,331:INFO:python_version: 3.8.13
2024-11-14 12:19:29,331:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 12:19:29,331:INFO:machine: x86_64
2024-11-14 12:19:29,331:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 12:19:29,331:INFO:Memory: svmem(total=270355722240, available=221558321152, percent=18.0, used=46707535872, free=73938223104, active=71818194944, inactive=64261963776, buffers=9031680, cached=149700931584, shared=195858432, slab=25249501184)
2024-11-14 12:19:29,333:INFO:Physical Core: 28
2024-11-14 12:19:29,334:INFO:Logical Core: 56
2024-11-14 12:19:29,334:INFO:Checking libraries
2024-11-14 12:19:29,334:INFO:System:
2024-11-14 12:19:29,334:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 12:19:29,334:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 12:19:29,334:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 12:19:29,334:INFO:PyCaret required dependencies:
2024-11-14 12:19:29,334:INFO:                 pip: 22.2.2
2024-11-14 12:19:29,334:INFO:          setuptools: 63.4.2
2024-11-14 12:19:29,334:INFO:             pycaret: 3.2.0
2024-11-14 12:19:29,334:INFO:             IPython: 8.12.2
2024-11-14 12:19:29,334:INFO:          ipywidgets: 7.7.1
2024-11-14 12:19:29,334:INFO:                tqdm: 4.64.1
2024-11-14 12:19:29,334:INFO:               numpy: 1.23.5
2024-11-14 12:19:29,334:INFO:              pandas: 1.5.3
2024-11-14 12:19:29,334:INFO:              jinja2: 3.1.2
2024-11-14 12:19:29,334:INFO:               scipy: 1.10.1
2024-11-14 12:19:29,334:INFO:              joblib: 1.3.0
2024-11-14 12:19:29,334:INFO:             sklearn: 1.1.2
2024-11-14 12:19:29,334:INFO:                pyod: 2.0.2
2024-11-14 12:19:29,334:INFO:            imblearn: 0.12.4
2024-11-14 12:19:29,334:INFO:   category_encoders: 2.6.4
2024-11-14 12:19:29,334:INFO:            lightgbm: 4.5.0
2024-11-14 12:19:29,334:INFO:               numba: 0.57.1
2024-11-14 12:19:29,334:INFO:            requests: 2.28.1
2024-11-14 12:19:29,334:INFO:          matplotlib: 3.5.1
2024-11-14 12:19:29,335:INFO:          scikitplot: 0.3.7
2024-11-14 12:19:29,335:INFO:         yellowbrick: 1.5
2024-11-14 12:19:29,335:INFO:              plotly: 5.24.1
2024-11-14 12:19:29,335:INFO:    plotly-resampler: Not installed
2024-11-14 12:19:29,335:INFO:             kaleido: 0.2.1
2024-11-14 12:19:29,335:INFO:           schemdraw: 0.15
2024-11-14 12:19:29,335:INFO:         statsmodels: 0.13.2
2024-11-14 12:19:29,335:INFO:              sktime: 0.21.1
2024-11-14 12:19:29,335:INFO:               tbats: 1.1.3
2024-11-14 12:19:29,335:INFO:            pmdarima: 2.0.4
2024-11-14 12:19:29,335:INFO:              psutil: 5.9.1
2024-11-14 12:19:29,335:INFO:          markupsafe: 2.1.1
2024-11-14 12:19:29,335:INFO:             pickle5: Not installed
2024-11-14 12:19:29,335:INFO:         cloudpickle: 2.1.0
2024-11-14 12:19:29,335:INFO:         deprecation: 2.1.0
2024-11-14 12:19:29,335:INFO:              xxhash: 3.5.0
2024-11-14 12:19:29,335:INFO:           wurlitzer: 3.1.1
2024-11-14 12:19:29,335:INFO:PyCaret optional dependencies:
2024-11-14 12:19:29,335:INFO:                shap: 0.44.1
2024-11-14 12:19:29,335:INFO:           interpret: 0.6.5
2024-11-14 12:19:29,335:INFO:                umap: 0.5.7
2024-11-14 12:19:29,335:INFO:     ydata_profiling: 4.6.0
2024-11-14 12:19:29,335:INFO:  explainerdashboard: 0.4.7
2024-11-14 12:19:29,335:INFO:             autoviz: Not installed
2024-11-14 12:19:29,335:INFO:           fairlearn: 0.7.0
2024-11-14 12:19:29,335:INFO:          deepchecks: Not installed
2024-11-14 12:19:29,335:INFO:             xgboost: 2.1.1
2024-11-14 12:19:29,335:INFO:            catboost: 1.2.7
2024-11-14 12:19:29,335:INFO:              kmodes: 0.12.2
2024-11-14 12:19:29,335:INFO:             mlxtend: 0.23.1
2024-11-14 12:19:29,335:INFO:       statsforecast: 1.5.0
2024-11-14 12:19:29,336:INFO:        tune_sklearn: 0.5.0
2024-11-14 12:19:29,336:INFO:                 ray: 2.10.0
2024-11-14 12:19:29,336:INFO:            hyperopt: 0.2.7
2024-11-14 12:19:29,336:INFO:              optuna: 4.1.0
2024-11-14 12:19:29,336:INFO:               skopt: 0.10.2
2024-11-14 12:19:29,336:INFO:              mlflow: 1.30.1
2024-11-14 12:19:29,336:INFO:              gradio: 3.50.2
2024-11-14 12:19:29,336:INFO:             fastapi: 0.115.5
2024-11-14 12:19:29,336:INFO:             uvicorn: 0.32.0
2024-11-14 12:19:29,336:INFO:              m2cgen: 0.10.0
2024-11-14 12:19:29,336:INFO:           evidently: 0.2.8
2024-11-14 12:19:29,336:INFO:               fugue: 0.8.6
2024-11-14 12:19:29,336:INFO:           streamlit: Not installed
2024-11-14 12:19:29,336:INFO:             prophet: Not installed
2024-11-14 12:19:29,336:INFO:None
2024-11-14 12:19:29,336:INFO:Set up data.
2024-11-14 12:19:29,346:INFO:Set up folding strategy.
2024-11-14 12:19:29,346:INFO:Set up train/test split.
2024-11-14 12:19:29,352:INFO:Set up index.
2024-11-14 12:19:29,353:INFO:Assigning column types.
2024-11-14 12:19:29,361:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 12:19:29,361:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,367:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,443:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,483:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,484:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:29,486:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:29,487:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,491:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,590:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:29,593:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:29,593:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 12:19:29,597:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,602:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,654:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,695:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:29,697:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:29,702:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,706:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,798:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,799:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:29,801:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:29,802:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 12:19:29,810:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,903:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:29,905:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:29,914:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:19:29,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:19:30,006:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:19:30,007:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:30,009:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:30,010:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 12:19:30,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:19:30,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:19:30,114:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:30,117:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:30,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:19:30,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:19:30,216:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:30,218:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:30,219:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 12:19:30,280:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:19:30,320:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:30,323:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:30,384:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:19:30,423:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:30,425:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:30,426:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 12:19:30,526:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:30,528:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:30,629:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:30,631:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:30,632:INFO:Preparing preprocessing pipeline...
2024-11-14 12:19:30,633:INFO:Set up simple imputation.
2024-11-14 12:19:30,651:INFO:Finished creating preprocessing pipeline.
2024-11-14 12:19:30,655:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 12:19:30,655:INFO:Creating final display dataframe.
2024-11-14 12:19:30,711:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              0626
2024-11-14 12:19:30,811:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:30,813:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:30,913:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:19:30,916:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:19:30,916:INFO:setup() successfully completed in 1.59s...............
2024-11-14 12:19:30,920:INFO:Initializing compare_models()
2024-11-14 12:19:30,920:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 12:19:30,920:INFO:Checking exceptions
2024-11-14 12:19:30,923:INFO:Preparing display monitor
2024-11-14 12:19:30,961:INFO:Initializing Linear Regression
2024-11-14 12:19:30,961:INFO:Total runtime is 1.9073486328125e-06 minutes
2024-11-14 12:19:30,964:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:30,965:INFO:Initializing create_model()
2024-11-14 12:19:30,965:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:30,965:INFO:Checking exceptions
2024-11-14 12:19:30,965:INFO:Importing libraries
2024-11-14 12:19:30,965:INFO:Copying training dataset
2024-11-14 12:19:30,970:INFO:Defining folds
2024-11-14 12:19:30,970:INFO:Declaring metric variables
2024-11-14 12:19:30,973:INFO:Importing untrained model
2024-11-14 12:19:30,977:INFO:Linear Regression Imported successfully
2024-11-14 12:19:30,983:INFO:Starting cross validation
2024-11-14 12:19:30,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:35,142:INFO:Calculating mean and std
2024-11-14 12:19:35,148:INFO:Creating metrics dataframe
2024-11-14 12:19:35,154:INFO:Uploading results into container
2024-11-14 12:19:35,155:INFO:Uploading model into container now
2024-11-14 12:19:35,156:INFO:_master_model_container: 1
2024-11-14 12:19:35,156:INFO:_display_container: 2
2024-11-14 12:19:35,157:INFO:LinearRegression(n_jobs=-1)
2024-11-14 12:19:35,157:INFO:create_model() successfully completed......................................
2024-11-14 12:19:35,368:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:35,368:INFO:Creating metrics dataframe
2024-11-14 12:19:35,378:INFO:Initializing Lasso Regression
2024-11-14 12:19:35,378:INFO:Total runtime is 0.07362412214279175 minutes
2024-11-14 12:19:35,381:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:35,382:INFO:Initializing create_model()
2024-11-14 12:19:35,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:35,382:INFO:Checking exceptions
2024-11-14 12:19:35,382:INFO:Importing libraries
2024-11-14 12:19:35,382:INFO:Copying training dataset
2024-11-14 12:19:35,390:INFO:Defining folds
2024-11-14 12:19:35,391:INFO:Declaring metric variables
2024-11-14 12:19:35,394:INFO:Importing untrained model
2024-11-14 12:19:35,398:INFO:Lasso Regression Imported successfully
2024-11-14 12:19:35,404:INFO:Starting cross validation
2024-11-14 12:19:35,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:38,449:INFO:Calculating mean and std
2024-11-14 12:19:38,453:INFO:Creating metrics dataframe
2024-11-14 12:19:38,460:INFO:Uploading results into container
2024-11-14 12:19:38,460:INFO:Uploading model into container now
2024-11-14 12:19:38,461:INFO:_master_model_container: 2
2024-11-14 12:19:38,461:INFO:_display_container: 2
2024-11-14 12:19:38,462:INFO:Lasso(random_state=123)
2024-11-14 12:19:38,462:INFO:create_model() successfully completed......................................
2024-11-14 12:19:38,605:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:38,605:INFO:Creating metrics dataframe
2024-11-14 12:19:38,614:INFO:Initializing Ridge Regression
2024-11-14 12:19:38,615:INFO:Total runtime is 0.12756701707839965 minutes
2024-11-14 12:19:38,618:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:38,618:INFO:Initializing create_model()
2024-11-14 12:19:38,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:38,618:INFO:Checking exceptions
2024-11-14 12:19:38,619:INFO:Importing libraries
2024-11-14 12:19:38,619:INFO:Copying training dataset
2024-11-14 12:19:38,626:INFO:Defining folds
2024-11-14 12:19:38,626:INFO:Declaring metric variables
2024-11-14 12:19:38,629:INFO:Importing untrained model
2024-11-14 12:19:38,633:INFO:Ridge Regression Imported successfully
2024-11-14 12:19:38,639:INFO:Starting cross validation
2024-11-14 12:19:38,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:41,560:INFO:Calculating mean and std
2024-11-14 12:19:41,564:INFO:Creating metrics dataframe
2024-11-14 12:19:41,571:INFO:Uploading results into container
2024-11-14 12:19:41,571:INFO:Uploading model into container now
2024-11-14 12:19:41,572:INFO:_master_model_container: 3
2024-11-14 12:19:41,572:INFO:_display_container: 2
2024-11-14 12:19:41,572:INFO:Ridge(random_state=123)
2024-11-14 12:19:41,572:INFO:create_model() successfully completed......................................
2024-11-14 12:19:41,707:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:41,707:INFO:Creating metrics dataframe
2024-11-14 12:19:41,718:INFO:Initializing Elastic Net
2024-11-14 12:19:41,718:INFO:Total runtime is 0.17928873697916667 minutes
2024-11-14 12:19:41,721:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:41,722:INFO:Initializing create_model()
2024-11-14 12:19:41,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:41,722:INFO:Checking exceptions
2024-11-14 12:19:41,722:INFO:Importing libraries
2024-11-14 12:19:41,722:INFO:Copying training dataset
2024-11-14 12:19:41,729:INFO:Defining folds
2024-11-14 12:19:41,729:INFO:Declaring metric variables
2024-11-14 12:19:41,732:INFO:Importing untrained model
2024-11-14 12:19:41,736:INFO:Elastic Net Imported successfully
2024-11-14 12:19:41,742:INFO:Starting cross validation
2024-11-14 12:19:41,743:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:44,588:INFO:Calculating mean and std
2024-11-14 12:19:44,592:INFO:Creating metrics dataframe
2024-11-14 12:19:44,599:INFO:Uploading results into container
2024-11-14 12:19:44,600:INFO:Uploading model into container now
2024-11-14 12:19:44,601:INFO:_master_model_container: 4
2024-11-14 12:19:44,601:INFO:_display_container: 2
2024-11-14 12:19:44,601:INFO:ElasticNet(random_state=123)
2024-11-14 12:19:44,601:INFO:create_model() successfully completed......................................
2024-11-14 12:19:44,741:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:44,741:INFO:Creating metrics dataframe
2024-11-14 12:19:44,752:INFO:Initializing Least Angle Regression
2024-11-14 12:19:44,752:INFO:Total runtime is 0.22985055446624755 minutes
2024-11-14 12:19:44,755:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:44,755:INFO:Initializing create_model()
2024-11-14 12:19:44,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:44,755:INFO:Checking exceptions
2024-11-14 12:19:44,756:INFO:Importing libraries
2024-11-14 12:19:44,756:INFO:Copying training dataset
2024-11-14 12:19:44,763:INFO:Defining folds
2024-11-14 12:19:44,763:INFO:Declaring metric variables
2024-11-14 12:19:44,766:INFO:Importing untrained model
2024-11-14 12:19:44,770:INFO:Least Angle Regression Imported successfully
2024-11-14 12:19:44,776:INFO:Starting cross validation
2024-11-14 12:19:44,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:47,411:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:47,424:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:47,455:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:47,456:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:47,485:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:47,536:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:47,546:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:47,563:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:47,573:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:47,619:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:47,630:INFO:Calculating mean and std
2024-11-14 12:19:47,634:INFO:Creating metrics dataframe
2024-11-14 12:19:47,640:INFO:Uploading results into container
2024-11-14 12:19:47,641:INFO:Uploading model into container now
2024-11-14 12:19:47,642:INFO:_master_model_container: 5
2024-11-14 12:19:47,642:INFO:_display_container: 2
2024-11-14 12:19:47,642:INFO:Lars(random_state=123)
2024-11-14 12:19:47,642:INFO:create_model() successfully completed......................................
2024-11-14 12:19:47,781:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:47,781:INFO:Creating metrics dataframe
2024-11-14 12:19:47,792:INFO:Initializing Lasso Least Angle Regression
2024-11-14 12:19:47,792:INFO:Total runtime is 0.2805198073387146 minutes
2024-11-14 12:19:47,795:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:47,796:INFO:Initializing create_model()
2024-11-14 12:19:47,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:47,796:INFO:Checking exceptions
2024-11-14 12:19:47,796:INFO:Importing libraries
2024-11-14 12:19:47,796:INFO:Copying training dataset
2024-11-14 12:19:47,803:INFO:Defining folds
2024-11-14 12:19:47,803:INFO:Declaring metric variables
2024-11-14 12:19:47,806:INFO:Importing untrained model
2024-11-14 12:19:47,810:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 12:19:47,816:INFO:Starting cross validation
2024-11-14 12:19:47,817:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:47,903:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:19:47,912:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:19:47,914:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:19:47,920:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:19:50,365:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:19:50,366:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:19:50,503:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:19:50,534:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:19:50,537:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:19:50,643:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:19:50,661:INFO:Calculating mean and std
2024-11-14 12:19:50,664:INFO:Creating metrics dataframe
2024-11-14 12:19:50,671:INFO:Uploading results into container
2024-11-14 12:19:50,672:INFO:Uploading model into container now
2024-11-14 12:19:50,672:INFO:_master_model_container: 6
2024-11-14 12:19:50,672:INFO:_display_container: 2
2024-11-14 12:19:50,673:INFO:LassoLars(random_state=123)
2024-11-14 12:19:50,673:INFO:create_model() successfully completed......................................
2024-11-14 12:19:50,800:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:50,800:INFO:Creating metrics dataframe
2024-11-14 12:19:50,811:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 12:19:50,811:INFO:Total runtime is 0.330840003490448 minutes
2024-11-14 12:19:50,814:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:50,815:INFO:Initializing create_model()
2024-11-14 12:19:50,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:50,815:INFO:Checking exceptions
2024-11-14 12:19:50,815:INFO:Importing libraries
2024-11-14 12:19:50,815:INFO:Copying training dataset
2024-11-14 12:19:50,822:INFO:Defining folds
2024-11-14 12:19:50,822:INFO:Declaring metric variables
2024-11-14 12:19:50,826:INFO:Importing untrained model
2024-11-14 12:19:50,829:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 12:19:50,838:INFO:Starting cross validation
2024-11-14 12:19:50,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:50,870:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:50,877:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:50,882:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:50,888:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:50,894:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:50,905:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:50,905:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:50,914:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:50,918:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:50,926:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:19:50,945:INFO:Calculating mean and std
2024-11-14 12:19:50,948:INFO:Creating metrics dataframe
2024-11-14 12:19:50,955:INFO:Uploading results into container
2024-11-14 12:19:50,956:INFO:Uploading model into container now
2024-11-14 12:19:50,956:INFO:_master_model_container: 7
2024-11-14 12:19:50,956:INFO:_display_container: 2
2024-11-14 12:19:50,956:INFO:OrthogonalMatchingPursuit()
2024-11-14 12:19:50,957:INFO:create_model() successfully completed......................................
2024-11-14 12:19:51,124:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:51,124:INFO:Creating metrics dataframe
2024-11-14 12:19:51,136:INFO:Initializing Bayesian Ridge
2024-11-14 12:19:51,136:INFO:Total runtime is 0.33625564177831013 minutes
2024-11-14 12:19:51,139:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:51,140:INFO:Initializing create_model()
2024-11-14 12:19:51,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:51,140:INFO:Checking exceptions
2024-11-14 12:19:51,140:INFO:Importing libraries
2024-11-14 12:19:51,140:INFO:Copying training dataset
2024-11-14 12:19:51,147:INFO:Defining folds
2024-11-14 12:19:51,147:INFO:Declaring metric variables
2024-11-14 12:19:51,150:INFO:Importing untrained model
2024-11-14 12:19:51,154:INFO:Bayesian Ridge Imported successfully
2024-11-14 12:19:51,161:INFO:Starting cross validation
2024-11-14 12:19:51,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:51,256:INFO:Calculating mean and std
2024-11-14 12:19:51,260:INFO:Creating metrics dataframe
2024-11-14 12:19:51,267:INFO:Uploading results into container
2024-11-14 12:19:51,267:INFO:Uploading model into container now
2024-11-14 12:19:51,268:INFO:_master_model_container: 8
2024-11-14 12:19:51,268:INFO:_display_container: 2
2024-11-14 12:19:51,268:INFO:BayesianRidge()
2024-11-14 12:19:51,268:INFO:create_model() successfully completed......................................
2024-11-14 12:19:51,414:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:51,414:INFO:Creating metrics dataframe
2024-11-14 12:19:51,426:INFO:Initializing Passive Aggressive Regressor
2024-11-14 12:19:51,426:INFO:Total runtime is 0.34109229644139605 minutes
2024-11-14 12:19:51,431:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:51,431:INFO:Initializing create_model()
2024-11-14 12:19:51,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:51,431:INFO:Checking exceptions
2024-11-14 12:19:51,432:INFO:Importing libraries
2024-11-14 12:19:51,432:INFO:Copying training dataset
2024-11-14 12:19:51,439:INFO:Defining folds
2024-11-14 12:19:51,439:INFO:Declaring metric variables
2024-11-14 12:19:51,442:INFO:Importing untrained model
2024-11-14 12:19:51,446:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 12:19:51,452:INFO:Starting cross validation
2024-11-14 12:19:51,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:51,662:INFO:Calculating mean and std
2024-11-14 12:19:51,666:INFO:Creating metrics dataframe
2024-11-14 12:19:51,673:INFO:Uploading results into container
2024-11-14 12:19:51,673:INFO:Uploading model into container now
2024-11-14 12:19:51,674:INFO:_master_model_container: 9
2024-11-14 12:19:51,674:INFO:_display_container: 2
2024-11-14 12:19:51,675:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-14 12:19:51,675:INFO:create_model() successfully completed......................................
2024-11-14 12:19:51,864:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:51,864:INFO:Creating metrics dataframe
2024-11-14 12:19:51,876:INFO:Initializing Huber Regressor
2024-11-14 12:19:51,876:INFO:Total runtime is 0.3485885461171468 minutes
2024-11-14 12:19:51,879:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:51,880:INFO:Initializing create_model()
2024-11-14 12:19:51,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:51,880:INFO:Checking exceptions
2024-11-14 12:19:51,880:INFO:Importing libraries
2024-11-14 12:19:51,880:INFO:Copying training dataset
2024-11-14 12:19:51,888:INFO:Defining folds
2024-11-14 12:19:51,888:INFO:Declaring metric variables
2024-11-14 12:19:51,892:INFO:Importing untrained model
2024-11-14 12:19:51,896:INFO:Huber Regressor Imported successfully
2024-11-14 12:19:51,902:INFO:Starting cross validation
2024-11-14 12:19:51,903:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:52,183:INFO:Calculating mean and std
2024-11-14 12:19:52,187:INFO:Creating metrics dataframe
2024-11-14 12:19:52,192:INFO:Uploading results into container
2024-11-14 12:19:52,193:INFO:Uploading model into container now
2024-11-14 12:19:52,194:INFO:_master_model_container: 10
2024-11-14 12:19:52,194:INFO:_display_container: 2
2024-11-14 12:19:52,194:INFO:HuberRegressor()
2024-11-14 12:19:52,194:INFO:create_model() successfully completed......................................
2024-11-14 12:19:52,343:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:52,344:INFO:Creating metrics dataframe
2024-11-14 12:19:52,355:INFO:Initializing K Neighbors Regressor
2024-11-14 12:19:52,355:INFO:Total runtime is 0.3565794785817464 minutes
2024-11-14 12:19:52,359:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:52,359:INFO:Initializing create_model()
2024-11-14 12:19:52,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:52,359:INFO:Checking exceptions
2024-11-14 12:19:52,360:INFO:Importing libraries
2024-11-14 12:19:52,360:INFO:Copying training dataset
2024-11-14 12:19:52,367:INFO:Defining folds
2024-11-14 12:19:52,367:INFO:Declaring metric variables
2024-11-14 12:19:52,371:INFO:Importing untrained model
2024-11-14 12:19:52,374:INFO:K Neighbors Regressor Imported successfully
2024-11-14 12:19:52,381:INFO:Starting cross validation
2024-11-14 12:19:52,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:52,552:INFO:Calculating mean and std
2024-11-14 12:19:52,557:INFO:Creating metrics dataframe
2024-11-14 12:19:52,562:INFO:Uploading results into container
2024-11-14 12:19:52,563:INFO:Uploading model into container now
2024-11-14 12:19:52,564:INFO:_master_model_container: 11
2024-11-14 12:19:52,564:INFO:_display_container: 2
2024-11-14 12:19:52,564:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 12:19:52,564:INFO:create_model() successfully completed......................................
2024-11-14 12:19:52,713:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:52,713:INFO:Creating metrics dataframe
2024-11-14 12:19:52,727:INFO:Initializing Decision Tree Regressor
2024-11-14 12:19:52,728:INFO:Total runtime is 0.362781814734141 minutes
2024-11-14 12:19:52,732:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:52,732:INFO:Initializing create_model()
2024-11-14 12:19:52,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:52,732:INFO:Checking exceptions
2024-11-14 12:19:52,732:INFO:Importing libraries
2024-11-14 12:19:52,732:INFO:Copying training dataset
2024-11-14 12:19:52,741:INFO:Defining folds
2024-11-14 12:19:52,741:INFO:Declaring metric variables
2024-11-14 12:19:52,745:INFO:Importing untrained model
2024-11-14 12:19:52,749:INFO:Decision Tree Regressor Imported successfully
2024-11-14 12:19:52,757:INFO:Starting cross validation
2024-11-14 12:19:52,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:52,934:INFO:Calculating mean and std
2024-11-14 12:19:52,937:INFO:Creating metrics dataframe
2024-11-14 12:19:52,942:INFO:Uploading results into container
2024-11-14 12:19:52,943:INFO:Uploading model into container now
2024-11-14 12:19:52,943:INFO:_master_model_container: 12
2024-11-14 12:19:52,944:INFO:_display_container: 2
2024-11-14 12:19:52,944:INFO:DecisionTreeRegressor(random_state=123)
2024-11-14 12:19:52,944:INFO:create_model() successfully completed......................................
2024-11-14 12:19:53,089:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:53,089:INFO:Creating metrics dataframe
2024-11-14 12:19:53,100:INFO:Initializing Random Forest Regressor
2024-11-14 12:19:53,101:INFO:Total runtime is 0.3689987063407898 minutes
2024-11-14 12:19:53,104:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:53,104:INFO:Initializing create_model()
2024-11-14 12:19:53,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:53,104:INFO:Checking exceptions
2024-11-14 12:19:53,105:INFO:Importing libraries
2024-11-14 12:19:53,105:INFO:Copying training dataset
2024-11-14 12:19:53,112:INFO:Defining folds
2024-11-14 12:19:53,112:INFO:Declaring metric variables
2024-11-14 12:19:53,115:INFO:Importing untrained model
2024-11-14 12:19:53,119:INFO:Random Forest Regressor Imported successfully
2024-11-14 12:19:53,126:INFO:Starting cross validation
2024-11-14 12:19:53,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:54,593:INFO:Calculating mean and std
2024-11-14 12:19:54,596:INFO:Creating metrics dataframe
2024-11-14 12:19:54,602:INFO:Uploading results into container
2024-11-14 12:19:54,603:INFO:Uploading model into container now
2024-11-14 12:19:54,604:INFO:_master_model_container: 13
2024-11-14 12:19:54,604:INFO:_display_container: 2
2024-11-14 12:19:54,605:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:19:54,605:INFO:create_model() successfully completed......................................
2024-11-14 12:19:54,735:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:54,735:INFO:Creating metrics dataframe
2024-11-14 12:19:54,747:INFO:Initializing Extra Trees Regressor
2024-11-14 12:19:54,747:INFO:Total runtime is 0.3964405536651611 minutes
2024-11-14 12:19:54,750:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:54,751:INFO:Initializing create_model()
2024-11-14 12:19:54,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:54,751:INFO:Checking exceptions
2024-11-14 12:19:54,751:INFO:Importing libraries
2024-11-14 12:19:54,751:INFO:Copying training dataset
2024-11-14 12:19:54,758:INFO:Defining folds
2024-11-14 12:19:54,759:INFO:Declaring metric variables
2024-11-14 12:19:54,762:INFO:Importing untrained model
2024-11-14 12:19:54,765:INFO:Extra Trees Regressor Imported successfully
2024-11-14 12:19:54,774:INFO:Starting cross validation
2024-11-14 12:19:54,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:55,597:INFO:Calculating mean and std
2024-11-14 12:19:55,601:INFO:Creating metrics dataframe
2024-11-14 12:19:55,606:INFO:Uploading results into container
2024-11-14 12:19:55,606:INFO:Uploading model into container now
2024-11-14 12:19:55,607:INFO:_master_model_container: 14
2024-11-14 12:19:55,607:INFO:_display_container: 2
2024-11-14 12:19:55,608:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:19:55,608:INFO:create_model() successfully completed......................................
2024-11-14 12:19:55,745:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:55,745:INFO:Creating metrics dataframe
2024-11-14 12:19:55,757:INFO:Initializing AdaBoost Regressor
2024-11-14 12:19:55,757:INFO:Total runtime is 0.4132732033729553 minutes
2024-11-14 12:19:55,760:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:55,761:INFO:Initializing create_model()
2024-11-14 12:19:55,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:55,761:INFO:Checking exceptions
2024-11-14 12:19:55,761:INFO:Importing libraries
2024-11-14 12:19:55,761:INFO:Copying training dataset
2024-11-14 12:19:55,768:INFO:Defining folds
2024-11-14 12:19:55,769:INFO:Declaring metric variables
2024-11-14 12:19:55,772:INFO:Importing untrained model
2024-11-14 12:19:55,776:INFO:AdaBoost Regressor Imported successfully
2024-11-14 12:19:55,782:INFO:Starting cross validation
2024-11-14 12:19:55,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:56,700:INFO:Calculating mean and std
2024-11-14 12:19:56,704:INFO:Creating metrics dataframe
2024-11-14 12:19:56,712:INFO:Uploading results into container
2024-11-14 12:19:56,713:INFO:Uploading model into container now
2024-11-14 12:19:56,713:INFO:_master_model_container: 15
2024-11-14 12:19:56,713:INFO:_display_container: 2
2024-11-14 12:19:56,714:INFO:AdaBoostRegressor(random_state=123)
2024-11-14 12:19:56,714:INFO:create_model() successfully completed......................................
2024-11-14 12:19:56,892:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:56,892:INFO:Creating metrics dataframe
2024-11-14 12:19:56,906:INFO:Initializing Gradient Boosting Regressor
2024-11-14 12:19:56,906:INFO:Total runtime is 0.4324197292327881 minutes
2024-11-14 12:19:56,909:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:56,909:INFO:Initializing create_model()
2024-11-14 12:19:56,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:56,910:INFO:Checking exceptions
2024-11-14 12:19:56,910:INFO:Importing libraries
2024-11-14 12:19:56,910:INFO:Copying training dataset
2024-11-14 12:19:56,917:INFO:Defining folds
2024-11-14 12:19:56,918:INFO:Declaring metric variables
2024-11-14 12:19:56,921:INFO:Importing untrained model
2024-11-14 12:19:56,925:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 12:19:56,931:INFO:Starting cross validation
2024-11-14 12:19:56,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:58,306:INFO:Calculating mean and std
2024-11-14 12:19:58,310:INFO:Creating metrics dataframe
2024-11-14 12:19:58,315:INFO:Uploading results into container
2024-11-14 12:19:58,316:INFO:Uploading model into container now
2024-11-14 12:19:58,316:INFO:_master_model_container: 16
2024-11-14 12:19:58,317:INFO:_display_container: 2
2024-11-14 12:19:58,317:INFO:GradientBoostingRegressor(random_state=123)
2024-11-14 12:19:58,317:INFO:create_model() successfully completed......................................
2024-11-14 12:19:58,476:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:58,476:INFO:Creating metrics dataframe
2024-11-14 12:19:58,489:INFO:Initializing Extreme Gradient Boosting
2024-11-14 12:19:58,489:INFO:Total runtime is 0.45881178776423137 minutes
2024-11-14 12:19:58,493:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:58,493:INFO:Initializing create_model()
2024-11-14 12:19:58,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:58,493:INFO:Checking exceptions
2024-11-14 12:19:58,493:INFO:Importing libraries
2024-11-14 12:19:58,493:INFO:Copying training dataset
2024-11-14 12:19:58,501:INFO:Defining folds
2024-11-14 12:19:58,502:INFO:Declaring metric variables
2024-11-14 12:19:58,505:INFO:Importing untrained model
2024-11-14 12:19:58,509:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 12:19:58,516:INFO:Starting cross validation
2024-11-14 12:19:58,516:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:19:58,888:INFO:Calculating mean and std
2024-11-14 12:19:58,892:INFO:Creating metrics dataframe
2024-11-14 12:19:58,899:INFO:Uploading results into container
2024-11-14 12:19:58,900:INFO:Uploading model into container now
2024-11-14 12:19:58,900:INFO:_master_model_container: 17
2024-11-14 12:19:58,900:INFO:_display_container: 2
2024-11-14 12:19:58,901:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-14 12:19:58,901:INFO:create_model() successfully completed......................................
2024-11-14 12:19:59,037:INFO:SubProcess create_model() end ==================================
2024-11-14 12:19:59,037:INFO:Creating metrics dataframe
2024-11-14 12:19:59,050:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 12:19:59,050:INFO:Total runtime is 0.4681536595026652 minutes
2024-11-14 12:19:59,053:INFO:SubProcess create_model() called ==================================
2024-11-14 12:19:59,054:INFO:Initializing create_model()
2024-11-14 12:19:59,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4ce7280>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1dd59d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:19:59,054:INFO:Checking exceptions
2024-11-14 12:19:59,054:INFO:Importing libraries
2024-11-14 12:19:59,054:INFO:Copying training dataset
2024-11-14 12:19:59,061:INFO:Defining folds
2024-11-14 12:19:59,062:INFO:Declaring metric variables
2024-11-14 12:19:59,065:INFO:Importing untrained model
2024-11-14 12:19:59,069:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 12:19:59,076:INFO:Starting cross validation
2024-11-14 12:19:59,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:24:36,324:INFO:PyCaret RegressionExperiment
2024-11-14 12:24:36,325:INFO:Logging name: reg-default-name
2024-11-14 12:24:36,325:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 12:24:36,325:INFO:version 3.2.0
2024-11-14 12:24:36,325:INFO:Initializing setup()
2024-11-14 12:24:36,325:INFO:self.USI: 04d9
2024-11-14 12:24:36,325:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 12:24:36,325:INFO:Checking environment
2024-11-14 12:24:36,325:INFO:python_version: 3.8.13
2024-11-14 12:24:36,325:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 12:24:36,325:INFO:machine: x86_64
2024-11-14 12:24:36,325:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 12:24:36,326:INFO:Memory: svmem(total=270355722240, available=221351415808, percent=18.1, used=46914387968, free=73335873536, active=71826268160, inactive=64840167424, buffers=10100736, cached=150095360000, shared=195837952, slab=25255264256)
2024-11-14 12:24:36,330:INFO:Physical Core: 28
2024-11-14 12:24:36,330:INFO:Logical Core: 56
2024-11-14 12:24:36,330:INFO:Checking libraries
2024-11-14 12:24:36,330:INFO:System:
2024-11-14 12:24:36,330:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 12:24:36,330:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 12:24:36,330:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 12:24:36,330:INFO:PyCaret required dependencies:
2024-11-14 12:24:36,330:INFO:                 pip: 22.2.2
2024-11-14 12:24:36,330:INFO:          setuptools: 63.4.2
2024-11-14 12:24:36,331:INFO:             pycaret: 3.2.0
2024-11-14 12:24:36,331:INFO:             IPython: 8.12.2
2024-11-14 12:24:36,331:INFO:          ipywidgets: 7.7.1
2024-11-14 12:24:36,331:INFO:                tqdm: 4.64.1
2024-11-14 12:24:36,331:INFO:               numpy: 1.23.5
2024-11-14 12:24:36,331:INFO:              pandas: 1.5.3
2024-11-14 12:24:36,331:INFO:              jinja2: 3.1.2
2024-11-14 12:24:36,331:INFO:               scipy: 1.10.1
2024-11-14 12:24:36,331:INFO:              joblib: 1.3.0
2024-11-14 12:24:36,331:INFO:             sklearn: 1.1.2
2024-11-14 12:24:36,331:INFO:                pyod: 2.0.2
2024-11-14 12:24:36,331:INFO:            imblearn: 0.12.4
2024-11-14 12:24:36,331:INFO:   category_encoders: 2.6.4
2024-11-14 12:24:36,331:INFO:            lightgbm: 4.5.0
2024-11-14 12:24:36,331:INFO:               numba: 0.57.1
2024-11-14 12:24:36,331:INFO:            requests: 2.28.1
2024-11-14 12:24:36,332:INFO:          matplotlib: 3.5.1
2024-11-14 12:24:36,332:INFO:          scikitplot: 0.3.7
2024-11-14 12:24:36,332:INFO:         yellowbrick: 1.5
2024-11-14 12:24:36,332:INFO:              plotly: 5.24.1
2024-11-14 12:24:36,332:INFO:    plotly-resampler: Not installed
2024-11-14 12:24:36,332:INFO:             kaleido: 0.2.1
2024-11-14 12:24:36,332:INFO:           schemdraw: 0.15
2024-11-14 12:24:36,332:INFO:         statsmodels: 0.13.2
2024-11-14 12:24:36,332:INFO:              sktime: 0.21.1
2024-11-14 12:24:36,332:INFO:               tbats: 1.1.3
2024-11-14 12:24:36,332:INFO:            pmdarima: 2.0.4
2024-11-14 12:24:36,332:INFO:              psutil: 5.9.1
2024-11-14 12:24:36,332:INFO:          markupsafe: 2.1.1
2024-11-14 12:24:36,332:INFO:             pickle5: Not installed
2024-11-14 12:24:36,332:INFO:         cloudpickle: 2.1.0
2024-11-14 12:24:36,332:INFO:         deprecation: 2.1.0
2024-11-14 12:24:36,332:INFO:              xxhash: 3.5.0
2024-11-14 12:24:36,333:INFO:           wurlitzer: 3.1.1
2024-11-14 12:24:36,333:INFO:PyCaret optional dependencies:
2024-11-14 12:24:36,333:INFO:                shap: 0.44.1
2024-11-14 12:24:36,333:INFO:           interpret: 0.6.5
2024-11-14 12:24:36,333:INFO:                umap: 0.5.7
2024-11-14 12:24:36,333:INFO:     ydata_profiling: 4.6.0
2024-11-14 12:24:36,333:INFO:  explainerdashboard: 0.4.7
2024-11-14 12:24:36,333:INFO:             autoviz: Not installed
2024-11-14 12:24:36,333:INFO:           fairlearn: 0.7.0
2024-11-14 12:24:36,333:INFO:          deepchecks: Not installed
2024-11-14 12:24:36,333:INFO:             xgboost: 2.1.1
2024-11-14 12:24:36,333:INFO:            catboost: 1.2.7
2024-11-14 12:24:36,333:INFO:              kmodes: 0.12.2
2024-11-14 12:24:36,333:INFO:             mlxtend: 0.23.1
2024-11-14 12:24:36,333:INFO:       statsforecast: 1.5.0
2024-11-14 12:24:36,333:INFO:        tune_sklearn: 0.5.0
2024-11-14 12:24:36,334:INFO:                 ray: 2.10.0
2024-11-14 12:24:36,334:INFO:            hyperopt: 0.2.7
2024-11-14 12:24:36,334:INFO:              optuna: 4.1.0
2024-11-14 12:24:36,334:INFO:               skopt: 0.10.2
2024-11-14 12:24:36,334:INFO:              mlflow: 1.30.1
2024-11-14 12:24:36,334:INFO:              gradio: 3.50.2
2024-11-14 12:24:36,334:INFO:             fastapi: 0.115.5
2024-11-14 12:24:36,334:INFO:             uvicorn: 0.32.0
2024-11-14 12:24:36,334:INFO:              m2cgen: 0.10.0
2024-11-14 12:24:36,334:INFO:           evidently: 0.2.8
2024-11-14 12:24:36,334:INFO:               fugue: 0.8.6
2024-11-14 12:24:36,334:INFO:           streamlit: Not installed
2024-11-14 12:24:36,334:INFO:             prophet: Not installed
2024-11-14 12:24:36,334:INFO:None
2024-11-14 12:24:36,334:INFO:Set up data.
2024-11-14 12:24:36,344:INFO:Set up folding strategy.
2024-11-14 12:24:36,344:INFO:Set up train/test split.
2024-11-14 12:24:36,350:INFO:Set up index.
2024-11-14 12:24:36,351:INFO:Assigning column types.
2024-11-14 12:24:36,356:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 12:24:36,356:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,361:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,474:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:36,477:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:36,477:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,482:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,486:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,576:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,577:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:36,579:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:36,579:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 12:24:36,584:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,588:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,640:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,680:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:36,682:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:36,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,690:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,742:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,782:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,785:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:36,787:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:36,787:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 12:24:36,796:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,887:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,888:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:36,890:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:36,899:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:24:36,990:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:36,993:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:36,993:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 12:24:37,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:24:37,095:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:24:37,095:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:37,098:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:37,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:24:37,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:24:37,199:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:37,201:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:37,202:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 12:24:37,261:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:24:37,300:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:37,302:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:37,364:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:24:37,405:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:37,407:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:37,408:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 12:24:37,507:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:37,509:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:37,610:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:37,613:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:37,614:INFO:Preparing preprocessing pipeline...
2024-11-14 12:24:37,614:INFO:Set up simple imputation.
2024-11-14 12:24:37,633:INFO:Finished creating preprocessing pipeline.
2024-11-14 12:24:37,636:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 12:24:37,637:INFO:Creating final display dataframe.
2024-11-14 12:24:37,691:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment      MlflowLogger
17              Experiment Name  reg-default-name
18                          USI              04d9
2024-11-14 12:24:37,796:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:37,798:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:37,899:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:24:37,901:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:24:37,902:INFO:Logging experiment in loggers
2024-11-14 12:24:39,170:INFO:SubProcess save_model() called ==================================
2024-11-14 12:24:39,179:INFO:Initializing save_model()
2024-11-14 12:24:39,179:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), model_name=/tmp/tmplfkorbs4/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2024-11-14 12:24:39,179:INFO:Adding model into prep_pipe
2024-11-14 12:24:39,179:WARNING:Only Model saved as it was a pipeline.
2024-11-14 12:24:39,182:INFO:/tmp/tmplfkorbs4/Transformation Pipeline.pkl saved in current working directory
2024-11-14 12:24:39,186:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 12:24:39,186:INFO:save_model() successfully completed......................................
2024-11-14 12:24:39,453:INFO:SubProcess save_model() end ==================================
2024-11-14 12:24:39,456:INFO:setup() successfully completed in 1.58s...............
2024-11-14 12:24:39,456:INFO:Initializing compare_models()
2024-11-14 12:24:39,457:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 12:24:39,457:INFO:Checking exceptions
2024-11-14 12:24:39,461:INFO:Preparing display monitor
2024-11-14 12:24:39,503:INFO:Initializing Linear Regression
2024-11-14 12:24:39,503:INFO:Total runtime is 3.45309575398763e-06 minutes
2024-11-14 12:24:39,506:INFO:SubProcess create_model() called ==================================
2024-11-14 12:24:39,507:INFO:Initializing create_model()
2024-11-14 12:24:39,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:24:39,507:INFO:Checking exceptions
2024-11-14 12:24:39,507:INFO:Importing libraries
2024-11-14 12:24:39,507:INFO:Copying training dataset
2024-11-14 12:24:39,513:INFO:Defining folds
2024-11-14 12:24:39,513:INFO:Declaring metric variables
2024-11-14 12:24:39,516:INFO:Importing untrained model
2024-11-14 12:24:39,519:INFO:Linear Regression Imported successfully
2024-11-14 12:24:39,526:INFO:Starting cross validation
2024-11-14 12:24:39,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:24:43,753:INFO:Calculating mean and std
2024-11-14 12:24:43,759:INFO:Creating metrics dataframe
2024-11-14 12:24:43,766:INFO:Uploading results into container
2024-11-14 12:24:43,767:INFO:Uploading model into container now
2024-11-14 12:24:43,767:INFO:_master_model_container: 1
2024-11-14 12:24:43,767:INFO:_display_container: 2
2024-11-14 12:24:43,768:INFO:LinearRegression(n_jobs=-1)
2024-11-14 12:24:43,768:INFO:create_model() successfully completed......................................
2024-11-14 12:24:43,987:INFO:SubProcess create_model() end ==================================
2024-11-14 12:24:43,987:INFO:Creating metrics dataframe
2024-11-14 12:24:43,999:INFO:Initializing Lasso Regression
2024-11-14 12:24:43,999:INFO:Total runtime is 0.07493605216344197 minutes
2024-11-14 12:24:44,003:INFO:SubProcess create_model() called ==================================
2024-11-14 12:24:44,003:INFO:Initializing create_model()
2024-11-14 12:24:44,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:24:44,003:INFO:Checking exceptions
2024-11-14 12:24:44,003:INFO:Importing libraries
2024-11-14 12:24:44,004:INFO:Copying training dataset
2024-11-14 12:24:44,011:INFO:Defining folds
2024-11-14 12:24:44,011:INFO:Declaring metric variables
2024-11-14 12:24:44,014:INFO:Importing untrained model
2024-11-14 12:24:44,018:INFO:Lasso Regression Imported successfully
2024-11-14 12:24:44,025:INFO:Starting cross validation
2024-11-14 12:24:44,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:24:46,851:INFO:Calculating mean and std
2024-11-14 12:24:46,855:INFO:Creating metrics dataframe
2024-11-14 12:24:46,860:INFO:Uploading results into container
2024-11-14 12:24:46,861:INFO:Uploading model into container now
2024-11-14 12:24:46,862:INFO:_master_model_container: 2
2024-11-14 12:24:46,862:INFO:_display_container: 2
2024-11-14 12:24:46,862:INFO:Lasso(random_state=123)
2024-11-14 12:24:46,862:INFO:create_model() successfully completed......................................
2024-11-14 12:24:47,073:INFO:SubProcess create_model() end ==================================
2024-11-14 12:24:47,074:INFO:Creating metrics dataframe
2024-11-14 12:24:47,084:INFO:Initializing Ridge Regression
2024-11-14 12:24:47,084:INFO:Total runtime is 0.12634838024775186 minutes
2024-11-14 12:24:47,087:INFO:SubProcess create_model() called ==================================
2024-11-14 12:24:47,088:INFO:Initializing create_model()
2024-11-14 12:24:47,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:24:47,088:INFO:Checking exceptions
2024-11-14 12:24:47,088:INFO:Importing libraries
2024-11-14 12:24:47,088:INFO:Copying training dataset
2024-11-14 12:24:47,095:INFO:Defining folds
2024-11-14 12:24:47,095:INFO:Declaring metric variables
2024-11-14 12:24:47,099:INFO:Importing untrained model
2024-11-14 12:24:47,102:INFO:Ridge Regression Imported successfully
2024-11-14 12:24:47,114:INFO:Starting cross validation
2024-11-14 12:24:47,116:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:24:49,861:INFO:Calculating mean and std
2024-11-14 12:24:49,865:INFO:Creating metrics dataframe
2024-11-14 12:24:49,871:INFO:Uploading results into container
2024-11-14 12:24:49,872:INFO:Uploading model into container now
2024-11-14 12:24:49,873:INFO:_master_model_container: 3
2024-11-14 12:24:49,873:INFO:_display_container: 2
2024-11-14 12:24:49,874:INFO:Ridge(random_state=123)
2024-11-14 12:24:49,874:INFO:create_model() successfully completed......................................
2024-11-14 12:24:50,090:INFO:SubProcess create_model() end ==================================
2024-11-14 12:24:50,090:INFO:Creating metrics dataframe
2024-11-14 12:24:50,100:INFO:Initializing Elastic Net
2024-11-14 12:24:50,100:INFO:Total runtime is 0.17662628094355265 minutes
2024-11-14 12:24:50,104:INFO:SubProcess create_model() called ==================================
2024-11-14 12:24:50,104:INFO:Initializing create_model()
2024-11-14 12:24:50,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:24:50,104:INFO:Checking exceptions
2024-11-14 12:24:50,104:INFO:Importing libraries
2024-11-14 12:24:50,104:INFO:Copying training dataset
2024-11-14 12:24:50,111:INFO:Defining folds
2024-11-14 12:24:50,111:INFO:Declaring metric variables
2024-11-14 12:24:50,115:INFO:Importing untrained model
2024-11-14 12:24:50,118:INFO:Elastic Net Imported successfully
2024-11-14 12:24:50,125:INFO:Starting cross validation
2024-11-14 12:24:50,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:24:53,191:INFO:Calculating mean and std
2024-11-14 12:24:53,195:INFO:Creating metrics dataframe
2024-11-14 12:24:53,203:INFO:Uploading results into container
2024-11-14 12:24:53,203:INFO:Uploading model into container now
2024-11-14 12:24:53,204:INFO:_master_model_container: 4
2024-11-14 12:24:53,204:INFO:_display_container: 2
2024-11-14 12:24:53,205:INFO:ElasticNet(random_state=123)
2024-11-14 12:24:53,205:INFO:create_model() successfully completed......................................
2024-11-14 12:24:53,401:INFO:SubProcess create_model() end ==================================
2024-11-14 12:24:53,401:INFO:Creating metrics dataframe
2024-11-14 12:24:53,411:INFO:Initializing Least Angle Regression
2024-11-14 12:24:53,411:INFO:Total runtime is 0.23180440664291382 minutes
2024-11-14 12:24:53,414:INFO:SubProcess create_model() called ==================================
2024-11-14 12:24:53,415:INFO:Initializing create_model()
2024-11-14 12:24:53,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:24:53,416:INFO:Checking exceptions
2024-11-14 12:24:53,416:INFO:Importing libraries
2024-11-14 12:24:53,416:INFO:Copying training dataset
2024-11-14 12:24:53,430:INFO:Defining folds
2024-11-14 12:24:53,430:INFO:Declaring metric variables
2024-11-14 12:24:53,434:INFO:Importing untrained model
2024-11-14 12:24:53,438:INFO:Least Angle Regression Imported successfully
2024-11-14 12:24:53,445:INFO:Starting cross validation
2024-11-14 12:24:53,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:24:55,958:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:55,965:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:55,990:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:56,140:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:56,150:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:56,156:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:56,161:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:56,172:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:56,197:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:56,208:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:56,227:INFO:Calculating mean and std
2024-11-14 12:24:56,231:INFO:Creating metrics dataframe
2024-11-14 12:24:56,237:INFO:Uploading results into container
2024-11-14 12:24:56,237:INFO:Uploading model into container now
2024-11-14 12:24:56,238:INFO:_master_model_container: 5
2024-11-14 12:24:56,238:INFO:_display_container: 2
2024-11-14 12:24:56,238:INFO:Lars(random_state=123)
2024-11-14 12:24:56,238:INFO:create_model() successfully completed......................................
2024-11-14 12:24:56,452:INFO:SubProcess create_model() end ==================================
2024-11-14 12:24:56,453:INFO:Creating metrics dataframe
2024-11-14 12:24:56,464:INFO:Initializing Lasso Least Angle Regression
2024-11-14 12:24:56,464:INFO:Total runtime is 0.2826853473981222 minutes
2024-11-14 12:24:56,467:INFO:SubProcess create_model() called ==================================
2024-11-14 12:24:56,468:INFO:Initializing create_model()
2024-11-14 12:24:56,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:24:56,468:INFO:Checking exceptions
2024-11-14 12:24:56,468:INFO:Importing libraries
2024-11-14 12:24:56,468:INFO:Copying training dataset
2024-11-14 12:24:56,475:INFO:Defining folds
2024-11-14 12:24:56,475:INFO:Declaring metric variables
2024-11-14 12:24:56,479:INFO:Importing untrained model
2024-11-14 12:24:56,482:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 12:24:56,489:INFO:Starting cross validation
2024-11-14 12:24:56,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:24:56,565:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:24:56,570:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:24:56,575:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:24:56,584:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:24:58,996:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:24:59,005:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:24:59,014:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:24:59,034:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:24:59,096:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:24:59,112:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:24:59,124:INFO:Calculating mean and std
2024-11-14 12:24:59,128:INFO:Creating metrics dataframe
2024-11-14 12:24:59,135:INFO:Uploading results into container
2024-11-14 12:24:59,136:INFO:Uploading model into container now
2024-11-14 12:24:59,136:INFO:_master_model_container: 6
2024-11-14 12:24:59,137:INFO:_display_container: 2
2024-11-14 12:24:59,137:INFO:LassoLars(random_state=123)
2024-11-14 12:24:59,137:INFO:create_model() successfully completed......................................
2024-11-14 12:24:59,321:INFO:SubProcess create_model() end ==================================
2024-11-14 12:24:59,321:INFO:Creating metrics dataframe
2024-11-14 12:24:59,332:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 12:24:59,332:INFO:Total runtime is 0.330482296148936 minutes
2024-11-14 12:24:59,335:INFO:SubProcess create_model() called ==================================
2024-11-14 12:24:59,335:INFO:Initializing create_model()
2024-11-14 12:24:59,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:24:59,336:INFO:Checking exceptions
2024-11-14 12:24:59,336:INFO:Importing libraries
2024-11-14 12:24:59,336:INFO:Copying training dataset
2024-11-14 12:24:59,343:INFO:Defining folds
2024-11-14 12:24:59,343:INFO:Declaring metric variables
2024-11-14 12:24:59,346:INFO:Importing untrained model
2024-11-14 12:24:59,351:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 12:24:59,359:INFO:Starting cross validation
2024-11-14 12:24:59,360:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:24:59,395:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:59,402:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:59,405:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:59,414:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:59,420:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:59,425:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:59,425:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:59,433:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:59,441:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:59,442:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:24:59,456:INFO:Calculating mean and std
2024-11-14 12:24:59,460:INFO:Creating metrics dataframe
2024-11-14 12:24:59,467:INFO:Uploading results into container
2024-11-14 12:24:59,468:INFO:Uploading model into container now
2024-11-14 12:24:59,468:INFO:_master_model_container: 7
2024-11-14 12:24:59,468:INFO:_display_container: 2
2024-11-14 12:24:59,469:INFO:OrthogonalMatchingPursuit()
2024-11-14 12:24:59,469:INFO:create_model() successfully completed......................................
2024-11-14 12:24:59,648:INFO:SubProcess create_model() end ==================================
2024-11-14 12:24:59,648:INFO:Creating metrics dataframe
2024-11-14 12:24:59,659:INFO:Initializing Bayesian Ridge
2024-11-14 12:24:59,659:INFO:Total runtime is 0.33593300580978397 minutes
2024-11-14 12:24:59,662:INFO:SubProcess create_model() called ==================================
2024-11-14 12:24:59,662:INFO:Initializing create_model()
2024-11-14 12:24:59,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:24:59,663:INFO:Checking exceptions
2024-11-14 12:24:59,663:INFO:Importing libraries
2024-11-14 12:24:59,663:INFO:Copying training dataset
2024-11-14 12:24:59,670:INFO:Defining folds
2024-11-14 12:24:59,670:INFO:Declaring metric variables
2024-11-14 12:24:59,673:INFO:Importing untrained model
2024-11-14 12:24:59,677:INFO:Bayesian Ridge Imported successfully
2024-11-14 12:24:59,683:INFO:Starting cross validation
2024-11-14 12:24:59,683:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:24:59,795:INFO:Calculating mean and std
2024-11-14 12:24:59,798:INFO:Creating metrics dataframe
2024-11-14 12:24:59,804:INFO:Uploading results into container
2024-11-14 12:24:59,804:INFO:Uploading model into container now
2024-11-14 12:24:59,805:INFO:_master_model_container: 8
2024-11-14 12:24:59,805:INFO:_display_container: 2
2024-11-14 12:24:59,805:INFO:BayesianRidge()
2024-11-14 12:24:59,805:INFO:create_model() successfully completed......................................
2024-11-14 12:24:59,964:INFO:SubProcess create_model() end ==================================
2024-11-14 12:24:59,964:INFO:Creating metrics dataframe
2024-11-14 12:24:59,977:INFO:Initializing Passive Aggressive Regressor
2024-11-14 12:24:59,977:INFO:Total runtime is 0.34124166568120323 minutes
2024-11-14 12:24:59,981:INFO:SubProcess create_model() called ==================================
2024-11-14 12:24:59,981:INFO:Initializing create_model()
2024-11-14 12:24:59,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:24:59,981:INFO:Checking exceptions
2024-11-14 12:24:59,981:INFO:Importing libraries
2024-11-14 12:24:59,982:INFO:Copying training dataset
2024-11-14 12:24:59,989:INFO:Defining folds
2024-11-14 12:24:59,989:INFO:Declaring metric variables
2024-11-14 12:24:59,993:INFO:Importing untrained model
2024-11-14 12:24:59,996:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 12:25:00,002:INFO:Starting cross validation
2024-11-14 12:25:00,003:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:25:00,193:INFO:Calculating mean and std
2024-11-14 12:25:00,197:INFO:Creating metrics dataframe
2024-11-14 12:25:00,203:INFO:Uploading results into container
2024-11-14 12:25:00,204:INFO:Uploading model into container now
2024-11-14 12:25:00,204:INFO:_master_model_container: 9
2024-11-14 12:25:00,205:INFO:_display_container: 2
2024-11-14 12:25:00,205:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-14 12:25:00,205:INFO:create_model() successfully completed......................................
2024-11-14 12:25:00,390:INFO:SubProcess create_model() end ==================================
2024-11-14 12:25:00,391:INFO:Creating metrics dataframe
2024-11-14 12:25:00,404:INFO:Initializing Huber Regressor
2024-11-14 12:25:00,405:INFO:Total runtime is 0.3483617941538493 minutes
2024-11-14 12:25:00,408:INFO:SubProcess create_model() called ==================================
2024-11-14 12:25:00,409:INFO:Initializing create_model()
2024-11-14 12:25:00,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:25:00,409:INFO:Checking exceptions
2024-11-14 12:25:00,409:INFO:Importing libraries
2024-11-14 12:25:00,409:INFO:Copying training dataset
2024-11-14 12:25:00,417:INFO:Defining folds
2024-11-14 12:25:00,417:INFO:Declaring metric variables
2024-11-14 12:25:00,422:INFO:Importing untrained model
2024-11-14 12:25:00,426:INFO:Huber Regressor Imported successfully
2024-11-14 12:25:00,433:INFO:Starting cross validation
2024-11-14 12:25:00,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:25:00,713:INFO:Calculating mean and std
2024-11-14 12:25:00,717:INFO:Creating metrics dataframe
2024-11-14 12:25:00,723:INFO:Uploading results into container
2024-11-14 12:25:00,724:INFO:Uploading model into container now
2024-11-14 12:25:00,724:INFO:_master_model_container: 10
2024-11-14 12:25:00,724:INFO:_display_container: 2
2024-11-14 12:25:00,725:INFO:HuberRegressor()
2024-11-14 12:25:00,725:INFO:create_model() successfully completed......................................
2024-11-14 12:25:00,939:INFO:SubProcess create_model() end ==================================
2024-11-14 12:25:00,939:INFO:Creating metrics dataframe
2024-11-14 12:25:00,952:INFO:Initializing K Neighbors Regressor
2024-11-14 12:25:00,952:INFO:Total runtime is 0.35748041470845543 minutes
2024-11-14 12:25:00,955:INFO:SubProcess create_model() called ==================================
2024-11-14 12:25:00,956:INFO:Initializing create_model()
2024-11-14 12:25:00,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:25:00,956:INFO:Checking exceptions
2024-11-14 12:25:00,956:INFO:Importing libraries
2024-11-14 12:25:00,956:INFO:Copying training dataset
2024-11-14 12:25:00,963:INFO:Defining folds
2024-11-14 12:25:00,963:INFO:Declaring metric variables
2024-11-14 12:25:00,967:INFO:Importing untrained model
2024-11-14 12:25:00,970:INFO:K Neighbors Regressor Imported successfully
2024-11-14 12:25:00,976:INFO:Starting cross validation
2024-11-14 12:25:00,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:25:01,161:INFO:Calculating mean and std
2024-11-14 12:25:01,164:INFO:Creating metrics dataframe
2024-11-14 12:25:01,169:INFO:Uploading results into container
2024-11-14 12:25:01,170:INFO:Uploading model into container now
2024-11-14 12:25:01,171:INFO:_master_model_container: 11
2024-11-14 12:25:01,171:INFO:_display_container: 2
2024-11-14 12:25:01,172:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 12:25:01,172:INFO:create_model() successfully completed......................................
2024-11-14 12:25:01,339:INFO:SubProcess create_model() end ==================================
2024-11-14 12:25:01,339:INFO:Creating metrics dataframe
2024-11-14 12:25:01,351:INFO:Initializing Decision Tree Regressor
2024-11-14 12:25:01,351:INFO:Total runtime is 0.3641343077023824 minutes
2024-11-14 12:25:01,354:INFO:SubProcess create_model() called ==================================
2024-11-14 12:25:01,354:INFO:Initializing create_model()
2024-11-14 12:25:01,355:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:25:01,355:INFO:Checking exceptions
2024-11-14 12:25:01,355:INFO:Importing libraries
2024-11-14 12:25:01,355:INFO:Copying training dataset
2024-11-14 12:25:01,362:INFO:Defining folds
2024-11-14 12:25:01,362:INFO:Declaring metric variables
2024-11-14 12:25:01,365:INFO:Importing untrained model
2024-11-14 12:25:01,369:INFO:Decision Tree Regressor Imported successfully
2024-11-14 12:25:01,376:INFO:Starting cross validation
2024-11-14 12:25:01,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:25:01,538:INFO:Calculating mean and std
2024-11-14 12:25:01,542:INFO:Creating metrics dataframe
2024-11-14 12:25:01,548:INFO:Uploading results into container
2024-11-14 12:25:01,548:INFO:Uploading model into container now
2024-11-14 12:25:01,549:INFO:_master_model_container: 12
2024-11-14 12:25:01,549:INFO:_display_container: 2
2024-11-14 12:25:01,549:INFO:DecisionTreeRegressor(random_state=123)
2024-11-14 12:25:01,550:INFO:create_model() successfully completed......................................
2024-11-14 12:25:01,738:INFO:SubProcess create_model() end ==================================
2024-11-14 12:25:01,738:INFO:Creating metrics dataframe
2024-11-14 12:25:01,750:INFO:Initializing Random Forest Regressor
2024-11-14 12:25:01,751:INFO:Total runtime is 0.370794153213501 minutes
2024-11-14 12:25:01,754:INFO:SubProcess create_model() called ==================================
2024-11-14 12:25:01,754:INFO:Initializing create_model()
2024-11-14 12:25:01,754:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:25:01,755:INFO:Checking exceptions
2024-11-14 12:25:01,755:INFO:Importing libraries
2024-11-14 12:25:01,755:INFO:Copying training dataset
2024-11-14 12:25:01,763:INFO:Defining folds
2024-11-14 12:25:01,763:INFO:Declaring metric variables
2024-11-14 12:25:01,767:INFO:Importing untrained model
2024-11-14 12:25:01,770:INFO:Random Forest Regressor Imported successfully
2024-11-14 12:25:01,777:INFO:Starting cross validation
2024-11-14 12:25:01,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:25:03,255:INFO:Calculating mean and std
2024-11-14 12:25:03,259:INFO:Creating metrics dataframe
2024-11-14 12:25:03,266:INFO:Uploading results into container
2024-11-14 12:25:03,267:INFO:Uploading model into container now
2024-11-14 12:25:03,267:INFO:_master_model_container: 13
2024-11-14 12:25:03,267:INFO:_display_container: 2
2024-11-14 12:25:03,268:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:25:03,268:INFO:create_model() successfully completed......................................
2024-11-14 12:25:03,460:INFO:SubProcess create_model() end ==================================
2024-11-14 12:25:03,461:INFO:Creating metrics dataframe
2024-11-14 12:25:03,474:INFO:Initializing Extra Trees Regressor
2024-11-14 12:25:03,474:INFO:Total runtime is 0.3995151082674663 minutes
2024-11-14 12:25:03,477:INFO:SubProcess create_model() called ==================================
2024-11-14 12:25:03,478:INFO:Initializing create_model()
2024-11-14 12:25:03,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:25:03,478:INFO:Checking exceptions
2024-11-14 12:25:03,478:INFO:Importing libraries
2024-11-14 12:25:03,478:INFO:Copying training dataset
2024-11-14 12:25:03,485:INFO:Defining folds
2024-11-14 12:25:03,485:INFO:Declaring metric variables
2024-11-14 12:25:03,489:INFO:Importing untrained model
2024-11-14 12:25:03,492:INFO:Extra Trees Regressor Imported successfully
2024-11-14 12:25:03,499:INFO:Starting cross validation
2024-11-14 12:25:03,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:25:04,321:INFO:Calculating mean and std
2024-11-14 12:25:04,324:INFO:Creating metrics dataframe
2024-11-14 12:25:04,329:INFO:Uploading results into container
2024-11-14 12:25:04,329:INFO:Uploading model into container now
2024-11-14 12:25:04,330:INFO:_master_model_container: 14
2024-11-14 12:25:04,330:INFO:_display_container: 2
2024-11-14 12:25:04,331:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:25:04,331:INFO:create_model() successfully completed......................................
2024-11-14 12:25:04,506:INFO:SubProcess create_model() end ==================================
2024-11-14 12:25:04,506:INFO:Creating metrics dataframe
2024-11-14 12:25:04,518:INFO:Initializing AdaBoost Regressor
2024-11-14 12:25:04,518:INFO:Total runtime is 0.4169200976689657 minutes
2024-11-14 12:25:04,521:INFO:SubProcess create_model() called ==================================
2024-11-14 12:25:04,522:INFO:Initializing create_model()
2024-11-14 12:25:04,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:25:04,522:INFO:Checking exceptions
2024-11-14 12:25:04,522:INFO:Importing libraries
2024-11-14 12:25:04,522:INFO:Copying training dataset
2024-11-14 12:25:04,530:INFO:Defining folds
2024-11-14 12:25:04,530:INFO:Declaring metric variables
2024-11-14 12:25:04,534:INFO:Importing untrained model
2024-11-14 12:25:04,537:INFO:AdaBoost Regressor Imported successfully
2024-11-14 12:25:04,543:INFO:Starting cross validation
2024-11-14 12:25:04,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:25:05,422:INFO:Calculating mean and std
2024-11-14 12:25:05,425:INFO:Creating metrics dataframe
2024-11-14 12:25:05,431:INFO:Uploading results into container
2024-11-14 12:25:05,432:INFO:Uploading model into container now
2024-11-14 12:25:05,433:INFO:_master_model_container: 15
2024-11-14 12:25:05,433:INFO:_display_container: 2
2024-11-14 12:25:05,433:INFO:AdaBoostRegressor(random_state=123)
2024-11-14 12:25:05,433:INFO:create_model() successfully completed......................................
2024-11-14 12:25:05,647:INFO:SubProcess create_model() end ==================================
2024-11-14 12:25:05,647:INFO:Creating metrics dataframe
2024-11-14 12:25:05,661:INFO:Initializing Gradient Boosting Regressor
2024-11-14 12:25:05,661:INFO:Total runtime is 0.4359645009040833 minutes
2024-11-14 12:25:05,664:INFO:SubProcess create_model() called ==================================
2024-11-14 12:25:05,665:INFO:Initializing create_model()
2024-11-14 12:25:05,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:25:05,665:INFO:Checking exceptions
2024-11-14 12:25:05,665:INFO:Importing libraries
2024-11-14 12:25:05,665:INFO:Copying training dataset
2024-11-14 12:25:05,672:INFO:Defining folds
2024-11-14 12:25:05,672:INFO:Declaring metric variables
2024-11-14 12:25:05,676:INFO:Importing untrained model
2024-11-14 12:25:05,679:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 12:25:05,686:INFO:Starting cross validation
2024-11-14 12:25:05,687:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:25:07,044:INFO:Calculating mean and std
2024-11-14 12:25:07,048:INFO:Creating metrics dataframe
2024-11-14 12:25:07,055:INFO:Uploading results into container
2024-11-14 12:25:07,055:INFO:Uploading model into container now
2024-11-14 12:25:07,056:INFO:_master_model_container: 16
2024-11-14 12:25:07,056:INFO:_display_container: 2
2024-11-14 12:25:07,056:INFO:GradientBoostingRegressor(random_state=123)
2024-11-14 12:25:07,056:INFO:create_model() successfully completed......................................
2024-11-14 12:25:07,253:INFO:SubProcess create_model() end ==================================
2024-11-14 12:25:07,253:INFO:Creating metrics dataframe
2024-11-14 12:25:07,267:INFO:Initializing Extreme Gradient Boosting
2024-11-14 12:25:07,267:INFO:Total runtime is 0.4627412120501201 minutes
2024-11-14 12:25:07,271:INFO:SubProcess create_model() called ==================================
2024-11-14 12:25:07,271:INFO:Initializing create_model()
2024-11-14 12:25:07,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:25:07,271:INFO:Checking exceptions
2024-11-14 12:25:07,272:INFO:Importing libraries
2024-11-14 12:25:07,272:INFO:Copying training dataset
2024-11-14 12:25:07,280:INFO:Defining folds
2024-11-14 12:25:07,280:INFO:Declaring metric variables
2024-11-14 12:25:07,284:INFO:Importing untrained model
2024-11-14 12:25:07,287:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 12:25:07,294:INFO:Starting cross validation
2024-11-14 12:25:07,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:25:07,639:INFO:Calculating mean and std
2024-11-14 12:25:07,643:INFO:Creating metrics dataframe
2024-11-14 12:25:07,650:INFO:Uploading results into container
2024-11-14 12:25:07,651:INFO:Uploading model into container now
2024-11-14 12:25:07,652:INFO:_master_model_container: 17
2024-11-14 12:25:07,652:INFO:_display_container: 2
2024-11-14 12:25:07,653:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-14 12:25:07,653:INFO:create_model() successfully completed......................................
2024-11-14 12:25:07,819:INFO:SubProcess create_model() end ==================================
2024-11-14 12:25:07,819:INFO:Creating metrics dataframe
2024-11-14 12:25:07,831:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 12:25:07,832:INFO:Total runtime is 0.4721436778704326 minutes
2024-11-14 12:25:07,835:INFO:SubProcess create_model() called ==================================
2024-11-14 12:25:07,835:INFO:Initializing create_model()
2024-11-14 12:25:07,835:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd6f700>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01022b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:25:07,835:INFO:Checking exceptions
2024-11-14 12:25:07,835:INFO:Importing libraries
2024-11-14 12:25:07,835:INFO:Copying training dataset
2024-11-14 12:25:07,843:INFO:Defining folds
2024-11-14 12:25:07,843:INFO:Declaring metric variables
2024-11-14 12:25:07,852:INFO:Importing untrained model
2024-11-14 12:25:07,857:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 12:25:07,863:INFO:Starting cross validation
2024-11-14 12:25:07,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:27:01,987:INFO:PyCaret RegressionExperiment
2024-11-14 12:27:01,988:INFO:Logging name: reg-default-name
2024-11-14 12:27:01,988:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 12:27:01,988:INFO:version 3.2.0
2024-11-14 12:27:01,988:INFO:Initializing setup()
2024-11-14 12:27:01,988:INFO:self.USI: 120d
2024-11-14 12:27:01,988:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 12:27:01,988:INFO:Checking environment
2024-11-14 12:27:01,988:INFO:python_version: 3.8.13
2024-11-14 12:27:01,988:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 12:27:01,988:INFO:machine: x86_64
2024-11-14 12:27:01,989:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 12:27:01,989:INFO:Memory: svmem(total=270355722240, available=221227651072, percent=18.2, used=47038095360, free=73309061120, active=71833268224, inactive=64862724096, buffers=10100736, cached=149998465024, shared=195837952, slab=25256718336)
2024-11-14 12:27:01,991:INFO:Physical Core: 28
2024-11-14 12:27:01,992:INFO:Logical Core: 56
2024-11-14 12:27:01,992:INFO:Checking libraries
2024-11-14 12:27:01,992:INFO:System:
2024-11-14 12:27:01,992:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 12:27:01,992:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 12:27:01,992:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 12:27:01,992:INFO:PyCaret required dependencies:
2024-11-14 12:27:01,992:INFO:                 pip: 22.2.2
2024-11-14 12:27:01,992:INFO:          setuptools: 63.4.2
2024-11-14 12:27:01,992:INFO:             pycaret: 3.2.0
2024-11-14 12:27:01,992:INFO:             IPython: 8.12.2
2024-11-14 12:27:01,992:INFO:          ipywidgets: 7.7.1
2024-11-14 12:27:01,992:INFO:                tqdm: 4.64.1
2024-11-14 12:27:01,992:INFO:               numpy: 1.23.5
2024-11-14 12:27:01,992:INFO:              pandas: 1.5.3
2024-11-14 12:27:01,992:INFO:              jinja2: 3.1.2
2024-11-14 12:27:01,992:INFO:               scipy: 1.10.1
2024-11-14 12:27:01,992:INFO:              joblib: 1.3.0
2024-11-14 12:27:01,992:INFO:             sklearn: 1.1.2
2024-11-14 12:27:01,992:INFO:                pyod: 2.0.2
2024-11-14 12:27:01,992:INFO:            imblearn: 0.12.4
2024-11-14 12:27:01,992:INFO:   category_encoders: 2.6.4
2024-11-14 12:27:01,992:INFO:            lightgbm: 4.5.0
2024-11-14 12:27:01,993:INFO:               numba: 0.57.1
2024-11-14 12:27:01,993:INFO:            requests: 2.28.1
2024-11-14 12:27:01,993:INFO:          matplotlib: 3.5.1
2024-11-14 12:27:01,993:INFO:          scikitplot: 0.3.7
2024-11-14 12:27:01,993:INFO:         yellowbrick: 1.5
2024-11-14 12:27:01,993:INFO:              plotly: 5.24.1
2024-11-14 12:27:01,993:INFO:    plotly-resampler: Not installed
2024-11-14 12:27:01,993:INFO:             kaleido: 0.2.1
2024-11-14 12:27:01,993:INFO:           schemdraw: 0.15
2024-11-14 12:27:01,993:INFO:         statsmodels: 0.13.2
2024-11-14 12:27:01,993:INFO:              sktime: 0.21.1
2024-11-14 12:27:01,993:INFO:               tbats: 1.1.3
2024-11-14 12:27:01,993:INFO:            pmdarima: 2.0.4
2024-11-14 12:27:01,993:INFO:              psutil: 5.9.1
2024-11-14 12:27:01,993:INFO:          markupsafe: 2.1.1
2024-11-14 12:27:01,993:INFO:             pickle5: Not installed
2024-11-14 12:27:01,993:INFO:         cloudpickle: 2.1.0
2024-11-14 12:27:01,993:INFO:         deprecation: 2.1.0
2024-11-14 12:27:01,993:INFO:              xxhash: 3.5.0
2024-11-14 12:27:01,993:INFO:           wurlitzer: 3.1.1
2024-11-14 12:27:01,993:INFO:PyCaret optional dependencies:
2024-11-14 12:27:01,993:INFO:                shap: 0.44.1
2024-11-14 12:27:01,993:INFO:           interpret: 0.6.5
2024-11-14 12:27:01,993:INFO:                umap: 0.5.7
2024-11-14 12:27:01,993:INFO:     ydata_profiling: 4.6.0
2024-11-14 12:27:01,993:INFO:  explainerdashboard: 0.4.7
2024-11-14 12:27:01,993:INFO:             autoviz: Not installed
2024-11-14 12:27:01,994:INFO:           fairlearn: 0.7.0
2024-11-14 12:27:01,994:INFO:          deepchecks: Not installed
2024-11-14 12:27:01,994:INFO:             xgboost: 2.1.1
2024-11-14 12:27:01,994:INFO:            catboost: 1.2.7
2024-11-14 12:27:01,994:INFO:              kmodes: 0.12.2
2024-11-14 12:27:01,994:INFO:             mlxtend: 0.23.1
2024-11-14 12:27:01,994:INFO:       statsforecast: 1.5.0
2024-11-14 12:27:01,994:INFO:        tune_sklearn: 0.5.0
2024-11-14 12:27:01,994:INFO:                 ray: 2.10.0
2024-11-14 12:27:01,994:INFO:            hyperopt: 0.2.7
2024-11-14 12:27:01,994:INFO:              optuna: 4.1.0
2024-11-14 12:27:01,994:INFO:               skopt: 0.10.2
2024-11-14 12:27:01,994:INFO:              mlflow: 1.30.1
2024-11-14 12:27:01,994:INFO:              gradio: 3.50.2
2024-11-14 12:27:01,994:INFO:             fastapi: 0.115.5
2024-11-14 12:27:01,994:INFO:             uvicorn: 0.32.0
2024-11-14 12:27:01,994:INFO:              m2cgen: 0.10.0
2024-11-14 12:27:01,994:INFO:           evidently: 0.2.8
2024-11-14 12:27:01,994:INFO:               fugue: 0.8.6
2024-11-14 12:27:01,994:INFO:           streamlit: Not installed
2024-11-14 12:27:01,994:INFO:             prophet: Not installed
2024-11-14 12:27:01,994:INFO:None
2024-11-14 12:27:01,994:INFO:Set up data.
2024-11-14 12:27:02,005:INFO:Set up folding strategy.
2024-11-14 12:27:02,005:INFO:Set up train/test split.
2024-11-14 12:27:02,011:INFO:Set up index.
2024-11-14 12:27:02,012:INFO:Assigning column types.
2024-11-14 12:27:02,017:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 12:27:02,018:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,024:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,030:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,139:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,140:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:02,143:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:02,143:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,148:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,211:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,253:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,254:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:02,257:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:02,257:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 12:27:02,262:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,266:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,322:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,364:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,364:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:02,367:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:02,372:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,376:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,476:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,477:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:02,479:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:02,480:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 12:27:02,489:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,547:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,589:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,589:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:02,592:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:02,601:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,659:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,702:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,702:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:02,705:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:02,705:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 12:27:02,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,816:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,817:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:02,819:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:02,886:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,929:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 12:27:02,929:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:02,932:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:02,933:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 12:27:02,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:27:03,040:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:03,043:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:03,109:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 12:27:03,151:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:03,154:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:03,155:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 12:27:03,263:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:03,266:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:03,375:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:03,378:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:03,379:INFO:Preparing preprocessing pipeline...
2024-11-14 12:27:03,379:INFO:Set up simple imputation.
2024-11-14 12:27:03,398:INFO:Finished creating preprocessing pipeline.
2024-11-14 12:27:03,402:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 12:27:03,402:INFO:Creating final display dataframe.
2024-11-14 12:27:03,457:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment      MlflowLogger
17              Experiment Name  reg-default-name
18                          USI              120d
2024-11-14 12:27:03,569:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:03,572:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:03,684:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 12:27:03,686:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 12:27:03,687:INFO:Logging experiment in loggers
2024-11-14 12:27:03,915:INFO:SubProcess save_model() called ==================================
2024-11-14 12:27:03,921:INFO:Initializing save_model()
2024-11-14 12:27:03,921:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), model_name=/tmp/tmpqdd5suqc/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2024-11-14 12:27:03,922:INFO:Adding model into prep_pipe
2024-11-14 12:27:03,922:WARNING:Only Model saved as it was a pipeline.
2024-11-14 12:27:03,923:INFO:/tmp/tmpqdd5suqc/Transformation Pipeline.pkl saved in current working directory
2024-11-14 12:27:03,927:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 12:27:03,927:INFO:save_model() successfully completed......................................
2024-11-14 12:27:04,165:INFO:SubProcess save_model() end ==================================
2024-11-14 12:27:04,168:INFO:setup() successfully completed in 1.7s...............
2024-11-14 12:28:23,827:INFO:Initializing compare_models()
2024-11-14 12:28:23,828:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 12:28:23,828:INFO:Checking exceptions
2024-11-14 12:28:23,835:INFO:Preparing display monitor
2024-11-14 12:28:23,880:INFO:Initializing Linear Regression
2024-11-14 12:28:23,880:INFO:Total runtime is 2.3722648620605467e-06 minutes
2024-11-14 12:28:23,884:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:23,884:INFO:Initializing create_model()
2024-11-14 12:28:23,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:23,884:INFO:Checking exceptions
2024-11-14 12:28:23,884:INFO:Importing libraries
2024-11-14 12:28:23,884:INFO:Copying training dataset
2024-11-14 12:28:23,891:INFO:Defining folds
2024-11-14 12:28:23,891:INFO:Declaring metric variables
2024-11-14 12:28:23,895:INFO:Importing untrained model
2024-11-14 12:28:23,899:INFO:Linear Regression Imported successfully
2024-11-14 12:28:23,906:INFO:Starting cross validation
2024-11-14 12:28:23,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:28,116:INFO:Calculating mean and std
2024-11-14 12:28:28,121:INFO:Creating metrics dataframe
2024-11-14 12:28:28,128:INFO:Uploading results into container
2024-11-14 12:28:28,129:INFO:Uploading model into container now
2024-11-14 12:28:28,129:INFO:_master_model_container: 1
2024-11-14 12:28:28,129:INFO:_display_container: 2
2024-11-14 12:28:28,130:INFO:LinearRegression(n_jobs=-1)
2024-11-14 12:28:28,130:INFO:create_model() successfully completed......................................
2024-11-14 12:28:28,335:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:28,335:INFO:Creating metrics dataframe
2024-11-14 12:28:28,345:INFO:Initializing Lasso Regression
2024-11-14 12:28:28,345:INFO:Total runtime is 0.07441786527633668 minutes
2024-11-14 12:28:28,348:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:28,349:INFO:Initializing create_model()
2024-11-14 12:28:28,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:28,349:INFO:Checking exceptions
2024-11-14 12:28:28,349:INFO:Importing libraries
2024-11-14 12:28:28,349:INFO:Copying training dataset
2024-11-14 12:28:28,357:INFO:Defining folds
2024-11-14 12:28:28,357:INFO:Declaring metric variables
2024-11-14 12:28:28,360:INFO:Importing untrained model
2024-11-14 12:28:28,364:INFO:Lasso Regression Imported successfully
2024-11-14 12:28:28,371:INFO:Starting cross validation
2024-11-14 12:28:28,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:31,416:INFO:Calculating mean and std
2024-11-14 12:28:31,420:INFO:Creating metrics dataframe
2024-11-14 12:28:31,427:INFO:Uploading results into container
2024-11-14 12:28:31,428:INFO:Uploading model into container now
2024-11-14 12:28:31,428:INFO:_master_model_container: 2
2024-11-14 12:28:31,428:INFO:_display_container: 2
2024-11-14 12:28:31,429:INFO:Lasso(random_state=123)
2024-11-14 12:28:31,429:INFO:create_model() successfully completed......................................
2024-11-14 12:28:31,603:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:31,603:INFO:Creating metrics dataframe
2024-11-14 12:28:31,613:INFO:Initializing Ridge Regression
2024-11-14 12:28:31,614:INFO:Total runtime is 0.1288966218630473 minutes
2024-11-14 12:28:31,617:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:31,617:INFO:Initializing create_model()
2024-11-14 12:28:31,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:31,618:INFO:Checking exceptions
2024-11-14 12:28:31,618:INFO:Importing libraries
2024-11-14 12:28:31,618:INFO:Copying training dataset
2024-11-14 12:28:31,625:INFO:Defining folds
2024-11-14 12:28:31,625:INFO:Declaring metric variables
2024-11-14 12:28:31,628:INFO:Importing untrained model
2024-11-14 12:28:31,632:INFO:Ridge Regression Imported successfully
2024-11-14 12:28:31,639:INFO:Starting cross validation
2024-11-14 12:28:31,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:34,778:INFO:Calculating mean and std
2024-11-14 12:28:34,782:INFO:Creating metrics dataframe
2024-11-14 12:28:34,788:INFO:Uploading results into container
2024-11-14 12:28:34,789:INFO:Uploading model into container now
2024-11-14 12:28:34,789:INFO:_master_model_container: 3
2024-11-14 12:28:34,790:INFO:_display_container: 2
2024-11-14 12:28:34,790:INFO:Ridge(random_state=123)
2024-11-14 12:28:34,790:INFO:create_model() successfully completed......................................
2024-11-14 12:28:34,962:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:34,963:INFO:Creating metrics dataframe
2024-11-14 12:28:34,972:INFO:Initializing Elastic Net
2024-11-14 12:28:34,973:INFO:Total runtime is 0.18487855195999148 minutes
2024-11-14 12:28:34,976:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:34,976:INFO:Initializing create_model()
2024-11-14 12:28:34,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:34,977:INFO:Checking exceptions
2024-11-14 12:28:34,977:INFO:Importing libraries
2024-11-14 12:28:34,977:INFO:Copying training dataset
2024-11-14 12:28:34,984:INFO:Defining folds
2024-11-14 12:28:34,984:INFO:Declaring metric variables
2024-11-14 12:28:34,987:INFO:Importing untrained model
2024-11-14 12:28:34,991:INFO:Elastic Net Imported successfully
2024-11-14 12:28:34,997:INFO:Starting cross validation
2024-11-14 12:28:34,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:37,853:INFO:Calculating mean and std
2024-11-14 12:28:37,857:INFO:Creating metrics dataframe
2024-11-14 12:28:37,863:INFO:Uploading results into container
2024-11-14 12:28:37,864:INFO:Uploading model into container now
2024-11-14 12:28:37,865:INFO:_master_model_container: 4
2024-11-14 12:28:37,865:INFO:_display_container: 2
2024-11-14 12:28:37,865:INFO:ElasticNet(random_state=123)
2024-11-14 12:28:37,865:INFO:create_model() successfully completed......................................
2024-11-14 12:28:38,038:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:38,038:INFO:Creating metrics dataframe
2024-11-14 12:28:38,049:INFO:Initializing Least Angle Regression
2024-11-14 12:28:38,049:INFO:Total runtime is 0.23614879846572878 minutes
2024-11-14 12:28:38,052:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:38,052:INFO:Initializing create_model()
2024-11-14 12:28:38,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:38,053:INFO:Checking exceptions
2024-11-14 12:28:38,053:INFO:Importing libraries
2024-11-14 12:28:38,053:INFO:Copying training dataset
2024-11-14 12:28:38,060:INFO:Defining folds
2024-11-14 12:28:38,060:INFO:Declaring metric variables
2024-11-14 12:28:38,063:INFO:Importing untrained model
2024-11-14 12:28:38,067:INFO:Least Angle Regression Imported successfully
2024-11-14 12:28:38,073:INFO:Starting cross validation
2024-11-14 12:28:38,074:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:40,615:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:40,637:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:40,689:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:40,689:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:40,707:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:40,786:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:40,809:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:40,985:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:41,009:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:41,133:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:41,151:INFO:Calculating mean and std
2024-11-14 12:28:41,154:INFO:Creating metrics dataframe
2024-11-14 12:28:41,160:INFO:Uploading results into container
2024-11-14 12:28:41,161:INFO:Uploading model into container now
2024-11-14 12:28:41,162:INFO:_master_model_container: 5
2024-11-14 12:28:41,162:INFO:_display_container: 2
2024-11-14 12:28:41,162:INFO:Lars(random_state=123)
2024-11-14 12:28:41,162:INFO:create_model() successfully completed......................................
2024-11-14 12:28:41,339:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:41,339:INFO:Creating metrics dataframe
2024-11-14 12:28:41,351:INFO:Initializing Lasso Least Angle Regression
2024-11-14 12:28:41,352:INFO:Total runtime is 0.29119579394658407 minutes
2024-11-14 12:28:41,355:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:41,356:INFO:Initializing create_model()
2024-11-14 12:28:41,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:41,356:INFO:Checking exceptions
2024-11-14 12:28:41,356:INFO:Importing libraries
2024-11-14 12:28:41,356:INFO:Copying training dataset
2024-11-14 12:28:41,363:INFO:Defining folds
2024-11-14 12:28:41,363:INFO:Declaring metric variables
2024-11-14 12:28:41,367:INFO:Importing untrained model
2024-11-14 12:28:41,370:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 12:28:41,376:INFO:Starting cross validation
2024-11-14 12:28:41,377:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:41,461:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:28:41,466:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:28:41,471:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:28:41,479:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:28:43,911:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:28:43,929:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:28:43,975:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:28:44,063:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:28:44,065:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:28:44,118:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 12:28:44,129:INFO:Calculating mean and std
2024-11-14 12:28:44,132:INFO:Creating metrics dataframe
2024-11-14 12:28:44,139:INFO:Uploading results into container
2024-11-14 12:28:44,140:INFO:Uploading model into container now
2024-11-14 12:28:44,141:INFO:_master_model_container: 6
2024-11-14 12:28:44,141:INFO:_display_container: 2
2024-11-14 12:28:44,141:INFO:LassoLars(random_state=123)
2024-11-14 12:28:44,141:INFO:create_model() successfully completed......................................
2024-11-14 12:28:44,323:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:44,323:INFO:Creating metrics dataframe
2024-11-14 12:28:44,335:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 12:28:44,335:INFO:Total runtime is 0.34091521898905436 minutes
2024-11-14 12:28:44,338:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:44,338:INFO:Initializing create_model()
2024-11-14 12:28:44,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:44,339:INFO:Checking exceptions
2024-11-14 12:28:44,339:INFO:Importing libraries
2024-11-14 12:28:44,339:INFO:Copying training dataset
2024-11-14 12:28:44,346:INFO:Defining folds
2024-11-14 12:28:44,346:INFO:Declaring metric variables
2024-11-14 12:28:44,350:INFO:Importing untrained model
2024-11-14 12:28:44,353:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 12:28:44,359:INFO:Starting cross validation
2024-11-14 12:28:44,360:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:44,390:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:44,402:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:44,404:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:44,412:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:44,416:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:44,418:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:44,424:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:44,429:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:44,436:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:44,441:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 12:28:44,462:INFO:Calculating mean and std
2024-11-14 12:28:44,467:INFO:Creating metrics dataframe
2024-11-14 12:28:44,473:INFO:Uploading results into container
2024-11-14 12:28:44,474:INFO:Uploading model into container now
2024-11-14 12:28:44,474:INFO:_master_model_container: 7
2024-11-14 12:28:44,475:INFO:_display_container: 2
2024-11-14 12:28:44,475:INFO:OrthogonalMatchingPursuit()
2024-11-14 12:28:44,475:INFO:create_model() successfully completed......................................
2024-11-14 12:28:44,673:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:44,673:INFO:Creating metrics dataframe
2024-11-14 12:28:44,685:INFO:Initializing Bayesian Ridge
2024-11-14 12:28:44,685:INFO:Total runtime is 0.3467582821846008 minutes
2024-11-14 12:28:44,689:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:44,689:INFO:Initializing create_model()
2024-11-14 12:28:44,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:44,690:INFO:Checking exceptions
2024-11-14 12:28:44,690:INFO:Importing libraries
2024-11-14 12:28:44,690:INFO:Copying training dataset
2024-11-14 12:28:44,697:INFO:Defining folds
2024-11-14 12:28:44,697:INFO:Declaring metric variables
2024-11-14 12:28:44,700:INFO:Importing untrained model
2024-11-14 12:28:44,704:INFO:Bayesian Ridge Imported successfully
2024-11-14 12:28:44,710:INFO:Starting cross validation
2024-11-14 12:28:44,711:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:44,815:INFO:Calculating mean and std
2024-11-14 12:28:44,818:INFO:Creating metrics dataframe
2024-11-14 12:28:44,824:INFO:Uploading results into container
2024-11-14 12:28:44,825:INFO:Uploading model into container now
2024-11-14 12:28:44,826:INFO:_master_model_container: 8
2024-11-14 12:28:44,826:INFO:_display_container: 2
2024-11-14 12:28:44,826:INFO:BayesianRidge()
2024-11-14 12:28:44,826:INFO:create_model() successfully completed......................................
2024-11-14 12:28:44,990:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:44,991:INFO:Creating metrics dataframe
2024-11-14 12:28:45,002:INFO:Initializing Passive Aggressive Regressor
2024-11-14 12:28:45,002:INFO:Total runtime is 0.3520388086636861 minutes
2024-11-14 12:28:45,006:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:45,006:INFO:Initializing create_model()
2024-11-14 12:28:45,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:45,006:INFO:Checking exceptions
2024-11-14 12:28:45,006:INFO:Importing libraries
2024-11-14 12:28:45,006:INFO:Copying training dataset
2024-11-14 12:28:45,013:INFO:Defining folds
2024-11-14 12:28:45,013:INFO:Declaring metric variables
2024-11-14 12:28:45,017:INFO:Importing untrained model
2024-11-14 12:28:45,020:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 12:28:45,026:INFO:Starting cross validation
2024-11-14 12:28:45,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:45,223:INFO:Calculating mean and std
2024-11-14 12:28:45,227:INFO:Creating metrics dataframe
2024-11-14 12:28:45,234:INFO:Uploading results into container
2024-11-14 12:28:45,235:INFO:Uploading model into container now
2024-11-14 12:28:45,236:INFO:_master_model_container: 9
2024-11-14 12:28:45,236:INFO:_display_container: 2
2024-11-14 12:28:45,236:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-14 12:28:45,236:INFO:create_model() successfully completed......................................
2024-11-14 12:28:45,413:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:45,414:INFO:Creating metrics dataframe
2024-11-14 12:28:45,425:INFO:Initializing Huber Regressor
2024-11-14 12:28:45,425:INFO:Total runtime is 0.35909204483032225 minutes
2024-11-14 12:28:45,429:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:45,429:INFO:Initializing create_model()
2024-11-14 12:28:45,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:45,429:INFO:Checking exceptions
2024-11-14 12:28:45,430:INFO:Importing libraries
2024-11-14 12:28:45,430:INFO:Copying training dataset
2024-11-14 12:28:45,437:INFO:Defining folds
2024-11-14 12:28:45,437:INFO:Declaring metric variables
2024-11-14 12:28:45,440:INFO:Importing untrained model
2024-11-14 12:28:45,444:INFO:Huber Regressor Imported successfully
2024-11-14 12:28:45,450:INFO:Starting cross validation
2024-11-14 12:28:45,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:45,728:INFO:Calculating mean and std
2024-11-14 12:28:45,732:INFO:Creating metrics dataframe
2024-11-14 12:28:45,739:INFO:Uploading results into container
2024-11-14 12:28:45,739:INFO:Uploading model into container now
2024-11-14 12:28:45,740:INFO:_master_model_container: 10
2024-11-14 12:28:45,740:INFO:_display_container: 2
2024-11-14 12:28:45,740:INFO:HuberRegressor()
2024-11-14 12:28:45,740:INFO:create_model() successfully completed......................................
2024-11-14 12:28:45,899:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:45,899:INFO:Creating metrics dataframe
2024-11-14 12:28:45,913:INFO:Initializing K Neighbors Regressor
2024-11-14 12:28:45,913:INFO:Total runtime is 0.367215096950531 minutes
2024-11-14 12:28:45,916:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:45,916:INFO:Initializing create_model()
2024-11-14 12:28:45,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:45,917:INFO:Checking exceptions
2024-11-14 12:28:45,917:INFO:Importing libraries
2024-11-14 12:28:45,917:INFO:Copying training dataset
2024-11-14 12:28:45,925:INFO:Defining folds
2024-11-14 12:28:45,925:INFO:Declaring metric variables
2024-11-14 12:28:45,929:INFO:Importing untrained model
2024-11-14 12:28:45,932:INFO:K Neighbors Regressor Imported successfully
2024-11-14 12:28:45,938:INFO:Starting cross validation
2024-11-14 12:28:45,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:46,105:INFO:Calculating mean and std
2024-11-14 12:28:46,108:INFO:Creating metrics dataframe
2024-11-14 12:28:46,114:INFO:Uploading results into container
2024-11-14 12:28:46,114:INFO:Uploading model into container now
2024-11-14 12:28:46,115:INFO:_master_model_container: 11
2024-11-14 12:28:46,116:INFO:_display_container: 2
2024-11-14 12:28:46,116:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 12:28:46,116:INFO:create_model() successfully completed......................................
2024-11-14 12:28:46,283:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:46,283:INFO:Creating metrics dataframe
2024-11-14 12:28:46,294:INFO:Initializing Decision Tree Regressor
2024-11-14 12:28:46,295:INFO:Total runtime is 0.373577090104421 minutes
2024-11-14 12:28:46,298:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:46,298:INFO:Initializing create_model()
2024-11-14 12:28:46,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:46,298:INFO:Checking exceptions
2024-11-14 12:28:46,298:INFO:Importing libraries
2024-11-14 12:28:46,299:INFO:Copying training dataset
2024-11-14 12:28:46,306:INFO:Defining folds
2024-11-14 12:28:46,306:INFO:Declaring metric variables
2024-11-14 12:28:46,309:INFO:Importing untrained model
2024-11-14 12:28:46,312:INFO:Decision Tree Regressor Imported successfully
2024-11-14 12:28:46,319:INFO:Starting cross validation
2024-11-14 12:28:46,320:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:46,509:INFO:Calculating mean and std
2024-11-14 12:28:46,513:INFO:Creating metrics dataframe
2024-11-14 12:28:46,519:INFO:Uploading results into container
2024-11-14 12:28:46,520:INFO:Uploading model into container now
2024-11-14 12:28:46,521:INFO:_master_model_container: 12
2024-11-14 12:28:46,521:INFO:_display_container: 2
2024-11-14 12:28:46,521:INFO:DecisionTreeRegressor(random_state=123)
2024-11-14 12:28:46,521:INFO:create_model() successfully completed......................................
2024-11-14 12:28:46,706:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:46,706:INFO:Creating metrics dataframe
2024-11-14 12:28:46,718:INFO:Initializing Random Forest Regressor
2024-11-14 12:28:46,718:INFO:Total runtime is 0.38063992659250895 minutes
2024-11-14 12:28:46,721:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:46,722:INFO:Initializing create_model()
2024-11-14 12:28:46,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:46,722:INFO:Checking exceptions
2024-11-14 12:28:46,722:INFO:Importing libraries
2024-11-14 12:28:46,722:INFO:Copying training dataset
2024-11-14 12:28:46,729:INFO:Defining folds
2024-11-14 12:28:46,729:INFO:Declaring metric variables
2024-11-14 12:28:46,732:INFO:Importing untrained model
2024-11-14 12:28:46,735:INFO:Random Forest Regressor Imported successfully
2024-11-14 12:28:46,741:INFO:Starting cross validation
2024-11-14 12:28:46,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:48,191:INFO:Calculating mean and std
2024-11-14 12:28:48,199:INFO:Creating metrics dataframe
2024-11-14 12:28:48,205:INFO:Uploading results into container
2024-11-14 12:28:48,206:INFO:Uploading model into container now
2024-11-14 12:28:48,206:INFO:_master_model_container: 13
2024-11-14 12:28:48,207:INFO:_display_container: 2
2024-11-14 12:28:48,207:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:28:48,207:INFO:create_model() successfully completed......................................
2024-11-14 12:28:48,387:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:48,387:INFO:Creating metrics dataframe
2024-11-14 12:28:48,399:INFO:Initializing Extra Trees Regressor
2024-11-14 12:28:48,399:INFO:Total runtime is 0.4086560289065043 minutes
2024-11-14 12:28:48,403:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:48,403:INFO:Initializing create_model()
2024-11-14 12:28:48,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:48,403:INFO:Checking exceptions
2024-11-14 12:28:48,403:INFO:Importing libraries
2024-11-14 12:28:48,404:INFO:Copying training dataset
2024-11-14 12:28:48,411:INFO:Defining folds
2024-11-14 12:28:48,411:INFO:Declaring metric variables
2024-11-14 12:28:48,415:INFO:Importing untrained model
2024-11-14 12:28:48,418:INFO:Extra Trees Regressor Imported successfully
2024-11-14 12:28:48,424:INFO:Starting cross validation
2024-11-14 12:28:48,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:49,284:INFO:Calculating mean and std
2024-11-14 12:28:49,288:INFO:Creating metrics dataframe
2024-11-14 12:28:49,293:INFO:Uploading results into container
2024-11-14 12:28:49,293:INFO:Uploading model into container now
2024-11-14 12:28:49,294:INFO:_master_model_container: 14
2024-11-14 12:28:49,294:INFO:_display_container: 2
2024-11-14 12:28:49,295:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:28:49,295:INFO:create_model() successfully completed......................................
2024-11-14 12:28:49,470:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:49,470:INFO:Creating metrics dataframe
2024-11-14 12:28:49,482:INFO:Initializing AdaBoost Regressor
2024-11-14 12:28:49,482:INFO:Total runtime is 0.4267076810201009 minutes
2024-11-14 12:28:49,486:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:49,486:INFO:Initializing create_model()
2024-11-14 12:28:49,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:49,486:INFO:Checking exceptions
2024-11-14 12:28:49,486:INFO:Importing libraries
2024-11-14 12:28:49,486:INFO:Copying training dataset
2024-11-14 12:28:49,494:INFO:Defining folds
2024-11-14 12:28:49,494:INFO:Declaring metric variables
2024-11-14 12:28:49,497:INFO:Importing untrained model
2024-11-14 12:28:49,501:INFO:AdaBoost Regressor Imported successfully
2024-11-14 12:28:49,507:INFO:Starting cross validation
2024-11-14 12:28:49,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:50,372:INFO:Calculating mean and std
2024-11-14 12:28:50,376:INFO:Creating metrics dataframe
2024-11-14 12:28:50,383:INFO:Uploading results into container
2024-11-14 12:28:50,384:INFO:Uploading model into container now
2024-11-14 12:28:50,384:INFO:_master_model_container: 15
2024-11-14 12:28:50,384:INFO:_display_container: 2
2024-11-14 12:28:50,384:INFO:AdaBoostRegressor(random_state=123)
2024-11-14 12:28:50,385:INFO:create_model() successfully completed......................................
2024-11-14 12:28:50,553:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:50,554:INFO:Creating metrics dataframe
2024-11-14 12:28:50,567:INFO:Initializing Gradient Boosting Regressor
2024-11-14 12:28:50,567:INFO:Total runtime is 0.4447913527488709 minutes
2024-11-14 12:28:50,571:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:50,571:INFO:Initializing create_model()
2024-11-14 12:28:50,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:50,572:INFO:Checking exceptions
2024-11-14 12:28:50,572:INFO:Importing libraries
2024-11-14 12:28:50,572:INFO:Copying training dataset
2024-11-14 12:28:50,579:INFO:Defining folds
2024-11-14 12:28:50,580:INFO:Declaring metric variables
2024-11-14 12:28:50,583:INFO:Importing untrained model
2024-11-14 12:28:50,587:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 12:28:50,593:INFO:Starting cross validation
2024-11-14 12:28:50,594:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:51,991:INFO:Calculating mean and std
2024-11-14 12:28:51,995:INFO:Creating metrics dataframe
2024-11-14 12:28:52,000:INFO:Uploading results into container
2024-11-14 12:28:52,001:INFO:Uploading model into container now
2024-11-14 12:28:52,002:INFO:_master_model_container: 16
2024-11-14 12:28:52,002:INFO:_display_container: 2
2024-11-14 12:28:52,003:INFO:GradientBoostingRegressor(random_state=123)
2024-11-14 12:28:52,003:INFO:create_model() successfully completed......................................
2024-11-14 12:28:52,204:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:52,205:INFO:Creating metrics dataframe
2024-11-14 12:28:52,218:INFO:Initializing Extreme Gradient Boosting
2024-11-14 12:28:52,218:INFO:Total runtime is 0.4723016897837321 minutes
2024-11-14 12:28:52,221:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:52,222:INFO:Initializing create_model()
2024-11-14 12:28:52,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:52,222:INFO:Checking exceptions
2024-11-14 12:28:52,222:INFO:Importing libraries
2024-11-14 12:28:52,222:INFO:Copying training dataset
2024-11-14 12:28:52,229:INFO:Defining folds
2024-11-14 12:28:52,230:INFO:Declaring metric variables
2024-11-14 12:28:52,233:INFO:Importing untrained model
2024-11-14 12:28:52,237:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 12:28:52,243:INFO:Starting cross validation
2024-11-14 12:28:52,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:28:52,561:INFO:Calculating mean and std
2024-11-14 12:28:52,565:INFO:Creating metrics dataframe
2024-11-14 12:28:52,571:INFO:Uploading results into container
2024-11-14 12:28:52,572:INFO:Uploading model into container now
2024-11-14 12:28:52,572:INFO:_master_model_container: 17
2024-11-14 12:28:52,572:INFO:_display_container: 2
2024-11-14 12:28:52,573:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-14 12:28:52,573:INFO:create_model() successfully completed......................................
2024-11-14 12:28:52,748:INFO:SubProcess create_model() end ==================================
2024-11-14 12:28:52,749:INFO:Creating metrics dataframe
2024-11-14 12:28:52,762:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 12:28:52,763:INFO:Total runtime is 0.4813776691754659 minutes
2024-11-14 12:28:52,766:INFO:SubProcess create_model() called ==================================
2024-11-14 12:28:52,767:INFO:Initializing create_model()
2024-11-14 12:28:52,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:28:52,767:INFO:Checking exceptions
2024-11-14 12:28:52,767:INFO:Importing libraries
2024-11-14 12:28:52,767:INFO:Copying training dataset
2024-11-14 12:28:52,775:INFO:Defining folds
2024-11-14 12:28:52,775:INFO:Declaring metric variables
2024-11-14 12:28:52,779:INFO:Importing untrained model
2024-11-14 12:28:52,782:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 12:28:52,788:INFO:Starting cross validation
2024-11-14 12:28:52,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:35:42,873:INFO:Calculating mean and std
2024-11-14 12:35:42,878:INFO:Creating metrics dataframe
2024-11-14 12:35:42,885:INFO:Uploading results into container
2024-11-14 12:35:42,885:INFO:Uploading model into container now
2024-11-14 12:35:42,886:INFO:_master_model_container: 18
2024-11-14 12:35:42,886:INFO:_display_container: 2
2024-11-14 12:35:42,887:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:35:42,887:INFO:create_model() successfully completed......................................
2024-11-14 12:35:43,139:INFO:SubProcess create_model() end ==================================
2024-11-14 12:35:43,140:INFO:Creating metrics dataframe
2024-11-14 12:35:43,154:INFO:Initializing CatBoost Regressor
2024-11-14 12:35:43,154:INFO:Total runtime is 7.321232453982036 minutes
2024-11-14 12:35:43,157:INFO:SubProcess create_model() called ==================================
2024-11-14 12:35:43,158:INFO:Initializing create_model()
2024-11-14 12:35:43,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:35:43,158:INFO:Checking exceptions
2024-11-14 12:35:43,158:INFO:Importing libraries
2024-11-14 12:35:43,158:INFO:Copying training dataset
2024-11-14 12:35:43,166:INFO:Defining folds
2024-11-14 12:35:43,167:INFO:Declaring metric variables
2024-11-14 12:35:43,170:INFO:Importing untrained model
2024-11-14 12:35:43,174:INFO:CatBoost Regressor Imported successfully
2024-11-14 12:35:43,180:INFO:Starting cross validation
2024-11-14 12:35:43,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:35:56,914:INFO:Calculating mean and std
2024-11-14 12:35:56,919:INFO:Creating metrics dataframe
2024-11-14 12:35:56,925:INFO:Uploading results into container
2024-11-14 12:35:56,926:INFO:Uploading model into container now
2024-11-14 12:35:56,926:INFO:_master_model_container: 19
2024-11-14 12:35:56,927:INFO:_display_container: 2
2024-11-14 12:35:56,927:INFO:<catboost.core.CatBoostRegressor object at 0x7fc08fab2d60>
2024-11-14 12:35:56,927:INFO:create_model() successfully completed......................................
2024-11-14 12:35:57,119:INFO:SubProcess create_model() end ==================================
2024-11-14 12:35:57,120:INFO:Creating metrics dataframe
2024-11-14 12:35:57,133:INFO:Initializing Dummy Regressor
2024-11-14 12:35:57,134:INFO:Total runtime is 7.554228202501934 minutes
2024-11-14 12:35:57,137:INFO:SubProcess create_model() called ==================================
2024-11-14 12:35:57,138:INFO:Initializing create_model()
2024-11-14 12:35:57,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50a0c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:35:57,138:INFO:Checking exceptions
2024-11-14 12:35:57,138:INFO:Importing libraries
2024-11-14 12:35:57,138:INFO:Copying training dataset
2024-11-14 12:35:57,145:INFO:Defining folds
2024-11-14 12:35:57,146:INFO:Declaring metric variables
2024-11-14 12:35:57,149:INFO:Importing untrained model
2024-11-14 12:35:57,153:INFO:Dummy Regressor Imported successfully
2024-11-14 12:35:57,159:INFO:Starting cross validation
2024-11-14 12:35:57,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:36:00,108:INFO:Calculating mean and std
2024-11-14 12:36:00,114:INFO:Creating metrics dataframe
2024-11-14 12:36:00,121:INFO:Uploading results into container
2024-11-14 12:36:00,122:INFO:Uploading model into container now
2024-11-14 12:36:00,123:INFO:_master_model_container: 20
2024-11-14 12:36:00,123:INFO:_display_container: 2
2024-11-14 12:36:00,123:INFO:DummyRegressor()
2024-11-14 12:36:00,123:INFO:create_model() successfully completed......................................
2024-11-14 12:36:00,332:INFO:SubProcess create_model() end ==================================
2024-11-14 12:36:00,332:INFO:Creating metrics dataframe
2024-11-14 12:36:00,356:INFO:Initializing create_model()
2024-11-14 12:36:00,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:36:00,356:INFO:Checking exceptions
2024-11-14 12:36:00,358:INFO:Importing libraries
2024-11-14 12:36:00,358:INFO:Copying training dataset
2024-11-14 12:36:00,365:INFO:Defining folds
2024-11-14 12:36:00,365:INFO:Declaring metric variables
2024-11-14 12:36:00,365:INFO:Importing untrained model
2024-11-14 12:36:00,365:INFO:Declaring custom model
2024-11-14 12:36:00,366:INFO:Extra Trees Regressor Imported successfully
2024-11-14 12:36:00,367:INFO:Cross validation set to False
2024-11-14 12:36:00,367:INFO:Fitting Model
2024-11-14 12:36:00,619:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:36:00,620:INFO:create_model() successfully completed......................................
2024-11-14 12:36:00,786:INFO:Creating Dashboard logs
2024-11-14 12:36:00,790:INFO:Model: Extra Trees Regressor
2024-11-14 12:36:01,022:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2024-11-14 12:36:01,066:INFO:Initializing predict_model()
2024-11-14 12:36:01,066:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fc08fb44700>)
2024-11-14 12:36:01,066:INFO:Checking exceptions
2024-11-14 12:36:01,066:INFO:Preloading libraries
2024-11-14 12:36:01,375:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-11-14 12:36:01,757:INFO:Creating Dashboard logs
2024-11-14 12:36:01,761:INFO:Model: Random Forest Regressor
2024-11-14 12:36:01,848:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2024-11-14 12:36:02,197:INFO:Creating Dashboard logs
2024-11-14 12:36:02,201:INFO:Model: Decision Tree Regressor
2024-11-14 12:36:02,267:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2024-11-14 12:36:02,500:INFO:Creating Dashboard logs
2024-11-14 12:36:02,503:INFO:Model: Extreme Gradient Boosting
2024-11-14 12:36:02,648:INFO:Logged params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 123, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0}
2024-11-14 12:36:02,987:INFO:Creating Dashboard logs
2024-11-14 12:36:02,991:INFO:Model: K Neighbors Regressor
2024-11-14 12:36:03,208:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-11-14 12:36:03,453:INFO:Creating Dashboard logs
2024-11-14 12:36:03,457:INFO:Model: CatBoost Regressor
2024-11-14 12:36:03,544:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/pycaret/loggers/dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/catboost/core.py", line 3504, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2024-11-14 12:36:03,544:INFO:Logged params: {}
2024-11-14 12:36:03,750:INFO:Creating Dashboard logs
2024-11-14 12:36:03,754:INFO:Model: Light Gradient Boosting Machine
2024-11-14 12:36:03,961:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-11-14 12:36:04,406:INFO:Creating Dashboard logs
2024-11-14 12:36:04,411:INFO:Model: Gradient Boosting Regressor
2024-11-14 12:36:04,568:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-11-14 12:36:04,855:INFO:Creating Dashboard logs
2024-11-14 12:36:04,859:INFO:Model: AdaBoost Regressor
2024-11-14 12:36:05,104:INFO:Logged params: {'base_estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 123}
2024-11-14 12:36:05,356:INFO:Creating Dashboard logs
2024-11-14 12:36:05,360:INFO:Model: Bayesian Ridge
2024-11-14 12:36:05,524:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'n_iter': 300, 'normalize': 'deprecated', 'tol': 0.001, 'verbose': False}
2024-11-14 12:36:05,734:INFO:Creating Dashboard logs
2024-11-14 12:36:05,737:INFO:Model: Ridge Regression
2024-11-14 12:36:05,907:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.001}
2024-11-14 12:36:06,155:INFO:Creating Dashboard logs
2024-11-14 12:36:06,159:INFO:Model: Least Angle Regression
2024-11-14 12:36:06,414:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'normalize': 'deprecated', 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2024-11-14 12:36:06,659:INFO:Creating Dashboard logs
2024-11-14 12:36:06,663:INFO:Model: Linear Regression
2024-11-14 12:36:06,796:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'normalize': 'deprecated', 'positive': False}
2024-11-14 12:36:07,050:INFO:Creating Dashboard logs
2024-11-14 12:36:07,054:INFO:Model: Huber Regressor
2024-11-14 12:36:07,226:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2024-11-14 12:36:07,465:INFO:Creating Dashboard logs
2024-11-14 12:36:07,469:INFO:Model: Lasso Regression
2024-11-14 12:36:07,550:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2024-11-14 12:36:07,765:INFO:Creating Dashboard logs
2024-11-14 12:36:07,769:INFO:Model: Elastic Net
2024-11-14 12:36:07,936:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'normalize': 'deprecated', 'positive': False, 'precompute': False, 'random_state': 123, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2024-11-14 12:36:08,184:INFO:Creating Dashboard logs
2024-11-14 12:36:08,188:INFO:Model: Orthogonal Matching Pursuit
2024-11-14 12:36:08,318:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'normalize': 'deprecated', 'precompute': 'auto', 'tol': None}
2024-11-14 12:36:08,614:INFO:Creating Dashboard logs
2024-11-14 12:36:08,617:INFO:Model: Lasso Least Angle Regression
2024-11-14 12:36:08,722:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'normalize': 'deprecated', 'positive': False, 'precompute': 'auto', 'random_state': 123, 'verbose': False}
2024-11-14 12:36:08,951:INFO:Creating Dashboard logs
2024-11-14 12:36:08,955:INFO:Model: Dummy Regressor
2024-11-14 12:36:09,187:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2024-11-14 12:36:09,636:INFO:Creating Dashboard logs
2024-11-14 12:36:09,640:INFO:Model: Passive Aggressive Regressor
2024-11-14 12:36:09,807:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-11-14 12:36:10,104:INFO:_master_model_container: 20
2024-11-14 12:36:10,105:INFO:_display_container: 2
2024-11-14 12:36:10,105:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:36:10,105:INFO:compare_models() successfully completed......................................
2024-11-14 12:43:43,493:INFO:Initializing compare_models()
2024-11-14 12:43:43,493:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 12:43:43,493:INFO:Checking exceptions
2024-11-14 12:43:43,503:INFO:Preparing display monitor
2024-11-14 12:43:43,544:INFO:Initializing Linear Regression
2024-11-14 12:43:43,545:INFO:Total runtime is 2.4040540059407553e-06 minutes
2024-11-14 12:43:43,548:INFO:SubProcess create_model() called ==================================
2024-11-14 12:43:43,549:INFO:Initializing create_model()
2024-11-14 12:43:43,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08ff686d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:43:43,549:INFO:Checking exceptions
2024-11-14 12:43:43,549:INFO:Importing libraries
2024-11-14 12:43:43,549:INFO:Copying training dataset
2024-11-14 12:43:43,556:INFO:Defining folds
2024-11-14 12:43:43,556:INFO:Declaring metric variables
2024-11-14 12:43:43,559:INFO:Importing untrained model
2024-11-14 12:43:43,563:INFO:Linear Regression Imported successfully
2024-11-14 12:43:43,571:INFO:Starting cross validation
2024-11-14 12:43:43,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:43:48,032:INFO:Calculating mean and std
2024-11-14 12:43:48,037:INFO:Creating metrics dataframe
2024-11-14 12:43:48,045:INFO:Uploading results into container
2024-11-14 12:43:48,046:INFO:Uploading model into container now
2024-11-14 12:43:48,047:INFO:_master_model_container: 21
2024-11-14 12:43:48,047:INFO:_display_container: 3
2024-11-14 12:43:48,047:INFO:LinearRegression(n_jobs=-1)
2024-11-14 12:43:48,047:INFO:create_model() successfully completed......................................
2024-11-14 12:43:48,257:INFO:SubProcess create_model() end ==================================
2024-11-14 12:43:48,257:INFO:Creating metrics dataframe
2024-11-14 12:43:48,266:INFO:Initializing Lasso Regression
2024-11-14 12:43:48,266:INFO:Total runtime is 0.07869508663813272 minutes
2024-11-14 12:43:48,269:INFO:SubProcess create_model() called ==================================
2024-11-14 12:43:48,270:INFO:Initializing create_model()
2024-11-14 12:43:48,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08ff686d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:43:48,270:INFO:Checking exceptions
2024-11-14 12:43:48,270:INFO:Importing libraries
2024-11-14 12:43:48,270:INFO:Copying training dataset
2024-11-14 12:43:48,278:INFO:Defining folds
2024-11-14 12:43:48,278:INFO:Declaring metric variables
2024-11-14 12:43:48,281:INFO:Importing untrained model
2024-11-14 12:43:48,284:INFO:Lasso Regression Imported successfully
2024-11-14 12:43:48,292:INFO:Starting cross validation
2024-11-14 12:43:48,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:43:51,061:INFO:Calculating mean and std
2024-11-14 12:43:51,065:INFO:Creating metrics dataframe
2024-11-14 12:43:51,071:INFO:Uploading results into container
2024-11-14 12:43:51,072:INFO:Uploading model into container now
2024-11-14 12:43:51,073:INFO:_master_model_container: 22
2024-11-14 12:43:51,073:INFO:_display_container: 3
2024-11-14 12:43:51,074:INFO:Lasso(random_state=123)
2024-11-14 12:43:51,074:INFO:create_model() successfully completed......................................
2024-11-14 12:43:51,243:INFO:SubProcess create_model() end ==================================
2024-11-14 12:43:51,243:INFO:Creating metrics dataframe
2024-11-14 12:43:51,253:INFO:Initializing Ridge Regression
2024-11-14 12:43:51,253:INFO:Total runtime is 0.12847167253494263 minutes
2024-11-14 12:43:51,256:INFO:SubProcess create_model() called ==================================
2024-11-14 12:43:51,256:INFO:Initializing create_model()
2024-11-14 12:43:51,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08ff686d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:43:51,257:INFO:Checking exceptions
2024-11-14 12:43:51,257:INFO:Importing libraries
2024-11-14 12:43:51,257:INFO:Copying training dataset
2024-11-14 12:43:51,264:INFO:Defining folds
2024-11-14 12:43:51,264:INFO:Declaring metric variables
2024-11-14 12:43:51,267:INFO:Importing untrained model
2024-11-14 12:43:51,271:INFO:Ridge Regression Imported successfully
2024-11-14 12:43:51,277:INFO:Starting cross validation
2024-11-14 12:43:51,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:56:25,229:INFO:Initializing tune_model()
2024-11-14 12:56:25,230:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>)
2024-11-14 12:56:25,230:INFO:Checking exceptions
2024-11-14 12:56:25,270:INFO:Copying training dataset
2024-11-14 12:56:25,276:INFO:Checking base model
2024-11-14 12:56:25,276:INFO:Base model : Extra Trees Regressor
2024-11-14 12:56:25,280:INFO:Declaring metric variables
2024-11-14 12:56:25,284:INFO:Defining Hyperparameters
2024-11-14 12:56:25,496:INFO:Tuning with n_jobs=-1
2024-11-14 12:56:25,496:INFO:Initializing RandomizedSearchCV
2024-11-14 12:56:30,902:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,923:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,927:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,933:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,947:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,950:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,952:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,956:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,956:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,972:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,977:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:30,988:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,016:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,017:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,026:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,038:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,046:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,050:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,050:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,053:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,105:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,108:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,108:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,128:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,131:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,188:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,192:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,197:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,200:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,270:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:56:31,541:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 12:58:16,073:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-11-14 12:58:16,078:INFO:Hyperparameter search completed
2024-11-14 12:58:16,078:INFO:SubProcess create_model() called ==================================
2024-11-14 12:58:16,079:INFO:Initializing create_model()
2024-11-14 12:58:16,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc0a0d0a760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'squared_error', 'bootstrap': False})
2024-11-14 12:58:16,079:INFO:Checking exceptions
2024-11-14 12:58:16,079:INFO:Importing libraries
2024-11-14 12:58:16,079:INFO:Copying training dataset
2024-11-14 12:58:16,087:INFO:Defining folds
2024-11-14 12:58:16,087:INFO:Declaring metric variables
2024-11-14 12:58:16,091:INFO:Importing untrained model
2024-11-14 12:58:16,091:INFO:Declaring custom model
2024-11-14 12:58:16,095:INFO:Extra Trees Regressor Imported successfully
2024-11-14 12:58:16,102:INFO:Starting cross validation
2024-11-14 12:58:16,103:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:58:16,783:INFO:Calculating mean and std
2024-11-14 12:58:16,787:INFO:Creating metrics dataframe
2024-11-14 12:58:16,796:INFO:Finalizing model
2024-11-14 12:58:17,181:INFO:Uploading results into container
2024-11-14 12:58:17,182:INFO:Uploading model into container now
2024-11-14 12:58:17,183:INFO:_master_model_container: 23
2024-11-14 12:58:17,183:INFO:_display_container: 3
2024-11-14 12:58:17,184:INFO:ExtraTreesRegressor(max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123)
2024-11-14 12:58:17,184:INFO:create_model() successfully completed......................................
2024-11-14 12:58:17,430:INFO:SubProcess create_model() end ==================================
2024-11-14 12:58:17,431:INFO:choose_better activated
2024-11-14 12:58:17,436:INFO:SubProcess create_model() called ==================================
2024-11-14 12:58:17,436:INFO:Initializing create_model()
2024-11-14 12:58:17,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 12:58:17,436:INFO:Checking exceptions
2024-11-14 12:58:17,439:INFO:Importing libraries
2024-11-14 12:58:17,439:INFO:Copying training dataset
2024-11-14 12:58:17,446:INFO:Defining folds
2024-11-14 12:58:17,446:INFO:Declaring metric variables
2024-11-14 12:58:17,446:INFO:Importing untrained model
2024-11-14 12:58:17,447:INFO:Declaring custom model
2024-11-14 12:58:17,447:INFO:Extra Trees Regressor Imported successfully
2024-11-14 12:58:17,448:INFO:Starting cross validation
2024-11-14 12:58:17,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 12:58:18,415:INFO:Calculating mean and std
2024-11-14 12:58:18,416:INFO:Creating metrics dataframe
2024-11-14 12:58:18,420:INFO:Finalizing model
2024-11-14 12:58:18,673:INFO:Uploading results into container
2024-11-14 12:58:18,674:INFO:Uploading model into container now
2024-11-14 12:58:18,675:INFO:_master_model_container: 24
2024-11-14 12:58:18,675:INFO:_display_container: 4
2024-11-14 12:58:18,675:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:58:18,675:INFO:create_model() successfully completed......................................
2024-11-14 12:58:18,865:INFO:SubProcess create_model() end ==================================
2024-11-14 12:58:18,866:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9809
2024-11-14 12:58:18,867:INFO:ExtraTreesRegressor(max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123) result for R2 is 0.7478
2024-11-14 12:58:18,867:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-11-14 12:58:18,867:INFO:choose_better completed
2024-11-14 12:58:18,867:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-11-14 12:58:18,868:INFO:Creating Dashboard logs
2024-11-14 12:58:18,875:INFO:Model: Extra Trees Regressor
2024-11-14 12:58:19,056:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2024-11-14 12:58:19,124:INFO:Initializing predict_model()
2024-11-14 12:58:19,124:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fc08faa7a60>)
2024-11-14 12:58:19,124:INFO:Checking exceptions
2024-11-14 12:58:19,124:INFO:Preloading libraries
2024-11-14 12:58:19,944:INFO:_master_model_container: 24
2024-11-14 12:58:19,945:INFO:_display_container: 3
2024-11-14 12:58:19,945:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 12:58:19,945:INFO:tune_model() successfully completed......................................
2024-11-14 13:02:00,929:INFO:Initializing tune_model()
2024-11-14 13:02:00,931:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>)
2024-11-14 13:02:00,931:INFO:Checking exceptions
2024-11-14 13:02:00,970:INFO:Copying training dataset
2024-11-14 13:02:00,974:INFO:Checking base model
2024-11-14 13:02:00,975:INFO:Base model : Extra Trees Regressor
2024-11-14 13:02:00,978:INFO:Declaring metric variables
2024-11-14 13:02:00,983:INFO:Defining Hyperparameters
2024-11-14 13:02:01,160:INFO:Tuning with n_jobs=-1
2024-11-14 13:02:01,161:INFO:Initializing RandomizedSearchCV
2024-11-14 13:03:47,827:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-11-14 13:03:47,832:INFO:Hyperparameter search completed
2024-11-14 13:03:47,833:INFO:SubProcess create_model() called ==================================
2024-11-14 13:03:47,835:INFO:Initializing create_model()
2024-11-14 13:03:47,835:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c5b8d130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'squared_error', 'bootstrap': False})
2024-11-14 13:03:47,835:INFO:Checking exceptions
2024-11-14 13:03:47,836:INFO:Importing libraries
2024-11-14 13:03:47,836:INFO:Copying training dataset
2024-11-14 13:03:47,855:INFO:Defining folds
2024-11-14 13:03:47,855:INFO:Declaring metric variables
2024-11-14 13:03:47,861:INFO:Importing untrained model
2024-11-14 13:03:47,861:INFO:Declaring custom model
2024-11-14 13:03:47,866:INFO:Extra Trees Regressor Imported successfully
2024-11-14 13:03:47,874:INFO:Starting cross validation
2024-11-14 13:03:47,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:03:48,590:INFO:Calculating mean and std
2024-11-14 13:03:48,594:INFO:Creating metrics dataframe
2024-11-14 13:03:48,606:INFO:Finalizing model
2024-11-14 13:03:49,044:INFO:Uploading results into container
2024-11-14 13:03:49,045:INFO:Uploading model into container now
2024-11-14 13:03:49,046:INFO:_master_model_container: 25
2024-11-14 13:03:49,046:INFO:_display_container: 4
2024-11-14 13:03:49,047:INFO:ExtraTreesRegressor(max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123)
2024-11-14 13:03:49,047:INFO:create_model() successfully completed......................................
2024-11-14 13:03:49,295:INFO:SubProcess create_model() end ==================================
2024-11-14 13:03:49,295:INFO:choose_better activated
2024-11-14 13:03:49,300:INFO:SubProcess create_model() called ==================================
2024-11-14 13:03:49,300:INFO:Initializing create_model()
2024-11-14 13:03:49,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:03:49,300:INFO:Checking exceptions
2024-11-14 13:03:49,303:INFO:Importing libraries
2024-11-14 13:03:49,303:INFO:Copying training dataset
2024-11-14 13:03:49,311:INFO:Defining folds
2024-11-14 13:03:49,312:INFO:Declaring metric variables
2024-11-14 13:03:49,312:INFO:Importing untrained model
2024-11-14 13:03:49,312:INFO:Declaring custom model
2024-11-14 13:03:49,313:INFO:Extra Trees Regressor Imported successfully
2024-11-14 13:03:49,313:INFO:Starting cross validation
2024-11-14 13:03:49,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:03:50,251:INFO:Calculating mean and std
2024-11-14 13:03:50,253:INFO:Creating metrics dataframe
2024-11-14 13:03:50,258:INFO:Finalizing model
2024-11-14 13:03:50,516:INFO:Uploading results into container
2024-11-14 13:03:50,517:INFO:Uploading model into container now
2024-11-14 13:03:50,518:INFO:_master_model_container: 26
2024-11-14 13:03:50,518:INFO:_display_container: 5
2024-11-14 13:03:50,519:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 13:03:50,519:INFO:create_model() successfully completed......................................
2024-11-14 13:03:50,718:INFO:SubProcess create_model() end ==================================
2024-11-14 13:03:50,719:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9809
2024-11-14 13:03:50,720:INFO:ExtraTreesRegressor(max_depth=11, max_features='sqrt',
                    min_impurity_decrease=0.0002, min_samples_leaf=5,
                    min_samples_split=7, n_estimators=200, n_jobs=-1,
                    random_state=123) result for R2 is 0.7478
2024-11-14 13:03:50,720:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-11-14 13:03:50,720:INFO:choose_better completed
2024-11-14 13:03:50,720:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-11-14 13:03:50,721:INFO:Creating Dashboard logs
2024-11-14 13:03:50,728:INFO:Model: Extra Trees Regressor
2024-11-14 13:03:51,030:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2024-11-14 13:03:51,144:INFO:Initializing predict_model()
2024-11-14 13:03:51,144:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fd92790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fc08faa78b0>)
2024-11-14 13:03:51,144:INFO:Checking exceptions
2024-11-14 13:03:51,144:INFO:Preloading libraries
2024-11-14 13:03:51,917:INFO:_master_model_container: 26
2024-11-14 13:03:51,917:INFO:_display_container: 4
2024-11-14 13:03:51,918:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-14 13:03:51,918:INFO:tune_model() successfully completed......................................
2024-11-14 13:12:49,850:INFO:PyCaret RegressionExperiment
2024-11-14 13:12:49,850:INFO:Logging name: reg-default-name
2024-11-14 13:12:49,850:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 13:12:49,851:INFO:version 3.2.0
2024-11-14 13:12:49,851:INFO:Initializing setup()
2024-11-14 13:12:49,851:INFO:self.USI: 864c
2024-11-14 13:12:49,851:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 13:12:49,851:INFO:Checking environment
2024-11-14 13:12:49,851:INFO:python_version: 3.8.13
2024-11-14 13:12:49,851:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 13:12:49,851:INFO:machine: x86_64
2024-11-14 13:12:49,851:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 13:12:49,852:INFO:Memory: svmem(total=270355722240, available=221085757440, percent=18.2, used=47180001280, free=72068485120, active=72062070784, inactive=65867235328, buffers=10100736, cached=151097135104, shared=195874816, slab=25260056576)
2024-11-14 13:12:49,855:INFO:Physical Core: 28
2024-11-14 13:12:49,855:INFO:Logical Core: 56
2024-11-14 13:12:49,855:INFO:Checking libraries
2024-11-14 13:12:49,855:INFO:System:
2024-11-14 13:12:49,855:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 13:12:49,855:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 13:12:49,855:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 13:12:49,855:INFO:PyCaret required dependencies:
2024-11-14 13:12:49,855:INFO:                 pip: 22.2.2
2024-11-14 13:12:49,855:INFO:          setuptools: 63.4.2
2024-11-14 13:12:49,855:INFO:             pycaret: 3.2.0
2024-11-14 13:12:49,855:INFO:             IPython: 8.12.2
2024-11-14 13:12:49,855:INFO:          ipywidgets: 7.7.1
2024-11-14 13:12:49,855:INFO:                tqdm: 4.64.1
2024-11-14 13:12:49,856:INFO:               numpy: 1.23.5
2024-11-14 13:12:49,856:INFO:              pandas: 1.5.3
2024-11-14 13:12:49,856:INFO:              jinja2: 3.1.2
2024-11-14 13:12:49,856:INFO:               scipy: 1.10.1
2024-11-14 13:12:49,856:INFO:              joblib: 1.3.0
2024-11-14 13:12:49,856:INFO:             sklearn: 1.1.2
2024-11-14 13:12:49,856:INFO:                pyod: 2.0.2
2024-11-14 13:12:49,856:INFO:            imblearn: 0.12.4
2024-11-14 13:12:49,856:INFO:   category_encoders: 2.6.4
2024-11-14 13:12:49,856:INFO:            lightgbm: 4.5.0
2024-11-14 13:12:49,856:INFO:               numba: 0.57.1
2024-11-14 13:12:49,856:INFO:            requests: 2.28.1
2024-11-14 13:12:49,856:INFO:          matplotlib: 3.5.1
2024-11-14 13:12:49,856:INFO:          scikitplot: 0.3.7
2024-11-14 13:12:49,856:INFO:         yellowbrick: 1.5
2024-11-14 13:12:49,856:INFO:              plotly: 5.24.1
2024-11-14 13:12:49,856:INFO:    plotly-resampler: Not installed
2024-11-14 13:12:49,856:INFO:             kaleido: 0.2.1
2024-11-14 13:12:49,856:INFO:           schemdraw: 0.15
2024-11-14 13:12:49,856:INFO:         statsmodels: 0.13.2
2024-11-14 13:12:49,856:INFO:              sktime: 0.21.1
2024-11-14 13:12:49,856:INFO:               tbats: 1.1.3
2024-11-14 13:12:49,856:INFO:            pmdarima: 2.0.4
2024-11-14 13:12:49,856:INFO:              psutil: 5.9.1
2024-11-14 13:12:49,856:INFO:          markupsafe: 2.1.1
2024-11-14 13:12:49,856:INFO:             pickle5: Not installed
2024-11-14 13:12:49,856:INFO:         cloudpickle: 2.1.0
2024-11-14 13:12:49,856:INFO:         deprecation: 2.1.0
2024-11-14 13:12:49,856:INFO:              xxhash: 3.5.0
2024-11-14 13:12:49,856:INFO:           wurlitzer: 3.1.1
2024-11-14 13:12:49,856:INFO:PyCaret optional dependencies:
2024-11-14 13:12:49,857:INFO:                shap: 0.44.1
2024-11-14 13:12:49,857:INFO:           interpret: 0.6.5
2024-11-14 13:12:49,857:INFO:                umap: 0.5.7
2024-11-14 13:12:49,857:INFO:     ydata_profiling: 4.6.0
2024-11-14 13:12:49,857:INFO:  explainerdashboard: 0.4.7
2024-11-14 13:12:49,857:INFO:             autoviz: Not installed
2024-11-14 13:12:49,857:INFO:           fairlearn: 0.7.0
2024-11-14 13:12:49,857:INFO:          deepchecks: Not installed
2024-11-14 13:12:49,857:INFO:             xgboost: 2.1.1
2024-11-14 13:12:49,857:INFO:            catboost: 1.2.7
2024-11-14 13:12:49,857:INFO:              kmodes: 0.12.2
2024-11-14 13:12:49,857:INFO:             mlxtend: 0.23.1
2024-11-14 13:12:49,857:INFO:       statsforecast: 1.5.0
2024-11-14 13:12:49,857:INFO:        tune_sklearn: 0.5.0
2024-11-14 13:12:49,857:INFO:                 ray: 2.10.0
2024-11-14 13:12:49,857:INFO:            hyperopt: 0.2.7
2024-11-14 13:12:49,857:INFO:              optuna: 4.1.0
2024-11-14 13:12:49,857:INFO:               skopt: 0.10.2
2024-11-14 13:12:49,857:INFO:              mlflow: 1.30.1
2024-11-14 13:12:49,857:INFO:              gradio: 3.50.2
2024-11-14 13:12:49,857:INFO:             fastapi: 0.115.5
2024-11-14 13:12:49,857:INFO:             uvicorn: 0.32.0
2024-11-14 13:12:49,857:INFO:              m2cgen: 0.10.0
2024-11-14 13:12:49,857:INFO:           evidently: 0.2.8
2024-11-14 13:12:49,857:INFO:               fugue: 0.8.6
2024-11-14 13:12:49,857:INFO:           streamlit: Not installed
2024-11-14 13:12:49,857:INFO:             prophet: Not installed
2024-11-14 13:12:49,857:INFO:None
2024-11-14 13:12:49,857:INFO:Set up data.
2024-11-14 13:12:49,868:INFO:Set up folding strategy.
2024-11-14 13:12:49,868:INFO:Set up train/test split.
2024-11-14 13:12:49,874:INFO:Set up index.
2024-11-14 13:12:49,876:INFO:Assigning column types.
2024-11-14 13:12:49,881:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 13:12:49,881:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 13:12:49,886:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 13:12:49,892:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:12:49,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:12:49,994:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:12:49,995:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:49,997:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:49,998:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,002:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,006:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,098:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:50,101:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:50,102:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 13:12:50,106:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,110:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,199:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:50,201:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:50,205:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,209:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,298:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,298:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:50,300:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:50,301:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 13:12:50,309:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,398:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:50,400:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:50,408:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,459:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,497:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,497:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:50,500:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:50,500:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 13:12:50,558:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,596:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,596:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:50,598:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:50,658:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,696:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:50,698:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:50,699:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 13:12:50,757:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,796:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:50,798:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:50,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:12:50,894:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:50,897:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:50,897:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 13:12:50,994:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:50,997:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:51,094:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:51,096:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:51,098:INFO:Preparing preprocessing pipeline...
2024-11-14 13:12:51,098:INFO:Set up simple imputation.
2024-11-14 13:12:51,116:INFO:Finished creating preprocessing pipeline.
2024-11-14 13:12:51,120:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 13:12:51,120:INFO:Creating final display dataframe.
2024-11-14 13:12:51,175:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              864c
2024-11-14 13:12:51,276:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:51,279:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:51,375:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:12:51,377:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:12:51,378:INFO:setup() successfully completed in 1.53s...............
2024-11-14 13:13:21,870:INFO:Initializing compare_models()
2024-11-14 13:13:21,870:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, include=['et', 'rf', 'lightgbm', 'xgboost', 'catboost'], fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, 'include': ['et', 'rf', 'lightgbm', 'xgboost', 'catboost'], 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 13:13:21,871:INFO:Checking exceptions
2024-11-14 13:13:21,876:INFO:Preparing display monitor
2024-11-14 13:13:21,916:INFO:Initializing Extra Trees Regressor
2024-11-14 13:13:21,916:INFO:Total runtime is 3.039836883544922e-06 minutes
2024-11-14 13:13:21,922:INFO:SubProcess create_model() called ==================================
2024-11-14 13:13:21,922:INFO:Initializing create_model()
2024-11-14 13:13:21,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c55acdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:13:21,922:INFO:Checking exceptions
2024-11-14 13:13:21,922:INFO:Importing libraries
2024-11-14 13:13:21,922:INFO:Copying training dataset
2024-11-14 13:13:21,929:INFO:Defining folds
2024-11-14 13:13:21,929:INFO:Declaring metric variables
2024-11-14 13:13:21,933:INFO:Importing untrained model
2024-11-14 13:13:21,937:INFO:Extra Trees Regressor Imported successfully
2024-11-14 13:13:21,945:INFO:Starting cross validation
2024-11-14 13:13:21,946:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:13:26,552:INFO:Calculating mean and std
2024-11-14 13:13:26,558:INFO:Creating metrics dataframe
2024-11-14 13:13:26,565:INFO:Uploading results into container
2024-11-14 13:13:26,566:INFO:Uploading model into container now
2024-11-14 13:13:26,567:INFO:_master_model_container: 1
2024-11-14 13:13:26,567:INFO:_display_container: 2
2024-11-14 13:13:26,568:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:13:26,568:INFO:create_model() successfully completed......................................
2024-11-14 13:13:26,830:INFO:SubProcess create_model() end ==================================
2024-11-14 13:13:26,830:INFO:Creating metrics dataframe
2024-11-14 13:13:26,841:INFO:Initializing Random Forest Regressor
2024-11-14 13:13:26,842:INFO:Total runtime is 0.08208839098612468 minutes
2024-11-14 13:13:26,846:INFO:SubProcess create_model() called ==================================
2024-11-14 13:13:26,846:INFO:Initializing create_model()
2024-11-14 13:13:26,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c55acdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:13:26,846:INFO:Checking exceptions
2024-11-14 13:13:26,847:INFO:Importing libraries
2024-11-14 13:13:26,847:INFO:Copying training dataset
2024-11-14 13:13:26,857:INFO:Defining folds
2024-11-14 13:13:26,857:INFO:Declaring metric variables
2024-11-14 13:13:26,861:INFO:Importing untrained model
2024-11-14 13:13:26,865:INFO:Random Forest Regressor Imported successfully
2024-11-14 13:13:26,873:INFO:Starting cross validation
2024-11-14 13:13:26,874:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:13:30,374:INFO:Calculating mean and std
2024-11-14 13:13:30,377:INFO:Creating metrics dataframe
2024-11-14 13:13:30,384:INFO:Uploading results into container
2024-11-14 13:13:30,385:INFO:Uploading model into container now
2024-11-14 13:13:30,385:INFO:_master_model_container: 2
2024-11-14 13:13:30,385:INFO:_display_container: 2
2024-11-14 13:13:30,386:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:13:30,386:INFO:create_model() successfully completed......................................
2024-11-14 13:13:30,565:INFO:SubProcess create_model() end ==================================
2024-11-14 13:13:30,565:INFO:Creating metrics dataframe
2024-11-14 13:13:30,578:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 13:13:30,578:INFO:Total runtime is 0.14436136484146117 minutes
2024-11-14 13:13:30,582:INFO:SubProcess create_model() called ==================================
2024-11-14 13:13:30,582:INFO:Initializing create_model()
2024-11-14 13:13:30,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c55acdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:13:30,583:INFO:Checking exceptions
2024-11-14 13:13:30,583:INFO:Importing libraries
2024-11-14 13:13:30,583:INFO:Copying training dataset
2024-11-14 13:13:30,591:INFO:Defining folds
2024-11-14 13:13:30,591:INFO:Declaring metric variables
2024-11-14 13:13:30,595:INFO:Importing untrained model
2024-11-14 13:13:30,599:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 13:13:30,607:INFO:Starting cross validation
2024-11-14 13:13:30,608:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:16:57,415:INFO:Calculating mean and std
2024-11-14 13:16:57,417:INFO:Creating metrics dataframe
2024-11-14 13:16:57,422:INFO:Uploading results into container
2024-11-14 13:16:57,423:INFO:Uploading model into container now
2024-11-14 13:16:57,423:INFO:_master_model_container: 3
2024-11-14 13:16:57,424:INFO:_display_container: 2
2024-11-14 13:16:57,424:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:16:57,424:INFO:create_model() successfully completed......................................
2024-11-14 13:16:57,589:INFO:SubProcess create_model() end ==================================
2024-11-14 13:16:57,589:INFO:Creating metrics dataframe
2024-11-14 13:16:57,599:INFO:Initializing Extreme Gradient Boosting
2024-11-14 13:16:57,599:INFO:Total runtime is 3.5947115302085875 minutes
2024-11-14 13:16:57,602:INFO:SubProcess create_model() called ==================================
2024-11-14 13:16:57,603:INFO:Initializing create_model()
2024-11-14 13:16:57,603:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c55acdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:16:57,603:INFO:Checking exceptions
2024-11-14 13:16:57,603:INFO:Importing libraries
2024-11-14 13:16:57,603:INFO:Copying training dataset
2024-11-14 13:16:57,610:INFO:Defining folds
2024-11-14 13:16:57,610:INFO:Declaring metric variables
2024-11-14 13:16:57,613:INFO:Importing untrained model
2024-11-14 13:16:57,617:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 13:16:57,623:INFO:Starting cross validation
2024-11-14 13:16:57,624:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:17:00,567:INFO:Calculating mean and std
2024-11-14 13:17:00,571:INFO:Creating metrics dataframe
2024-11-14 13:17:00,578:INFO:Uploading results into container
2024-11-14 13:17:00,579:INFO:Uploading model into container now
2024-11-14 13:17:00,580:INFO:_master_model_container: 4
2024-11-14 13:17:00,580:INFO:_display_container: 2
2024-11-14 13:17:00,581:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=42, ...)
2024-11-14 13:17:00,581:INFO:create_model() successfully completed......................................
2024-11-14 13:17:00,769:INFO:SubProcess create_model() end ==================================
2024-11-14 13:17:00,769:INFO:Creating metrics dataframe
2024-11-14 13:17:00,779:INFO:Initializing CatBoost Regressor
2024-11-14 13:17:00,779:INFO:Total runtime is 3.6477173964182534 minutes
2024-11-14 13:17:00,783:INFO:SubProcess create_model() called ==================================
2024-11-14 13:17:00,783:INFO:Initializing create_model()
2024-11-14 13:17:00,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c55acdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:17:00,783:INFO:Checking exceptions
2024-11-14 13:17:00,783:INFO:Importing libraries
2024-11-14 13:17:00,783:INFO:Copying training dataset
2024-11-14 13:17:00,790:INFO:Defining folds
2024-11-14 13:17:00,790:INFO:Declaring metric variables
2024-11-14 13:17:00,794:INFO:Importing untrained model
2024-11-14 13:17:00,797:INFO:CatBoost Regressor Imported successfully
2024-11-14 13:17:00,804:INFO:Starting cross validation
2024-11-14 13:17:00,805:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:17:10,895:INFO:Calculating mean and std
2024-11-14 13:17:10,897:INFO:Creating metrics dataframe
2024-11-14 13:17:10,903:INFO:Uploading results into container
2024-11-14 13:17:10,904:INFO:Uploading model into container now
2024-11-14 13:17:10,904:INFO:_master_model_container: 5
2024-11-14 13:17:10,904:INFO:_display_container: 2
2024-11-14 13:17:10,904:INFO:<catboost.core.CatBoostRegressor object at 0x7fc08f92afa0>
2024-11-14 13:17:10,905:INFO:create_model() successfully completed......................................
2024-11-14 13:17:11,083:INFO:SubProcess create_model() end ==================================
2024-11-14 13:17:11,083:INFO:Creating metrics dataframe
2024-11-14 13:17:11,103:INFO:Initializing create_model()
2024-11-14 13:17:11,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:17:11,103:INFO:Checking exceptions
2024-11-14 13:17:11,105:INFO:Importing libraries
2024-11-14 13:17:11,105:INFO:Copying training dataset
2024-11-14 13:17:11,111:INFO:Defining folds
2024-11-14 13:17:11,111:INFO:Declaring metric variables
2024-11-14 13:17:11,111:INFO:Importing untrained model
2024-11-14 13:17:11,111:INFO:Declaring custom model
2024-11-14 13:17:11,111:INFO:Extra Trees Regressor Imported successfully
2024-11-14 13:17:11,112:INFO:Cross validation set to False
2024-11-14 13:17:11,112:INFO:Fitting Model
2024-11-14 13:17:11,367:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:17:11,368:INFO:create_model() successfully completed......................................
2024-11-14 13:17:11,577:INFO:_master_model_container: 5
2024-11-14 13:17:11,577:INFO:_display_container: 2
2024-11-14 13:17:11,578:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:17:11,578:INFO:compare_models() successfully completed......................................
2024-11-14 13:17:22,012:INFO:Initializing tune_model()
2024-11-14 13:17:22,013:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>)
2024-11-14 13:17:22,013:INFO:Checking exceptions
2024-11-14 13:17:22,049:INFO:Copying training dataset
2024-11-14 13:17:22,055:INFO:Checking base model
2024-11-14 13:17:22,055:INFO:Base model : Extra Trees Regressor
2024-11-14 13:17:22,059:INFO:Declaring metric variables
2024-11-14 13:17:22,063:INFO:Defining Hyperparameters
2024-11-14 13:17:22,259:INFO:Tuning with n_jobs=-1
2024-11-14 13:17:22,259:INFO:Initializing RandomizedSearchCV
2024-11-14 13:18:14,992:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 13:18:15,091:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 13:18:16,187:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 13:18:16,331:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 13:18:28,058:INFO:best_params: {'actual_estimator__n_estimators': 30, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-11-14 13:18:28,062:INFO:Hyperparameter search completed
2024-11-14 13:18:28,063:INFO:SubProcess create_model() called ==================================
2024-11-14 13:18:28,064:INFO:Initializing create_model()
2024-11-14 13:18:28,064:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfb510d130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 30, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0001, 'max_features': 'log2', 'max_depth': 11, 'criterion': 'squared_error', 'bootstrap': False})
2024-11-14 13:18:28,064:INFO:Checking exceptions
2024-11-14 13:18:28,064:INFO:Importing libraries
2024-11-14 13:18:28,064:INFO:Copying training dataset
2024-11-14 13:18:28,072:INFO:Defining folds
2024-11-14 13:18:28,072:INFO:Declaring metric variables
2024-11-14 13:18:28,076:INFO:Importing untrained model
2024-11-14 13:18:28,076:INFO:Declaring custom model
2024-11-14 13:18:28,080:INFO:Extra Trees Regressor Imported successfully
2024-11-14 13:18:28,087:INFO:Starting cross validation
2024-11-14 13:18:28,088:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:18:28,354:INFO:Calculating mean and std
2024-11-14 13:18:28,358:INFO:Creating metrics dataframe
2024-11-14 13:18:28,366:INFO:Finalizing model
2024-11-14 13:18:28,467:INFO:Uploading results into container
2024-11-14 13:18:28,468:INFO:Uploading model into container now
2024-11-14 13:18:28,469:INFO:_master_model_container: 6
2024-11-14 13:18:28,469:INFO:_display_container: 3
2024-11-14 13:18:28,470:INFO:ExtraTreesRegressor(max_depth=11, max_features='log2',
                    min_impurity_decrease=0.0001, min_samples_leaf=3,
                    min_samples_split=7, n_estimators=30, n_jobs=-1,
                    random_state=42)
2024-11-14 13:18:28,470:INFO:create_model() successfully completed......................................
2024-11-14 13:18:28,673:INFO:SubProcess create_model() end ==================================
2024-11-14 13:18:28,673:INFO:choose_better activated
2024-11-14 13:18:28,677:INFO:SubProcess create_model() called ==================================
2024-11-14 13:18:28,678:INFO:Initializing create_model()
2024-11-14 13:18:28,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:18:28,678:INFO:Checking exceptions
2024-11-14 13:18:28,680:INFO:Importing libraries
2024-11-14 13:18:28,680:INFO:Copying training dataset
2024-11-14 13:18:28,687:INFO:Defining folds
2024-11-14 13:18:28,687:INFO:Declaring metric variables
2024-11-14 13:18:28,687:INFO:Importing untrained model
2024-11-14 13:18:28,687:INFO:Declaring custom model
2024-11-14 13:18:28,688:INFO:Extra Trees Regressor Imported successfully
2024-11-14 13:18:28,688:INFO:Starting cross validation
2024-11-14 13:18:28,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:18:29,603:INFO:Calculating mean and std
2024-11-14 13:18:29,604:INFO:Creating metrics dataframe
2024-11-14 13:18:29,608:INFO:Finalizing model
2024-11-14 13:18:29,857:INFO:Uploading results into container
2024-11-14 13:18:29,859:INFO:Uploading model into container now
2024-11-14 13:18:29,860:INFO:_master_model_container: 7
2024-11-14 13:18:29,860:INFO:_display_container: 4
2024-11-14 13:18:29,860:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:18:29,861:INFO:create_model() successfully completed......................................
2024-11-14 13:18:30,091:INFO:SubProcess create_model() end ==================================
2024-11-14 13:18:30,092:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9809
2024-11-14 13:18:30,093:INFO:ExtraTreesRegressor(max_depth=11, max_features='log2',
                    min_impurity_decrease=0.0001, min_samples_leaf=3,
                    min_samples_split=7, n_estimators=30, n_jobs=-1,
                    random_state=42) result for R2 is 0.7602
2024-11-14 13:18:30,093:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42) is best model
2024-11-14 13:18:30,094:INFO:choose_better completed
2024-11-14 13:18:30,094:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-11-14 13:18:30,108:INFO:_master_model_container: 7
2024-11-14 13:18:30,108:INFO:_display_container: 3
2024-11-14 13:18:30,109:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:18:30,109:INFO:tune_model() successfully completed......................................
2024-11-14 13:35:39,057:INFO:Initializing create_model()
2024-11-14 13:35:39,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c4c820a0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:35:39,058:INFO:Checking exceptions
2024-11-14 13:35:39,090:INFO:Importing libraries
2024-11-14 13:35:39,090:INFO:Copying training dataset
2024-11-14 13:35:39,100:INFO:Defining folds
2024-11-14 13:35:39,100:INFO:Declaring metric variables
2024-11-14 13:35:39,104:INFO:Importing untrained model
2024-11-14 13:35:39,108:INFO:Extra Trees Regressor Imported successfully
2024-11-14 13:35:39,116:INFO:Starting cross validation
2024-11-14 13:35:39,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:35:44,165:INFO:Calculating mean and std
2024-11-14 13:35:44,169:INFO:Creating metrics dataframe
2024-11-14 13:35:44,180:INFO:Finalizing model
2024-11-14 13:35:44,474:INFO:Uploading results into container
2024-11-14 13:35:44,476:INFO:Uploading model into container now
2024-11-14 13:35:44,488:INFO:_master_model_container: 8
2024-11-14 13:35:44,488:INFO:_display_container: 4
2024-11-14 13:35:44,489:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:35:44,489:INFO:create_model() successfully completed......................................
2024-11-14 13:37:50,167:INFO:PyCaret RegressionExperiment
2024-11-14 13:37:50,167:INFO:Logging name: reg-default-name
2024-11-14 13:37:50,168:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 13:37:50,168:INFO:version 3.2.0
2024-11-14 13:37:50,168:INFO:Initializing setup()
2024-11-14 13:37:50,168:INFO:self.USI: 877e
2024-11-14 13:37:50,168:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 13:37:50,168:INFO:Checking environment
2024-11-14 13:37:50,168:INFO:python_version: 3.8.13
2024-11-14 13:37:50,168:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 13:37:50,168:INFO:machine: x86_64
2024-11-14 13:37:50,168:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 13:37:50,168:INFO:Memory: svmem(total=270355722240, available=215628357632, percent=20.2, used=52637323264, free=66385162240, active=72111476736, inactive=71364456448, buffers=10100736, cached=151323136000, shared=196108288, slab=25314009088)
2024-11-14 13:37:50,171:INFO:Physical Core: 28
2024-11-14 13:37:50,171:INFO:Logical Core: 56
2024-11-14 13:37:50,171:INFO:Checking libraries
2024-11-14 13:37:50,171:INFO:System:
2024-11-14 13:37:50,171:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 13:37:50,171:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 13:37:50,171:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 13:37:50,171:INFO:PyCaret required dependencies:
2024-11-14 13:37:50,172:INFO:                 pip: 22.2.2
2024-11-14 13:37:50,172:INFO:          setuptools: 63.4.2
2024-11-14 13:37:50,172:INFO:             pycaret: 3.2.0
2024-11-14 13:37:50,172:INFO:             IPython: 8.12.2
2024-11-14 13:37:50,172:INFO:          ipywidgets: 7.7.1
2024-11-14 13:37:50,172:INFO:                tqdm: 4.64.1
2024-11-14 13:37:50,172:INFO:               numpy: 1.23.5
2024-11-14 13:37:50,172:INFO:              pandas: 1.5.3
2024-11-14 13:37:50,172:INFO:              jinja2: 3.1.2
2024-11-14 13:37:50,172:INFO:               scipy: 1.10.1
2024-11-14 13:37:50,172:INFO:              joblib: 1.3.0
2024-11-14 13:37:50,172:INFO:             sklearn: 1.1.2
2024-11-14 13:37:50,172:INFO:                pyod: 2.0.2
2024-11-14 13:37:50,172:INFO:            imblearn: 0.12.4
2024-11-14 13:37:50,172:INFO:   category_encoders: 2.6.4
2024-11-14 13:37:50,172:INFO:            lightgbm: 4.5.0
2024-11-14 13:37:50,172:INFO:               numba: 0.57.1
2024-11-14 13:37:50,172:INFO:            requests: 2.28.1
2024-11-14 13:37:50,172:INFO:          matplotlib: 3.5.1
2024-11-14 13:37:50,172:INFO:          scikitplot: 0.3.7
2024-11-14 13:37:50,172:INFO:         yellowbrick: 1.5
2024-11-14 13:37:50,172:INFO:              plotly: 5.24.1
2024-11-14 13:37:50,172:INFO:    plotly-resampler: Not installed
2024-11-14 13:37:50,173:INFO:             kaleido: 0.2.1
2024-11-14 13:37:50,173:INFO:           schemdraw: 0.15
2024-11-14 13:37:50,173:INFO:         statsmodels: 0.13.2
2024-11-14 13:37:50,173:INFO:              sktime: 0.21.1
2024-11-14 13:37:50,173:INFO:               tbats: 1.1.3
2024-11-14 13:37:50,173:INFO:            pmdarima: 2.0.4
2024-11-14 13:37:50,173:INFO:              psutil: 5.9.1
2024-11-14 13:37:50,173:INFO:          markupsafe: 2.1.1
2024-11-14 13:37:50,173:INFO:             pickle5: Not installed
2024-11-14 13:37:50,173:INFO:         cloudpickle: 2.1.0
2024-11-14 13:37:50,173:INFO:         deprecation: 2.1.0
2024-11-14 13:37:50,173:INFO:              xxhash: 3.5.0
2024-11-14 13:37:50,173:INFO:           wurlitzer: 3.1.1
2024-11-14 13:37:50,173:INFO:PyCaret optional dependencies:
2024-11-14 13:37:50,173:INFO:                shap: 0.44.1
2024-11-14 13:37:50,173:INFO:           interpret: 0.6.5
2024-11-14 13:37:50,173:INFO:                umap: 0.5.7
2024-11-14 13:37:50,173:INFO:     ydata_profiling: 4.6.0
2024-11-14 13:37:50,173:INFO:  explainerdashboard: 0.4.7
2024-11-14 13:37:50,173:INFO:             autoviz: Not installed
2024-11-14 13:37:50,173:INFO:           fairlearn: 0.7.0
2024-11-14 13:37:50,173:INFO:          deepchecks: Not installed
2024-11-14 13:37:50,173:INFO:             xgboost: 2.1.1
2024-11-14 13:37:50,173:INFO:            catboost: 1.2.7
2024-11-14 13:37:50,174:INFO:              kmodes: 0.12.2
2024-11-14 13:37:50,174:INFO:             mlxtend: 0.23.1
2024-11-14 13:37:50,174:INFO:       statsforecast: 1.5.0
2024-11-14 13:37:50,174:INFO:        tune_sklearn: 0.5.0
2024-11-14 13:37:50,174:INFO:                 ray: 2.10.0
2024-11-14 13:37:50,174:INFO:            hyperopt: 0.2.7
2024-11-14 13:37:50,174:INFO:              optuna: 4.1.0
2024-11-14 13:37:50,174:INFO:               skopt: 0.10.2
2024-11-14 13:37:50,174:INFO:              mlflow: 1.30.1
2024-11-14 13:37:50,174:INFO:              gradio: 3.50.2
2024-11-14 13:37:50,174:INFO:             fastapi: 0.115.5
2024-11-14 13:37:50,174:INFO:             uvicorn: 0.32.0
2024-11-14 13:37:50,174:INFO:              m2cgen: 0.10.0
2024-11-14 13:37:50,174:INFO:           evidently: 0.2.8
2024-11-14 13:37:50,174:INFO:               fugue: 0.8.6
2024-11-14 13:37:50,174:INFO:           streamlit: Not installed
2024-11-14 13:37:50,174:INFO:             prophet: Not installed
2024-11-14 13:37:50,174:INFO:None
2024-11-14 13:37:50,174:INFO:Set up data.
2024-11-14 13:37:50,183:INFO:Set up folding strategy.
2024-11-14 13:37:50,183:INFO:Set up train/test split.
2024-11-14 13:37:50,189:INFO:Set up index.
2024-11-14 13:37:50,191:INFO:Assigning column types.
2024-11-14 13:37:50,196:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 13:37:50,196:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,201:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,206:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,277:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,328:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,329:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:50,332:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:50,334:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,339:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,345:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,399:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,438:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:50,440:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:50,440:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 13:37:50,444:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,448:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,500:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,539:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:50,542:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:50,546:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,550:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,601:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,641:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,641:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:50,644:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:50,644:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 13:37:50,652:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,704:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,742:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,742:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:50,745:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:50,753:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,803:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,843:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:50,845:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:50,845:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 13:37:50,904:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:37:50,943:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:50,945:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:51,005:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:37:51,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 13:37:51,043:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:51,045:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:51,045:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 13:37:51,105:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:37:51,144:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:51,146:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:51,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 13:37:51,244:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:51,246:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:51,246:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 13:37:51,345:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:51,347:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:51,447:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:51,449:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:51,451:INFO:Preparing preprocessing pipeline...
2024-11-14 13:37:51,451:INFO:Set up simple imputation.
2024-11-14 13:37:51,480:INFO:Finished creating preprocessing pipeline.
2024-11-14 13:37:51,483:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Latitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 13:37:51,483:INFO:Creating final display dataframe.
2024-11-14 13:37:51,539:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Longitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              877e
2024-11-14 13:37:51,634:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:51,637:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:51,738:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 13:37:51,740:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 13:37:51,742:INFO:setup() successfully completed in 1.58s...............
2024-11-14 13:37:51,742:INFO:Initializing compare_models()
2024-11-14 13:37:51,742:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, include=['et', 'rf', 'lightgbm', 'xgboost', 'catboost'], fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, 'include': ['et', 'rf', 'lightgbm', 'xgboost', 'catboost'], 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 13:37:51,743:INFO:Checking exceptions
2024-11-14 13:37:51,746:INFO:Preparing display monitor
2024-11-14 13:37:51,785:INFO:Initializing Extra Trees Regressor
2024-11-14 13:37:51,785:INFO:Total runtime is 2.8729438781738283e-06 minutes
2024-11-14 13:37:51,789:INFO:SubProcess create_model() called ==================================
2024-11-14 13:37:51,790:INFO:Initializing create_model()
2024-11-14 13:37:51,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd0066dc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:37:51,790:INFO:Checking exceptions
2024-11-14 13:37:51,790:INFO:Importing libraries
2024-11-14 13:37:51,790:INFO:Copying training dataset
2024-11-14 13:37:51,797:INFO:Defining folds
2024-11-14 13:37:51,797:INFO:Declaring metric variables
2024-11-14 13:37:51,800:INFO:Importing untrained model
2024-11-14 13:37:51,804:INFO:Extra Trees Regressor Imported successfully
2024-11-14 13:37:51,810:INFO:Starting cross validation
2024-11-14 13:37:51,811:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:37:55,009:INFO:Calculating mean and std
2024-11-14 13:37:55,013:INFO:Creating metrics dataframe
2024-11-14 13:37:55,020:INFO:Uploading results into container
2024-11-14 13:37:55,020:INFO:Uploading model into container now
2024-11-14 13:37:55,021:INFO:_master_model_container: 1
2024-11-14 13:37:55,021:INFO:_display_container: 2
2024-11-14 13:37:55,021:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:37:55,022:INFO:create_model() successfully completed......................................
2024-11-14 13:37:55,233:INFO:SubProcess create_model() end ==================================
2024-11-14 13:37:55,234:INFO:Creating metrics dataframe
2024-11-14 13:37:55,242:INFO:Initializing Random Forest Regressor
2024-11-14 13:37:55,243:INFO:Total runtime is 0.05762157837549845 minutes
2024-11-14 13:37:55,246:INFO:SubProcess create_model() called ==================================
2024-11-14 13:37:55,247:INFO:Initializing create_model()
2024-11-14 13:37:55,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd0066dc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:37:55,247:INFO:Checking exceptions
2024-11-14 13:37:55,247:INFO:Importing libraries
2024-11-14 13:37:55,247:INFO:Copying training dataset
2024-11-14 13:37:55,254:INFO:Defining folds
2024-11-14 13:37:55,254:INFO:Declaring metric variables
2024-11-14 13:37:55,257:INFO:Importing untrained model
2024-11-14 13:37:55,261:INFO:Random Forest Regressor Imported successfully
2024-11-14 13:37:55,268:INFO:Starting cross validation
2024-11-14 13:37:55,268:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:37:58,794:INFO:Calculating mean and std
2024-11-14 13:37:58,797:INFO:Creating metrics dataframe
2024-11-14 13:37:58,804:INFO:Uploading results into container
2024-11-14 13:37:58,805:INFO:Uploading model into container now
2024-11-14 13:37:58,805:INFO:_master_model_container: 2
2024-11-14 13:37:58,806:INFO:_display_container: 2
2024-11-14 13:37:58,806:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:37:58,806:INFO:create_model() successfully completed......................................
2024-11-14 13:37:59,033:INFO:SubProcess create_model() end ==================================
2024-11-14 13:37:59,033:INFO:Creating metrics dataframe
2024-11-14 13:37:59,045:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 13:37:59,045:INFO:Total runtime is 0.12100300391515095 minutes
2024-11-14 13:37:59,049:INFO:SubProcess create_model() called ==================================
2024-11-14 13:37:59,050:INFO:Initializing create_model()
2024-11-14 13:37:59,050:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd0066dc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:37:59,050:INFO:Checking exceptions
2024-11-14 13:37:59,050:INFO:Importing libraries
2024-11-14 13:37:59,050:INFO:Copying training dataset
2024-11-14 13:37:59,058:INFO:Defining folds
2024-11-14 13:37:59,059:INFO:Declaring metric variables
2024-11-14 13:37:59,063:INFO:Importing untrained model
2024-11-14 13:37:59,067:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 13:37:59,074:INFO:Starting cross validation
2024-11-14 13:37:59,075:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:41:29,514:INFO:Calculating mean and std
2024-11-14 13:41:29,518:INFO:Creating metrics dataframe
2024-11-14 13:41:29,524:INFO:Uploading results into container
2024-11-14 13:41:29,525:INFO:Uploading model into container now
2024-11-14 13:41:29,526:INFO:_master_model_container: 3
2024-11-14 13:41:29,526:INFO:_display_container: 2
2024-11-14 13:41:29,527:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:41:29,527:INFO:create_model() successfully completed......................................
2024-11-14 13:41:29,712:INFO:SubProcess create_model() end ==================================
2024-11-14 13:41:29,712:INFO:Creating metrics dataframe
2024-11-14 13:41:29,723:INFO:Initializing Extreme Gradient Boosting
2024-11-14 13:41:29,723:INFO:Total runtime is 3.6322902997334796 minutes
2024-11-14 13:41:29,726:INFO:SubProcess create_model() called ==================================
2024-11-14 13:41:29,726:INFO:Initializing create_model()
2024-11-14 13:41:29,727:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd0066dc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:41:29,727:INFO:Checking exceptions
2024-11-14 13:41:29,727:INFO:Importing libraries
2024-11-14 13:41:29,727:INFO:Copying training dataset
2024-11-14 13:41:29,735:INFO:Defining folds
2024-11-14 13:41:29,735:INFO:Declaring metric variables
2024-11-14 13:41:29,739:INFO:Importing untrained model
2024-11-14 13:41:29,742:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 13:41:29,749:INFO:Starting cross validation
2024-11-14 13:41:29,750:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:41:31,346:INFO:Calculating mean and std
2024-11-14 13:41:31,351:INFO:Creating metrics dataframe
2024-11-14 13:41:31,357:INFO:Uploading results into container
2024-11-14 13:41:31,358:INFO:Uploading model into container now
2024-11-14 13:41:31,358:INFO:_master_model_container: 4
2024-11-14 13:41:31,359:INFO:_display_container: 2
2024-11-14 13:41:31,360:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=42, ...)
2024-11-14 13:41:31,360:INFO:create_model() successfully completed......................................
2024-11-14 13:41:31,543:INFO:SubProcess create_model() end ==================================
2024-11-14 13:41:31,543:INFO:Creating metrics dataframe
2024-11-14 13:41:31,555:INFO:Initializing CatBoost Regressor
2024-11-14 13:41:31,555:INFO:Total runtime is 3.662830551465352 minutes
2024-11-14 13:41:31,559:INFO:SubProcess create_model() called ==================================
2024-11-14 13:41:31,559:INFO:Initializing create_model()
2024-11-14 13:41:31,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd0066dc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:41:31,559:INFO:Checking exceptions
2024-11-14 13:41:31,559:INFO:Importing libraries
2024-11-14 13:41:31,560:INFO:Copying training dataset
2024-11-14 13:41:31,567:INFO:Defining folds
2024-11-14 13:41:31,567:INFO:Declaring metric variables
2024-11-14 13:41:31,571:INFO:Importing untrained model
2024-11-14 13:41:31,574:INFO:CatBoost Regressor Imported successfully
2024-11-14 13:41:31,581:INFO:Starting cross validation
2024-11-14 13:41:31,582:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 13:41:38,320:INFO:Calculating mean and std
2024-11-14 13:41:38,323:INFO:Creating metrics dataframe
2024-11-14 13:41:38,329:INFO:Uploading results into container
2024-11-14 13:41:38,330:INFO:Uploading model into container now
2024-11-14 13:41:38,331:INFO:_master_model_container: 5
2024-11-14 13:41:38,331:INFO:_display_container: 2
2024-11-14 13:41:38,331:INFO:<catboost.core.CatBoostRegressor object at 0x7fc08fb0d700>
2024-11-14 13:41:38,331:INFO:create_model() successfully completed......................................
2024-11-14 13:41:38,492:INFO:SubProcess create_model() end ==================================
2024-11-14 13:41:38,493:INFO:Creating metrics dataframe
2024-11-14 13:41:38,514:INFO:Initializing create_model()
2024-11-14 13:41:38,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 13:41:38,514:INFO:Checking exceptions
2024-11-14 13:41:38,516:INFO:Importing libraries
2024-11-14 13:41:38,516:INFO:Copying training dataset
2024-11-14 13:41:38,524:INFO:Defining folds
2024-11-14 13:41:38,524:INFO:Declaring metric variables
2024-11-14 13:41:38,524:INFO:Importing untrained model
2024-11-14 13:41:38,524:INFO:Declaring custom model
2024-11-14 13:41:38,524:INFO:Extra Trees Regressor Imported successfully
2024-11-14 13:41:38,525:INFO:Cross validation set to False
2024-11-14 13:41:38,525:INFO:Fitting Model
2024-11-14 13:41:38,780:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:41:38,780:INFO:create_model() successfully completed......................................
2024-11-14 13:41:39,113:INFO:_master_model_container: 5
2024-11-14 13:41:39,113:INFO:_display_container: 2
2024-11-14 13:41:39,113:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 13:41:39,114:INFO:compare_models() successfully completed......................................
2024-11-14 15:00:08,441:INFO:Initializing compare_models()
2024-11-14 15:00:08,442:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, include=['et', 'rf', 'lightgbm', 'xgboost', 'catboost'], fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, 'include': ['et', 'rf', 'lightgbm', 'xgboost', 'catboost'], 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 15:00:08,442:INFO:Checking exceptions
2024-11-14 15:00:08,448:INFO:Preparing display monitor
2024-11-14 15:00:08,491:INFO:Initializing Extra Trees Regressor
2024-11-14 15:00:08,491:INFO:Total runtime is 4.525979359944662e-06 minutes
2024-11-14 15:00:08,495:INFO:SubProcess create_model() called ==================================
2024-11-14 15:00:08,495:INFO:Initializing create_model()
2024-11-14 15:00:08,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c45ba2e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:00:08,495:INFO:Checking exceptions
2024-11-14 15:00:08,495:INFO:Importing libraries
2024-11-14 15:00:08,496:INFO:Copying training dataset
2024-11-14 15:00:08,503:INFO:Defining folds
2024-11-14 15:00:08,503:INFO:Declaring metric variables
2024-11-14 15:00:08,507:INFO:Importing untrained model
2024-11-14 15:00:08,512:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:00:08,519:INFO:Starting cross validation
2024-11-14 15:00:08,520:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:00:13,433:INFO:Calculating mean and std
2024-11-14 15:00:13,438:INFO:Creating metrics dataframe
2024-11-14 15:00:13,446:INFO:Uploading results into container
2024-11-14 15:00:13,447:INFO:Uploading model into container now
2024-11-14 15:00:13,447:INFO:_master_model_container: 6
2024-11-14 15:00:13,447:INFO:_display_container: 3
2024-11-14 15:00:13,448:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:00:13,448:INFO:create_model() successfully completed......................................
2024-11-14 15:00:13,675:INFO:SubProcess create_model() end ==================================
2024-11-14 15:00:13,675:INFO:Creating metrics dataframe
2024-11-14 15:00:13,687:INFO:Initializing Random Forest Regressor
2024-11-14 15:00:13,687:INFO:Total runtime is 0.0866102417310079 minutes
2024-11-14 15:00:13,691:INFO:SubProcess create_model() called ==================================
2024-11-14 15:00:13,692:INFO:Initializing create_model()
2024-11-14 15:00:13,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd0066b20>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c45ba2e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:00:13,692:INFO:Checking exceptions
2024-11-14 15:00:13,692:INFO:Importing libraries
2024-11-14 15:00:13,692:INFO:Copying training dataset
2024-11-14 15:00:13,701:INFO:Defining folds
2024-11-14 15:00:13,702:INFO:Declaring metric variables
2024-11-14 15:00:13,706:INFO:Importing untrained model
2024-11-14 15:00:13,710:INFO:Random Forest Regressor Imported successfully
2024-11-14 15:00:13,717:INFO:Starting cross validation
2024-11-14 15:00:13,718:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:00:47,945:INFO:PyCaret RegressionExperiment
2024-11-14 15:00:47,946:INFO:Logging name: reg-default-name
2024-11-14 15:00:47,946:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 15:00:47,946:INFO:version 3.2.0
2024-11-14 15:00:47,946:INFO:Initializing setup()
2024-11-14 15:00:47,946:INFO:self.USI: 5dfb
2024-11-14 15:00:47,946:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 15:00:47,946:INFO:Checking environment
2024-11-14 15:00:47,946:INFO:python_version: 3.8.13
2024-11-14 15:00:47,946:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 15:00:47,946:INFO:machine: x86_64
2024-11-14 15:00:47,946:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 15:00:47,947:INFO:Memory: svmem(total=270355722240, available=214073417728, percent=20.8, used=54192324608, free=62820720640, active=72599941120, inactive=74150379520, buffers=10100736, cached=153332576256, shared=195915776, slab=25464889344)
2024-11-14 15:00:47,949:INFO:Physical Core: 28
2024-11-14 15:00:47,949:INFO:Logical Core: 56
2024-11-14 15:00:47,949:INFO:Checking libraries
2024-11-14 15:00:47,949:INFO:System:
2024-11-14 15:00:47,949:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 15:00:47,949:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 15:00:47,949:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 15:00:47,949:INFO:PyCaret required dependencies:
2024-11-14 15:00:47,949:INFO:                 pip: 22.2.2
2024-11-14 15:00:47,949:INFO:          setuptools: 63.4.2
2024-11-14 15:00:47,949:INFO:             pycaret: 3.2.0
2024-11-14 15:00:47,949:INFO:             IPython: 8.12.2
2024-11-14 15:00:47,949:INFO:          ipywidgets: 7.7.1
2024-11-14 15:00:47,949:INFO:                tqdm: 4.64.1
2024-11-14 15:00:47,950:INFO:               numpy: 1.23.5
2024-11-14 15:00:47,950:INFO:              pandas: 1.5.3
2024-11-14 15:00:47,950:INFO:              jinja2: 3.1.2
2024-11-14 15:00:47,950:INFO:               scipy: 1.10.1
2024-11-14 15:00:47,950:INFO:              joblib: 1.3.0
2024-11-14 15:00:47,950:INFO:             sklearn: 1.1.2
2024-11-14 15:00:47,950:INFO:                pyod: 2.0.2
2024-11-14 15:00:47,950:INFO:            imblearn: 0.12.4
2024-11-14 15:00:47,950:INFO:   category_encoders: 2.6.4
2024-11-14 15:00:47,950:INFO:            lightgbm: 4.5.0
2024-11-14 15:00:47,950:INFO:               numba: 0.57.1
2024-11-14 15:00:47,950:INFO:            requests: 2.28.1
2024-11-14 15:00:47,950:INFO:          matplotlib: 3.5.1
2024-11-14 15:00:47,950:INFO:          scikitplot: 0.3.7
2024-11-14 15:00:47,950:INFO:         yellowbrick: 1.5
2024-11-14 15:00:47,950:INFO:              plotly: 5.24.1
2024-11-14 15:00:47,950:INFO:    plotly-resampler: Not installed
2024-11-14 15:00:47,950:INFO:             kaleido: 0.2.1
2024-11-14 15:00:47,950:INFO:           schemdraw: 0.15
2024-11-14 15:00:47,950:INFO:         statsmodels: 0.13.2
2024-11-14 15:00:47,950:INFO:              sktime: 0.21.1
2024-11-14 15:00:47,950:INFO:               tbats: 1.1.3
2024-11-14 15:00:47,950:INFO:            pmdarima: 2.0.4
2024-11-14 15:00:47,950:INFO:              psutil: 5.9.1
2024-11-14 15:00:47,950:INFO:          markupsafe: 2.1.1
2024-11-14 15:00:47,950:INFO:             pickle5: Not installed
2024-11-14 15:00:47,950:INFO:         cloudpickle: 2.1.0
2024-11-14 15:00:47,950:INFO:         deprecation: 2.1.0
2024-11-14 15:00:47,950:INFO:              xxhash: 3.5.0
2024-11-14 15:00:47,950:INFO:           wurlitzer: 3.1.1
2024-11-14 15:00:47,951:INFO:PyCaret optional dependencies:
2024-11-14 15:00:47,951:INFO:                shap: 0.44.1
2024-11-14 15:00:47,951:INFO:           interpret: 0.6.5
2024-11-14 15:00:47,951:INFO:                umap: 0.5.7
2024-11-14 15:00:47,951:INFO:     ydata_profiling: 4.6.0
2024-11-14 15:00:47,951:INFO:  explainerdashboard: 0.4.7
2024-11-14 15:00:47,951:INFO:             autoviz: Not installed
2024-11-14 15:00:47,951:INFO:           fairlearn: 0.7.0
2024-11-14 15:00:47,951:INFO:          deepchecks: Not installed
2024-11-14 15:00:47,951:INFO:             xgboost: 2.1.1
2024-11-14 15:00:47,951:INFO:            catboost: 1.2.7
2024-11-14 15:00:47,951:INFO:              kmodes: 0.12.2
2024-11-14 15:00:47,951:INFO:             mlxtend: 0.23.1
2024-11-14 15:00:47,951:INFO:       statsforecast: 1.5.0
2024-11-14 15:00:47,951:INFO:        tune_sklearn: 0.5.0
2024-11-14 15:00:47,951:INFO:                 ray: 2.10.0
2024-11-14 15:00:47,951:INFO:            hyperopt: 0.2.7
2024-11-14 15:00:47,951:INFO:              optuna: 4.1.0
2024-11-14 15:00:47,951:INFO:               skopt: 0.10.2
2024-11-14 15:00:47,951:INFO:              mlflow: 1.30.1
2024-11-14 15:00:47,951:INFO:              gradio: 3.50.2
2024-11-14 15:00:47,951:INFO:             fastapi: 0.115.5
2024-11-14 15:00:47,951:INFO:             uvicorn: 0.32.0
2024-11-14 15:00:47,951:INFO:              m2cgen: 0.10.0
2024-11-14 15:00:47,951:INFO:           evidently: 0.2.8
2024-11-14 15:00:47,951:INFO:               fugue: 0.8.6
2024-11-14 15:00:47,951:INFO:           streamlit: Not installed
2024-11-14 15:00:47,951:INFO:             prophet: Not installed
2024-11-14 15:00:47,951:INFO:None
2024-11-14 15:00:47,951:INFO:Set up data.
2024-11-14 15:00:47,963:INFO:Set up folding strategy.
2024-11-14 15:00:47,964:INFO:Set up train/test split.
2024-11-14 15:00:47,969:INFO:Set up index.
2024-11-14 15:00:47,971:INFO:Assigning column types.
2024-11-14 15:00:47,976:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 15:00:47,976:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 15:00:47,982:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:00:47,987:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,052:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,090:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:48,093:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:48,093:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,097:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,101:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,151:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,191:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,192:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:48,194:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:48,195:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 15:00:48,199:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,203:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,253:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,290:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,290:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:48,293:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:48,297:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,301:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,351:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,389:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:48,392:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:48,392:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 15:00:48,400:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,489:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:48,491:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:48,500:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,550:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,589:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,590:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:48,592:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:48,593:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 15:00:48,654:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,692:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,692:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:48,695:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:48,756:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,794:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,795:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:48,797:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:48,797:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 15:00:48,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:00:48,896:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:48,898:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:48,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:00:49,001:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:49,003:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:49,004:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 15:00:49,099:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:49,101:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:49,196:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:49,199:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:49,200:INFO:Preparing preprocessing pipeline...
2024-11-14 15:00:49,200:INFO:Set up simple imputation.
2024-11-14 15:00:49,219:INFO:Finished creating preprocessing pipeline.
2024-11-14 15:00:49,222:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Latitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 15:00:49,222:INFO:Creating final display dataframe.
2024-11-14 15:00:49,277:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Longitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5dfb
2024-11-14 15:00:49,376:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:49,379:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:49,477:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:00:49,479:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:00:49,480:INFO:setup() successfully completed in 1.54s...............
2024-11-14 15:00:49,480:INFO:Initializing compare_models()
2024-11-14 15:00:49,480:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, include=['et', 'rf', 'lightgbm', 'xgboost', 'catboost'], fold=5, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, 'include': ['et', 'rf', 'lightgbm', 'xgboost', 'catboost'], 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 15:00:49,480:INFO:Checking exceptions
2024-11-14 15:00:49,483:INFO:Preparing display monitor
2024-11-14 15:00:49,518:INFO:Initializing Extra Trees Regressor
2024-11-14 15:00:49,518:INFO:Total runtime is 2.6265780131022137e-06 minutes
2024-11-14 15:00:49,521:INFO:SubProcess create_model() called ==================================
2024-11-14 15:00:49,522:INFO:Initializing create_model()
2024-11-14 15:00:49,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01311f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:00:49,524:INFO:Checking exceptions
2024-11-14 15:00:49,524:INFO:Importing libraries
2024-11-14 15:00:49,524:INFO:Copying training dataset
2024-11-14 15:00:49,532:INFO:Defining folds
2024-11-14 15:00:49,532:INFO:Declaring metric variables
2024-11-14 15:00:49,536:INFO:Importing untrained model
2024-11-14 15:00:49,540:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:00:49,546:INFO:Starting cross validation
2024-11-14 15:00:49,547:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:00:54,370:INFO:Calculating mean and std
2024-11-14 15:00:54,373:INFO:Creating metrics dataframe
2024-11-14 15:00:54,379:INFO:Uploading results into container
2024-11-14 15:00:54,380:INFO:Uploading model into container now
2024-11-14 15:00:54,381:INFO:_master_model_container: 1
2024-11-14 15:00:54,381:INFO:_display_container: 2
2024-11-14 15:00:54,381:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:00:54,382:INFO:create_model() successfully completed......................................
2024-11-14 15:00:54,679:INFO:SubProcess create_model() end ==================================
2024-11-14 15:00:54,679:INFO:Creating metrics dataframe
2024-11-14 15:00:54,691:INFO:Initializing Random Forest Regressor
2024-11-14 15:00:54,692:INFO:Total runtime is 0.08622867663701375 minutes
2024-11-14 15:00:54,696:INFO:SubProcess create_model() called ==================================
2024-11-14 15:00:54,696:INFO:Initializing create_model()
2024-11-14 15:00:54,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01311f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:00:54,696:INFO:Checking exceptions
2024-11-14 15:00:54,696:INFO:Importing libraries
2024-11-14 15:00:54,696:INFO:Copying training dataset
2024-11-14 15:00:54,707:INFO:Defining folds
2024-11-14 15:00:54,707:INFO:Declaring metric variables
2024-11-14 15:00:54,711:INFO:Importing untrained model
2024-11-14 15:00:54,714:INFO:Random Forest Regressor Imported successfully
2024-11-14 15:00:54,721:INFO:Starting cross validation
2024-11-14 15:00:54,722:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:00:58,232:INFO:Calculating mean and std
2024-11-14 15:00:58,235:INFO:Creating metrics dataframe
2024-11-14 15:00:58,242:INFO:Uploading results into container
2024-11-14 15:00:58,243:INFO:Uploading model into container now
2024-11-14 15:00:58,244:INFO:_master_model_container: 2
2024-11-14 15:00:58,244:INFO:_display_container: 2
2024-11-14 15:00:58,245:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:00:58,245:INFO:create_model() successfully completed......................................
2024-11-14 15:00:58,443:INFO:SubProcess create_model() end ==================================
2024-11-14 15:00:58,444:INFO:Creating metrics dataframe
2024-11-14 15:00:58,455:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 15:00:58,455:INFO:Total runtime is 0.14895883003870647 minutes
2024-11-14 15:00:58,459:INFO:SubProcess create_model() called ==================================
2024-11-14 15:00:58,460:INFO:Initializing create_model()
2024-11-14 15:00:58,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01311f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:00:58,460:INFO:Checking exceptions
2024-11-14 15:00:58,460:INFO:Importing libraries
2024-11-14 15:00:58,460:INFO:Copying training dataset
2024-11-14 15:00:58,468:INFO:Defining folds
2024-11-14 15:00:58,469:INFO:Declaring metric variables
2024-11-14 15:00:58,473:INFO:Importing untrained model
2024-11-14 15:00:58,477:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 15:00:58,484:INFO:Starting cross validation
2024-11-14 15:00:58,485:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:04:30,878:INFO:Calculating mean and std
2024-11-14 15:04:30,880:INFO:Creating metrics dataframe
2024-11-14 15:04:30,884:INFO:Uploading results into container
2024-11-14 15:04:30,885:INFO:Uploading model into container now
2024-11-14 15:04:30,885:INFO:_master_model_container: 3
2024-11-14 15:04:30,886:INFO:_display_container: 2
2024-11-14 15:04:30,886:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:04:30,886:INFO:create_model() successfully completed......................................
2024-11-14 15:04:31,054:INFO:SubProcess create_model() end ==================================
2024-11-14 15:04:31,054:INFO:Creating metrics dataframe
2024-11-14 15:04:31,066:INFO:Initializing Extreme Gradient Boosting
2024-11-14 15:04:31,066:INFO:Total runtime is 3.6924704035123193 minutes
2024-11-14 15:04:31,069:INFO:SubProcess create_model() called ==================================
2024-11-14 15:04:31,070:INFO:Initializing create_model()
2024-11-14 15:04:31,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, estimator=xgboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01311f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:04:31,070:INFO:Checking exceptions
2024-11-14 15:04:31,070:INFO:Importing libraries
2024-11-14 15:04:31,071:INFO:Copying training dataset
2024-11-14 15:04:31,077:INFO:Defining folds
2024-11-14 15:04:31,078:INFO:Declaring metric variables
2024-11-14 15:04:31,081:INFO:Importing untrained model
2024-11-14 15:04:31,085:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 15:04:31,091:INFO:Starting cross validation
2024-11-14 15:04:31,092:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:04:33,991:INFO:Calculating mean and std
2024-11-14 15:04:33,995:INFO:Creating metrics dataframe
2024-11-14 15:04:34,003:INFO:Uploading results into container
2024-11-14 15:04:34,003:INFO:Uploading model into container now
2024-11-14 15:04:34,004:INFO:_master_model_container: 4
2024-11-14 15:04:34,004:INFO:_display_container: 2
2024-11-14 15:04:34,005:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=42, ...)
2024-11-14 15:04:34,005:INFO:create_model() successfully completed......................................
2024-11-14 15:04:34,210:INFO:SubProcess create_model() end ==================================
2024-11-14 15:04:34,210:INFO:Creating metrics dataframe
2024-11-14 15:04:34,221:INFO:Initializing CatBoost Regressor
2024-11-14 15:04:34,221:INFO:Total runtime is 3.745049258073171 minutes
2024-11-14 15:04:34,224:INFO:SubProcess create_model() called ==================================
2024-11-14 15:04:34,225:INFO:Initializing create_model()
2024-11-14 15:04:34,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, estimator=catboost, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd01311f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:04:34,225:INFO:Checking exceptions
2024-11-14 15:04:34,225:INFO:Importing libraries
2024-11-14 15:04:34,225:INFO:Copying training dataset
2024-11-14 15:04:34,232:INFO:Defining folds
2024-11-14 15:04:34,232:INFO:Declaring metric variables
2024-11-14 15:04:34,235:INFO:Importing untrained model
2024-11-14 15:04:34,239:INFO:CatBoost Regressor Imported successfully
2024-11-14 15:04:34,245:INFO:Starting cross validation
2024-11-14 15:04:34,246:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:04:44,498:INFO:Calculating mean and std
2024-11-14 15:04:44,501:INFO:Creating metrics dataframe
2024-11-14 15:04:44,507:INFO:Uploading results into container
2024-11-14 15:04:44,508:INFO:Uploading model into container now
2024-11-14 15:04:44,508:INFO:_master_model_container: 5
2024-11-14 15:04:44,508:INFO:_display_container: 2
2024-11-14 15:04:44,508:INFO:<catboost.core.CatBoostRegressor object at 0x7fbfd03a3490>
2024-11-14 15:04:44,508:INFO:create_model() successfully completed......................................
2024-11-14 15:04:44,695:INFO:SubProcess create_model() end ==================================
2024-11-14 15:04:44,695:INFO:Creating metrics dataframe
2024-11-14 15:04:44,716:INFO:Initializing create_model()
2024-11-14 15:04:44,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:04:44,716:INFO:Checking exceptions
2024-11-14 15:04:44,718:INFO:Importing libraries
2024-11-14 15:04:44,718:INFO:Copying training dataset
2024-11-14 15:04:44,724:INFO:Defining folds
2024-11-14 15:04:44,724:INFO:Declaring metric variables
2024-11-14 15:04:44,725:INFO:Importing untrained model
2024-11-14 15:04:44,725:INFO:Declaring custom model
2024-11-14 15:04:44,725:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:04:44,726:INFO:Cross validation set to False
2024-11-14 15:04:44,726:INFO:Fitting Model
2024-11-14 15:04:44,995:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:04:44,995:INFO:create_model() successfully completed......................................
2024-11-14 15:04:45,193:INFO:_master_model_container: 5
2024-11-14 15:04:45,194:INFO:_display_container: 2
2024-11-14 15:04:45,194:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:04:45,194:INFO:compare_models() successfully completed......................................
2024-11-14 15:08:52,075:INFO:Initializing create_model()
2024-11-14 15:08:52,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:08:52,076:INFO:Checking exceptions
2024-11-14 15:08:52,108:INFO:Importing libraries
2024-11-14 15:08:52,108:INFO:Copying training dataset
2024-11-14 15:08:52,117:INFO:Defining folds
2024-11-14 15:08:52,117:INFO:Declaring metric variables
2024-11-14 15:08:52,121:INFO:Importing untrained model
2024-11-14 15:08:52,125:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:08:52,132:INFO:Starting cross validation
2024-11-14 15:08:52,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:08:54,501:INFO:Calculating mean and std
2024-11-14 15:08:54,506:INFO:Creating metrics dataframe
2024-11-14 15:08:54,515:INFO:Finalizing model
2024-11-14 15:08:54,806:INFO:Uploading results into container
2024-11-14 15:08:54,807:INFO:Uploading model into container now
2024-11-14 15:08:54,819:INFO:_master_model_container: 6
2024-11-14 15:08:54,819:INFO:_display_container: 3
2024-11-14 15:08:54,819:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:08:54,819:INFO:create_model() successfully completed......................................
2024-11-14 15:10:46,045:INFO:Initializing tune_model()
2024-11-14 15:10:46,046:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>)
2024-11-14 15:10:46,047:INFO:Checking exceptions
2024-11-14 15:10:46,087:INFO:Copying training dataset
2024-11-14 15:10:46,093:INFO:Checking base model
2024-11-14 15:10:46,093:INFO:Base model : Extra Trees Regressor
2024-11-14 15:10:46,097:INFO:Declaring metric variables
2024-11-14 15:10:46,101:INFO:Defining Hyperparameters
2024-11-14 15:10:46,311:INFO:Tuning with n_jobs=-1
2024-11-14 15:10:46,311:INFO:Initializing RandomizedSearchCV
2024-11-14 15:11:04,575:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:04,596:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:04,615:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:04,657:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:04,757:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:04,816:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:04,819:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:04,820:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:04,837:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:04,958:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:05,017:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:05,035:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:05,326:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/wurlitzer.py:231: RuntimeWarning: Failed to set pipe buffer size: [Errno 1] Operation not permitted
  warnings.warn(

2024-11-14 15:11:51,871:INFO:best_params: {'actual_estimator__n_estimators': 30, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-11-14 15:11:51,876:INFO:Hyperparameter search completed
2024-11-14 15:11:51,876:INFO:SubProcess create_model() called ==================================
2024-11-14 15:11:51,878:INFO:Initializing create_model()
2024-11-14 15:11:51,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fbfd0175460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 30, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0001, 'max_features': 'log2', 'max_depth': 11, 'criterion': 'squared_error', 'bootstrap': False})
2024-11-14 15:11:51,878:INFO:Checking exceptions
2024-11-14 15:11:51,879:INFO:Importing libraries
2024-11-14 15:11:51,879:INFO:Copying training dataset
2024-11-14 15:11:51,886:INFO:Defining folds
2024-11-14 15:11:51,886:INFO:Declaring metric variables
2024-11-14 15:11:51,890:INFO:Importing untrained model
2024-11-14 15:11:51,891:INFO:Declaring custom model
2024-11-14 15:11:51,894:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:11:51,900:INFO:Starting cross validation
2024-11-14 15:11:51,901:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:11:52,131:INFO:Calculating mean and std
2024-11-14 15:11:52,135:INFO:Creating metrics dataframe
2024-11-14 15:11:52,143:INFO:Finalizing model
2024-11-14 15:11:52,267:INFO:Uploading results into container
2024-11-14 15:11:52,268:INFO:Uploading model into container now
2024-11-14 15:11:52,269:INFO:_master_model_container: 7
2024-11-14 15:11:52,269:INFO:_display_container: 4
2024-11-14 15:11:52,270:INFO:ExtraTreesRegressor(max_depth=11, max_features='log2',
                    min_impurity_decrease=0.0001, min_samples_leaf=3,
                    min_samples_split=7, n_estimators=30, n_jobs=-1,
                    random_state=42)
2024-11-14 15:11:52,270:INFO:create_model() successfully completed......................................
2024-11-14 15:11:52,484:INFO:SubProcess create_model() end ==================================
2024-11-14 15:11:52,484:INFO:choose_better activated
2024-11-14 15:11:52,489:INFO:SubProcess create_model() called ==================================
2024-11-14 15:11:52,490:INFO:Initializing create_model()
2024-11-14 15:11:52,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fbfd014a640>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:11:52,490:INFO:Checking exceptions
2024-11-14 15:11:52,492:INFO:Importing libraries
2024-11-14 15:11:52,492:INFO:Copying training dataset
2024-11-14 15:11:52,498:INFO:Defining folds
2024-11-14 15:11:52,498:INFO:Declaring metric variables
2024-11-14 15:11:52,498:INFO:Importing untrained model
2024-11-14 15:11:52,498:INFO:Declaring custom model
2024-11-14 15:11:52,499:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:11:52,499:INFO:Starting cross validation
2024-11-14 15:11:52,500:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:11:53,460:INFO:Calculating mean and std
2024-11-14 15:11:53,461:INFO:Creating metrics dataframe
2024-11-14 15:11:53,465:INFO:Finalizing model
2024-11-14 15:11:53,733:INFO:Uploading results into container
2024-11-14 15:11:53,734:INFO:Uploading model into container now
2024-11-14 15:11:53,735:INFO:_master_model_container: 8
2024-11-14 15:11:53,735:INFO:_display_container: 5
2024-11-14 15:11:53,736:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:11:53,736:INFO:create_model() successfully completed......................................
2024-11-14 15:11:53,955:INFO:SubProcess create_model() end ==================================
2024-11-14 15:11:53,956:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42) result for R2 is 0.9586
2024-11-14 15:11:53,957:INFO:ExtraTreesRegressor(max_depth=11, max_features='log2',
                    min_impurity_decrease=0.0001, min_samples_leaf=3,
                    min_samples_split=7, n_estimators=30, n_jobs=-1,
                    random_state=42) result for R2 is 0.6954
2024-11-14 15:11:53,957:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42) is best model
2024-11-14 15:11:53,957:INFO:choose_better completed
2024-11-14 15:11:53,958:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-11-14 15:11:53,973:INFO:_master_model_container: 8
2024-11-14 15:11:53,973:INFO:_display_container: 4
2024-11-14 15:11:53,974:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:11:53,974:INFO:tune_model() successfully completed......................................
2024-11-14 15:14:37,860:INFO:PyCaret RegressionExperiment
2024-11-14 15:14:37,860:INFO:Logging name: reg-default-name
2024-11-14 15:14:37,860:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 15:14:37,860:INFO:version 3.2.0
2024-11-14 15:14:37,860:INFO:Initializing setup()
2024-11-14 15:14:37,860:INFO:self.USI: 3149
2024-11-14 15:14:37,861:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 15:14:37,861:INFO:Checking environment
2024-11-14 15:14:37,861:INFO:python_version: 3.8.13
2024-11-14 15:14:37,861:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 15:14:37,861:INFO:machine: x86_64
2024-11-14 15:14:37,861:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 15:14:37,861:INFO:Memory: svmem(total=270355722240, available=198573576192, percent=26.6, used=69691850752, free=47090855936, active=73688076288, inactive=88676720640, buffers=10100736, cached=153562914816, shared=196169728, slab=25500798976)
2024-11-14 15:14:37,864:INFO:Physical Core: 28
2024-11-14 15:14:37,864:INFO:Logical Core: 56
2024-11-14 15:14:37,864:INFO:Checking libraries
2024-11-14 15:14:37,864:INFO:System:
2024-11-14 15:14:37,864:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 15:14:37,864:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 15:14:37,864:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 15:14:37,864:INFO:PyCaret required dependencies:
2024-11-14 15:14:37,865:INFO:                 pip: 22.2.2
2024-11-14 15:14:37,865:INFO:          setuptools: 63.4.2
2024-11-14 15:14:37,865:INFO:             pycaret: 3.2.0
2024-11-14 15:14:37,865:INFO:             IPython: 8.12.2
2024-11-14 15:14:37,865:INFO:          ipywidgets: 7.7.1
2024-11-14 15:14:37,865:INFO:                tqdm: 4.64.1
2024-11-14 15:14:37,865:INFO:               numpy: 1.23.5
2024-11-14 15:14:37,865:INFO:              pandas: 1.5.3
2024-11-14 15:14:37,865:INFO:              jinja2: 3.1.2
2024-11-14 15:14:37,865:INFO:               scipy: 1.10.1
2024-11-14 15:14:37,865:INFO:              joblib: 1.3.0
2024-11-14 15:14:37,865:INFO:             sklearn: 1.1.2
2024-11-14 15:14:37,865:INFO:                pyod: 2.0.2
2024-11-14 15:14:37,865:INFO:            imblearn: 0.12.4
2024-11-14 15:14:37,865:INFO:   category_encoders: 2.6.4
2024-11-14 15:14:37,865:INFO:            lightgbm: 4.5.0
2024-11-14 15:14:37,865:INFO:               numba: 0.57.1
2024-11-14 15:14:37,865:INFO:            requests: 2.28.1
2024-11-14 15:14:37,865:INFO:          matplotlib: 3.5.1
2024-11-14 15:14:37,865:INFO:          scikitplot: 0.3.7
2024-11-14 15:14:37,865:INFO:         yellowbrick: 1.5
2024-11-14 15:14:37,866:INFO:              plotly: 5.24.1
2024-11-14 15:14:37,866:INFO:    plotly-resampler: Not installed
2024-11-14 15:14:37,866:INFO:             kaleido: 0.2.1
2024-11-14 15:14:37,866:INFO:           schemdraw: 0.15
2024-11-14 15:14:37,866:INFO:         statsmodels: 0.13.2
2024-11-14 15:14:37,866:INFO:              sktime: 0.21.1
2024-11-14 15:14:37,866:INFO:               tbats: 1.1.3
2024-11-14 15:14:37,866:INFO:            pmdarima: 2.0.4
2024-11-14 15:14:37,866:INFO:              psutil: 5.9.1
2024-11-14 15:14:37,866:INFO:          markupsafe: 2.1.1
2024-11-14 15:14:37,866:INFO:             pickle5: Not installed
2024-11-14 15:14:37,866:INFO:         cloudpickle: 2.1.0
2024-11-14 15:14:37,866:INFO:         deprecation: 2.1.0
2024-11-14 15:14:37,866:INFO:              xxhash: 3.5.0
2024-11-14 15:14:37,866:INFO:           wurlitzer: 3.1.1
2024-11-14 15:14:37,866:INFO:PyCaret optional dependencies:
2024-11-14 15:14:37,866:INFO:                shap: 0.44.1
2024-11-14 15:14:37,866:INFO:           interpret: 0.6.5
2024-11-14 15:14:37,866:INFO:                umap: 0.5.7
2024-11-14 15:14:37,866:INFO:     ydata_profiling: 4.6.0
2024-11-14 15:14:37,866:INFO:  explainerdashboard: 0.4.7
2024-11-14 15:14:37,866:INFO:             autoviz: Not installed
2024-11-14 15:14:37,866:INFO:           fairlearn: 0.7.0
2024-11-14 15:14:37,866:INFO:          deepchecks: Not installed
2024-11-14 15:14:37,866:INFO:             xgboost: 2.1.1
2024-11-14 15:14:37,867:INFO:            catboost: 1.2.7
2024-11-14 15:14:37,867:INFO:              kmodes: 0.12.2
2024-11-14 15:14:37,867:INFO:             mlxtend: 0.23.1
2024-11-14 15:14:37,867:INFO:       statsforecast: 1.5.0
2024-11-14 15:14:37,867:INFO:        tune_sklearn: 0.5.0
2024-11-14 15:14:37,867:INFO:                 ray: 2.10.0
2024-11-14 15:14:37,867:INFO:            hyperopt: 0.2.7
2024-11-14 15:14:37,867:INFO:              optuna: 4.1.0
2024-11-14 15:14:37,867:INFO:               skopt: 0.10.2
2024-11-14 15:14:37,867:INFO:              mlflow: 1.30.1
2024-11-14 15:14:37,867:INFO:              gradio: 3.50.2
2024-11-14 15:14:37,867:INFO:             fastapi: 0.115.5
2024-11-14 15:14:37,867:INFO:             uvicorn: 0.32.0
2024-11-14 15:14:37,867:INFO:              m2cgen: 0.10.0
2024-11-14 15:14:37,867:INFO:           evidently: 0.2.8
2024-11-14 15:14:37,867:INFO:               fugue: 0.8.6
2024-11-14 15:14:37,867:INFO:           streamlit: Not installed
2024-11-14 15:14:37,867:INFO:             prophet: Not installed
2024-11-14 15:14:37,867:INFO:None
2024-11-14 15:14:37,867:INFO:Set up data.
2024-11-14 15:14:37,880:INFO:Set up folding strategy.
2024-11-14 15:14:37,880:INFO:Set up train/test split.
2024-11-14 15:14:37,886:INFO:Set up index.
2024-11-14 15:14:37,888:INFO:Assigning column types.
2024-11-14 15:14:37,893:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 15:14:37,893:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 15:14:37,900:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:14:37,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:14:37,980:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,042:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:38,047:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:38,048:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,054:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,059:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,164:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,164:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:38,167:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:38,168:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 15:14:38,172:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,177:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,234:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,278:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:38,281:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:38,286:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,291:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,353:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,396:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,397:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:38,400:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:38,401:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 15:14:38,410:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,469:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,514:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:38,517:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:38,528:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,589:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,636:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:38,639:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:38,640:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 15:14:38,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,752:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,753:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:38,756:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:38,825:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,869:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:38,872:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:38,873:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 15:14:38,940:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:14:38,984:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:38,987:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:39,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:14:39,099:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:39,101:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:39,102:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 15:14:39,215:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:39,218:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:39,336:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:39,339:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:39,341:INFO:Preparing preprocessing pipeline...
2024-11-14 15:14:39,341:INFO:Set up simple imputation.
2024-11-14 15:14:39,370:INFO:Finished creating preprocessing pipeline.
2024-11-14 15:14:39,374:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['USA_WSPD', 'MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 15:14:39,374:INFO:Creating final display dataframe.
2024-11-14 15:14:39,440:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 8)
4        Transformed data shape        (31316, 8)
5   Transformed train set shape        (21921, 8)
6    Transformed test set shape         (9395, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              3149
2024-11-14 15:14:39,560:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:39,563:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:39,682:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:14:39,685:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:14:39,687:INFO:setup() successfully completed in 1.83s...............
2024-11-14 15:14:39,687:INFO:Initializing compare_models()
2024-11-14 15:14:39,687:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 15:14:39,687:INFO:Checking exceptions
2024-11-14 15:14:39,691:INFO:Preparing display monitor
2024-11-14 15:14:39,730:INFO:Initializing Linear Regression
2024-11-14 15:14:39,732:INFO:Total runtime is 3.322362899780273e-05 minutes
2024-11-14 15:14:39,735:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:39,735:INFO:Initializing create_model()
2024-11-14 15:14:39,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:39,736:INFO:Checking exceptions
2024-11-14 15:14:39,736:INFO:Importing libraries
2024-11-14 15:14:39,736:INFO:Copying training dataset
2024-11-14 15:14:39,743:INFO:Defining folds
2024-11-14 15:14:39,743:INFO:Declaring metric variables
2024-11-14 15:14:39,746:INFO:Importing untrained model
2024-11-14 15:14:39,749:INFO:Linear Regression Imported successfully
2024-11-14 15:14:39,756:INFO:Starting cross validation
2024-11-14 15:14:39,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:39,876:INFO:Calculating mean and std
2024-11-14 15:14:39,877:INFO:Creating metrics dataframe
2024-11-14 15:14:39,885:INFO:Uploading results into container
2024-11-14 15:14:39,886:INFO:Uploading model into container now
2024-11-14 15:14:39,887:INFO:_master_model_container: 1
2024-11-14 15:14:39,887:INFO:_display_container: 2
2024-11-14 15:14:39,887:INFO:LinearRegression(n_jobs=-1)
2024-11-14 15:14:39,887:INFO:create_model() successfully completed......................................
2024-11-14 15:14:40,090:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:40,090:INFO:Creating metrics dataframe
2024-11-14 15:14:40,099:INFO:Initializing Lasso Regression
2024-11-14 15:14:40,099:INFO:Total runtime is 0.006156365076700846 minutes
2024-11-14 15:14:40,103:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:40,103:INFO:Initializing create_model()
2024-11-14 15:14:40,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:40,103:INFO:Checking exceptions
2024-11-14 15:14:40,103:INFO:Importing libraries
2024-11-14 15:14:40,104:INFO:Copying training dataset
2024-11-14 15:14:40,109:INFO:Defining folds
2024-11-14 15:14:40,109:INFO:Declaring metric variables
2024-11-14 15:14:40,112:INFO:Importing untrained model
2024-11-14 15:14:40,116:INFO:Lasso Regression Imported successfully
2024-11-14 15:14:40,123:INFO:Starting cross validation
2024-11-14 15:14:40,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:40,293:INFO:Calculating mean and std
2024-11-14 15:14:40,294:INFO:Creating metrics dataframe
2024-11-14 15:14:40,301:INFO:Uploading results into container
2024-11-14 15:14:40,302:INFO:Uploading model into container now
2024-11-14 15:14:40,303:INFO:_master_model_container: 2
2024-11-14 15:14:40,303:INFO:_display_container: 2
2024-11-14 15:14:40,303:INFO:Lasso(random_state=42)
2024-11-14 15:14:40,303:INFO:create_model() successfully completed......................................
2024-11-14 15:14:40,466:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:40,466:INFO:Creating metrics dataframe
2024-11-14 15:14:40,476:INFO:Initializing Ridge Regression
2024-11-14 15:14:40,476:INFO:Total runtime is 0.012443248430887857 minutes
2024-11-14 15:14:40,480:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:40,480:INFO:Initializing create_model()
2024-11-14 15:14:40,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:40,480:INFO:Checking exceptions
2024-11-14 15:14:40,481:INFO:Importing libraries
2024-11-14 15:14:40,481:INFO:Copying training dataset
2024-11-14 15:14:40,487:INFO:Defining folds
2024-11-14 15:14:40,487:INFO:Declaring metric variables
2024-11-14 15:14:40,490:INFO:Importing untrained model
2024-11-14 15:14:40,494:INFO:Ridge Regression Imported successfully
2024-11-14 15:14:40,500:INFO:Starting cross validation
2024-11-14 15:14:40,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:40,651:INFO:Calculating mean and std
2024-11-14 15:14:40,652:INFO:Creating metrics dataframe
2024-11-14 15:14:40,658:INFO:Uploading results into container
2024-11-14 15:14:40,659:INFO:Uploading model into container now
2024-11-14 15:14:40,659:INFO:_master_model_container: 3
2024-11-14 15:14:40,659:INFO:_display_container: 2
2024-11-14 15:14:40,660:INFO:Ridge(random_state=42)
2024-11-14 15:14:40,660:INFO:create_model() successfully completed......................................
2024-11-14 15:14:40,821:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:40,822:INFO:Creating metrics dataframe
2024-11-14 15:14:40,832:INFO:Initializing Elastic Net
2024-11-14 15:14:40,832:INFO:Total runtime is 0.01836653153101603 minutes
2024-11-14 15:14:40,835:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:40,836:INFO:Initializing create_model()
2024-11-14 15:14:40,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:40,836:INFO:Checking exceptions
2024-11-14 15:14:40,836:INFO:Importing libraries
2024-11-14 15:14:40,836:INFO:Copying training dataset
2024-11-14 15:14:40,845:INFO:Defining folds
2024-11-14 15:14:40,846:INFO:Declaring metric variables
2024-11-14 15:14:40,849:INFO:Importing untrained model
2024-11-14 15:14:40,853:INFO:Elastic Net Imported successfully
2024-11-14 15:14:40,860:INFO:Starting cross validation
2024-11-14 15:14:40,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:40,991:INFO:Calculating mean and std
2024-11-14 15:14:40,995:INFO:Creating metrics dataframe
2024-11-14 15:14:41,003:INFO:Uploading results into container
2024-11-14 15:14:41,003:INFO:Uploading model into container now
2024-11-14 15:14:41,004:INFO:_master_model_container: 4
2024-11-14 15:14:41,004:INFO:_display_container: 2
2024-11-14 15:14:41,004:INFO:ElasticNet(random_state=42)
2024-11-14 15:14:41,004:INFO:create_model() successfully completed......................................
2024-11-14 15:14:41,207:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:41,207:INFO:Creating metrics dataframe
2024-11-14 15:14:41,218:INFO:Initializing Least Angle Regression
2024-11-14 15:14:41,219:INFO:Total runtime is 0.024812130133310954 minutes
2024-11-14 15:14:41,222:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:41,222:INFO:Initializing create_model()
2024-11-14 15:14:41,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:41,223:INFO:Checking exceptions
2024-11-14 15:14:41,223:INFO:Importing libraries
2024-11-14 15:14:41,223:INFO:Copying training dataset
2024-11-14 15:14:41,233:INFO:Defining folds
2024-11-14 15:14:41,234:INFO:Declaring metric variables
2024-11-14 15:14:41,239:INFO:Importing untrained model
2024-11-14 15:14:41,242:INFO:Least Angle Regression Imported successfully
2024-11-14 15:14:41,249:INFO:Starting cross validation
2024-11-14 15:14:41,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:41,287:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,292:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,300:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,303:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,312:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,314:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,324:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,331:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,337:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,347:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,363:INFO:Calculating mean and std
2024-11-14 15:14:41,367:INFO:Creating metrics dataframe
2024-11-14 15:14:41,372:INFO:Uploading results into container
2024-11-14 15:14:41,373:INFO:Uploading model into container now
2024-11-14 15:14:41,374:INFO:_master_model_container: 5
2024-11-14 15:14:41,374:INFO:_display_container: 2
2024-11-14 15:14:41,374:INFO:Lars(random_state=42)
2024-11-14 15:14:41,375:INFO:create_model() successfully completed......................................
2024-11-14 15:14:41,555:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:41,555:INFO:Creating metrics dataframe
2024-11-14 15:14:41,566:INFO:Initializing Lasso Least Angle Regression
2024-11-14 15:14:41,566:INFO:Total runtime is 0.03060907522837321 minutes
2024-11-14 15:14:41,570:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:41,570:INFO:Initializing create_model()
2024-11-14 15:14:41,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:41,570:INFO:Checking exceptions
2024-11-14 15:14:41,570:INFO:Importing libraries
2024-11-14 15:14:41,571:INFO:Copying training dataset
2024-11-14 15:14:41,578:INFO:Defining folds
2024-11-14 15:14:41,578:INFO:Declaring metric variables
2024-11-14 15:14:41,582:INFO:Importing untrained model
2024-11-14 15:14:41,585:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 15:14:41,592:INFO:Starting cross validation
2024-11-14 15:14:41,592:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:41,626:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:14:41,630:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:14:41,640:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:14:41,645:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:14:41,649:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:14:41,660:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:14:41,664:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:14:41,676:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:14:41,688:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:14:41,692:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:14:41,711:INFO:Calculating mean and std
2024-11-14 15:14:41,714:INFO:Creating metrics dataframe
2024-11-14 15:14:41,720:INFO:Uploading results into container
2024-11-14 15:14:41,721:INFO:Uploading model into container now
2024-11-14 15:14:41,722:INFO:_master_model_container: 6
2024-11-14 15:14:41,722:INFO:_display_container: 2
2024-11-14 15:14:41,722:INFO:LassoLars(random_state=42)
2024-11-14 15:14:41,722:INFO:create_model() successfully completed......................................
2024-11-14 15:14:41,884:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:41,884:INFO:Creating metrics dataframe
2024-11-14 15:14:41,895:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 15:14:41,895:INFO:Total runtime is 0.0360876202583313 minutes
2024-11-14 15:14:41,898:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:41,899:INFO:Initializing create_model()
2024-11-14 15:14:41,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:41,899:INFO:Checking exceptions
2024-11-14 15:14:41,899:INFO:Importing libraries
2024-11-14 15:14:41,899:INFO:Copying training dataset
2024-11-14 15:14:41,906:INFO:Defining folds
2024-11-14 15:14:41,907:INFO:Declaring metric variables
2024-11-14 15:14:41,910:INFO:Importing untrained model
2024-11-14 15:14:41,914:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 15:14:41,920:INFO:Starting cross validation
2024-11-14 15:14:41,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:41,952:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,959:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,965:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,971:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,978:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,981:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,988:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,991:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:41,996:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:42,005:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:14:42,023:INFO:Calculating mean and std
2024-11-14 15:14:42,026:INFO:Creating metrics dataframe
2024-11-14 15:14:42,032:INFO:Uploading results into container
2024-11-14 15:14:42,033:INFO:Uploading model into container now
2024-11-14 15:14:42,034:INFO:_master_model_container: 7
2024-11-14 15:14:42,034:INFO:_display_container: 2
2024-11-14 15:14:42,034:INFO:OrthogonalMatchingPursuit()
2024-11-14 15:14:42,034:INFO:create_model() successfully completed......................................
2024-11-14 15:14:42,209:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:42,209:INFO:Creating metrics dataframe
2024-11-14 15:14:42,220:INFO:Initializing Bayesian Ridge
2024-11-14 15:14:42,220:INFO:Total runtime is 0.041502082347869874 minutes
2024-11-14 15:14:42,223:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:42,224:INFO:Initializing create_model()
2024-11-14 15:14:42,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:42,224:INFO:Checking exceptions
2024-11-14 15:14:42,224:INFO:Importing libraries
2024-11-14 15:14:42,224:INFO:Copying training dataset
2024-11-14 15:14:42,231:INFO:Defining folds
2024-11-14 15:14:42,231:INFO:Declaring metric variables
2024-11-14 15:14:42,235:INFO:Importing untrained model
2024-11-14 15:14:42,238:INFO:Bayesian Ridge Imported successfully
2024-11-14 15:14:42,244:INFO:Starting cross validation
2024-11-14 15:14:42,245:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:42,417:INFO:Calculating mean and std
2024-11-14 15:14:42,421:INFO:Creating metrics dataframe
2024-11-14 15:14:42,427:INFO:Uploading results into container
2024-11-14 15:14:42,428:INFO:Uploading model into container now
2024-11-14 15:14:42,428:INFO:_master_model_container: 8
2024-11-14 15:14:42,429:INFO:_display_container: 2
2024-11-14 15:14:42,429:INFO:BayesianRidge()
2024-11-14 15:14:42,429:INFO:create_model() successfully completed......................................
2024-11-14 15:14:42,593:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:42,593:INFO:Creating metrics dataframe
2024-11-14 15:14:42,606:INFO:Initializing Passive Aggressive Regressor
2024-11-14 15:14:42,606:INFO:Total runtime is 0.04793726205825806 minutes
2024-11-14 15:14:42,609:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:42,609:INFO:Initializing create_model()
2024-11-14 15:14:42,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:42,610:INFO:Checking exceptions
2024-11-14 15:14:42,610:INFO:Importing libraries
2024-11-14 15:14:42,610:INFO:Copying training dataset
2024-11-14 15:14:42,617:INFO:Defining folds
2024-11-14 15:14:42,617:INFO:Declaring metric variables
2024-11-14 15:14:42,620:INFO:Importing untrained model
2024-11-14 15:14:42,624:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 15:14:42,630:INFO:Starting cross validation
2024-11-14 15:14:42,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:42,757:INFO:Calculating mean and std
2024-11-14 15:14:42,761:INFO:Creating metrics dataframe
2024-11-14 15:14:42,768:INFO:Uploading results into container
2024-11-14 15:14:42,768:INFO:Uploading model into container now
2024-11-14 15:14:42,769:INFO:_master_model_container: 9
2024-11-14 15:14:42,769:INFO:_display_container: 2
2024-11-14 15:14:42,769:INFO:PassiveAggressiveRegressor(random_state=42)
2024-11-14 15:14:42,770:INFO:create_model() successfully completed......................................
2024-11-14 15:14:42,964:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:42,965:INFO:Creating metrics dataframe
2024-11-14 15:14:42,976:INFO:Initializing Huber Regressor
2024-11-14 15:14:42,976:INFO:Total runtime is 0.05410294135411581 minutes
2024-11-14 15:14:42,979:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:42,980:INFO:Initializing create_model()
2024-11-14 15:14:42,980:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:42,980:INFO:Checking exceptions
2024-11-14 15:14:42,980:INFO:Importing libraries
2024-11-14 15:14:42,980:INFO:Copying training dataset
2024-11-14 15:14:42,988:INFO:Defining folds
2024-11-14 15:14:42,988:INFO:Declaring metric variables
2024-11-14 15:14:42,992:INFO:Importing untrained model
2024-11-14 15:14:42,995:INFO:Huber Regressor Imported successfully
2024-11-14 15:14:43,002:INFO:Starting cross validation
2024-11-14 15:14:43,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:43,260:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:14:43,294:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:14:43,295:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:14:43,295:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:14:43,305:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:14:43,305:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:14:43,311:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:14:43,340:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:14:43,396:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:14:43,405:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:14:43,425:INFO:Calculating mean and std
2024-11-14 15:14:43,429:INFO:Creating metrics dataframe
2024-11-14 15:14:43,435:INFO:Uploading results into container
2024-11-14 15:14:43,436:INFO:Uploading model into container now
2024-11-14 15:14:43,436:INFO:_master_model_container: 10
2024-11-14 15:14:43,437:INFO:_display_container: 2
2024-11-14 15:14:43,437:INFO:HuberRegressor()
2024-11-14 15:14:43,437:INFO:create_model() successfully completed......................................
2024-11-14 15:14:43,623:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:43,623:INFO:Creating metrics dataframe
2024-11-14 15:14:43,635:INFO:Initializing K Neighbors Regressor
2024-11-14 15:14:43,635:INFO:Total runtime is 0.06508948802947999 minutes
2024-11-14 15:14:43,638:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:43,639:INFO:Initializing create_model()
2024-11-14 15:14:43,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:43,639:INFO:Checking exceptions
2024-11-14 15:14:43,639:INFO:Importing libraries
2024-11-14 15:14:43,639:INFO:Copying training dataset
2024-11-14 15:14:43,646:INFO:Defining folds
2024-11-14 15:14:43,647:INFO:Declaring metric variables
2024-11-14 15:14:43,654:INFO:Importing untrained model
2024-11-14 15:14:43,660:INFO:K Neighbors Regressor Imported successfully
2024-11-14 15:14:43,666:INFO:Starting cross validation
2024-11-14 15:14:43,666:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:43,888:INFO:Calculating mean and std
2024-11-14 15:14:43,892:INFO:Creating metrics dataframe
2024-11-14 15:14:43,897:INFO:Uploading results into container
2024-11-14 15:14:43,898:INFO:Uploading model into container now
2024-11-14 15:14:43,899:INFO:_master_model_container: 11
2024-11-14 15:14:43,899:INFO:_display_container: 2
2024-11-14 15:14:43,900:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 15:14:43,900:INFO:create_model() successfully completed......................................
2024-11-14 15:14:44,064:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:44,064:INFO:Creating metrics dataframe
2024-11-14 15:14:44,075:INFO:Initializing Decision Tree Regressor
2024-11-14 15:14:44,076:INFO:Total runtime is 0.0724297046661377 minutes
2024-11-14 15:14:44,079:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:44,079:INFO:Initializing create_model()
2024-11-14 15:14:44,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:44,080:INFO:Checking exceptions
2024-11-14 15:14:44,080:INFO:Importing libraries
2024-11-14 15:14:44,080:INFO:Copying training dataset
2024-11-14 15:14:44,087:INFO:Defining folds
2024-11-14 15:14:44,087:INFO:Declaring metric variables
2024-11-14 15:14:44,091:INFO:Importing untrained model
2024-11-14 15:14:44,094:INFO:Decision Tree Regressor Imported successfully
2024-11-14 15:14:44,101:INFO:Starting cross validation
2024-11-14 15:14:44,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:44,232:INFO:Calculating mean and std
2024-11-14 15:14:44,236:INFO:Creating metrics dataframe
2024-11-14 15:14:44,243:INFO:Uploading results into container
2024-11-14 15:14:44,244:INFO:Uploading model into container now
2024-11-14 15:14:44,244:INFO:_master_model_container: 12
2024-11-14 15:14:44,244:INFO:_display_container: 2
2024-11-14 15:14:44,245:INFO:DecisionTreeRegressor(random_state=42)
2024-11-14 15:14:44,245:INFO:create_model() successfully completed......................................
2024-11-14 15:14:44,410:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:44,410:INFO:Creating metrics dataframe
2024-11-14 15:14:44,422:INFO:Initializing Random Forest Regressor
2024-11-14 15:14:44,422:INFO:Total runtime is 0.07820841471354167 minutes
2024-11-14 15:14:44,426:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:44,426:INFO:Initializing create_model()
2024-11-14 15:14:44,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:44,426:INFO:Checking exceptions
2024-11-14 15:14:44,426:INFO:Importing libraries
2024-11-14 15:14:44,427:INFO:Copying training dataset
2024-11-14 15:14:44,433:INFO:Defining folds
2024-11-14 15:14:44,434:INFO:Declaring metric variables
2024-11-14 15:14:44,437:INFO:Importing untrained model
2024-11-14 15:14:44,441:INFO:Random Forest Regressor Imported successfully
2024-11-14 15:14:44,452:INFO:Starting cross validation
2024-11-14 15:14:44,454:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:45,403:INFO:Calculating mean and std
2024-11-14 15:14:45,407:INFO:Creating metrics dataframe
2024-11-14 15:14:45,412:INFO:Uploading results into container
2024-11-14 15:14:45,413:INFO:Uploading model into container now
2024-11-14 15:14:45,414:INFO:_master_model_container: 13
2024-11-14 15:14:45,414:INFO:_display_container: 2
2024-11-14 15:14:45,414:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:14:45,414:INFO:create_model() successfully completed......................................
2024-11-14 15:14:45,613:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:45,613:INFO:Creating metrics dataframe
2024-11-14 15:14:45,626:INFO:Initializing Extra Trees Regressor
2024-11-14 15:14:45,626:INFO:Total runtime is 0.09827622175216676 minutes
2024-11-14 15:14:45,630:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:45,630:INFO:Initializing create_model()
2024-11-14 15:14:45,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:45,630:INFO:Checking exceptions
2024-11-14 15:14:45,631:INFO:Importing libraries
2024-11-14 15:14:45,631:INFO:Copying training dataset
2024-11-14 15:14:45,637:INFO:Defining folds
2024-11-14 15:14:45,637:INFO:Declaring metric variables
2024-11-14 15:14:45,641:INFO:Importing untrained model
2024-11-14 15:14:45,644:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:14:45,651:INFO:Starting cross validation
2024-11-14 15:14:45,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:46,204:INFO:Calculating mean and std
2024-11-14 15:14:46,208:INFO:Creating metrics dataframe
2024-11-14 15:14:46,213:INFO:Uploading results into container
2024-11-14 15:14:46,213:INFO:Uploading model into container now
2024-11-14 15:14:46,214:INFO:_master_model_container: 14
2024-11-14 15:14:46,214:INFO:_display_container: 2
2024-11-14 15:14:46,215:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:14:46,215:INFO:create_model() successfully completed......................................
2024-11-14 15:14:46,384:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:46,384:INFO:Creating metrics dataframe
2024-11-14 15:14:46,396:INFO:Initializing AdaBoost Regressor
2024-11-14 15:14:46,396:INFO:Total runtime is 0.11110515197118125 minutes
2024-11-14 15:14:46,399:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:46,400:INFO:Initializing create_model()
2024-11-14 15:14:46,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:46,400:INFO:Checking exceptions
2024-11-14 15:14:46,400:INFO:Importing libraries
2024-11-14 15:14:46,400:INFO:Copying training dataset
2024-11-14 15:14:46,407:INFO:Defining folds
2024-11-14 15:14:46,407:INFO:Declaring metric variables
2024-11-14 15:14:46,410:INFO:Importing untrained model
2024-11-14 15:14:46,413:INFO:AdaBoost Regressor Imported successfully
2024-11-14 15:14:46,419:INFO:Starting cross validation
2024-11-14 15:14:46,420:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:47,110:INFO:Calculating mean and std
2024-11-14 15:14:47,113:INFO:Creating metrics dataframe
2024-11-14 15:14:47,121:INFO:Uploading results into container
2024-11-14 15:14:47,123:INFO:Uploading model into container now
2024-11-14 15:14:47,124:INFO:_master_model_container: 15
2024-11-14 15:14:47,124:INFO:_display_container: 2
2024-11-14 15:14:47,124:INFO:AdaBoostRegressor(random_state=42)
2024-11-14 15:14:47,125:INFO:create_model() successfully completed......................................
2024-11-14 15:14:47,309:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:47,310:INFO:Creating metrics dataframe
2024-11-14 15:14:47,322:INFO:Initializing Gradient Boosting Regressor
2024-11-14 15:14:47,323:INFO:Total runtime is 0.12654723326365155 minutes
2024-11-14 15:14:47,326:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:47,326:INFO:Initializing create_model()
2024-11-14 15:14:47,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:47,327:INFO:Checking exceptions
2024-11-14 15:14:47,327:INFO:Importing libraries
2024-11-14 15:14:47,327:INFO:Copying training dataset
2024-11-14 15:14:47,335:INFO:Defining folds
2024-11-14 15:14:47,335:INFO:Declaring metric variables
2024-11-14 15:14:47,339:INFO:Importing untrained model
2024-11-14 15:14:47,342:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 15:14:47,349:INFO:Starting cross validation
2024-11-14 15:14:47,350:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:49,184:INFO:Calculating mean and std
2024-11-14 15:14:49,187:INFO:Creating metrics dataframe
2024-11-14 15:14:49,195:INFO:Uploading results into container
2024-11-14 15:14:49,195:INFO:Uploading model into container now
2024-11-14 15:14:49,196:INFO:_master_model_container: 16
2024-11-14 15:14:49,196:INFO:_display_container: 2
2024-11-14 15:14:49,196:INFO:GradientBoostingRegressor(random_state=42)
2024-11-14 15:14:49,197:INFO:create_model() successfully completed......................................
2024-11-14 15:14:49,381:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:49,382:INFO:Creating metrics dataframe
2024-11-14 15:14:49,395:INFO:Initializing Extreme Gradient Boosting
2024-11-14 15:14:49,395:INFO:Total runtime is 0.16108138163884483 minutes
2024-11-14 15:14:49,398:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:49,398:INFO:Initializing create_model()
2024-11-14 15:14:49,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:49,399:INFO:Checking exceptions
2024-11-14 15:14:49,399:INFO:Importing libraries
2024-11-14 15:14:49,399:INFO:Copying training dataset
2024-11-14 15:14:49,406:INFO:Defining folds
2024-11-14 15:14:49,406:INFO:Declaring metric variables
2024-11-14 15:14:49,410:INFO:Importing untrained model
2024-11-14 15:14:49,413:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 15:14:49,420:INFO:Starting cross validation
2024-11-14 15:14:49,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:14:49,741:INFO:Calculating mean and std
2024-11-14 15:14:49,745:INFO:Creating metrics dataframe
2024-11-14 15:14:49,751:INFO:Uploading results into container
2024-11-14 15:14:49,752:INFO:Uploading model into container now
2024-11-14 15:14:49,752:INFO:_master_model_container: 17
2024-11-14 15:14:49,753:INFO:_display_container: 2
2024-11-14 15:14:49,754:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=42, ...)
2024-11-14 15:14:49,754:INFO:create_model() successfully completed......................................
2024-11-14 15:14:49,958:INFO:SubProcess create_model() end ==================================
2024-11-14 15:14:49,958:INFO:Creating metrics dataframe
2024-11-14 15:14:49,971:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 15:14:49,972:INFO:Total runtime is 0.17069741884867354 minutes
2024-11-14 15:14:49,975:INFO:SubProcess create_model() called ==================================
2024-11-14 15:14:49,975:INFO:Initializing create_model()
2024-11-14 15:14:49,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1c49056d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c50d7640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:14:49,976:INFO:Checking exceptions
2024-11-14 15:14:49,976:INFO:Importing libraries
2024-11-14 15:14:49,976:INFO:Copying training dataset
2024-11-14 15:14:49,983:INFO:Defining folds
2024-11-14 15:14:49,983:INFO:Declaring metric variables
2024-11-14 15:14:49,987:INFO:Importing untrained model
2024-11-14 15:14:49,990:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 15:14:49,997:INFO:Starting cross validation
2024-11-14 15:14:49,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:21:56,455:INFO:PyCaret RegressionExperiment
2024-11-14 15:21:56,455:INFO:Logging name: reg-default-name
2024-11-14 15:21:56,455:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 15:21:56,455:INFO:version 3.2.0
2024-11-14 15:21:56,455:INFO:Initializing setup()
2024-11-14 15:21:56,455:INFO:self.USI: 5257
2024-11-14 15:21:56,455:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 15:21:56,455:INFO:Checking environment
2024-11-14 15:21:56,456:INFO:python_version: 3.8.13
2024-11-14 15:21:56,456:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 15:21:56,456:INFO:machine: x86_64
2024-11-14 15:21:56,456:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 15:21:56,456:INFO:Memory: svmem(total=270355722240, available=207061782528, percent=23.4, used=61204029440, free=54238769152, active=73769361408, inactive=81513091072, buffers=10100736, cached=154902822912, shared=195915776, slab=25476128768)
2024-11-14 15:21:56,459:INFO:Physical Core: 28
2024-11-14 15:21:56,459:INFO:Logical Core: 56
2024-11-14 15:21:56,459:INFO:Checking libraries
2024-11-14 15:21:56,459:INFO:System:
2024-11-14 15:21:56,459:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 15:21:56,459:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 15:21:56,459:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 15:21:56,460:INFO:PyCaret required dependencies:
2024-11-14 15:21:56,460:INFO:                 pip: 22.2.2
2024-11-14 15:21:56,460:INFO:          setuptools: 63.4.2
2024-11-14 15:21:56,460:INFO:             pycaret: 3.2.0
2024-11-14 15:21:56,460:INFO:             IPython: 8.12.2
2024-11-14 15:21:56,460:INFO:          ipywidgets: 7.7.1
2024-11-14 15:21:56,460:INFO:                tqdm: 4.64.1
2024-11-14 15:21:56,460:INFO:               numpy: 1.23.5
2024-11-14 15:21:56,460:INFO:              pandas: 1.5.3
2024-11-14 15:21:56,460:INFO:              jinja2: 3.1.2
2024-11-14 15:21:56,460:INFO:               scipy: 1.10.1
2024-11-14 15:21:56,460:INFO:              joblib: 1.3.0
2024-11-14 15:21:56,460:INFO:             sklearn: 1.1.2
2024-11-14 15:21:56,460:INFO:                pyod: 2.0.2
2024-11-14 15:21:56,460:INFO:            imblearn: 0.12.4
2024-11-14 15:21:56,460:INFO:   category_encoders: 2.6.4
2024-11-14 15:21:56,460:INFO:            lightgbm: 4.5.0
2024-11-14 15:21:56,460:INFO:               numba: 0.57.1
2024-11-14 15:21:56,461:INFO:            requests: 2.28.1
2024-11-14 15:21:56,461:INFO:          matplotlib: 3.5.1
2024-11-14 15:21:56,461:INFO:          scikitplot: 0.3.7
2024-11-14 15:21:56,461:INFO:         yellowbrick: 1.5
2024-11-14 15:21:56,461:INFO:              plotly: 5.24.1
2024-11-14 15:21:56,461:INFO:    plotly-resampler: Not installed
2024-11-14 15:21:56,461:INFO:             kaleido: 0.2.1
2024-11-14 15:21:56,461:INFO:           schemdraw: 0.15
2024-11-14 15:21:56,461:INFO:         statsmodels: 0.13.2
2024-11-14 15:21:56,461:INFO:              sktime: 0.21.1
2024-11-14 15:21:56,461:INFO:               tbats: 1.1.3
2024-11-14 15:21:56,461:INFO:            pmdarima: 2.0.4
2024-11-14 15:21:56,461:INFO:              psutil: 5.9.1
2024-11-14 15:21:56,461:INFO:          markupsafe: 2.1.1
2024-11-14 15:21:56,461:INFO:             pickle5: Not installed
2024-11-14 15:21:56,461:INFO:         cloudpickle: 2.1.0
2024-11-14 15:21:56,461:INFO:         deprecation: 2.1.0
2024-11-14 15:21:56,461:INFO:              xxhash: 3.5.0
2024-11-14 15:21:56,461:INFO:           wurlitzer: 3.1.1
2024-11-14 15:21:56,461:INFO:PyCaret optional dependencies:
2024-11-14 15:21:56,461:INFO:                shap: 0.44.1
2024-11-14 15:21:56,461:INFO:           interpret: 0.6.5
2024-11-14 15:21:56,461:INFO:                umap: 0.5.7
2024-11-14 15:21:56,461:INFO:     ydata_profiling: 4.6.0
2024-11-14 15:21:56,461:INFO:  explainerdashboard: 0.4.7
2024-11-14 15:21:56,461:INFO:             autoviz: Not installed
2024-11-14 15:21:56,461:INFO:           fairlearn: 0.7.0
2024-11-14 15:21:56,461:INFO:          deepchecks: Not installed
2024-11-14 15:21:56,461:INFO:             xgboost: 2.1.1
2024-11-14 15:21:56,461:INFO:            catboost: 1.2.7
2024-11-14 15:21:56,461:INFO:              kmodes: 0.12.2
2024-11-14 15:21:56,462:INFO:             mlxtend: 0.23.1
2024-11-14 15:21:56,462:INFO:       statsforecast: 1.5.0
2024-11-14 15:21:56,462:INFO:        tune_sklearn: 0.5.0
2024-11-14 15:21:56,462:INFO:                 ray: 2.10.0
2024-11-14 15:21:56,462:INFO:            hyperopt: 0.2.7
2024-11-14 15:21:56,462:INFO:              optuna: 4.1.0
2024-11-14 15:21:56,462:INFO:               skopt: 0.10.2
2024-11-14 15:21:56,462:INFO:              mlflow: 1.30.1
2024-11-14 15:21:56,462:INFO:              gradio: 3.50.2
2024-11-14 15:21:56,462:INFO:             fastapi: 0.115.5
2024-11-14 15:21:56,462:INFO:             uvicorn: 0.32.0
2024-11-14 15:21:56,462:INFO:              m2cgen: 0.10.0
2024-11-14 15:21:56,462:INFO:           evidently: 0.2.8
2024-11-14 15:21:56,462:INFO:               fugue: 0.8.6
2024-11-14 15:21:56,462:INFO:           streamlit: Not installed
2024-11-14 15:21:56,462:INFO:             prophet: Not installed
2024-11-14 15:21:56,462:INFO:None
2024-11-14 15:21:56,462:INFO:Set up data.
2024-11-14 15:21:56,478:INFO:Set up folding strategy.
2024-11-14 15:21:56,478:INFO:Set up train/test split.
2024-11-14 15:21:56,483:INFO:Set up index.
2024-11-14 15:21:56,485:INFO:Assigning column types.
2024-11-14 15:21:56,489:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 15:21:56,490:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,495:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,500:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,566:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,609:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,610:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:56,612:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:56,613:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,617:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,622:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,711:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,711:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:56,713:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:56,715:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 15:21:56,719:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,723:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,775:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,814:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:56,816:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:56,821:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,824:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,913:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,913:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:56,916:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:56,916:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 15:21:56,924:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:21:56,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,015:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:57,017:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:57,025:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,076:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,114:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:57,116:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:57,117:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 15:21:57,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,215:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:57,217:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:57,275:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,314:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:57,316:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:57,316:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 15:21:57,376:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,414:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:57,416:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:57,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:21:57,519:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:57,522:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:57,522:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 15:21:57,618:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:57,620:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:57,716:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:57,719:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:57,720:INFO:Preparing preprocessing pipeline...
2024-11-14 15:21:57,720:INFO:Set up simple imputation.
2024-11-14 15:21:57,738:INFO:Finished creating preprocessing pipeline.
2024-11-14 15:21:57,742:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['USA_WSPD', 'MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 15:21:57,742:INFO:Creating final display dataframe.
2024-11-14 15:21:57,795:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 8)
4        Transformed data shape        (31316, 8)
5   Transformed train set shape        (21921, 8)
6    Transformed test set shape         (9395, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5257
2024-11-14 15:21:57,891:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:57,893:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:57,989:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:21:57,991:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:21:57,992:INFO:setup() successfully completed in 1.54s...............
2024-11-14 15:21:57,992:INFO:Initializing compare_models()
2024-11-14 15:21:57,992:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 15:21:57,992:INFO:Checking exceptions
2024-11-14 15:21:57,994:INFO:Preparing display monitor
2024-11-14 15:21:58,031:INFO:Initializing Linear Regression
2024-11-14 15:21:58,031:INFO:Total runtime is 2.3325284322102864e-06 minutes
2024-11-14 15:21:58,034:INFO:SubProcess create_model() called ==================================
2024-11-14 15:21:58,034:INFO:Initializing create_model()
2024-11-14 15:21:58,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:21:58,034:INFO:Checking exceptions
2024-11-14 15:21:58,035:INFO:Importing libraries
2024-11-14 15:21:58,035:INFO:Copying training dataset
2024-11-14 15:21:58,040:INFO:Defining folds
2024-11-14 15:21:58,040:INFO:Declaring metric variables
2024-11-14 15:21:58,043:INFO:Importing untrained model
2024-11-14 15:21:58,046:INFO:Linear Regression Imported successfully
2024-11-14 15:21:58,052:INFO:Starting cross validation
2024-11-14 15:21:58,053:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:02,929:INFO:Calculating mean and std
2024-11-14 15:22:02,938:INFO:Creating metrics dataframe
2024-11-14 15:22:02,944:INFO:Uploading results into container
2024-11-14 15:22:02,945:INFO:Uploading model into container now
2024-11-14 15:22:02,947:INFO:_master_model_container: 1
2024-11-14 15:22:02,947:INFO:_display_container: 2
2024-11-14 15:22:02,947:INFO:LinearRegression(n_jobs=-1)
2024-11-14 15:22:02,948:INFO:create_model() successfully completed......................................
2024-11-14 15:22:03,213:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:03,213:INFO:Creating metrics dataframe
2024-11-14 15:22:03,223:INFO:Initializing Lasso Regression
2024-11-14 15:22:03,223:INFO:Total runtime is 0.08654229640960694 minutes
2024-11-14 15:22:03,227:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:03,227:INFO:Initializing create_model()
2024-11-14 15:22:03,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:03,227:INFO:Checking exceptions
2024-11-14 15:22:03,228:INFO:Importing libraries
2024-11-14 15:22:03,228:INFO:Copying training dataset
2024-11-14 15:22:03,236:INFO:Defining folds
2024-11-14 15:22:03,237:INFO:Declaring metric variables
2024-11-14 15:22:03,240:INFO:Importing untrained model
2024-11-14 15:22:03,244:INFO:Lasso Regression Imported successfully
2024-11-14 15:22:03,250:INFO:Starting cross validation
2024-11-14 15:22:03,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:06,255:INFO:Calculating mean and std
2024-11-14 15:22:06,259:INFO:Creating metrics dataframe
2024-11-14 15:22:06,266:INFO:Uploading results into container
2024-11-14 15:22:06,267:INFO:Uploading model into container now
2024-11-14 15:22:06,267:INFO:_master_model_container: 2
2024-11-14 15:22:06,267:INFO:_display_container: 2
2024-11-14 15:22:06,268:INFO:Lasso(random_state=42)
2024-11-14 15:22:06,268:INFO:create_model() successfully completed......................................
2024-11-14 15:22:06,459:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:06,459:INFO:Creating metrics dataframe
2024-11-14 15:22:06,469:INFO:Initializing Ridge Regression
2024-11-14 15:22:06,470:INFO:Total runtime is 0.14064993063608805 minutes
2024-11-14 15:22:06,473:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:06,473:INFO:Initializing create_model()
2024-11-14 15:22:06,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:06,473:INFO:Checking exceptions
2024-11-14 15:22:06,473:INFO:Importing libraries
2024-11-14 15:22:06,474:INFO:Copying training dataset
2024-11-14 15:22:06,481:INFO:Defining folds
2024-11-14 15:22:06,481:INFO:Declaring metric variables
2024-11-14 15:22:06,484:INFO:Importing untrained model
2024-11-14 15:22:06,488:INFO:Ridge Regression Imported successfully
2024-11-14 15:22:06,494:INFO:Starting cross validation
2024-11-14 15:22:06,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:09,367:INFO:Calculating mean and std
2024-11-14 15:22:09,371:INFO:Creating metrics dataframe
2024-11-14 15:22:09,376:INFO:Uploading results into container
2024-11-14 15:22:09,377:INFO:Uploading model into container now
2024-11-14 15:22:09,377:INFO:_master_model_container: 3
2024-11-14 15:22:09,377:INFO:_display_container: 2
2024-11-14 15:22:09,378:INFO:Ridge(random_state=42)
2024-11-14 15:22:09,378:INFO:create_model() successfully completed......................................
2024-11-14 15:22:09,569:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:09,569:INFO:Creating metrics dataframe
2024-11-14 15:22:09,579:INFO:Initializing Elastic Net
2024-11-14 15:22:09,580:INFO:Total runtime is 0.1924803336461385 minutes
2024-11-14 15:22:09,583:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:09,583:INFO:Initializing create_model()
2024-11-14 15:22:09,583:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:09,584:INFO:Checking exceptions
2024-11-14 15:22:09,584:INFO:Importing libraries
2024-11-14 15:22:09,584:INFO:Copying training dataset
2024-11-14 15:22:09,590:INFO:Defining folds
2024-11-14 15:22:09,591:INFO:Declaring metric variables
2024-11-14 15:22:09,594:INFO:Importing untrained model
2024-11-14 15:22:09,597:INFO:Elastic Net Imported successfully
2024-11-14 15:22:09,604:INFO:Starting cross validation
2024-11-14 15:22:09,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:12,682:INFO:Calculating mean and std
2024-11-14 15:22:12,686:INFO:Creating metrics dataframe
2024-11-14 15:22:12,692:INFO:Uploading results into container
2024-11-14 15:22:12,693:INFO:Uploading model into container now
2024-11-14 15:22:12,693:INFO:_master_model_container: 4
2024-11-14 15:22:12,693:INFO:_display_container: 2
2024-11-14 15:22:12,694:INFO:ElasticNet(random_state=42)
2024-11-14 15:22:12,694:INFO:create_model() successfully completed......................................
2024-11-14 15:22:12,886:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:12,886:INFO:Creating metrics dataframe
2024-11-14 15:22:12,897:INFO:Initializing Least Angle Regression
2024-11-14 15:22:12,897:INFO:Total runtime is 0.24777406056722007 minutes
2024-11-14 15:22:12,901:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:12,901:INFO:Initializing create_model()
2024-11-14 15:22:12,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:12,901:INFO:Checking exceptions
2024-11-14 15:22:12,901:INFO:Importing libraries
2024-11-14 15:22:12,901:INFO:Copying training dataset
2024-11-14 15:22:12,908:INFO:Defining folds
2024-11-14 15:22:12,908:INFO:Declaring metric variables
2024-11-14 15:22:12,912:INFO:Importing untrained model
2024-11-14 15:22:12,915:INFO:Least Angle Regression Imported successfully
2024-11-14 15:22:12,922:INFO:Starting cross validation
2024-11-14 15:22:12,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:15,497:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:15,550:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:15,574:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:15,582:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:15,639:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:15,654:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:15,656:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:15,717:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:15,848:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:15,900:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:15,918:INFO:Calculating mean and std
2024-11-14 15:22:15,922:INFO:Creating metrics dataframe
2024-11-14 15:22:15,927:INFO:Uploading results into container
2024-11-14 15:22:15,928:INFO:Uploading model into container now
2024-11-14 15:22:15,929:INFO:_master_model_container: 5
2024-11-14 15:22:15,929:INFO:_display_container: 2
2024-11-14 15:22:15,929:INFO:Lars(random_state=42)
2024-11-14 15:22:15,929:INFO:create_model() successfully completed......................................
2024-11-14 15:22:16,100:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:16,100:INFO:Creating metrics dataframe
2024-11-14 15:22:16,111:INFO:Initializing Lasso Least Angle Regression
2024-11-14 15:22:16,111:INFO:Total runtime is 0.3013343612353007 minutes
2024-11-14 15:22:16,114:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:16,114:INFO:Initializing create_model()
2024-11-14 15:22:16,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:16,114:INFO:Checking exceptions
2024-11-14 15:22:16,115:INFO:Importing libraries
2024-11-14 15:22:16,115:INFO:Copying training dataset
2024-11-14 15:22:16,121:INFO:Defining folds
2024-11-14 15:22:16,122:INFO:Declaring metric variables
2024-11-14 15:22:16,126:INFO:Importing untrained model
2024-11-14 15:22:16,132:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 15:22:16,139:INFO:Starting cross validation
2024-11-14 15:22:16,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:16,219:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:22:16,219:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:22:16,226:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:22:16,232:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:22:18,663:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:22:18,782:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:22:18,837:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:22:18,839:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:22:18,841:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:22:18,859:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:22:18,871:INFO:Calculating mean and std
2024-11-14 15:22:18,875:INFO:Creating metrics dataframe
2024-11-14 15:22:18,880:INFO:Uploading results into container
2024-11-14 15:22:18,881:INFO:Uploading model into container now
2024-11-14 15:22:18,882:INFO:_master_model_container: 6
2024-11-14 15:22:18,882:INFO:_display_container: 2
2024-11-14 15:22:18,882:INFO:LassoLars(random_state=42)
2024-11-14 15:22:18,882:INFO:create_model() successfully completed......................................
2024-11-14 15:22:19,049:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:19,049:INFO:Creating metrics dataframe
2024-11-14 15:22:19,061:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 15:22:19,061:INFO:Total runtime is 0.3505086421966553 minutes
2024-11-14 15:22:19,064:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:19,065:INFO:Initializing create_model()
2024-11-14 15:22:19,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:19,065:INFO:Checking exceptions
2024-11-14 15:22:19,065:INFO:Importing libraries
2024-11-14 15:22:19,065:INFO:Copying training dataset
2024-11-14 15:22:19,072:INFO:Defining folds
2024-11-14 15:22:19,072:INFO:Declaring metric variables
2024-11-14 15:22:19,076:INFO:Importing untrained model
2024-11-14 15:22:19,079:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 15:22:19,086:INFO:Starting cross validation
2024-11-14 15:22:19,087:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:19,121:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:19,125:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:19,131:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:19,136:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:19,142:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:19,145:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:19,153:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:19,158:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:19,164:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:19,170:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:22:19,189:INFO:Calculating mean and std
2024-11-14 15:22:19,192:INFO:Creating metrics dataframe
2024-11-14 15:22:19,199:INFO:Uploading results into container
2024-11-14 15:22:19,200:INFO:Uploading model into container now
2024-11-14 15:22:19,200:INFO:_master_model_container: 7
2024-11-14 15:22:19,200:INFO:_display_container: 2
2024-11-14 15:22:19,200:INFO:OrthogonalMatchingPursuit()
2024-11-14 15:22:19,201:INFO:create_model() successfully completed......................................
2024-11-14 15:22:19,364:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:19,364:INFO:Creating metrics dataframe
2024-11-14 15:22:19,374:INFO:Initializing Bayesian Ridge
2024-11-14 15:22:19,375:INFO:Total runtime is 0.3557307561238607 minutes
2024-11-14 15:22:19,378:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:19,378:INFO:Initializing create_model()
2024-11-14 15:22:19,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:19,378:INFO:Checking exceptions
2024-11-14 15:22:19,378:INFO:Importing libraries
2024-11-14 15:22:19,378:INFO:Copying training dataset
2024-11-14 15:22:19,385:INFO:Defining folds
2024-11-14 15:22:19,385:INFO:Declaring metric variables
2024-11-14 15:22:19,388:INFO:Importing untrained model
2024-11-14 15:22:19,392:INFO:Bayesian Ridge Imported successfully
2024-11-14 15:22:19,399:INFO:Starting cross validation
2024-11-14 15:22:19,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:19,532:INFO:Calculating mean and std
2024-11-14 15:22:19,536:INFO:Creating metrics dataframe
2024-11-14 15:22:19,543:INFO:Uploading results into container
2024-11-14 15:22:19,544:INFO:Uploading model into container now
2024-11-14 15:22:19,544:INFO:_master_model_container: 8
2024-11-14 15:22:19,545:INFO:_display_container: 2
2024-11-14 15:22:19,545:INFO:BayesianRidge()
2024-11-14 15:22:19,545:INFO:create_model() successfully completed......................................
2024-11-14 15:22:19,727:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:19,728:INFO:Creating metrics dataframe
2024-11-14 15:22:19,738:INFO:Initializing Passive Aggressive Regressor
2024-11-14 15:22:19,739:INFO:Total runtime is 0.36179822285970054 minutes
2024-11-14 15:22:19,742:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:19,742:INFO:Initializing create_model()
2024-11-14 15:22:19,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:19,743:INFO:Checking exceptions
2024-11-14 15:22:19,743:INFO:Importing libraries
2024-11-14 15:22:19,743:INFO:Copying training dataset
2024-11-14 15:22:19,749:INFO:Defining folds
2024-11-14 15:22:19,750:INFO:Declaring metric variables
2024-11-14 15:22:19,753:INFO:Importing untrained model
2024-11-14 15:22:19,757:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 15:22:19,763:INFO:Starting cross validation
2024-11-14 15:22:19,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:19,900:INFO:Calculating mean and std
2024-11-14 15:22:19,903:INFO:Creating metrics dataframe
2024-11-14 15:22:19,909:INFO:Uploading results into container
2024-11-14 15:22:19,910:INFO:Uploading model into container now
2024-11-14 15:22:19,910:INFO:_master_model_container: 9
2024-11-14 15:22:19,910:INFO:_display_container: 2
2024-11-14 15:22:19,911:INFO:PassiveAggressiveRegressor(random_state=42)
2024-11-14 15:22:19,911:INFO:create_model() successfully completed......................................
2024-11-14 15:22:20,094:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:20,094:INFO:Creating metrics dataframe
2024-11-14 15:22:20,106:INFO:Initializing Huber Regressor
2024-11-14 15:22:20,106:INFO:Total runtime is 0.3679254253705343 minutes
2024-11-14 15:22:20,109:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:20,110:INFO:Initializing create_model()
2024-11-14 15:22:20,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:20,110:INFO:Checking exceptions
2024-11-14 15:22:20,110:INFO:Importing libraries
2024-11-14 15:22:20,110:INFO:Copying training dataset
2024-11-14 15:22:20,117:INFO:Defining folds
2024-11-14 15:22:20,117:INFO:Declaring metric variables
2024-11-14 15:22:20,122:INFO:Importing untrained model
2024-11-14 15:22:20,126:INFO:Huber Regressor Imported successfully
2024-11-14 15:22:20,132:INFO:Starting cross validation
2024-11-14 15:22:20,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:20,400:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:22:20,408:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:22:20,410:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:22:20,415:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:22:20,432:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:22:20,434:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:22:20,438:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:22:20,444:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:22:20,451:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:22:20,478:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:22:20,489:INFO:Calculating mean and std
2024-11-14 15:22:20,493:INFO:Creating metrics dataframe
2024-11-14 15:22:20,499:INFO:Uploading results into container
2024-11-14 15:22:20,500:INFO:Uploading model into container now
2024-11-14 15:22:20,500:INFO:_master_model_container: 10
2024-11-14 15:22:20,500:INFO:_display_container: 2
2024-11-14 15:22:20,501:INFO:HuberRegressor()
2024-11-14 15:22:20,501:INFO:create_model() successfully completed......................................
2024-11-14 15:22:20,690:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:20,690:INFO:Creating metrics dataframe
2024-11-14 15:22:20,703:INFO:Initializing K Neighbors Regressor
2024-11-14 15:22:20,703:INFO:Total runtime is 0.3778674403826396 minutes
2024-11-14 15:22:20,706:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:20,706:INFO:Initializing create_model()
2024-11-14 15:22:20,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:20,707:INFO:Checking exceptions
2024-11-14 15:22:20,707:INFO:Importing libraries
2024-11-14 15:22:20,707:INFO:Copying training dataset
2024-11-14 15:22:20,713:INFO:Defining folds
2024-11-14 15:22:20,714:INFO:Declaring metric variables
2024-11-14 15:22:20,717:INFO:Importing untrained model
2024-11-14 15:22:20,720:INFO:K Neighbors Regressor Imported successfully
2024-11-14 15:22:20,726:INFO:Starting cross validation
2024-11-14 15:22:20,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:20,972:INFO:Calculating mean and std
2024-11-14 15:22:20,975:INFO:Creating metrics dataframe
2024-11-14 15:22:20,982:INFO:Uploading results into container
2024-11-14 15:22:20,983:INFO:Uploading model into container now
2024-11-14 15:22:20,983:INFO:_master_model_container: 11
2024-11-14 15:22:20,984:INFO:_display_container: 2
2024-11-14 15:22:20,984:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 15:22:20,984:INFO:create_model() successfully completed......................................
2024-11-14 15:22:21,157:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:21,157:INFO:Creating metrics dataframe
2024-11-14 15:22:21,171:INFO:Initializing Decision Tree Regressor
2024-11-14 15:22:21,171:INFO:Total runtime is 0.3856755375862122 minutes
2024-11-14 15:22:21,175:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:21,175:INFO:Initializing create_model()
2024-11-14 15:22:21,175:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:21,175:INFO:Checking exceptions
2024-11-14 15:22:21,175:INFO:Importing libraries
2024-11-14 15:22:21,175:INFO:Copying training dataset
2024-11-14 15:22:21,183:INFO:Defining folds
2024-11-14 15:22:21,183:INFO:Declaring metric variables
2024-11-14 15:22:21,186:INFO:Importing untrained model
2024-11-14 15:22:21,190:INFO:Decision Tree Regressor Imported successfully
2024-11-14 15:22:21,196:INFO:Starting cross validation
2024-11-14 15:22:21,197:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:21,322:INFO:Calculating mean and std
2024-11-14 15:22:21,326:INFO:Creating metrics dataframe
2024-11-14 15:22:21,331:INFO:Uploading results into container
2024-11-14 15:22:21,332:INFO:Uploading model into container now
2024-11-14 15:22:21,333:INFO:_master_model_container: 12
2024-11-14 15:22:21,333:INFO:_display_container: 2
2024-11-14 15:22:21,333:INFO:DecisionTreeRegressor(random_state=42)
2024-11-14 15:22:21,333:INFO:create_model() successfully completed......................................
2024-11-14 15:22:21,547:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:21,547:INFO:Creating metrics dataframe
2024-11-14 15:22:21,560:INFO:Initializing Random Forest Regressor
2024-11-14 15:22:21,560:INFO:Total runtime is 0.39215652147928876 minutes
2024-11-14 15:22:21,563:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:21,564:INFO:Initializing create_model()
2024-11-14 15:22:21,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:21,564:INFO:Checking exceptions
2024-11-14 15:22:21,564:INFO:Importing libraries
2024-11-14 15:22:21,564:INFO:Copying training dataset
2024-11-14 15:22:21,571:INFO:Defining folds
2024-11-14 15:22:21,571:INFO:Declaring metric variables
2024-11-14 15:22:21,574:INFO:Importing untrained model
2024-11-14 15:22:21,578:INFO:Random Forest Regressor Imported successfully
2024-11-14 15:22:21,584:INFO:Starting cross validation
2024-11-14 15:22:21,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:22,523:INFO:Calculating mean and std
2024-11-14 15:22:22,526:INFO:Creating metrics dataframe
2024-11-14 15:22:22,531:INFO:Uploading results into container
2024-11-14 15:22:22,532:INFO:Uploading model into container now
2024-11-14 15:22:22,533:INFO:_master_model_container: 13
2024-11-14 15:22:22,533:INFO:_display_container: 2
2024-11-14 15:22:22,533:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:22:22,533:INFO:create_model() successfully completed......................................
2024-11-14 15:22:22,716:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:22,716:INFO:Creating metrics dataframe
2024-11-14 15:22:22,733:INFO:Initializing Extra Trees Regressor
2024-11-14 15:22:22,733:INFO:Total runtime is 0.4117039243380229 minutes
2024-11-14 15:22:22,737:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:22,737:INFO:Initializing create_model()
2024-11-14 15:22:22,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:22,738:INFO:Checking exceptions
2024-11-14 15:22:22,738:INFO:Importing libraries
2024-11-14 15:22:22,738:INFO:Copying training dataset
2024-11-14 15:22:22,748:INFO:Defining folds
2024-11-14 15:22:22,748:INFO:Declaring metric variables
2024-11-14 15:22:22,752:INFO:Importing untrained model
2024-11-14 15:22:22,757:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:22:22,764:INFO:Starting cross validation
2024-11-14 15:22:22,765:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:23,333:INFO:Calculating mean and std
2024-11-14 15:22:23,337:INFO:Creating metrics dataframe
2024-11-14 15:22:23,343:INFO:Uploading results into container
2024-11-14 15:22:23,344:INFO:Uploading model into container now
2024-11-14 15:22:23,344:INFO:_master_model_container: 14
2024-11-14 15:22:23,345:INFO:_display_container: 2
2024-11-14 15:22:23,345:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:22:23,345:INFO:create_model() successfully completed......................................
2024-11-14 15:22:23,535:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:23,535:INFO:Creating metrics dataframe
2024-11-14 15:22:23,548:INFO:Initializing AdaBoost Regressor
2024-11-14 15:22:23,548:INFO:Total runtime is 0.42528455654780073 minutes
2024-11-14 15:22:23,551:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:23,552:INFO:Initializing create_model()
2024-11-14 15:22:23,552:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:23,552:INFO:Checking exceptions
2024-11-14 15:22:23,552:INFO:Importing libraries
2024-11-14 15:22:23,552:INFO:Copying training dataset
2024-11-14 15:22:23,559:INFO:Defining folds
2024-11-14 15:22:23,559:INFO:Declaring metric variables
2024-11-14 15:22:23,563:INFO:Importing untrained model
2024-11-14 15:22:23,566:INFO:AdaBoost Regressor Imported successfully
2024-11-14 15:22:23,572:INFO:Starting cross validation
2024-11-14 15:22:23,573:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:24,314:INFO:Calculating mean and std
2024-11-14 15:22:24,318:INFO:Creating metrics dataframe
2024-11-14 15:22:24,323:INFO:Uploading results into container
2024-11-14 15:22:24,324:INFO:Uploading model into container now
2024-11-14 15:22:24,324:INFO:_master_model_container: 15
2024-11-14 15:22:24,325:INFO:_display_container: 2
2024-11-14 15:22:24,325:INFO:AdaBoostRegressor(random_state=42)
2024-11-14 15:22:24,325:INFO:create_model() successfully completed......................................
2024-11-14 15:22:24,513:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:24,513:INFO:Creating metrics dataframe
2024-11-14 15:22:24,526:INFO:Initializing Gradient Boosting Regressor
2024-11-14 15:22:24,526:INFO:Total runtime is 0.44158917665481573 minutes
2024-11-14 15:22:24,529:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:24,530:INFO:Initializing create_model()
2024-11-14 15:22:24,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:24,530:INFO:Checking exceptions
2024-11-14 15:22:24,530:INFO:Importing libraries
2024-11-14 15:22:24,530:INFO:Copying training dataset
2024-11-14 15:22:24,537:INFO:Defining folds
2024-11-14 15:22:24,538:INFO:Declaring metric variables
2024-11-14 15:22:24,541:INFO:Importing untrained model
2024-11-14 15:22:24,545:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 15:22:24,551:INFO:Starting cross validation
2024-11-14 15:22:24,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:26,320:INFO:Calculating mean and std
2024-11-14 15:22:26,323:INFO:Creating metrics dataframe
2024-11-14 15:22:26,328:INFO:Uploading results into container
2024-11-14 15:22:26,329:INFO:Uploading model into container now
2024-11-14 15:22:26,329:INFO:_master_model_container: 16
2024-11-14 15:22:26,329:INFO:_display_container: 2
2024-11-14 15:22:26,330:INFO:GradientBoostingRegressor(random_state=42)
2024-11-14 15:22:26,330:INFO:create_model() successfully completed......................................
2024-11-14 15:22:26,512:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:26,512:INFO:Creating metrics dataframe
2024-11-14 15:22:26,524:INFO:Initializing Extreme Gradient Boosting
2024-11-14 15:22:26,525:INFO:Total runtime is 0.47489893039067593 minutes
2024-11-14 15:22:26,528:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:26,528:INFO:Initializing create_model()
2024-11-14 15:22:26,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:26,529:INFO:Checking exceptions
2024-11-14 15:22:26,529:INFO:Importing libraries
2024-11-14 15:22:26,529:INFO:Copying training dataset
2024-11-14 15:22:26,535:INFO:Defining folds
2024-11-14 15:22:26,535:INFO:Declaring metric variables
2024-11-14 15:22:26,539:INFO:Importing untrained model
2024-11-14 15:22:26,542:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 15:22:26,549:INFO:Starting cross validation
2024-11-14 15:22:26,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:22:26,833:INFO:Calculating mean and std
2024-11-14 15:22:26,837:INFO:Creating metrics dataframe
2024-11-14 15:22:26,843:INFO:Uploading results into container
2024-11-14 15:22:26,844:INFO:Uploading model into container now
2024-11-14 15:22:26,844:INFO:_master_model_container: 17
2024-11-14 15:22:26,844:INFO:_display_container: 2
2024-11-14 15:22:26,845:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=42, ...)
2024-11-14 15:22:26,845:INFO:create_model() successfully completed......................................
2024-11-14 15:22:27,012:INFO:SubProcess create_model() end ==================================
2024-11-14 15:22:27,012:INFO:Creating metrics dataframe
2024-11-14 15:22:27,025:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 15:22:27,025:INFO:Total runtime is 0.48323521216710413 minutes
2024-11-14 15:22:27,028:INFO:SubProcess create_model() called ==================================
2024-11-14 15:22:27,028:INFO:Initializing create_model()
2024-11-14 15:22:27,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:22:27,029:INFO:Checking exceptions
2024-11-14 15:22:27,029:INFO:Importing libraries
2024-11-14 15:22:27,029:INFO:Copying training dataset
2024-11-14 15:22:27,035:INFO:Defining folds
2024-11-14 15:22:27,036:INFO:Declaring metric variables
2024-11-14 15:22:27,039:INFO:Importing untrained model
2024-11-14 15:22:27,042:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 15:22:27,049:INFO:Starting cross validation
2024-11-14 15:22:27,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:29:39,131:INFO:Calculating mean and std
2024-11-14 15:29:39,134:INFO:Creating metrics dataframe
2024-11-14 15:29:39,142:INFO:Uploading results into container
2024-11-14 15:29:39,143:INFO:Uploading model into container now
2024-11-14 15:29:39,143:INFO:_master_model_container: 18
2024-11-14 15:29:39,144:INFO:_display_container: 2
2024-11-14 15:29:39,144:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:29:39,144:INFO:create_model() successfully completed......................................
2024-11-14 15:29:39,386:INFO:SubProcess create_model() end ==================================
2024-11-14 15:29:39,386:INFO:Creating metrics dataframe
2024-11-14 15:29:39,401:INFO:Initializing CatBoost Regressor
2024-11-14 15:29:39,401:INFO:Total runtime is 7.6895021319389345 minutes
2024-11-14 15:29:39,404:INFO:SubProcess create_model() called ==================================
2024-11-14 15:29:39,405:INFO:Initializing create_model()
2024-11-14 15:29:39,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:29:39,405:INFO:Checking exceptions
2024-11-14 15:29:39,405:INFO:Importing libraries
2024-11-14 15:29:39,405:INFO:Copying training dataset
2024-11-14 15:29:39,413:INFO:Defining folds
2024-11-14 15:29:39,413:INFO:Declaring metric variables
2024-11-14 15:29:39,416:INFO:Importing untrained model
2024-11-14 15:29:39,420:INFO:CatBoost Regressor Imported successfully
2024-11-14 15:29:39,426:INFO:Starting cross validation
2024-11-14 15:29:39,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:29:51,627:INFO:Calculating mean and std
2024-11-14 15:29:51,632:INFO:Creating metrics dataframe
2024-11-14 15:29:51,640:INFO:Uploading results into container
2024-11-14 15:29:51,640:INFO:Uploading model into container now
2024-11-14 15:29:51,641:INFO:_master_model_container: 19
2024-11-14 15:29:51,641:INFO:_display_container: 2
2024-11-14 15:29:51,641:INFO:<catboost.core.CatBoostRegressor object at 0x7fc1a7a42fa0>
2024-11-14 15:29:51,641:INFO:create_model() successfully completed......................................
2024-11-14 15:29:51,841:INFO:SubProcess create_model() end ==================================
2024-11-14 15:29:51,841:INFO:Creating metrics dataframe
2024-11-14 15:29:51,856:INFO:Initializing Dummy Regressor
2024-11-14 15:29:51,856:INFO:Total runtime is 7.89708536863327 minutes
2024-11-14 15:29:51,859:INFO:SubProcess create_model() called ==================================
2024-11-14 15:29:51,859:INFO:Initializing create_model()
2024-11-14 15:29:51,860:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1c4c82be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:29:51,860:INFO:Checking exceptions
2024-11-14 15:29:51,860:INFO:Importing libraries
2024-11-14 15:29:51,860:INFO:Copying training dataset
2024-11-14 15:29:51,868:INFO:Defining folds
2024-11-14 15:29:51,868:INFO:Declaring metric variables
2024-11-14 15:29:51,871:INFO:Importing untrained model
2024-11-14 15:29:51,875:INFO:Dummy Regressor Imported successfully
2024-11-14 15:29:51,880:INFO:Starting cross validation
2024-11-14 15:29:51,881:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:29:57,349:INFO:Calculating mean and std
2024-11-14 15:29:57,352:INFO:Creating metrics dataframe
2024-11-14 15:29:57,359:INFO:Uploading results into container
2024-11-14 15:29:57,360:INFO:Uploading model into container now
2024-11-14 15:29:57,360:INFO:_master_model_container: 20
2024-11-14 15:29:57,360:INFO:_display_container: 2
2024-11-14 15:29:57,361:INFO:DummyRegressor()
2024-11-14 15:29:57,361:INFO:create_model() successfully completed......................................
2024-11-14 15:29:57,547:INFO:SubProcess create_model() end ==================================
2024-11-14 15:29:57,548:INFO:Creating metrics dataframe
2024-11-14 15:29:57,570:INFO:Initializing create_model()
2024-11-14 15:29:57,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc1a7abac10>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:29:57,570:INFO:Checking exceptions
2024-11-14 15:29:57,572:INFO:Importing libraries
2024-11-14 15:29:57,572:INFO:Copying training dataset
2024-11-14 15:29:57,578:INFO:Defining folds
2024-11-14 15:29:57,578:INFO:Declaring metric variables
2024-11-14 15:29:57,579:INFO:Importing untrained model
2024-11-14 15:29:57,579:INFO:Declaring custom model
2024-11-14 15:29:57,579:INFO:Linear Regression Imported successfully
2024-11-14 15:29:57,580:INFO:Cross validation set to False
2024-11-14 15:29:57,580:INFO:Fitting Model
2024-11-14 15:29:57,596:INFO:LinearRegression(n_jobs=-1)
2024-11-14 15:29:57,597:INFO:create_model() successfully completed......................................
2024-11-14 15:29:57,879:INFO:_master_model_container: 20
2024-11-14 15:29:57,879:INFO:_display_container: 2
2024-11-14 15:29:57,879:INFO:LinearRegression(n_jobs=-1)
2024-11-14 15:29:57,879:INFO:compare_models() successfully completed......................................
2024-11-14 15:30:12,162:INFO:PyCaret RegressionExperiment
2024-11-14 15:30:12,162:INFO:Logging name: reg-default-name
2024-11-14 15:30:12,162:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 15:30:12,162:INFO:version 3.2.0
2024-11-14 15:30:12,162:INFO:Initializing setup()
2024-11-14 15:30:12,162:INFO:self.USI: 4e5c
2024-11-14 15:30:12,162:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 15:30:12,162:INFO:Checking environment
2024-11-14 15:30:12,162:INFO:python_version: 3.8.13
2024-11-14 15:30:12,163:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 15:30:12,163:INFO:machine: x86_64
2024-11-14 15:30:12,163:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 15:30:12,163:INFO:Memory: svmem(total=270355722240, available=186420314112, percent=31.0, used=81850605568, free=51748904960, active=73537482752, inactive=91386503168, buffers=9031680, cached=136747180032, shared=196165632, slab=20976226304)
2024-11-14 15:30:12,167:INFO:Physical Core: 28
2024-11-14 15:30:12,167:INFO:Logical Core: 56
2024-11-14 15:30:12,167:INFO:Checking libraries
2024-11-14 15:30:12,167:INFO:System:
2024-11-14 15:30:12,167:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 15:30:12,167:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 15:30:12,167:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 15:30:12,167:INFO:PyCaret required dependencies:
2024-11-14 15:30:12,167:INFO:                 pip: 22.2.2
2024-11-14 15:30:12,167:INFO:          setuptools: 63.4.2
2024-11-14 15:30:12,167:INFO:             pycaret: 3.2.0
2024-11-14 15:30:12,167:INFO:             IPython: 8.12.2
2024-11-14 15:30:12,167:INFO:          ipywidgets: 7.7.1
2024-11-14 15:30:12,167:INFO:                tqdm: 4.64.1
2024-11-14 15:30:12,167:INFO:               numpy: 1.23.5
2024-11-14 15:30:12,167:INFO:              pandas: 1.5.3
2024-11-14 15:30:12,167:INFO:              jinja2: 3.1.2
2024-11-14 15:30:12,167:INFO:               scipy: 1.10.1
2024-11-14 15:30:12,167:INFO:              joblib: 1.3.0
2024-11-14 15:30:12,168:INFO:             sklearn: 1.1.2
2024-11-14 15:30:12,168:INFO:                pyod: 2.0.2
2024-11-14 15:30:12,168:INFO:            imblearn: 0.12.4
2024-11-14 15:30:12,168:INFO:   category_encoders: 2.6.4
2024-11-14 15:30:12,168:INFO:            lightgbm: 4.5.0
2024-11-14 15:30:12,168:INFO:               numba: 0.57.1
2024-11-14 15:30:12,168:INFO:            requests: 2.28.1
2024-11-14 15:30:12,168:INFO:          matplotlib: 3.5.1
2024-11-14 15:30:12,168:INFO:          scikitplot: 0.3.7
2024-11-14 15:30:12,168:INFO:         yellowbrick: 1.5
2024-11-14 15:30:12,168:INFO:              plotly: 5.24.1
2024-11-14 15:30:12,168:INFO:    plotly-resampler: Not installed
2024-11-14 15:30:12,168:INFO:             kaleido: 0.2.1
2024-11-14 15:30:12,168:INFO:           schemdraw: 0.15
2024-11-14 15:30:12,168:INFO:         statsmodels: 0.13.2
2024-11-14 15:30:12,168:INFO:              sktime: 0.21.1
2024-11-14 15:30:12,168:INFO:               tbats: 1.1.3
2024-11-14 15:30:12,168:INFO:            pmdarima: 2.0.4
2024-11-14 15:30:12,168:INFO:              psutil: 5.9.1
2024-11-14 15:30:12,168:INFO:          markupsafe: 2.1.1
2024-11-14 15:30:12,168:INFO:             pickle5: Not installed
2024-11-14 15:30:12,168:INFO:         cloudpickle: 2.1.0
2024-11-14 15:30:12,168:INFO:         deprecation: 2.1.0
2024-11-14 15:30:12,168:INFO:              xxhash: 3.5.0
2024-11-14 15:30:12,168:INFO:           wurlitzer: 3.1.1
2024-11-14 15:30:12,168:INFO:PyCaret optional dependencies:
2024-11-14 15:30:12,168:INFO:                shap: 0.44.1
2024-11-14 15:30:12,168:INFO:           interpret: 0.6.5
2024-11-14 15:30:12,168:INFO:                umap: 0.5.7
2024-11-14 15:30:12,169:INFO:     ydata_profiling: 4.6.0
2024-11-14 15:30:12,169:INFO:  explainerdashboard: 0.4.7
2024-11-14 15:30:12,169:INFO:             autoviz: Not installed
2024-11-14 15:30:12,169:INFO:           fairlearn: 0.7.0
2024-11-14 15:30:12,169:INFO:          deepchecks: Not installed
2024-11-14 15:30:12,169:INFO:             xgboost: 2.1.1
2024-11-14 15:30:12,169:INFO:            catboost: 1.2.7
2024-11-14 15:30:12,169:INFO:              kmodes: 0.12.2
2024-11-14 15:30:12,169:INFO:             mlxtend: 0.23.1
2024-11-14 15:30:12,169:INFO:       statsforecast: 1.5.0
2024-11-14 15:30:12,169:INFO:        tune_sklearn: 0.5.0
2024-11-14 15:30:12,169:INFO:                 ray: 2.10.0
2024-11-14 15:30:12,169:INFO:            hyperopt: 0.2.7
2024-11-14 15:30:12,169:INFO:              optuna: 4.1.0
2024-11-14 15:30:12,169:INFO:               skopt: 0.10.2
2024-11-14 15:30:12,169:INFO:              mlflow: 1.30.1
2024-11-14 15:30:12,169:INFO:              gradio: 3.50.2
2024-11-14 15:30:12,169:INFO:             fastapi: 0.115.5
2024-11-14 15:30:12,169:INFO:             uvicorn: 0.32.0
2024-11-14 15:30:12,169:INFO:              m2cgen: 0.10.0
2024-11-14 15:30:12,169:INFO:           evidently: 0.2.8
2024-11-14 15:30:12,169:INFO:               fugue: 0.8.6
2024-11-14 15:30:12,169:INFO:           streamlit: Not installed
2024-11-14 15:30:12,169:INFO:             prophet: Not installed
2024-11-14 15:30:12,169:INFO:None
2024-11-14 15:30:12,169:INFO:Set up data.
2024-11-14 15:30:12,180:INFO:Set up folding strategy.
2024-11-14 15:30:12,180:INFO:Set up train/test split.
2024-11-14 15:30:12,185:INFO:Set up index.
2024-11-14 15:30:12,188:INFO:Assigning column types.
2024-11-14 15:30:12,193:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 15:30:12,193:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,198:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,204:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,271:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,311:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,312:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:12,315:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:12,316:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,320:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,324:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,418:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,419:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:12,421:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:12,422:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 15:30:12,426:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,430:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,484:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,523:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:12,525:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:12,530:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,534:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,585:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,624:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:12,627:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:12,628:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 15:30:12,635:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,728:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:12,730:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:12,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,792:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,830:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:12,833:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:12,833:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 15:30:12,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:30:12,933:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:12,935:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:12,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:30:13,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:30:13,034:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:13,036:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:13,037:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 15:30:13,096:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:30:13,134:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:13,137:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:13,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:30:13,236:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:13,238:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:13,239:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 15:30:13,336:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:13,339:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:13,446:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:13,449:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:13,450:INFO:Preparing preprocessing pipeline...
2024-11-14 15:30:13,450:INFO:Set up simple imputation.
2024-11-14 15:30:13,470:INFO:Finished creating preprocessing pipeline.
2024-11-14 15:30:13,473:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 15:30:13,473:INFO:Creating final display dataframe.
2024-11-14 15:30:13,529:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 7)
4        Transformed data shape        (31316, 7)
5   Transformed train set shape        (21921, 7)
6    Transformed test set shape         (9395, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4e5c
2024-11-14 15:30:13,628:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:13,631:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:13,731:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:30:13,733:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:30:13,734:INFO:setup() successfully completed in 1.57s...............
2024-11-14 15:30:13,735:INFO:Initializing compare_models()
2024-11-14 15:30:13,735:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 15:30:13,736:INFO:Checking exceptions
2024-11-14 15:30:13,738:INFO:Preparing display monitor
2024-11-14 15:30:13,775:INFO:Initializing Linear Regression
2024-11-14 15:30:13,775:INFO:Total runtime is 2.006689707438151e-06 minutes
2024-11-14 15:30:13,779:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:13,779:INFO:Initializing create_model()
2024-11-14 15:30:13,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:13,779:INFO:Checking exceptions
2024-11-14 15:30:13,779:INFO:Importing libraries
2024-11-14 15:30:13,779:INFO:Copying training dataset
2024-11-14 15:30:13,785:INFO:Defining folds
2024-11-14 15:30:13,785:INFO:Declaring metric variables
2024-11-14 15:30:13,788:INFO:Importing untrained model
2024-11-14 15:30:13,792:INFO:Linear Regression Imported successfully
2024-11-14 15:30:13,799:INFO:Starting cross validation
2024-11-14 15:30:13,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:16,775:INFO:Calculating mean and std
2024-11-14 15:30:16,779:INFO:Creating metrics dataframe
2024-11-14 15:30:16,785:INFO:Uploading results into container
2024-11-14 15:30:16,786:INFO:Uploading model into container now
2024-11-14 15:30:16,787:INFO:_master_model_container: 1
2024-11-14 15:30:16,787:INFO:_display_container: 2
2024-11-14 15:30:16,788:INFO:LinearRegression(n_jobs=-1)
2024-11-14 15:30:16,788:INFO:create_model() successfully completed......................................
2024-11-14 15:30:17,010:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:17,010:INFO:Creating metrics dataframe
2024-11-14 15:30:17,019:INFO:Initializing Lasso Regression
2024-11-14 15:30:17,019:INFO:Total runtime is 0.05406097571055094 minutes
2024-11-14 15:30:17,022:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:17,023:INFO:Initializing create_model()
2024-11-14 15:30:17,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:17,023:INFO:Checking exceptions
2024-11-14 15:30:17,023:INFO:Importing libraries
2024-11-14 15:30:17,023:INFO:Copying training dataset
2024-11-14 15:30:17,030:INFO:Defining folds
2024-11-14 15:30:17,030:INFO:Declaring metric variables
2024-11-14 15:30:17,034:INFO:Importing untrained model
2024-11-14 15:30:17,037:INFO:Lasso Regression Imported successfully
2024-11-14 15:30:17,043:INFO:Starting cross validation
2024-11-14 15:30:17,044:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:20,278:INFO:Calculating mean and std
2024-11-14 15:30:20,282:INFO:Creating metrics dataframe
2024-11-14 15:30:20,288:INFO:Uploading results into container
2024-11-14 15:30:20,289:INFO:Uploading model into container now
2024-11-14 15:30:20,289:INFO:_master_model_container: 2
2024-11-14 15:30:20,290:INFO:_display_container: 2
2024-11-14 15:30:20,290:INFO:Lasso(random_state=42)
2024-11-14 15:30:20,290:INFO:create_model() successfully completed......................................
2024-11-14 15:30:20,471:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:20,471:INFO:Creating metrics dataframe
2024-11-14 15:30:20,482:INFO:Initializing Ridge Regression
2024-11-14 15:30:20,482:INFO:Total runtime is 0.11177416642506917 minutes
2024-11-14 15:30:20,485:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:20,485:INFO:Initializing create_model()
2024-11-14 15:30:20,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:20,486:INFO:Checking exceptions
2024-11-14 15:30:20,486:INFO:Importing libraries
2024-11-14 15:30:20,486:INFO:Copying training dataset
2024-11-14 15:30:20,493:INFO:Defining folds
2024-11-14 15:30:20,493:INFO:Declaring metric variables
2024-11-14 15:30:20,496:INFO:Importing untrained model
2024-11-14 15:30:20,500:INFO:Ridge Regression Imported successfully
2024-11-14 15:30:20,507:INFO:Starting cross validation
2024-11-14 15:30:20,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:23,510:INFO:Calculating mean and std
2024-11-14 15:30:23,514:INFO:Creating metrics dataframe
2024-11-14 15:30:23,520:INFO:Uploading results into container
2024-11-14 15:30:23,520:INFO:Uploading model into container now
2024-11-14 15:30:23,521:INFO:_master_model_container: 3
2024-11-14 15:30:23,521:INFO:_display_container: 2
2024-11-14 15:30:23,521:INFO:Ridge(random_state=42)
2024-11-14 15:30:23,521:INFO:create_model() successfully completed......................................
2024-11-14 15:30:23,739:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:23,739:INFO:Creating metrics dataframe
2024-11-14 15:30:23,750:INFO:Initializing Elastic Net
2024-11-14 15:30:23,750:INFO:Total runtime is 0.1662454088528951 minutes
2024-11-14 15:30:23,753:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:23,754:INFO:Initializing create_model()
2024-11-14 15:30:23,754:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:23,754:INFO:Checking exceptions
2024-11-14 15:30:23,754:INFO:Importing libraries
2024-11-14 15:30:23,754:INFO:Copying training dataset
2024-11-14 15:30:23,761:INFO:Defining folds
2024-11-14 15:30:23,761:INFO:Declaring metric variables
2024-11-14 15:30:23,765:INFO:Importing untrained model
2024-11-14 15:30:23,768:INFO:Elastic Net Imported successfully
2024-11-14 15:30:23,774:INFO:Starting cross validation
2024-11-14 15:30:23,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:26,506:INFO:Calculating mean and std
2024-11-14 15:30:26,510:INFO:Creating metrics dataframe
2024-11-14 15:30:26,516:INFO:Uploading results into container
2024-11-14 15:30:26,517:INFO:Uploading model into container now
2024-11-14 15:30:26,517:INFO:_master_model_container: 4
2024-11-14 15:30:26,517:INFO:_display_container: 2
2024-11-14 15:30:26,518:INFO:ElasticNet(random_state=42)
2024-11-14 15:30:26,518:INFO:create_model() successfully completed......................................
2024-11-14 15:30:26,715:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:26,715:INFO:Creating metrics dataframe
2024-11-14 15:30:26,726:INFO:Initializing Least Angle Regression
2024-11-14 15:30:26,726:INFO:Total runtime is 0.215848712126414 minutes
2024-11-14 15:30:26,729:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:26,730:INFO:Initializing create_model()
2024-11-14 15:30:26,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:26,730:INFO:Checking exceptions
2024-11-14 15:30:26,730:INFO:Importing libraries
2024-11-14 15:30:26,730:INFO:Copying training dataset
2024-11-14 15:30:26,738:INFO:Defining folds
2024-11-14 15:30:26,738:INFO:Declaring metric variables
2024-11-14 15:30:26,742:INFO:Importing untrained model
2024-11-14 15:30:26,745:INFO:Least Angle Regression Imported successfully
2024-11-14 15:30:26,751:INFO:Starting cross validation
2024-11-14 15:30:26,752:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:26,790:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:26,792:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.258e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:30:26,793:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.129e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:30:26,793:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.305e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:30:26,793:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.266e-05, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:30:26,794:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.730e-06, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:30:26,794:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.732e-06, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:30:26,797:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:26,802:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:26,804:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:26,810:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:26,818:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:26,821:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.725e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:30:26,821:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.336e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:30:26,821:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.741e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:30:26,822:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.063e-06, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:30:26,827:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:26,837:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:26,842:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:26,843:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:26,864:INFO:Calculating mean and std
2024-11-14 15:30:26,868:INFO:Creating metrics dataframe
2024-11-14 15:30:26,875:INFO:Uploading results into container
2024-11-14 15:30:26,876:INFO:Uploading model into container now
2024-11-14 15:30:26,876:INFO:_master_model_container: 5
2024-11-14 15:30:26,876:INFO:_display_container: 2
2024-11-14 15:30:26,877:INFO:Lars(random_state=42)
2024-11-14 15:30:26,877:INFO:create_model() successfully completed......................................
2024-11-14 15:30:27,046:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:27,046:INFO:Creating metrics dataframe
2024-11-14 15:30:27,057:INFO:Initializing Lasso Least Angle Regression
2024-11-14 15:30:27,057:INFO:Total runtime is 0.22136706113815308 minutes
2024-11-14 15:30:27,061:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:27,061:INFO:Initializing create_model()
2024-11-14 15:30:27,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:27,061:INFO:Checking exceptions
2024-11-14 15:30:27,061:INFO:Importing libraries
2024-11-14 15:30:27,061:INFO:Copying training dataset
2024-11-14 15:30:27,068:INFO:Defining folds
2024-11-14 15:30:27,068:INFO:Declaring metric variables
2024-11-14 15:30:27,071:INFO:Importing untrained model
2024-11-14 15:30:27,075:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 15:30:27,081:INFO:Starting cross validation
2024-11-14 15:30:27,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:27,119:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:30:27,121:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:30:27,130:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:30:27,133:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:30:27,139:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:30:27,145:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:30:27,145:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:30:27,153:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:30:27,158:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:30:27,165:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:30:27,183:INFO:Calculating mean and std
2024-11-14 15:30:27,187:INFO:Creating metrics dataframe
2024-11-14 15:30:27,193:INFO:Uploading results into container
2024-11-14 15:30:27,194:INFO:Uploading model into container now
2024-11-14 15:30:27,195:INFO:_master_model_container: 6
2024-11-14 15:30:27,195:INFO:_display_container: 2
2024-11-14 15:30:27,195:INFO:LassoLars(random_state=42)
2024-11-14 15:30:27,195:INFO:create_model() successfully completed......................................
2024-11-14 15:30:27,376:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:27,376:INFO:Creating metrics dataframe
2024-11-14 15:30:27,388:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 15:30:27,388:INFO:Total runtime is 0.22687576214472452 minutes
2024-11-14 15:30:27,391:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:27,391:INFO:Initializing create_model()
2024-11-14 15:30:27,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:27,392:INFO:Checking exceptions
2024-11-14 15:30:27,392:INFO:Importing libraries
2024-11-14 15:30:27,392:INFO:Copying training dataset
2024-11-14 15:30:27,399:INFO:Defining folds
2024-11-14 15:30:27,399:INFO:Declaring metric variables
2024-11-14 15:30:27,402:INFO:Importing untrained model
2024-11-14 15:30:27,406:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 15:30:27,412:INFO:Starting cross validation
2024-11-14 15:30:27,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:27,448:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:27,452:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:27,457:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:27,461:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:27,468:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:27,481:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:27,482:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:27,483:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:27,493:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:27,497:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:30:27,517:INFO:Calculating mean and std
2024-11-14 15:30:27,520:INFO:Creating metrics dataframe
2024-11-14 15:30:27,527:INFO:Uploading results into container
2024-11-14 15:30:27,528:INFO:Uploading model into container now
2024-11-14 15:30:27,528:INFO:_master_model_container: 7
2024-11-14 15:30:27,528:INFO:_display_container: 2
2024-11-14 15:30:27,528:INFO:OrthogonalMatchingPursuit()
2024-11-14 15:30:27,529:INFO:create_model() successfully completed......................................
2024-11-14 15:30:27,727:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:27,727:INFO:Creating metrics dataframe
2024-11-14 15:30:27,739:INFO:Initializing Bayesian Ridge
2024-11-14 15:30:27,739:INFO:Total runtime is 0.23273371458053588 minutes
2024-11-14 15:30:27,743:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:27,743:INFO:Initializing create_model()
2024-11-14 15:30:27,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:27,743:INFO:Checking exceptions
2024-11-14 15:30:27,744:INFO:Importing libraries
2024-11-14 15:30:27,744:INFO:Copying training dataset
2024-11-14 15:30:27,750:INFO:Defining folds
2024-11-14 15:30:27,751:INFO:Declaring metric variables
2024-11-14 15:30:27,754:INFO:Importing untrained model
2024-11-14 15:30:27,757:INFO:Bayesian Ridge Imported successfully
2024-11-14 15:30:27,764:INFO:Starting cross validation
2024-11-14 15:30:27,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:27,862:INFO:Calculating mean and std
2024-11-14 15:30:27,866:INFO:Creating metrics dataframe
2024-11-14 15:30:27,871:INFO:Uploading results into container
2024-11-14 15:30:27,872:INFO:Uploading model into container now
2024-11-14 15:30:27,872:INFO:_master_model_container: 8
2024-11-14 15:30:27,872:INFO:_display_container: 2
2024-11-14 15:30:27,873:INFO:BayesianRidge()
2024-11-14 15:30:27,873:INFO:create_model() successfully completed......................................
2024-11-14 15:30:28,053:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:28,053:INFO:Creating metrics dataframe
2024-11-14 15:30:28,065:INFO:Initializing Passive Aggressive Regressor
2024-11-14 15:30:28,065:INFO:Total runtime is 0.2381597598393758 minutes
2024-11-14 15:30:28,068:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:28,068:INFO:Initializing create_model()
2024-11-14 15:30:28,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:28,069:INFO:Checking exceptions
2024-11-14 15:30:28,069:INFO:Importing libraries
2024-11-14 15:30:28,069:INFO:Copying training dataset
2024-11-14 15:30:28,076:INFO:Defining folds
2024-11-14 15:30:28,076:INFO:Declaring metric variables
2024-11-14 15:30:28,079:INFO:Importing untrained model
2024-11-14 15:30:28,083:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 15:30:28,090:INFO:Starting cross validation
2024-11-14 15:30:28,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:28,223:INFO:Calculating mean and std
2024-11-14 15:30:28,227:INFO:Creating metrics dataframe
2024-11-14 15:30:28,234:INFO:Uploading results into container
2024-11-14 15:30:28,235:INFO:Uploading model into container now
2024-11-14 15:30:28,235:INFO:_master_model_container: 9
2024-11-14 15:30:28,236:INFO:_display_container: 2
2024-11-14 15:30:28,236:INFO:PassiveAggressiveRegressor(random_state=42)
2024-11-14 15:30:28,236:INFO:create_model() successfully completed......................................
2024-11-14 15:30:28,413:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:28,413:INFO:Creating metrics dataframe
2024-11-14 15:30:28,424:INFO:Initializing Huber Regressor
2024-11-14 15:30:28,425:INFO:Total runtime is 0.24415429035822547 minutes
2024-11-14 15:30:28,428:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:28,428:INFO:Initializing create_model()
2024-11-14 15:30:28,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:28,428:INFO:Checking exceptions
2024-11-14 15:30:28,429:INFO:Importing libraries
2024-11-14 15:30:28,429:INFO:Copying training dataset
2024-11-14 15:30:28,435:INFO:Defining folds
2024-11-14 15:30:28,436:INFO:Declaring metric variables
2024-11-14 15:30:28,439:INFO:Importing untrained model
2024-11-14 15:30:28,443:INFO:Huber Regressor Imported successfully
2024-11-14 15:30:28,449:INFO:Starting cross validation
2024-11-14 15:30:28,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:28,793:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:30:28,796:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:30:28,806:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:30:28,875:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:30:28,886:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:30:28,900:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:30:28,905:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:30:28,934:INFO:Calculating mean and std
2024-11-14 15:30:28,938:INFO:Creating metrics dataframe
2024-11-14 15:30:28,944:INFO:Uploading results into container
2024-11-14 15:30:28,945:INFO:Uploading model into container now
2024-11-14 15:30:28,945:INFO:_master_model_container: 10
2024-11-14 15:30:28,945:INFO:_display_container: 2
2024-11-14 15:30:28,946:INFO:HuberRegressor()
2024-11-14 15:30:28,946:INFO:create_model() successfully completed......................................
2024-11-14 15:30:29,121:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:29,122:INFO:Creating metrics dataframe
2024-11-14 15:30:29,134:INFO:Initializing K Neighbors Regressor
2024-11-14 15:30:29,134:INFO:Total runtime is 0.2559780597686767 minutes
2024-11-14 15:30:29,137:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:29,138:INFO:Initializing create_model()
2024-11-14 15:30:29,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:29,138:INFO:Checking exceptions
2024-11-14 15:30:29,138:INFO:Importing libraries
2024-11-14 15:30:29,138:INFO:Copying training dataset
2024-11-14 15:30:29,145:INFO:Defining folds
2024-11-14 15:30:29,146:INFO:Declaring metric variables
2024-11-14 15:30:29,149:INFO:Importing untrained model
2024-11-14 15:30:29,152:INFO:K Neighbors Regressor Imported successfully
2024-11-14 15:30:29,159:INFO:Starting cross validation
2024-11-14 15:30:29,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:29,385:INFO:Calculating mean and std
2024-11-14 15:30:29,388:INFO:Creating metrics dataframe
2024-11-14 15:30:29,395:INFO:Uploading results into container
2024-11-14 15:30:29,396:INFO:Uploading model into container now
2024-11-14 15:30:29,396:INFO:_master_model_container: 11
2024-11-14 15:30:29,397:INFO:_display_container: 2
2024-11-14 15:30:29,397:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 15:30:29,397:INFO:create_model() successfully completed......................................
2024-11-14 15:30:29,592:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:29,593:INFO:Creating metrics dataframe
2024-11-14 15:30:29,609:INFO:Initializing Decision Tree Regressor
2024-11-14 15:30:29,610:INFO:Total runtime is 0.2639071424802144 minutes
2024-11-14 15:30:29,614:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:29,615:INFO:Initializing create_model()
2024-11-14 15:30:29,615:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:29,615:INFO:Checking exceptions
2024-11-14 15:30:29,615:INFO:Importing libraries
2024-11-14 15:30:29,615:INFO:Copying training dataset
2024-11-14 15:30:29,623:INFO:Defining folds
2024-11-14 15:30:29,623:INFO:Declaring metric variables
2024-11-14 15:30:29,627:INFO:Importing untrained model
2024-11-14 15:30:29,632:INFO:Decision Tree Regressor Imported successfully
2024-11-14 15:30:29,640:INFO:Starting cross validation
2024-11-14 15:30:29,641:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:29,817:INFO:Calculating mean and std
2024-11-14 15:30:29,820:INFO:Creating metrics dataframe
2024-11-14 15:30:29,827:INFO:Uploading results into container
2024-11-14 15:30:29,828:INFO:Uploading model into container now
2024-11-14 15:30:29,828:INFO:_master_model_container: 12
2024-11-14 15:30:29,828:INFO:_display_container: 2
2024-11-14 15:30:29,828:INFO:DecisionTreeRegressor(random_state=42)
2024-11-14 15:30:29,829:INFO:create_model() successfully completed......................................
2024-11-14 15:30:30,045:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:30,045:INFO:Creating metrics dataframe
2024-11-14 15:30:30,058:INFO:Initializing Random Forest Regressor
2024-11-14 15:30:30,058:INFO:Total runtime is 0.27137862841288246 minutes
2024-11-14 15:30:30,061:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:30,062:INFO:Initializing create_model()
2024-11-14 15:30:30,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:30,062:INFO:Checking exceptions
2024-11-14 15:30:30,062:INFO:Importing libraries
2024-11-14 15:30:30,062:INFO:Copying training dataset
2024-11-14 15:30:30,069:INFO:Defining folds
2024-11-14 15:30:30,069:INFO:Declaring metric variables
2024-11-14 15:30:30,073:INFO:Importing untrained model
2024-11-14 15:30:30,076:INFO:Random Forest Regressor Imported successfully
2024-11-14 15:30:30,083:INFO:Starting cross validation
2024-11-14 15:30:30,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:31,673:INFO:Calculating mean and std
2024-11-14 15:30:31,676:INFO:Creating metrics dataframe
2024-11-14 15:30:31,682:INFO:Uploading results into container
2024-11-14 15:30:31,682:INFO:Uploading model into container now
2024-11-14 15:30:31,683:INFO:_master_model_container: 13
2024-11-14 15:30:31,683:INFO:_display_container: 2
2024-11-14 15:30:31,684:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:30:31,684:INFO:create_model() successfully completed......................................
2024-11-14 15:30:31,849:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:31,849:INFO:Creating metrics dataframe
2024-11-14 15:30:31,861:INFO:Initializing Extra Trees Regressor
2024-11-14 15:30:31,861:INFO:Total runtime is 0.3014304399490356 minutes
2024-11-14 15:30:31,864:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:31,865:INFO:Initializing create_model()
2024-11-14 15:30:31,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:31,865:INFO:Checking exceptions
2024-11-14 15:30:31,865:INFO:Importing libraries
2024-11-14 15:30:31,865:INFO:Copying training dataset
2024-11-14 15:30:31,872:INFO:Defining folds
2024-11-14 15:30:31,872:INFO:Declaring metric variables
2024-11-14 15:30:31,875:INFO:Importing untrained model
2024-11-14 15:30:31,878:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:30:31,885:INFO:Starting cross validation
2024-11-14 15:30:31,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:32,801:INFO:Calculating mean and std
2024-11-14 15:30:32,807:INFO:Creating metrics dataframe
2024-11-14 15:30:32,813:INFO:Uploading results into container
2024-11-14 15:30:32,813:INFO:Uploading model into container now
2024-11-14 15:30:32,814:INFO:_master_model_container: 14
2024-11-14 15:30:32,814:INFO:_display_container: 2
2024-11-14 15:30:32,815:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:30:32,815:INFO:create_model() successfully completed......................................
2024-11-14 15:30:32,986:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:32,987:INFO:Creating metrics dataframe
2024-11-14 15:30:32,999:INFO:Initializing AdaBoost Regressor
2024-11-14 15:30:32,999:INFO:Total runtime is 0.32039546171824135 minutes
2024-11-14 15:30:33,002:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:33,003:INFO:Initializing create_model()
2024-11-14 15:30:33,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:33,003:INFO:Checking exceptions
2024-11-14 15:30:33,003:INFO:Importing libraries
2024-11-14 15:30:33,003:INFO:Copying training dataset
2024-11-14 15:30:33,011:INFO:Defining folds
2024-11-14 15:30:33,011:INFO:Declaring metric variables
2024-11-14 15:30:33,014:INFO:Importing untrained model
2024-11-14 15:30:33,018:INFO:AdaBoost Regressor Imported successfully
2024-11-14 15:30:33,024:INFO:Starting cross validation
2024-11-14 15:30:33,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:33,803:INFO:Calculating mean and std
2024-11-14 15:30:33,807:INFO:Creating metrics dataframe
2024-11-14 15:30:33,814:INFO:Uploading results into container
2024-11-14 15:30:33,815:INFO:Uploading model into container now
2024-11-14 15:30:33,816:INFO:_master_model_container: 15
2024-11-14 15:30:33,816:INFO:_display_container: 2
2024-11-14 15:30:33,816:INFO:AdaBoostRegressor(random_state=42)
2024-11-14 15:30:33,816:INFO:create_model() successfully completed......................................
2024-11-14 15:30:33,980:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:33,980:INFO:Creating metrics dataframe
2024-11-14 15:30:33,992:INFO:Initializing Gradient Boosting Regressor
2024-11-14 15:30:33,992:INFO:Total runtime is 0.33695323864618937 minutes
2024-11-14 15:30:33,996:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:33,996:INFO:Initializing create_model()
2024-11-14 15:30:33,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:33,996:INFO:Checking exceptions
2024-11-14 15:30:33,997:INFO:Importing libraries
2024-11-14 15:30:33,997:INFO:Copying training dataset
2024-11-14 15:30:34,003:INFO:Defining folds
2024-11-14 15:30:34,003:INFO:Declaring metric variables
2024-11-14 15:30:34,007:INFO:Importing untrained model
2024-11-14 15:30:34,010:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 15:30:34,017:INFO:Starting cross validation
2024-11-14 15:30:34,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:35,877:INFO:Calculating mean and std
2024-11-14 15:30:35,883:INFO:Creating metrics dataframe
2024-11-14 15:30:35,890:INFO:Uploading results into container
2024-11-14 15:30:35,891:INFO:Uploading model into container now
2024-11-14 15:30:35,891:INFO:_master_model_container: 16
2024-11-14 15:30:35,891:INFO:_display_container: 2
2024-11-14 15:30:35,892:INFO:GradientBoostingRegressor(random_state=42)
2024-11-14 15:30:35,892:INFO:create_model() successfully completed......................................
2024-11-14 15:30:36,095:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:36,095:INFO:Creating metrics dataframe
2024-11-14 15:30:36,108:INFO:Initializing Extreme Gradient Boosting
2024-11-14 15:30:36,108:INFO:Total runtime is 0.37221936384836835 minutes
2024-11-14 15:30:36,112:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:36,112:INFO:Initializing create_model()
2024-11-14 15:30:36,113:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:36,113:INFO:Checking exceptions
2024-11-14 15:30:36,113:INFO:Importing libraries
2024-11-14 15:30:36,113:INFO:Copying training dataset
2024-11-14 15:30:36,119:INFO:Defining folds
2024-11-14 15:30:36,119:INFO:Declaring metric variables
2024-11-14 15:30:36,123:INFO:Importing untrained model
2024-11-14 15:30:36,127:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 15:30:36,133:INFO:Starting cross validation
2024-11-14 15:30:36,134:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:30:36,453:INFO:Calculating mean and std
2024-11-14 15:30:36,456:INFO:Creating metrics dataframe
2024-11-14 15:30:36,463:INFO:Uploading results into container
2024-11-14 15:30:36,464:INFO:Uploading model into container now
2024-11-14 15:30:36,464:INFO:_master_model_container: 17
2024-11-14 15:30:36,464:INFO:_display_container: 2
2024-11-14 15:30:36,465:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=42, ...)
2024-11-14 15:30:36,465:INFO:create_model() successfully completed......................................
2024-11-14 15:30:36,631:INFO:SubProcess create_model() end ==================================
2024-11-14 15:30:36,632:INFO:Creating metrics dataframe
2024-11-14 15:30:36,645:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 15:30:36,646:INFO:Total runtime is 0.3811722199122111 minutes
2024-11-14 15:30:36,649:INFO:SubProcess create_model() called ==================================
2024-11-14 15:30:36,649:INFO:Initializing create_model()
2024-11-14 15:30:36,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:30:36,650:INFO:Checking exceptions
2024-11-14 15:30:36,650:INFO:Importing libraries
2024-11-14 15:30:36,650:INFO:Copying training dataset
2024-11-14 15:30:36,657:INFO:Defining folds
2024-11-14 15:30:36,657:INFO:Declaring metric variables
2024-11-14 15:30:36,660:INFO:Importing untrained model
2024-11-14 15:30:36,664:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 15:30:36,670:INFO:Starting cross validation
2024-11-14 15:30:36,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:37:48,013:INFO:Calculating mean and std
2024-11-14 15:37:48,018:INFO:Creating metrics dataframe
2024-11-14 15:37:48,024:INFO:Uploading results into container
2024-11-14 15:37:48,025:INFO:Uploading model into container now
2024-11-14 15:37:48,026:INFO:_master_model_container: 18
2024-11-14 15:37:48,026:INFO:_display_container: 2
2024-11-14 15:37:48,027:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:37:48,027:INFO:create_model() successfully completed......................................
2024-11-14 15:37:48,264:INFO:SubProcess create_model() end ==================================
2024-11-14 15:37:48,264:INFO:Creating metrics dataframe
2024-11-14 15:37:48,291:INFO:Initializing CatBoost Regressor
2024-11-14 15:37:48,291:INFO:Total runtime is 7.5752577225367235 minutes
2024-11-14 15:37:48,294:INFO:SubProcess create_model() called ==================================
2024-11-14 15:37:48,294:INFO:Initializing create_model()
2024-11-14 15:37:48,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:37:48,294:INFO:Checking exceptions
2024-11-14 15:37:48,295:INFO:Importing libraries
2024-11-14 15:37:48,295:INFO:Copying training dataset
2024-11-14 15:37:48,302:INFO:Defining folds
2024-11-14 15:37:48,303:INFO:Declaring metric variables
2024-11-14 15:37:48,306:INFO:Importing untrained model
2024-11-14 15:37:48,309:INFO:CatBoost Regressor Imported successfully
2024-11-14 15:37:48,316:INFO:Starting cross validation
2024-11-14 15:37:48,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:38:05,368:INFO:Calculating mean and std
2024-11-14 15:38:05,373:INFO:Creating metrics dataframe
2024-11-14 15:38:05,381:INFO:Uploading results into container
2024-11-14 15:38:05,381:INFO:Uploading model into container now
2024-11-14 15:38:05,382:INFO:_master_model_container: 19
2024-11-14 15:38:05,382:INFO:_display_container: 2
2024-11-14 15:38:05,382:INFO:<catboost.core.CatBoostRegressor object at 0x7fbfb4f9dca0>
2024-11-14 15:38:05,382:INFO:create_model() successfully completed......................................
2024-11-14 15:38:05,575:INFO:SubProcess create_model() end ==================================
2024-11-14 15:38:05,575:INFO:Creating metrics dataframe
2024-11-14 15:38:05,589:INFO:Initializing Dummy Regressor
2024-11-14 15:38:05,590:INFO:Total runtime is 7.863571472962698 minutes
2024-11-14 15:38:05,593:INFO:SubProcess create_model() called ==================================
2024-11-14 15:38:05,593:INFO:Initializing create_model()
2024-11-14 15:38:05,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc1a7aba970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:38:05,594:INFO:Checking exceptions
2024-11-14 15:38:05,594:INFO:Importing libraries
2024-11-14 15:38:05,594:INFO:Copying training dataset
2024-11-14 15:38:05,601:INFO:Defining folds
2024-11-14 15:38:05,601:INFO:Declaring metric variables
2024-11-14 15:38:05,604:INFO:Importing untrained model
2024-11-14 15:38:05,608:INFO:Dummy Regressor Imported successfully
2024-11-14 15:38:05,614:INFO:Starting cross validation
2024-11-14 15:38:05,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:38:08,662:INFO:Calculating mean and std
2024-11-14 15:38:08,666:INFO:Creating metrics dataframe
2024-11-14 15:38:08,673:INFO:Uploading results into container
2024-11-14 15:38:08,674:INFO:Uploading model into container now
2024-11-14 15:38:08,674:INFO:_master_model_container: 20
2024-11-14 15:38:08,675:INFO:_display_container: 2
2024-11-14 15:38:08,675:INFO:DummyRegressor()
2024-11-14 15:38:08,675:INFO:create_model() successfully completed......................................
2024-11-14 15:38:08,886:INFO:SubProcess create_model() end ==================================
2024-11-14 15:38:08,886:INFO:Creating metrics dataframe
2024-11-14 15:38:08,909:INFO:Initializing create_model()
2024-11-14 15:38:08,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:38:08,909:INFO:Checking exceptions
2024-11-14 15:38:08,911:INFO:Importing libraries
2024-11-14 15:38:08,911:INFO:Copying training dataset
2024-11-14 15:38:08,918:INFO:Defining folds
2024-11-14 15:38:08,918:INFO:Declaring metric variables
2024-11-14 15:38:08,918:INFO:Importing untrained model
2024-11-14 15:38:08,918:INFO:Declaring custom model
2024-11-14 15:38:08,919:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:38:08,919:INFO:Cross validation set to False
2024-11-14 15:38:08,919:INFO:Fitting Model
2024-11-14 15:38:09,185:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:38:09,186:INFO:create_model() successfully completed......................................
2024-11-14 15:38:09,416:INFO:_master_model_container: 20
2024-11-14 15:38:09,416:INFO:_display_container: 2
2024-11-14 15:38:09,416:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:38:09,416:INFO:compare_models() successfully completed......................................
2024-11-14 15:38:59,221:INFO:Initializing plot_model()
2024-11-14 15:38:59,221:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, system=True)
2024-11-14 15:38:59,222:INFO:Checking exceptions
2024-11-14 15:38:59,281:INFO:Preloading libraries
2024-11-14 15:38:59,392:INFO:Copying training dataset
2024-11-14 15:38:59,393:INFO:Plot type: residuals
2024-11-14 15:38:59,527:INFO:Fitting Model
2024-11-14 15:38:59,527:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-14 15:38:59,692:INFO:Scoring test/hold-out set
2024-11-14 15:39:00,725:INFO:Visual Rendered Successfully
2024-11-14 15:39:00,962:INFO:plot_model() successfully completed......................................
2024-11-14 15:40:14,374:INFO:Initializing create_model()
2024-11-14 15:40:14,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:40:14,375:INFO:Checking exceptions
2024-11-14 15:40:14,410:INFO:Importing libraries
2024-11-14 15:40:14,410:INFO:Copying training dataset
2024-11-14 15:40:14,418:INFO:Defining folds
2024-11-14 15:40:14,418:INFO:Declaring metric variables
2024-11-14 15:40:14,422:INFO:Importing untrained model
2024-11-14 15:40:14,426:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 15:40:14,434:INFO:Starting cross validation
2024-11-14 15:40:14,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:42:14,652:INFO:Initializing create_model()
2024-11-14 15:42:14,652:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:42:14,652:INFO:Checking exceptions
2024-11-14 15:42:14,692:INFO:Importing libraries
2024-11-14 15:42:14,693:INFO:Copying training dataset
2024-11-14 15:42:14,702:INFO:Defining folds
2024-11-14 15:42:14,702:INFO:Declaring metric variables
2024-11-14 15:42:14,706:INFO:Importing untrained model
2024-11-14 15:42:14,711:INFO:Random Forest Regressor Imported successfully
2024-11-14 15:42:14,719:INFO:Starting cross validation
2024-11-14 15:42:14,720:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:42:21,158:INFO:Calculating mean and std
2024-11-14 15:42:21,162:INFO:Creating metrics dataframe
2024-11-14 15:42:21,172:INFO:Finalizing model
2024-11-14 15:42:21,611:INFO:Uploading results into container
2024-11-14 15:42:21,612:INFO:Uploading model into container now
2024-11-14 15:42:21,623:INFO:_master_model_container: 21
2024-11-14 15:42:21,624:INFO:_display_container: 3
2024-11-14 15:42:21,624:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:42:21,624:INFO:create_model() successfully completed......................................
2024-11-14 15:46:25,031:INFO:Initializing create_model()
2024-11-14 15:46:25,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08fbb8520>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:46:25,032:INFO:Checking exceptions
2024-11-14 15:46:25,065:INFO:Importing libraries
2024-11-14 15:46:25,065:INFO:Copying training dataset
2024-11-14 15:46:25,075:INFO:Defining folds
2024-11-14 15:46:25,075:INFO:Declaring metric variables
2024-11-14 15:46:25,079:INFO:Importing untrained model
2024-11-14 15:46:25,083:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:46:25,090:INFO:Starting cross validation
2024-11-14 15:46:25,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:46:28,713:INFO:Calculating mean and std
2024-11-14 15:46:28,720:INFO:Creating metrics dataframe
2024-11-14 15:46:28,728:INFO:Finalizing model
2024-11-14 15:46:28,973:INFO:Uploading results into container
2024-11-14 15:46:28,974:INFO:Uploading model into container now
2024-11-14 15:46:28,983:INFO:_master_model_container: 22
2024-11-14 15:46:28,983:INFO:_display_container: 4
2024-11-14 15:46:28,984:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:46:28,984:INFO:create_model() successfully completed......................................
2024-11-14 15:49:32,690:INFO:PyCaret RegressionExperiment
2024-11-14 15:49:32,690:INFO:Logging name: reg-default-name
2024-11-14 15:49:32,690:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-14 15:49:32,690:INFO:version 3.2.0
2024-11-14 15:49:32,690:INFO:Initializing setup()
2024-11-14 15:49:32,690:INFO:self.USI: 786d
2024-11-14 15:49:32,690:INFO:self._variable_keys: {'seed', 'fold_generator', 'y_test', 'n_jobs_param', 'memory', 'fold_groups_param', 'y_train', 'target_param', 'exp_name_log', 'USI', 'fold_shuffle_param', 'y', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'pipeline', 'html_param', 'logging_param', '_ml_usecase', 'exp_id', 'X_test', 'gpu_param', 'X', 'data', 'idx', 'X_train', '_available_plots'}
2024-11-14 15:49:32,690:INFO:Checking environment
2024-11-14 15:49:32,690:INFO:python_version: 3.8.13
2024-11-14 15:49:32,690:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-14 15:49:32,690:INFO:machine: x86_64
2024-11-14 15:49:32,690:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 15:49:32,691:INFO:Memory: svmem(total=270355722240, available=178654666752, percent=33.9, used=89610891264, free=51502927872, active=66847014912, inactive=99583062016, buffers=10100736, cached=129231802368, shared=195973120, slab=20029546496)
2024-11-14 15:49:32,693:INFO:Physical Core: 28
2024-11-14 15:49:32,693:INFO:Logical Core: 56
2024-11-14 15:49:32,693:INFO:Checking libraries
2024-11-14 15:49:32,693:INFO:System:
2024-11-14 15:49:32,693:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-14 15:49:32,693:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-14 15:49:32,693:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-14 15:49:32,693:INFO:PyCaret required dependencies:
2024-11-14 15:49:32,693:INFO:                 pip: 22.2.2
2024-11-14 15:49:32,693:INFO:          setuptools: 63.4.2
2024-11-14 15:49:32,693:INFO:             pycaret: 3.2.0
2024-11-14 15:49:32,693:INFO:             IPython: 8.12.2
2024-11-14 15:49:32,693:INFO:          ipywidgets: 7.7.1
2024-11-14 15:49:32,693:INFO:                tqdm: 4.64.1
2024-11-14 15:49:32,693:INFO:               numpy: 1.23.5
2024-11-14 15:49:32,693:INFO:              pandas: 1.5.3
2024-11-14 15:49:32,693:INFO:              jinja2: 3.1.2
2024-11-14 15:49:32,693:INFO:               scipy: 1.10.1
2024-11-14 15:49:32,693:INFO:              joblib: 1.3.0
2024-11-14 15:49:32,694:INFO:             sklearn: 1.1.2
2024-11-14 15:49:32,694:INFO:                pyod: 2.0.2
2024-11-14 15:49:32,694:INFO:            imblearn: 0.12.4
2024-11-14 15:49:32,694:INFO:   category_encoders: 2.6.4
2024-11-14 15:49:32,694:INFO:            lightgbm: 4.5.0
2024-11-14 15:49:32,694:INFO:               numba: 0.57.1
2024-11-14 15:49:32,694:INFO:            requests: 2.28.1
2024-11-14 15:49:32,694:INFO:          matplotlib: 3.5.1
2024-11-14 15:49:32,694:INFO:          scikitplot: 0.3.7
2024-11-14 15:49:32,694:INFO:         yellowbrick: 1.5
2024-11-14 15:49:32,694:INFO:              plotly: 5.24.1
2024-11-14 15:49:32,694:INFO:    plotly-resampler: Not installed
2024-11-14 15:49:32,694:INFO:             kaleido: 0.2.1
2024-11-14 15:49:32,694:INFO:           schemdraw: 0.15
2024-11-14 15:49:32,694:INFO:         statsmodels: 0.13.2
2024-11-14 15:49:32,694:INFO:              sktime: 0.21.1
2024-11-14 15:49:32,694:INFO:               tbats: 1.1.3
2024-11-14 15:49:32,694:INFO:            pmdarima: 2.0.4
2024-11-14 15:49:32,694:INFO:              psutil: 5.9.1
2024-11-14 15:49:32,694:INFO:          markupsafe: 2.1.1
2024-11-14 15:49:32,694:INFO:             pickle5: Not installed
2024-11-14 15:49:32,694:INFO:         cloudpickle: 2.1.0
2024-11-14 15:49:32,694:INFO:         deprecation: 2.1.0
2024-11-14 15:49:32,694:INFO:              xxhash: 3.5.0
2024-11-14 15:49:32,694:INFO:           wurlitzer: 3.1.1
2024-11-14 15:49:32,694:INFO:PyCaret optional dependencies:
2024-11-14 15:49:32,694:INFO:                shap: 0.44.1
2024-11-14 15:49:32,694:INFO:           interpret: 0.6.5
2024-11-14 15:49:32,695:INFO:                umap: 0.5.7
2024-11-14 15:49:32,695:INFO:     ydata_profiling: 4.6.0
2024-11-14 15:49:32,695:INFO:  explainerdashboard: 0.4.7
2024-11-14 15:49:32,695:INFO:             autoviz: Not installed
2024-11-14 15:49:32,695:INFO:           fairlearn: 0.7.0
2024-11-14 15:49:32,695:INFO:          deepchecks: Not installed
2024-11-14 15:49:32,695:INFO:             xgboost: 2.1.1
2024-11-14 15:49:32,695:INFO:            catboost: 1.2.7
2024-11-14 15:49:32,695:INFO:              kmodes: 0.12.2
2024-11-14 15:49:32,695:INFO:             mlxtend: 0.23.1
2024-11-14 15:49:32,695:INFO:       statsforecast: 1.5.0
2024-11-14 15:49:32,695:INFO:        tune_sklearn: 0.5.0
2024-11-14 15:49:32,695:INFO:                 ray: 2.10.0
2024-11-14 15:49:32,695:INFO:            hyperopt: 0.2.7
2024-11-14 15:49:32,695:INFO:              optuna: 4.1.0
2024-11-14 15:49:32,695:INFO:               skopt: 0.10.2
2024-11-14 15:49:32,695:INFO:              mlflow: 1.30.1
2024-11-14 15:49:32,695:INFO:              gradio: 3.50.2
2024-11-14 15:49:32,695:INFO:             fastapi: 0.115.5
2024-11-14 15:49:32,695:INFO:             uvicorn: 0.32.0
2024-11-14 15:49:32,695:INFO:              m2cgen: 0.10.0
2024-11-14 15:49:32,695:INFO:           evidently: 0.2.8
2024-11-14 15:49:32,695:INFO:               fugue: 0.8.6
2024-11-14 15:49:32,695:INFO:           streamlit: Not installed
2024-11-14 15:49:32,695:INFO:             prophet: Not installed
2024-11-14 15:49:32,695:INFO:None
2024-11-14 15:49:32,695:INFO:Set up data.
2024-11-14 15:49:32,706:INFO:Set up folding strategy.
2024-11-14 15:49:32,706:INFO:Set up train/test split.
2024-11-14 15:49:32,712:INFO:Set up index.
2024-11-14 15:49:32,713:INFO:Assigning column types.
2024-11-14 15:49:32,718:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-14 15:49:32,718:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,723:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,728:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,828:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,828:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:32,831:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:32,832:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,836:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,840:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,889:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,928:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:32,931:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:32,931:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-14 15:49:32,935:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,939:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:49:32,989:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,026:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:33,029:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:33,033:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,037:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,086:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,124:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,124:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:33,127:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:33,127:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-14 15:49:33,136:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,186:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,224:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:33,227:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:33,235:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,323:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:33,325:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:33,326:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-14 15:49:33,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,420:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:33,423:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:33,480:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,521:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,522:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:33,524:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:33,525:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-14 15:49:33,585:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,622:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:33,625:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:33,683:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-14 15:49:33,722:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:33,724:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:33,725:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-14 15:49:33,823:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:33,826:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:33,922:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:33,925:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:33,926:INFO:Preparing preprocessing pipeline...
2024-11-14 15:49:33,926:INFO:Set up simple imputation.
2024-11-14 15:49:33,946:INFO:Finished creating preprocessing pipeline.
2024-11-14 15:49:33,949:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-14 15:49:33,949:INFO:Creating final display dataframe.
2024-11-14 15:49:34,003:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 7)
4        Transformed data shape        (31316, 7)
5   Transformed train set shape        (21921, 7)
6    Transformed test set shape         (9395, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              786d
2024-11-14 15:49:34,104:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:34,107:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:34,202:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-14 15:49:34,204:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-14 15:49:34,205:INFO:setup() successfully completed in 1.52s...............
2024-11-14 15:49:34,205:INFO:Initializing compare_models()
2024-11-14 15:49:34,205:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-14 15:49:34,205:INFO:Checking exceptions
2024-11-14 15:49:34,207:INFO:Preparing display monitor
2024-11-14 15:49:34,242:INFO:Initializing Linear Regression
2024-11-14 15:49:34,242:INFO:Total runtime is 2.9047330220540365e-06 minutes
2024-11-14 15:49:34,245:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:34,245:INFO:Initializing create_model()
2024-11-14 15:49:34,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:34,246:INFO:Checking exceptions
2024-11-14 15:49:34,246:INFO:Importing libraries
2024-11-14 15:49:34,246:INFO:Copying training dataset
2024-11-14 15:49:34,253:INFO:Defining folds
2024-11-14 15:49:34,253:INFO:Declaring metric variables
2024-11-14 15:49:34,256:INFO:Importing untrained model
2024-11-14 15:49:34,259:INFO:Linear Regression Imported successfully
2024-11-14 15:49:34,266:INFO:Starting cross validation
2024-11-14 15:49:34,266:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:36,219:INFO:Calculating mean and std
2024-11-14 15:49:36,223:INFO:Creating metrics dataframe
2024-11-14 15:49:36,230:INFO:Uploading results into container
2024-11-14 15:49:36,231:INFO:Uploading model into container now
2024-11-14 15:49:36,232:INFO:_master_model_container: 1
2024-11-14 15:49:36,232:INFO:_display_container: 2
2024-11-14 15:49:36,232:INFO:LinearRegression(n_jobs=-1)
2024-11-14 15:49:36,232:INFO:create_model() successfully completed......................................
2024-11-14 15:49:36,461:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:36,461:INFO:Creating metrics dataframe
2024-11-14 15:49:36,470:INFO:Initializing Lasso Regression
2024-11-14 15:49:36,470:INFO:Total runtime is 0.03714413245519002 minutes
2024-11-14 15:49:36,474:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:36,474:INFO:Initializing create_model()
2024-11-14 15:49:36,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:36,474:INFO:Checking exceptions
2024-11-14 15:49:36,474:INFO:Importing libraries
2024-11-14 15:49:36,474:INFO:Copying training dataset
2024-11-14 15:49:36,481:INFO:Defining folds
2024-11-14 15:49:36,482:INFO:Declaring metric variables
2024-11-14 15:49:36,485:INFO:Importing untrained model
2024-11-14 15:49:36,488:INFO:Lasso Regression Imported successfully
2024-11-14 15:49:36,494:INFO:Starting cross validation
2024-11-14 15:49:36,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:39,329:INFO:Calculating mean and std
2024-11-14 15:49:39,333:INFO:Creating metrics dataframe
2024-11-14 15:49:39,339:INFO:Uploading results into container
2024-11-14 15:49:39,340:INFO:Uploading model into container now
2024-11-14 15:49:39,341:INFO:_master_model_container: 2
2024-11-14 15:49:39,341:INFO:_display_container: 2
2024-11-14 15:49:39,341:INFO:Lasso(random_state=42)
2024-11-14 15:49:39,341:INFO:create_model() successfully completed......................................
2024-11-14 15:49:39,533:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:39,533:INFO:Creating metrics dataframe
2024-11-14 15:49:39,543:INFO:Initializing Ridge Regression
2024-11-14 15:49:39,543:INFO:Total runtime is 0.08836093346277873 minutes
2024-11-14 15:49:39,547:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:39,547:INFO:Initializing create_model()
2024-11-14 15:49:39,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:39,547:INFO:Checking exceptions
2024-11-14 15:49:39,548:INFO:Importing libraries
2024-11-14 15:49:39,548:INFO:Copying training dataset
2024-11-14 15:49:39,554:INFO:Defining folds
2024-11-14 15:49:39,554:INFO:Declaring metric variables
2024-11-14 15:49:39,558:INFO:Importing untrained model
2024-11-14 15:49:39,561:INFO:Ridge Regression Imported successfully
2024-11-14 15:49:39,568:INFO:Starting cross validation
2024-11-14 15:49:39,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:42,332:INFO:Calculating mean and std
2024-11-14 15:49:42,336:INFO:Creating metrics dataframe
2024-11-14 15:49:42,343:INFO:Uploading results into container
2024-11-14 15:49:42,344:INFO:Uploading model into container now
2024-11-14 15:49:42,344:INFO:_master_model_container: 3
2024-11-14 15:49:42,344:INFO:_display_container: 2
2024-11-14 15:49:42,345:INFO:Ridge(random_state=42)
2024-11-14 15:49:42,345:INFO:create_model() successfully completed......................................
2024-11-14 15:49:42,542:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:42,542:INFO:Creating metrics dataframe
2024-11-14 15:49:42,552:INFO:Initializing Elastic Net
2024-11-14 15:49:42,552:INFO:Total runtime is 0.13850005467732748 minutes
2024-11-14 15:49:42,555:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:42,555:INFO:Initializing create_model()
2024-11-14 15:49:42,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:42,556:INFO:Checking exceptions
2024-11-14 15:49:42,556:INFO:Importing libraries
2024-11-14 15:49:42,556:INFO:Copying training dataset
2024-11-14 15:49:42,563:INFO:Defining folds
2024-11-14 15:49:42,563:INFO:Declaring metric variables
2024-11-14 15:49:42,567:INFO:Importing untrained model
2024-11-14 15:49:42,570:INFO:Elastic Net Imported successfully
2024-11-14 15:49:42,576:INFO:Starting cross validation
2024-11-14 15:49:42,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:45,391:INFO:Calculating mean and std
2024-11-14 15:49:45,395:INFO:Creating metrics dataframe
2024-11-14 15:49:45,401:INFO:Uploading results into container
2024-11-14 15:49:45,401:INFO:Uploading model into container now
2024-11-14 15:49:45,405:INFO:_master_model_container: 4
2024-11-14 15:49:45,406:INFO:_display_container: 2
2024-11-14 15:49:45,406:INFO:ElasticNet(random_state=42)
2024-11-14 15:49:45,406:INFO:create_model() successfully completed......................................
2024-11-14 15:49:45,607:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:45,607:INFO:Creating metrics dataframe
2024-11-14 15:49:45,617:INFO:Initializing Least Angle Regression
2024-11-14 15:49:45,618:INFO:Total runtime is 0.18959758679072064 minutes
2024-11-14 15:49:45,621:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:45,621:INFO:Initializing create_model()
2024-11-14 15:49:45,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:45,621:INFO:Checking exceptions
2024-11-14 15:49:45,621:INFO:Importing libraries
2024-11-14 15:49:45,621:INFO:Copying training dataset
2024-11-14 15:49:45,628:INFO:Defining folds
2024-11-14 15:49:45,628:INFO:Declaring metric variables
2024-11-14 15:49:45,632:INFO:Importing untrained model
2024-11-14 15:49:45,635:INFO:Least Angle Regression Imported successfully
2024-11-14 15:49:45,648:INFO:Starting cross validation
2024-11-14 15:49:45,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:48,276:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:48,382:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:48,385:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.258e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:49:48,385:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.129e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:49:48,386:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.305e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:49:48,386:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.266e-05, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:49:48,386:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.730e-06, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:49:48,386:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.732e-06, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:49:48,412:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:48,416:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:48,439:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:48,443:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:48,454:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:48,472:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:48,475:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.725e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:49:48,476:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.336e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:49:48,476:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.741e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:49:48,476:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=5.063e-06, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-14 15:49:48,486:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:48,491:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:48,509:INFO:Calculating mean and std
2024-11-14 15:49:48,513:INFO:Creating metrics dataframe
2024-11-14 15:49:48,521:INFO:Uploading results into container
2024-11-14 15:49:48,522:INFO:Uploading model into container now
2024-11-14 15:49:48,523:INFO:_master_model_container: 5
2024-11-14 15:49:48,523:INFO:_display_container: 2
2024-11-14 15:49:48,524:INFO:Lars(random_state=42)
2024-11-14 15:49:48,524:INFO:create_model() successfully completed......................................
2024-11-14 15:49:48,748:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:48,748:INFO:Creating metrics dataframe
2024-11-14 15:49:48,759:INFO:Initializing Lasso Least Angle Regression
2024-11-14 15:49:48,759:INFO:Total runtime is 0.24195832411448162 minutes
2024-11-14 15:49:48,763:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:48,763:INFO:Initializing create_model()
2024-11-14 15:49:48,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:48,763:INFO:Checking exceptions
2024-11-14 15:49:48,763:INFO:Importing libraries
2024-11-14 15:49:48,763:INFO:Copying training dataset
2024-11-14 15:49:48,771:INFO:Defining folds
2024-11-14 15:49:48,771:INFO:Declaring metric variables
2024-11-14 15:49:48,775:INFO:Importing untrained model
2024-11-14 15:49:48,778:INFO:Lasso Least Angle Regression Imported successfully
2024-11-14 15:49:48,785:INFO:Starting cross validation
2024-11-14 15:49:48,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:48,835:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:49:48,839:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:49:48,848:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:49:48,863:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:49:48,870:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:49:48,876:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:49:48,886:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:49:51,315:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:49:51,318:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:49:51,468:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-14 15:49:51,486:INFO:Calculating mean and std
2024-11-14 15:49:51,490:INFO:Creating metrics dataframe
2024-11-14 15:49:51,496:INFO:Uploading results into container
2024-11-14 15:49:51,497:INFO:Uploading model into container now
2024-11-14 15:49:51,497:INFO:_master_model_container: 6
2024-11-14 15:49:51,497:INFO:_display_container: 2
2024-11-14 15:49:51,498:INFO:LassoLars(random_state=42)
2024-11-14 15:49:51,498:INFO:create_model() successfully completed......................................
2024-11-14 15:49:51,697:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:51,698:INFO:Creating metrics dataframe
2024-11-14 15:49:51,709:INFO:Initializing Orthogonal Matching Pursuit
2024-11-14 15:49:51,709:INFO:Total runtime is 0.2911175966262817 minutes
2024-11-14 15:49:51,712:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:51,712:INFO:Initializing create_model()
2024-11-14 15:49:51,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:51,713:INFO:Checking exceptions
2024-11-14 15:49:51,713:INFO:Importing libraries
2024-11-14 15:49:51,713:INFO:Copying training dataset
2024-11-14 15:49:51,720:INFO:Defining folds
2024-11-14 15:49:51,720:INFO:Declaring metric variables
2024-11-14 15:49:51,723:INFO:Importing untrained model
2024-11-14 15:49:51,726:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-14 15:49:51,733:INFO:Starting cross validation
2024-11-14 15:49:51,734:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:51,768:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:51,776:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:51,821:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:51,825:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:51,831:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:54,221:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:54,229:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:54,248:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:54,319:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:54,424:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-14 15:49:54,444:INFO:Calculating mean and std
2024-11-14 15:49:54,448:INFO:Creating metrics dataframe
2024-11-14 15:49:54,455:INFO:Uploading results into container
2024-11-14 15:49:54,456:INFO:Uploading model into container now
2024-11-14 15:49:54,456:INFO:_master_model_container: 7
2024-11-14 15:49:54,457:INFO:_display_container: 2
2024-11-14 15:49:54,457:INFO:OrthogonalMatchingPursuit()
2024-11-14 15:49:54,457:INFO:create_model() successfully completed......................................
2024-11-14 15:49:54,638:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:54,638:INFO:Creating metrics dataframe
2024-11-14 15:49:54,649:INFO:Initializing Bayesian Ridge
2024-11-14 15:49:54,649:INFO:Total runtime is 0.3401275078455607 minutes
2024-11-14 15:49:54,652:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:54,653:INFO:Initializing create_model()
2024-11-14 15:49:54,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:54,653:INFO:Checking exceptions
2024-11-14 15:49:54,653:INFO:Importing libraries
2024-11-14 15:49:54,653:INFO:Copying training dataset
2024-11-14 15:49:54,660:INFO:Defining folds
2024-11-14 15:49:54,660:INFO:Declaring metric variables
2024-11-14 15:49:54,663:INFO:Importing untrained model
2024-11-14 15:49:54,667:INFO:Bayesian Ridge Imported successfully
2024-11-14 15:49:54,674:INFO:Starting cross validation
2024-11-14 15:49:54,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:54,790:INFO:Calculating mean and std
2024-11-14 15:49:54,793:INFO:Creating metrics dataframe
2024-11-14 15:49:54,799:INFO:Uploading results into container
2024-11-14 15:49:54,800:INFO:Uploading model into container now
2024-11-14 15:49:54,800:INFO:_master_model_container: 8
2024-11-14 15:49:54,801:INFO:_display_container: 2
2024-11-14 15:49:54,801:INFO:BayesianRidge()
2024-11-14 15:49:54,801:INFO:create_model() successfully completed......................................
2024-11-14 15:49:54,986:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:54,986:INFO:Creating metrics dataframe
2024-11-14 15:49:54,997:INFO:Initializing Passive Aggressive Regressor
2024-11-14 15:49:54,998:INFO:Total runtime is 0.3459322611490885 minutes
2024-11-14 15:49:55,001:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:55,001:INFO:Initializing create_model()
2024-11-14 15:49:55,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:55,001:INFO:Checking exceptions
2024-11-14 15:49:55,002:INFO:Importing libraries
2024-11-14 15:49:55,002:INFO:Copying training dataset
2024-11-14 15:49:55,009:INFO:Defining folds
2024-11-14 15:49:55,009:INFO:Declaring metric variables
2024-11-14 15:49:55,012:INFO:Importing untrained model
2024-11-14 15:49:55,015:INFO:Passive Aggressive Regressor Imported successfully
2024-11-14 15:49:55,022:INFO:Starting cross validation
2024-11-14 15:49:55,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:55,150:INFO:Calculating mean and std
2024-11-14 15:49:55,154:INFO:Creating metrics dataframe
2024-11-14 15:49:55,160:INFO:Uploading results into container
2024-11-14 15:49:55,160:INFO:Uploading model into container now
2024-11-14 15:49:55,161:INFO:_master_model_container: 9
2024-11-14 15:49:55,161:INFO:_display_container: 2
2024-11-14 15:49:55,161:INFO:PassiveAggressiveRegressor(random_state=42)
2024-11-14 15:49:55,161:INFO:create_model() successfully completed......................................
2024-11-14 15:49:55,325:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:55,326:INFO:Creating metrics dataframe
2024-11-14 15:49:55,337:INFO:Initializing Huber Regressor
2024-11-14 15:49:55,337:INFO:Total runtime is 0.3515960574150085 minutes
2024-11-14 15:49:55,341:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:55,341:INFO:Initializing create_model()
2024-11-14 15:49:55,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:55,341:INFO:Checking exceptions
2024-11-14 15:49:55,341:INFO:Importing libraries
2024-11-14 15:49:55,341:INFO:Copying training dataset
2024-11-14 15:49:55,348:INFO:Defining folds
2024-11-14 15:49:55,348:INFO:Declaring metric variables
2024-11-14 15:49:55,352:INFO:Importing untrained model
2024-11-14 15:49:55,355:INFO:Huber Regressor Imported successfully
2024-11-14 15:49:55,362:INFO:Starting cross validation
2024-11-14 15:49:55,362:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:55,657:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:49:55,661:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:49:55,663:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:49:55,674:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:49:55,681:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:49:55,811:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:49:55,824:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-14 15:49:55,839:INFO:Calculating mean and std
2024-11-14 15:49:55,843:INFO:Creating metrics dataframe
2024-11-14 15:49:55,848:INFO:Uploading results into container
2024-11-14 15:49:55,849:INFO:Uploading model into container now
2024-11-14 15:49:55,850:INFO:_master_model_container: 10
2024-11-14 15:49:55,850:INFO:_display_container: 2
2024-11-14 15:49:55,850:INFO:HuberRegressor()
2024-11-14 15:49:55,850:INFO:create_model() successfully completed......................................
2024-11-14 15:49:56,019:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:56,019:INFO:Creating metrics dataframe
2024-11-14 15:49:56,030:INFO:Initializing K Neighbors Regressor
2024-11-14 15:49:56,031:INFO:Total runtime is 0.36314808130264276 minutes
2024-11-14 15:49:56,034:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:56,034:INFO:Initializing create_model()
2024-11-14 15:49:56,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:56,034:INFO:Checking exceptions
2024-11-14 15:49:56,034:INFO:Importing libraries
2024-11-14 15:49:56,035:INFO:Copying training dataset
2024-11-14 15:49:56,041:INFO:Defining folds
2024-11-14 15:49:56,041:INFO:Declaring metric variables
2024-11-14 15:49:56,045:INFO:Importing untrained model
2024-11-14 15:49:56,048:INFO:K Neighbors Regressor Imported successfully
2024-11-14 15:49:56,054:INFO:Starting cross validation
2024-11-14 15:49:56,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:56,264:INFO:Calculating mean and std
2024-11-14 15:49:56,268:INFO:Creating metrics dataframe
2024-11-14 15:49:56,275:INFO:Uploading results into container
2024-11-14 15:49:56,275:INFO:Uploading model into container now
2024-11-14 15:49:56,276:INFO:_master_model_container: 11
2024-11-14 15:49:56,276:INFO:_display_container: 2
2024-11-14 15:49:56,276:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-14 15:49:56,276:INFO:create_model() successfully completed......................................
2024-11-14 15:49:56,470:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:56,471:INFO:Creating metrics dataframe
2024-11-14 15:49:56,483:INFO:Initializing Decision Tree Regressor
2024-11-14 15:49:56,483:INFO:Total runtime is 0.37068759202957147 minutes
2024-11-14 15:49:56,486:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:56,487:INFO:Initializing create_model()
2024-11-14 15:49:56,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:56,487:INFO:Checking exceptions
2024-11-14 15:49:56,487:INFO:Importing libraries
2024-11-14 15:49:56,487:INFO:Copying training dataset
2024-11-14 15:49:56,494:INFO:Defining folds
2024-11-14 15:49:56,494:INFO:Declaring metric variables
2024-11-14 15:49:56,497:INFO:Importing untrained model
2024-11-14 15:49:56,500:INFO:Decision Tree Regressor Imported successfully
2024-11-14 15:49:56,507:INFO:Starting cross validation
2024-11-14 15:49:56,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:56,669:INFO:Calculating mean and std
2024-11-14 15:49:56,673:INFO:Creating metrics dataframe
2024-11-14 15:49:56,679:INFO:Uploading results into container
2024-11-14 15:49:56,680:INFO:Uploading model into container now
2024-11-14 15:49:56,680:INFO:_master_model_container: 12
2024-11-14 15:49:56,681:INFO:_display_container: 2
2024-11-14 15:49:56,681:INFO:DecisionTreeRegressor(random_state=42)
2024-11-14 15:49:56,681:INFO:create_model() successfully completed......................................
2024-11-14 15:49:56,876:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:56,876:INFO:Creating metrics dataframe
2024-11-14 15:49:56,887:INFO:Initializing Random Forest Regressor
2024-11-14 15:49:56,887:INFO:Total runtime is 0.37742740710576367 minutes
2024-11-14 15:49:56,891:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:56,891:INFO:Initializing create_model()
2024-11-14 15:49:56,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:56,891:INFO:Checking exceptions
2024-11-14 15:49:56,892:INFO:Importing libraries
2024-11-14 15:49:56,892:INFO:Copying training dataset
2024-11-14 15:49:56,898:INFO:Defining folds
2024-11-14 15:49:56,898:INFO:Declaring metric variables
2024-11-14 15:49:56,905:INFO:Importing untrained model
2024-11-14 15:49:56,910:INFO:Random Forest Regressor Imported successfully
2024-11-14 15:49:56,917:INFO:Starting cross validation
2024-11-14 15:49:56,917:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:58,498:INFO:Calculating mean and std
2024-11-14 15:49:58,505:INFO:Creating metrics dataframe
2024-11-14 15:49:58,514:INFO:Uploading results into container
2024-11-14 15:49:58,515:INFO:Uploading model into container now
2024-11-14 15:49:58,516:INFO:_master_model_container: 13
2024-11-14 15:49:58,516:INFO:_display_container: 2
2024-11-14 15:49:58,516:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:49:58,517:INFO:create_model() successfully completed......................................
2024-11-14 15:49:58,694:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:58,694:INFO:Creating metrics dataframe
2024-11-14 15:49:58,707:INFO:Initializing Extra Trees Regressor
2024-11-14 15:49:58,707:INFO:Total runtime is 0.4077502171198526 minutes
2024-11-14 15:49:58,710:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:58,710:INFO:Initializing create_model()
2024-11-14 15:49:58,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:58,711:INFO:Checking exceptions
2024-11-14 15:49:58,711:INFO:Importing libraries
2024-11-14 15:49:58,711:INFO:Copying training dataset
2024-11-14 15:49:58,718:INFO:Defining folds
2024-11-14 15:49:58,718:INFO:Declaring metric variables
2024-11-14 15:49:58,721:INFO:Importing untrained model
2024-11-14 15:49:58,725:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:49:58,733:INFO:Starting cross validation
2024-11-14 15:49:58,734:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:49:59,668:INFO:Calculating mean and std
2024-11-14 15:49:59,672:INFO:Creating metrics dataframe
2024-11-14 15:49:59,679:INFO:Uploading results into container
2024-11-14 15:49:59,680:INFO:Uploading model into container now
2024-11-14 15:49:59,680:INFO:_master_model_container: 14
2024-11-14 15:49:59,680:INFO:_display_container: 2
2024-11-14 15:49:59,681:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:49:59,681:INFO:create_model() successfully completed......................................
2024-11-14 15:49:59,853:INFO:SubProcess create_model() end ==================================
2024-11-14 15:49:59,854:INFO:Creating metrics dataframe
2024-11-14 15:49:59,867:INFO:Initializing AdaBoost Regressor
2024-11-14 15:49:59,867:INFO:Total runtime is 0.4270840485890705 minutes
2024-11-14 15:49:59,870:INFO:SubProcess create_model() called ==================================
2024-11-14 15:49:59,871:INFO:Initializing create_model()
2024-11-14 15:49:59,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:49:59,871:INFO:Checking exceptions
2024-11-14 15:49:59,871:INFO:Importing libraries
2024-11-14 15:49:59,871:INFO:Copying training dataset
2024-11-14 15:49:59,879:INFO:Defining folds
2024-11-14 15:49:59,879:INFO:Declaring metric variables
2024-11-14 15:49:59,882:INFO:Importing untrained model
2024-11-14 15:49:59,886:INFO:AdaBoost Regressor Imported successfully
2024-11-14 15:49:59,892:INFO:Starting cross validation
2024-11-14 15:49:59,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:50:00,736:INFO:Calculating mean and std
2024-11-14 15:50:00,740:INFO:Creating metrics dataframe
2024-11-14 15:50:00,745:INFO:Uploading results into container
2024-11-14 15:50:00,746:INFO:Uploading model into container now
2024-11-14 15:50:00,747:INFO:_master_model_container: 15
2024-11-14 15:50:00,747:INFO:_display_container: 2
2024-11-14 15:50:00,747:INFO:AdaBoostRegressor(random_state=42)
2024-11-14 15:50:00,747:INFO:create_model() successfully completed......................................
2024-11-14 15:50:00,935:INFO:SubProcess create_model() end ==================================
2024-11-14 15:50:00,935:INFO:Creating metrics dataframe
2024-11-14 15:50:00,948:INFO:Initializing Gradient Boosting Regressor
2024-11-14 15:50:00,948:INFO:Total runtime is 0.4451117157936095 minutes
2024-11-14 15:50:00,952:INFO:SubProcess create_model() called ==================================
2024-11-14 15:50:00,952:INFO:Initializing create_model()
2024-11-14 15:50:00,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:50:00,953:INFO:Checking exceptions
2024-11-14 15:50:00,953:INFO:Importing libraries
2024-11-14 15:50:00,953:INFO:Copying training dataset
2024-11-14 15:50:00,960:INFO:Defining folds
2024-11-14 15:50:00,960:INFO:Declaring metric variables
2024-11-14 15:50:00,963:INFO:Importing untrained model
2024-11-14 15:50:00,972:INFO:Gradient Boosting Regressor Imported successfully
2024-11-14 15:50:00,980:INFO:Starting cross validation
2024-11-14 15:50:00,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:50:02,685:INFO:Calculating mean and std
2024-11-14 15:50:02,689:INFO:Creating metrics dataframe
2024-11-14 15:50:02,695:INFO:Uploading results into container
2024-11-14 15:50:02,696:INFO:Uploading model into container now
2024-11-14 15:50:02,696:INFO:_master_model_container: 16
2024-11-14 15:50:02,696:INFO:_display_container: 2
2024-11-14 15:50:02,697:INFO:GradientBoostingRegressor(random_state=42)
2024-11-14 15:50:02,697:INFO:create_model() successfully completed......................................
2024-11-14 15:50:02,898:INFO:SubProcess create_model() end ==================================
2024-11-14 15:50:02,899:INFO:Creating metrics dataframe
2024-11-14 15:50:02,913:INFO:Initializing Extreme Gradient Boosting
2024-11-14 15:50:02,913:INFO:Total runtime is 0.47785426775614404 minutes
2024-11-14 15:50:02,916:INFO:SubProcess create_model() called ==================================
2024-11-14 15:50:02,917:INFO:Initializing create_model()
2024-11-14 15:50:02,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:50:02,917:INFO:Checking exceptions
2024-11-14 15:50:02,917:INFO:Importing libraries
2024-11-14 15:50:02,917:INFO:Copying training dataset
2024-11-14 15:50:02,925:INFO:Defining folds
2024-11-14 15:50:02,925:INFO:Declaring metric variables
2024-11-14 15:50:02,929:INFO:Importing untrained model
2024-11-14 15:50:02,932:INFO:Extreme Gradient Boosting Imported successfully
2024-11-14 15:50:02,939:INFO:Starting cross validation
2024-11-14 15:50:02,940:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:50:03,350:INFO:Calculating mean and std
2024-11-14 15:50:03,353:INFO:Creating metrics dataframe
2024-11-14 15:50:03,360:INFO:Uploading results into container
2024-11-14 15:50:03,360:INFO:Uploading model into container now
2024-11-14 15:50:03,361:INFO:_master_model_container: 17
2024-11-14 15:50:03,361:INFO:_display_container: 2
2024-11-14 15:50:03,362:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=42, ...)
2024-11-14 15:50:03,362:INFO:create_model() successfully completed......................................
2024-11-14 15:50:03,530:INFO:SubProcess create_model() end ==================================
2024-11-14 15:50:03,530:INFO:Creating metrics dataframe
2024-11-14 15:50:03,543:INFO:Initializing Light Gradient Boosting Machine
2024-11-14 15:50:03,543:INFO:Total runtime is 0.4883557240168252 minutes
2024-11-14 15:50:03,546:INFO:SubProcess create_model() called ==================================
2024-11-14 15:50:03,547:INFO:Initializing create_model()
2024-11-14 15:50:03,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:50:03,547:INFO:Checking exceptions
2024-11-14 15:50:03,547:INFO:Importing libraries
2024-11-14 15:50:03,547:INFO:Copying training dataset
2024-11-14 15:50:03,554:INFO:Defining folds
2024-11-14 15:50:03,554:INFO:Declaring metric variables
2024-11-14 15:50:03,558:INFO:Importing untrained model
2024-11-14 15:50:03,561:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-14 15:50:03,568:INFO:Starting cross validation
2024-11-14 15:50:03,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:57:08,261:INFO:Calculating mean and std
2024-11-14 15:57:08,267:INFO:Creating metrics dataframe
2024-11-14 15:57:08,272:INFO:Uploading results into container
2024-11-14 15:57:08,273:INFO:Uploading model into container now
2024-11-14 15:57:08,274:INFO:_master_model_container: 18
2024-11-14 15:57:08,274:INFO:_display_container: 2
2024-11-14 15:57:08,275:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:57:08,275:INFO:create_model() successfully completed......................................
2024-11-14 15:57:08,499:INFO:SubProcess create_model() end ==================================
2024-11-14 15:57:08,499:INFO:Creating metrics dataframe
2024-11-14 15:57:08,512:INFO:Initializing CatBoost Regressor
2024-11-14 15:57:08,512:INFO:Total runtime is 7.571175197760264 minutes
2024-11-14 15:57:08,516:INFO:SubProcess create_model() called ==================================
2024-11-14 15:57:08,516:INFO:Initializing create_model()
2024-11-14 15:57:08,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:57:08,516:INFO:Checking exceptions
2024-11-14 15:57:08,516:INFO:Importing libraries
2024-11-14 15:57:08,516:INFO:Copying training dataset
2024-11-14 15:57:08,523:INFO:Defining folds
2024-11-14 15:57:08,524:INFO:Declaring metric variables
2024-11-14 15:57:08,527:INFO:Importing untrained model
2024-11-14 15:57:08,530:INFO:CatBoost Regressor Imported successfully
2024-11-14 15:57:08,536:INFO:Starting cross validation
2024-11-14 15:57:08,537:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:57:21,313:INFO:Calculating mean and std
2024-11-14 15:57:21,319:INFO:Creating metrics dataframe
2024-11-14 15:57:21,330:INFO:Uploading results into container
2024-11-14 15:57:21,331:INFO:Uploading model into container now
2024-11-14 15:57:21,332:INFO:_master_model_container: 19
2024-11-14 15:57:21,332:INFO:_display_container: 2
2024-11-14 15:57:21,332:INFO:<catboost.core.CatBoostRegressor object at 0x7fc08fbdc760>
2024-11-14 15:57:21,332:INFO:create_model() successfully completed......................................
2024-11-14 15:57:21,550:INFO:SubProcess create_model() end ==================================
2024-11-14 15:57:21,551:INFO:Creating metrics dataframe
2024-11-14 15:57:21,565:INFO:Initializing Dummy Regressor
2024-11-14 15:57:21,565:INFO:Total runtime is 7.788721342881521 minutes
2024-11-14 15:57:21,568:INFO:SubProcess create_model() called ==================================
2024-11-14 15:57:21,569:INFO:Initializing create_model()
2024-11-14 15:57:21,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc08f86a1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:57:21,569:INFO:Checking exceptions
2024-11-14 15:57:21,569:INFO:Importing libraries
2024-11-14 15:57:21,569:INFO:Copying training dataset
2024-11-14 15:57:21,579:INFO:Defining folds
2024-11-14 15:57:21,579:INFO:Declaring metric variables
2024-11-14 15:57:21,583:INFO:Importing untrained model
2024-11-14 15:57:21,586:INFO:Dummy Regressor Imported successfully
2024-11-14 15:57:21,592:INFO:Starting cross validation
2024-11-14 15:57:21,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:57:24,434:INFO:Calculating mean and std
2024-11-14 15:57:24,439:INFO:Creating metrics dataframe
2024-11-14 15:57:24,446:INFO:Uploading results into container
2024-11-14 15:57:24,447:INFO:Uploading model into container now
2024-11-14 15:57:24,448:INFO:_master_model_container: 20
2024-11-14 15:57:24,448:INFO:_display_container: 2
2024-11-14 15:57:24,448:INFO:DummyRegressor()
2024-11-14 15:57:24,448:INFO:create_model() successfully completed......................................
2024-11-14 15:57:24,661:INFO:SubProcess create_model() end ==================================
2024-11-14 15:57:24,661:INFO:Creating metrics dataframe
2024-11-14 15:57:24,685:INFO:Initializing create_model()
2024-11-14 15:57:24,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:57:24,685:INFO:Checking exceptions
2024-11-14 15:57:24,687:INFO:Importing libraries
2024-11-14 15:57:24,687:INFO:Copying training dataset
2024-11-14 15:57:24,695:INFO:Defining folds
2024-11-14 15:57:24,695:INFO:Declaring metric variables
2024-11-14 15:57:24,695:INFO:Importing untrained model
2024-11-14 15:57:24,695:INFO:Declaring custom model
2024-11-14 15:57:24,695:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:57:24,696:INFO:Cross validation set to False
2024-11-14 15:57:24,696:INFO:Fitting Model
2024-11-14 15:57:24,952:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:57:24,953:INFO:create_model() successfully completed......................................
2024-11-14 15:57:25,185:INFO:_master_model_container: 20
2024-11-14 15:57:25,186:INFO:_display_container: 2
2024-11-14 15:57:25,186:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:57:25,186:INFO:compare_models() successfully completed......................................
2024-11-14 15:57:25,301:INFO:Initializing create_model()
2024-11-14 15:57:25,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc08f87ac10>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-14 15:57:25,302:INFO:Checking exceptions
2024-11-14 15:57:25,338:INFO:Importing libraries
2024-11-14 15:57:25,338:INFO:Copying training dataset
2024-11-14 15:57:25,346:INFO:Defining folds
2024-11-14 15:57:25,346:INFO:Declaring metric variables
2024-11-14 15:57:25,351:INFO:Importing untrained model
2024-11-14 15:57:25,355:INFO:Extra Trees Regressor Imported successfully
2024-11-14 15:57:25,363:INFO:Starting cross validation
2024-11-14 15:57:25,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-14 15:57:28,946:INFO:Calculating mean and std
2024-11-14 15:57:28,949:INFO:Creating metrics dataframe
2024-11-14 15:57:28,958:INFO:Finalizing model
2024-11-14 15:57:29,211:INFO:Uploading results into container
2024-11-14 15:57:29,213:INFO:Uploading model into container now
2024-11-14 15:57:29,224:INFO:_master_model_container: 21
2024-11-14 15:57:29,224:INFO:_display_container: 3
2024-11-14 15:57:29,224:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2024-11-14 15:57:29,225:INFO:create_model() successfully completed......................................
