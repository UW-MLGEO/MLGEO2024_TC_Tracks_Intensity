2024-11-13 17:02:04,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:02:04,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:02:04,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:02:04,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:12:07,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:12:07,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:12:07,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:12:07,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-13 17:12:50,768:WARNING:<ipython-input-8-70ef97ec7642>:9: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.
To preserve the previous behavior, use

	>>> .groupby(..., group_keys=False)

To adopt the future behavior and silence this warning, use 

	>>> .groupby(..., group_keys=True)
  df_SHIPS_24 = filtered_df.groupby('Code').apply(lambda x: x[['Original_Times', 'Code', 'Times', 'Latitude', 'Longitude', 'Vmax', 'MSLP', 'Daily_SST_Avg', 'Mid_Level_RH', 'Vshear', 'Vert_Vel']]).reset_index(drop=True)

2024-11-13 17:13:11,388:WARNING:<ipython-input-11-72a982439e21>:10: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_SHIPS_24_common.loc[:, 'New_Times'] = new_times #Add the new times to the DataFrame

2024-11-13 17:13:11,410:WARNING:<ipython-input-12-132cce1a3ba2>:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_BT_24_common['ISO_TIME'] = pd.to_datetime(df_BT_24_common['ISO_TIME'])

2024-11-13 17:13:18,589:INFO:PyCaret RegressionExperiment
2024-11-13 17:13:18,589:INFO:Logging name: reg-default-name
2024-11-13 17:13:18,589:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:13:18,589:INFO:version 3.2.0
2024-11-13 17:13:18,590:INFO:Initializing setup()
2024-11-13 17:13:18,590:INFO:self.USI: d612
2024-11-13 17:13:18,590:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:13:18,590:INFO:Checking environment
2024-11-13 17:13:18,590:INFO:python_version: 3.8.13
2024-11-13 17:13:18,590:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:13:18,590:INFO:machine: x86_64
2024-11-13 17:13:18,625:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:13:18,626:INFO:Memory: svmem(total=270355722240, available=217298403328, percent=19.6, used=50976284672, free=55903637504, active=11450572800, inactive=142715473920, buffers=8888320, cached=163466911744, shared=187334656, slab=25016049664)
2024-11-13 17:13:18,628:INFO:Physical Core: 28
2024-11-13 17:13:18,628:INFO:Logical Core: 56
2024-11-13 17:13:18,628:INFO:Checking libraries
2024-11-13 17:13:18,629:INFO:System:
2024-11-13 17:13:18,629:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:13:18,629:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:13:18,629:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:13:18,629:INFO:PyCaret required dependencies:
2024-11-13 17:13:18,826:INFO:                 pip: 22.2.2
2024-11-13 17:13:18,826:INFO:          setuptools: 63.4.2
2024-11-13 17:13:18,826:INFO:             pycaret: 3.2.0
2024-11-13 17:13:18,826:INFO:             IPython: 8.12.2
2024-11-13 17:13:18,826:INFO:          ipywidgets: 7.7.1
2024-11-13 17:13:18,826:INFO:                tqdm: 4.64.1
2024-11-13 17:13:18,826:INFO:               numpy: 1.23.5
2024-11-13 17:13:18,826:INFO:              pandas: 1.5.3
2024-11-13 17:13:18,826:INFO:              jinja2: 3.1.2
2024-11-13 17:13:18,826:INFO:               scipy: 1.10.1
2024-11-13 17:13:18,826:INFO:              joblib: 1.3.0
2024-11-13 17:13:18,826:INFO:             sklearn: 1.1.2
2024-11-13 17:13:18,827:INFO:                pyod: 2.0.2
2024-11-13 17:13:18,827:INFO:            imblearn: 0.12.4
2024-11-13 17:13:18,827:INFO:   category_encoders: 2.6.4
2024-11-13 17:13:18,827:INFO:            lightgbm: 4.5.0
2024-11-13 17:13:18,827:INFO:               numba: 0.57.1
2024-11-13 17:13:18,827:INFO:            requests: 2.28.1
2024-11-13 17:13:18,827:INFO:          matplotlib: 3.5.1
2024-11-13 17:13:18,827:INFO:          scikitplot: 0.3.7
2024-11-13 17:13:18,827:INFO:         yellowbrick: 1.5
2024-11-13 17:13:18,827:INFO:              plotly: 5.24.1
2024-11-13 17:13:18,827:INFO:    plotly-resampler: Not installed
2024-11-13 17:13:18,827:INFO:             kaleido: 0.2.1
2024-11-13 17:13:18,827:INFO:           schemdraw: 0.15
2024-11-13 17:13:18,827:INFO:         statsmodels: 0.13.2
2024-11-13 17:13:18,827:INFO:              sktime: 0.21.1
2024-11-13 17:13:18,827:INFO:               tbats: 1.1.3
2024-11-13 17:13:18,827:INFO:            pmdarima: 2.0.4
2024-11-13 17:13:18,827:INFO:              psutil: 5.9.1
2024-11-13 17:13:18,827:INFO:          markupsafe: 2.1.1
2024-11-13 17:13:18,827:INFO:             pickle5: Not installed
2024-11-13 17:13:18,827:INFO:         cloudpickle: 2.1.0
2024-11-13 17:13:18,827:INFO:         deprecation: 2.1.0
2024-11-13 17:13:18,827:INFO:              xxhash: 3.5.0
2024-11-13 17:13:18,827:INFO:           wurlitzer: 3.1.1
2024-11-13 17:13:18,827:INFO:PyCaret optional dependencies:
2024-11-13 17:13:21,326:INFO:                shap: 0.44.1
2024-11-13 17:13:21,326:INFO:           interpret: 0.6.5
2024-11-13 17:13:21,326:INFO:                umap: 0.5.7
2024-11-13 17:13:21,326:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:13:21,326:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:13:21,326:INFO:             autoviz: Not installed
2024-11-13 17:13:21,326:INFO:           fairlearn: 0.7.0
2024-11-13 17:13:21,326:INFO:          deepchecks: Not installed
2024-11-13 17:13:21,326:INFO:             xgboost: 2.1.1
2024-11-13 17:13:21,326:INFO:            catboost: 1.2.7
2024-11-13 17:13:21,326:INFO:              kmodes: 0.12.2
2024-11-13 17:13:21,326:INFO:             mlxtend: 0.23.1
2024-11-13 17:13:21,326:INFO:       statsforecast: 1.5.0
2024-11-13 17:13:21,326:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:13:21,326:INFO:                 ray: 2.10.0
2024-11-13 17:13:21,326:INFO:            hyperopt: 0.2.7
2024-11-13 17:13:21,326:INFO:              optuna: 4.1.0
2024-11-13 17:13:21,326:INFO:               skopt: 0.10.2
2024-11-13 17:13:21,326:INFO:              mlflow: 1.30.1
2024-11-13 17:13:21,326:INFO:              gradio: 3.50.2
2024-11-13 17:13:21,326:INFO:             fastapi: 0.115.5
2024-11-13 17:13:21,326:INFO:             uvicorn: 0.32.0
2024-11-13 17:13:21,326:INFO:              m2cgen: 0.10.0
2024-11-13 17:13:21,326:INFO:           evidently: 0.2.8
2024-11-13 17:13:21,326:INFO:               fugue: 0.8.6
2024-11-13 17:13:21,326:INFO:           streamlit: Not installed
2024-11-13 17:13:21,326:INFO:             prophet: Not installed
2024-11-13 17:13:21,326:INFO:None
2024-11-13 17:13:21,327:INFO:Set up data.
2024-11-13 17:13:21,351:INFO:Set up folding strategy.
2024-11-13 17:13:21,351:INFO:Set up train/test split.
2024-11-13 17:13:21,358:INFO:Set up index.
2024-11-13 17:13:21,360:INFO:Assigning column types.
2024-11-13 17:13:21,364:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 17:13:21,365:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,368:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,423:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,480:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:21,483:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:21,503:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,508:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,513:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,617:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:21,620:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:21,620:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 17:13:21,624:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,628:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,677:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,715:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:21,717:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:21,721:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,725:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,774:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,820:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:21,822:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:21,823:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 17:13:21,830:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,921:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:21,923:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:21,931:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:13:21,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,021:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,023:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,024:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 17:13:22,081:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,118:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,120:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,215:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,217:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,218:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 17:13:22,275:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,312:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,314:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:13:22,409:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,411:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,411:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 17:13:22,504:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,507:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,601:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:22,604:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:22,606:INFO:Preparing preprocessing pipeline...
2024-11-13 17:13:22,606:INFO:Set up simple imputation.
2024-11-13 17:13:22,610:INFO:Set up encoding of categorical features.
2024-11-13 17:13:22,725:INFO:Finished creating preprocessing pipeline.
2024-11-13 17:13:22,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Latitude', 'Longitude', 'MSLP',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel', 'USA_WSPD',
                                             'USA_PRES', 'WMO_WIND',
                                             'USA_WIND'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Code', 'USA_ATCF_ID', 'WMO_PRES'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Code', 'USA_ATCF_ID', 'WMO_PRES'],
                                    transformer=TargetEncoder(cols=['Code',
                                                                    'USA_ATCF_ID',
                                                                    'WMO_PRES'],
                                                              handle_missing='return_nan')))])
2024-11-13 17:13:22,732:INFO:Creating final display dataframe.
2024-11-13 17:13:23,047:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape       (31316, 15)
4        Transformed data shape       (31316, 15)
5   Transformed train set shape       (21921, 15)
6    Transformed test set shape        (9395, 15)
7              Numeric features                11
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              d612
2024-11-13 17:13:23,183:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:23,186:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:23,285:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:13:23,287:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:13:23,288:INFO:setup() successfully completed in 4.7s...............
2024-11-13 17:15:00,619:INFO:Initializing compare_models()
2024-11-13 17:15:00,619:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 17:15:00,620:INFO:Checking exceptions
2024-11-13 17:15:00,627:INFO:Preparing display monitor
2024-11-13 17:15:00,680:INFO:Initializing Linear Regression
2024-11-13 17:15:00,681:INFO:Total runtime is 1.9828478495279947e-06 minutes
2024-11-13 17:15:00,685:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:00,685:INFO:Initializing create_model()
2024-11-13 17:15:00,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:00,685:INFO:Checking exceptions
2024-11-13 17:15:00,685:INFO:Importing libraries
2024-11-13 17:15:00,685:INFO:Copying training dataset
2024-11-13 17:15:00,694:INFO:Defining folds
2024-11-13 17:15:00,694:INFO:Declaring metric variables
2024-11-13 17:15:00,698:INFO:Importing untrained model
2024-11-13 17:15:00,702:INFO:Linear Regression Imported successfully
2024-11-13 17:15:00,710:INFO:Starting cross validation
2024-11-13 17:15:00,713:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:05,076:INFO:Calculating mean and std
2024-11-13 17:15:05,081:INFO:Creating metrics dataframe
2024-11-13 17:15:05,090:INFO:Uploading results into container
2024-11-13 17:15:05,091:INFO:Uploading model into container now
2024-11-13 17:15:05,091:INFO:_master_model_container: 1
2024-11-13 17:15:05,091:INFO:_display_container: 2
2024-11-13 17:15:05,092:INFO:LinearRegression(n_jobs=-1)
2024-11-13 17:15:05,092:INFO:create_model() successfully completed......................................
2024-11-13 17:15:05,318:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:05,318:INFO:Creating metrics dataframe
2024-11-13 17:15:05,328:INFO:Initializing Lasso Regression
2024-11-13 17:15:05,329:INFO:Total runtime is 0.0774680495262146 minutes
2024-11-13 17:15:05,332:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:05,332:INFO:Initializing create_model()
2024-11-13 17:15:05,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:05,332:INFO:Checking exceptions
2024-11-13 17:15:05,333:INFO:Importing libraries
2024-11-13 17:15:05,333:INFO:Copying training dataset
2024-11-13 17:15:05,345:INFO:Defining folds
2024-11-13 17:15:05,345:INFO:Declaring metric variables
2024-11-13 17:15:05,350:INFO:Importing untrained model
2024-11-13 17:15:05,353:INFO:Lasso Regression Imported successfully
2024-11-13 17:15:05,360:INFO:Starting cross validation
2024-11-13 17:15:05,362:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:08,534:INFO:Calculating mean and std
2024-11-13 17:15:08,538:INFO:Creating metrics dataframe
2024-11-13 17:15:08,545:INFO:Uploading results into container
2024-11-13 17:15:08,545:INFO:Uploading model into container now
2024-11-13 17:15:08,546:INFO:_master_model_container: 2
2024-11-13 17:15:08,546:INFO:_display_container: 2
2024-11-13 17:15:08,547:INFO:Lasso(random_state=123)
2024-11-13 17:15:08,547:INFO:create_model() successfully completed......................................
2024-11-13 17:15:08,743:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:08,743:INFO:Creating metrics dataframe
2024-11-13 17:15:08,753:INFO:Initializing Ridge Regression
2024-11-13 17:15:08,753:INFO:Total runtime is 0.13455013036727906 minutes
2024-11-13 17:15:08,757:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:08,757:INFO:Initializing create_model()
2024-11-13 17:15:08,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:08,758:INFO:Checking exceptions
2024-11-13 17:15:08,758:INFO:Importing libraries
2024-11-13 17:15:08,758:INFO:Copying training dataset
2024-11-13 17:15:08,767:INFO:Defining folds
2024-11-13 17:15:08,768:INFO:Declaring metric variables
2024-11-13 17:15:08,771:INFO:Importing untrained model
2024-11-13 17:15:08,775:INFO:Ridge Regression Imported successfully
2024-11-13 17:15:08,781:INFO:Starting cross validation
2024-11-13 17:15:08,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:11,752:INFO:Calculating mean and std
2024-11-13 17:15:11,756:INFO:Creating metrics dataframe
2024-11-13 17:15:11,764:INFO:Uploading results into container
2024-11-13 17:15:11,764:INFO:Uploading model into container now
2024-11-13 17:15:11,765:INFO:_master_model_container: 3
2024-11-13 17:15:11,765:INFO:_display_container: 2
2024-11-13 17:15:11,766:INFO:Ridge(random_state=123)
2024-11-13 17:15:11,766:INFO:create_model() successfully completed......................................
2024-11-13 17:15:11,910:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:11,910:INFO:Creating metrics dataframe
2024-11-13 17:15:11,920:INFO:Initializing Elastic Net
2024-11-13 17:15:11,921:INFO:Total runtime is 0.18733490308125814 minutes
2024-11-13 17:15:11,924:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:11,924:INFO:Initializing create_model()
2024-11-13 17:15:11,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:11,924:INFO:Checking exceptions
2024-11-13 17:15:11,924:INFO:Importing libraries
2024-11-13 17:15:11,924:INFO:Copying training dataset
2024-11-13 17:15:11,932:INFO:Defining folds
2024-11-13 17:15:11,933:INFO:Declaring metric variables
2024-11-13 17:15:11,936:INFO:Importing untrained model
2024-11-13 17:15:11,939:INFO:Elastic Net Imported successfully
2024-11-13 17:15:11,945:INFO:Starting cross validation
2024-11-13 17:15:11,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:15,125:INFO:Calculating mean and std
2024-11-13 17:15:15,129:INFO:Creating metrics dataframe
2024-11-13 17:15:15,135:INFO:Uploading results into container
2024-11-13 17:15:15,136:INFO:Uploading model into container now
2024-11-13 17:15:15,137:INFO:_master_model_container: 4
2024-11-13 17:15:15,137:INFO:_display_container: 2
2024-11-13 17:15:15,137:INFO:ElasticNet(random_state=123)
2024-11-13 17:15:15,137:INFO:create_model() successfully completed......................................
2024-11-13 17:15:15,312:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:15,312:INFO:Creating metrics dataframe
2024-11-13 17:15:15,323:INFO:Initializing Least Angle Regression
2024-11-13 17:15:15,323:INFO:Total runtime is 0.24405117829640705 minutes
2024-11-13 17:15:15,327:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:15,327:INFO:Initializing create_model()
2024-11-13 17:15:15,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:15,328:INFO:Checking exceptions
2024-11-13 17:15:15,328:INFO:Importing libraries
2024-11-13 17:15:15,328:INFO:Copying training dataset
2024-11-13 17:15:15,337:INFO:Defining folds
2024-11-13 17:15:15,337:INFO:Declaring metric variables
2024-11-13 17:15:15,341:INFO:Importing untrained model
2024-11-13 17:15:15,344:INFO:Least Angle Regression Imported successfully
2024-11-13 17:15:15,351:INFO:Starting cross validation
2024-11-13 17:15:15,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:18,079:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,091:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.310e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,092:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.310e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,092:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.016e-07, with an active set of 5 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,092:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.016e-07, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,116:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,123:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.511e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,123:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.511e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,124:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.990e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,124:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.990e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,124:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.961e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,125:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.961e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,178:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,183:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.482e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,183:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.482e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,184:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.949e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,184:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.949e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,184:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.900e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,185:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.900e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,193:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,193:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,199:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.196e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,200:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.595e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,200:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.595e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,200:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.856e-07, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,225:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,230:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,232:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.576e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,233:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.611e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,233:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.021e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,233:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.860e-07, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,234:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.723e-07, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,234:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.709e-07, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,234:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.222e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,259:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,259:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,266:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=8.577e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,267:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.013e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,267:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.013e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,267:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.813e-07, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,267:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.967e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,267:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.574e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,268:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.574e-07, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 17:15:18,576:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:18,611:INFO:Calculating mean and std
2024-11-13 17:15:18,615:INFO:Creating metrics dataframe
2024-11-13 17:15:18,623:INFO:Uploading results into container
2024-11-13 17:15:18,624:INFO:Uploading model into container now
2024-11-13 17:15:18,625:INFO:_master_model_container: 5
2024-11-13 17:15:18,625:INFO:_display_container: 2
2024-11-13 17:15:18,626:INFO:Lars(random_state=123)
2024-11-13 17:15:18,626:INFO:create_model() successfully completed......................................
2024-11-13 17:15:18,785:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:18,785:INFO:Creating metrics dataframe
2024-11-13 17:15:18,796:INFO:Initializing Lasso Least Angle Regression
2024-11-13 17:15:18,796:INFO:Total runtime is 0.30193233489990234 minutes
2024-11-13 17:15:18,800:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:18,800:INFO:Initializing create_model()
2024-11-13 17:15:18,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:18,801:INFO:Checking exceptions
2024-11-13 17:15:18,801:INFO:Importing libraries
2024-11-13 17:15:18,801:INFO:Copying training dataset
2024-11-13 17:15:18,814:INFO:Defining folds
2024-11-13 17:15:18,815:INFO:Declaring metric variables
2024-11-13 17:15:18,818:INFO:Importing untrained model
2024-11-13 17:15:18,822:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 17:15:18,828:INFO:Starting cross validation
2024-11-13 17:15:18,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:19,091:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:19,110:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:19,110:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:19,118:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,459:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,590:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,650:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,697:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,712:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,743:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:15:21,780:INFO:Calculating mean and std
2024-11-13 17:15:21,784:INFO:Creating metrics dataframe
2024-11-13 17:15:21,791:INFO:Uploading results into container
2024-11-13 17:15:21,791:INFO:Uploading model into container now
2024-11-13 17:15:21,792:INFO:_master_model_container: 6
2024-11-13 17:15:21,792:INFO:_display_container: 2
2024-11-13 17:15:21,793:INFO:LassoLars(random_state=123)
2024-11-13 17:15:21,793:INFO:create_model() successfully completed......................................
2024-11-13 17:15:21,938:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:21,938:INFO:Creating metrics dataframe
2024-11-13 17:15:21,950:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 17:15:21,950:INFO:Total runtime is 0.3545009732246399 minutes
2024-11-13 17:15:21,954:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:21,954:INFO:Initializing create_model()
2024-11-13 17:15:21,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:21,954:INFO:Checking exceptions
2024-11-13 17:15:21,955:INFO:Importing libraries
2024-11-13 17:15:21,955:INFO:Copying training dataset
2024-11-13 17:15:21,963:INFO:Defining folds
2024-11-13 17:15:21,963:INFO:Declaring metric variables
2024-11-13 17:15:21,966:INFO:Importing untrained model
2024-11-13 17:15:21,970:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 17:15:21,977:INFO:Starting cross validation
2024-11-13 17:15:21,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:22,128:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,128:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,141:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,155:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,181:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,184:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,188:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,195:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,205:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,234:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:15:22,275:INFO:Calculating mean and std
2024-11-13 17:15:22,278:INFO:Creating metrics dataframe
2024-11-13 17:15:22,284:INFO:Uploading results into container
2024-11-13 17:15:22,285:INFO:Uploading model into container now
2024-11-13 17:15:22,286:INFO:_master_model_container: 7
2024-11-13 17:15:22,286:INFO:_display_container: 2
2024-11-13 17:15:22,286:INFO:OrthogonalMatchingPursuit()
2024-11-13 17:15:22,286:INFO:create_model() successfully completed......................................
2024-11-13 17:15:22,424:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:22,424:INFO:Creating metrics dataframe
2024-11-13 17:15:22,440:INFO:Initializing Bayesian Ridge
2024-11-13 17:15:22,440:INFO:Total runtime is 0.3626571933428447 minutes
2024-11-13 17:15:22,443:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:22,444:INFO:Initializing create_model()
2024-11-13 17:15:22,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:22,444:INFO:Checking exceptions
2024-11-13 17:15:22,444:INFO:Importing libraries
2024-11-13 17:15:22,445:INFO:Copying training dataset
2024-11-13 17:15:22,455:INFO:Defining folds
2024-11-13 17:15:22,455:INFO:Declaring metric variables
2024-11-13 17:15:22,458:INFO:Importing untrained model
2024-11-13 17:15:22,462:INFO:Bayesian Ridge Imported successfully
2024-11-13 17:15:22,468:INFO:Starting cross validation
2024-11-13 17:15:22,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:22,749:INFO:Calculating mean and std
2024-11-13 17:15:22,753:INFO:Creating metrics dataframe
2024-11-13 17:15:22,759:INFO:Uploading results into container
2024-11-13 17:15:22,760:INFO:Uploading model into container now
2024-11-13 17:15:22,761:INFO:_master_model_container: 8
2024-11-13 17:15:22,761:INFO:_display_container: 2
2024-11-13 17:15:22,761:INFO:BayesianRidge()
2024-11-13 17:15:22,761:INFO:create_model() successfully completed......................................
2024-11-13 17:15:22,929:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:22,929:INFO:Creating metrics dataframe
2024-11-13 17:15:22,941:INFO:Initializing Passive Aggressive Regressor
2024-11-13 17:15:22,941:INFO:Total runtime is 0.37101398309071865 minutes
2024-11-13 17:15:22,945:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:22,945:INFO:Initializing create_model()
2024-11-13 17:15:22,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:22,945:INFO:Checking exceptions
2024-11-13 17:15:22,945:INFO:Importing libraries
2024-11-13 17:15:22,946:INFO:Copying training dataset
2024-11-13 17:15:22,954:INFO:Defining folds
2024-11-13 17:15:22,954:INFO:Declaring metric variables
2024-11-13 17:15:22,958:INFO:Importing untrained model
2024-11-13 17:15:22,961:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 17:15:22,968:INFO:Starting cross validation
2024-11-13 17:15:22,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:23,354:INFO:Calculating mean and std
2024-11-13 17:15:23,358:INFO:Creating metrics dataframe
2024-11-13 17:15:23,364:INFO:Uploading results into container
2024-11-13 17:15:23,365:INFO:Uploading model into container now
2024-11-13 17:15:23,365:INFO:_master_model_container: 9
2024-11-13 17:15:23,365:INFO:_display_container: 2
2024-11-13 17:15:23,366:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 17:15:23,366:INFO:create_model() successfully completed......................................
2024-11-13 17:15:23,507:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:23,507:INFO:Creating metrics dataframe
2024-11-13 17:15:23,519:INFO:Initializing Huber Regressor
2024-11-13 17:15:23,519:INFO:Total runtime is 0.38064066569010424 minutes
2024-11-13 17:15:23,522:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:23,523:INFO:Initializing create_model()
2024-11-13 17:15:23,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:23,523:INFO:Checking exceptions
2024-11-13 17:15:23,523:INFO:Importing libraries
2024-11-13 17:15:23,523:INFO:Copying training dataset
2024-11-13 17:15:23,531:INFO:Defining folds
2024-11-13 17:15:23,531:INFO:Declaring metric variables
2024-11-13 17:15:23,535:INFO:Importing untrained model
2024-11-13 17:15:23,538:INFO:Huber Regressor Imported successfully
2024-11-13 17:15:23,545:INFO:Starting cross validation
2024-11-13 17:15:23,546:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:23,859:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,891:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,909:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,912:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,922:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,962:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:23,989:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:24,026:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:24,031:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:24,035:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:15:24,080:INFO:Calculating mean and std
2024-11-13 17:15:24,084:INFO:Creating metrics dataframe
2024-11-13 17:15:24,090:INFO:Uploading results into container
2024-11-13 17:15:24,091:INFO:Uploading model into container now
2024-11-13 17:15:24,092:INFO:_master_model_container: 10
2024-11-13 17:15:24,092:INFO:_display_container: 2
2024-11-13 17:15:24,092:INFO:HuberRegressor()
2024-11-13 17:15:24,092:INFO:create_model() successfully completed......................................
2024-11-13 17:15:24,245:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:24,245:INFO:Creating metrics dataframe
2024-11-13 17:15:24,258:INFO:Initializing K Neighbors Regressor
2024-11-13 17:15:24,258:INFO:Total runtime is 0.39295694828033456 minutes
2024-11-13 17:15:24,261:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:24,261:INFO:Initializing create_model()
2024-11-13 17:15:24,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:24,262:INFO:Checking exceptions
2024-11-13 17:15:24,262:INFO:Importing libraries
2024-11-13 17:15:24,262:INFO:Copying training dataset
2024-11-13 17:15:24,270:INFO:Defining folds
2024-11-13 17:15:24,271:INFO:Declaring metric variables
2024-11-13 17:15:24,274:INFO:Importing untrained model
2024-11-13 17:15:24,277:INFO:K Neighbors Regressor Imported successfully
2024-11-13 17:15:24,283:INFO:Starting cross validation
2024-11-13 17:15:24,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:24,727:INFO:Calculating mean and std
2024-11-13 17:15:24,730:INFO:Creating metrics dataframe
2024-11-13 17:15:24,735:INFO:Uploading results into container
2024-11-13 17:15:24,736:INFO:Uploading model into container now
2024-11-13 17:15:24,737:INFO:_master_model_container: 11
2024-11-13 17:15:24,737:INFO:_display_container: 2
2024-11-13 17:15:24,737:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 17:15:24,737:INFO:create_model() successfully completed......................................
2024-11-13 17:15:24,933:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:24,933:INFO:Creating metrics dataframe
2024-11-13 17:15:24,946:INFO:Initializing Decision Tree Regressor
2024-11-13 17:15:24,946:INFO:Total runtime is 0.4044304768244426 minutes
2024-11-13 17:15:24,949:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:24,950:INFO:Initializing create_model()
2024-11-13 17:15:24,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:24,950:INFO:Checking exceptions
2024-11-13 17:15:24,950:INFO:Importing libraries
2024-11-13 17:15:24,950:INFO:Copying training dataset
2024-11-13 17:15:24,958:INFO:Defining folds
2024-11-13 17:15:24,959:INFO:Declaring metric variables
2024-11-13 17:15:24,962:INFO:Importing untrained model
2024-11-13 17:15:24,965:INFO:Decision Tree Regressor Imported successfully
2024-11-13 17:15:24,972:INFO:Starting cross validation
2024-11-13 17:15:24,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:25,364:INFO:Calculating mean and std
2024-11-13 17:15:25,367:INFO:Creating metrics dataframe
2024-11-13 17:15:25,375:INFO:Uploading results into container
2024-11-13 17:15:25,375:INFO:Uploading model into container now
2024-11-13 17:15:25,376:INFO:_master_model_container: 12
2024-11-13 17:15:25,376:INFO:_display_container: 2
2024-11-13 17:15:25,376:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 17:15:25,376:INFO:create_model() successfully completed......................................
2024-11-13 17:15:25,529:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:25,530:INFO:Creating metrics dataframe
2024-11-13 17:15:25,542:INFO:Initializing Random Forest Regressor
2024-11-13 17:15:25,542:INFO:Total runtime is 0.4143658479054769 minutes
2024-11-13 17:15:25,545:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:25,546:INFO:Initializing create_model()
2024-11-13 17:15:25,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:25,546:INFO:Checking exceptions
2024-11-13 17:15:25,546:INFO:Importing libraries
2024-11-13 17:15:25,546:INFO:Copying training dataset
2024-11-13 17:15:25,554:INFO:Defining folds
2024-11-13 17:15:25,554:INFO:Declaring metric variables
2024-11-13 17:15:25,558:INFO:Importing untrained model
2024-11-13 17:15:25,561:INFO:Random Forest Regressor Imported successfully
2024-11-13 17:15:25,567:INFO:Starting cross validation
2024-11-13 17:15:25,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:27,039:INFO:Calculating mean and std
2024-11-13 17:15:27,042:INFO:Creating metrics dataframe
2024-11-13 17:15:27,047:INFO:Uploading results into container
2024-11-13 17:15:27,048:INFO:Uploading model into container now
2024-11-13 17:15:27,049:INFO:_master_model_container: 13
2024-11-13 17:15:27,049:INFO:_display_container: 2
2024-11-13 17:15:27,049:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:15:27,050:INFO:create_model() successfully completed......................................
2024-11-13 17:15:27,182:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:27,183:INFO:Creating metrics dataframe
2024-11-13 17:15:27,195:INFO:Initializing Extra Trees Regressor
2024-11-13 17:15:27,195:INFO:Total runtime is 0.44190859794616705 minutes
2024-11-13 17:15:27,198:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:27,199:INFO:Initializing create_model()
2024-11-13 17:15:27,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:27,199:INFO:Checking exceptions
2024-11-13 17:15:27,199:INFO:Importing libraries
2024-11-13 17:15:27,199:INFO:Copying training dataset
2024-11-13 17:15:27,207:INFO:Defining folds
2024-11-13 17:15:27,207:INFO:Declaring metric variables
2024-11-13 17:15:27,211:INFO:Importing untrained model
2024-11-13 17:15:27,214:INFO:Extra Trees Regressor Imported successfully
2024-11-13 17:15:27,221:INFO:Starting cross validation
2024-11-13 17:15:27,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:27,951:INFO:Calculating mean and std
2024-11-13 17:15:27,954:INFO:Creating metrics dataframe
2024-11-13 17:15:27,960:INFO:Uploading results into container
2024-11-13 17:15:27,960:INFO:Uploading model into container now
2024-11-13 17:15:27,961:INFO:_master_model_container: 14
2024-11-13 17:15:27,961:INFO:_display_container: 2
2024-11-13 17:15:27,961:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:15:27,961:INFO:create_model() successfully completed......................................
2024-11-13 17:15:28,095:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:28,096:INFO:Creating metrics dataframe
2024-11-13 17:15:28,108:INFO:Initializing AdaBoost Regressor
2024-11-13 17:15:28,108:INFO:Total runtime is 0.4571333726247152 minutes
2024-11-13 17:15:28,112:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:28,112:INFO:Initializing create_model()
2024-11-13 17:15:28,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:28,113:INFO:Checking exceptions
2024-11-13 17:15:28,113:INFO:Importing libraries
2024-11-13 17:15:28,113:INFO:Copying training dataset
2024-11-13 17:15:28,120:INFO:Defining folds
2024-11-13 17:15:28,121:INFO:Declaring metric variables
2024-11-13 17:15:28,124:INFO:Importing untrained model
2024-11-13 17:15:28,128:INFO:AdaBoost Regressor Imported successfully
2024-11-13 17:15:28,134:INFO:Starting cross validation
2024-11-13 17:15:28,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:29,286:INFO:Calculating mean and std
2024-11-13 17:15:29,289:INFO:Creating metrics dataframe
2024-11-13 17:15:29,295:INFO:Uploading results into container
2024-11-13 17:15:29,296:INFO:Uploading model into container now
2024-11-13 17:15:29,297:INFO:_master_model_container: 15
2024-11-13 17:15:29,297:INFO:_display_container: 2
2024-11-13 17:15:29,297:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 17:15:29,297:INFO:create_model() successfully completed......................................
2024-11-13 17:15:29,478:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:29,479:INFO:Creating metrics dataframe
2024-11-13 17:15:29,491:INFO:Initializing Gradient Boosting Regressor
2024-11-13 17:15:29,491:INFO:Total runtime is 0.4801816860834758 minutes
2024-11-13 17:15:29,495:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:29,495:INFO:Initializing create_model()
2024-11-13 17:15:29,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:29,495:INFO:Checking exceptions
2024-11-13 17:15:29,495:INFO:Importing libraries
2024-11-13 17:15:29,495:INFO:Copying training dataset
2024-11-13 17:15:29,505:INFO:Defining folds
2024-11-13 17:15:29,505:INFO:Declaring metric variables
2024-11-13 17:15:29,508:INFO:Importing untrained model
2024-11-13 17:15:29,512:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 17:15:29,518:INFO:Starting cross validation
2024-11-13 17:15:29,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:32,891:INFO:Calculating mean and std
2024-11-13 17:15:32,894:INFO:Creating metrics dataframe
2024-11-13 17:15:32,900:INFO:Uploading results into container
2024-11-13 17:15:32,901:INFO:Uploading model into container now
2024-11-13 17:15:32,902:INFO:_master_model_container: 16
2024-11-13 17:15:32,902:INFO:_display_container: 2
2024-11-13 17:15:32,902:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 17:15:32,903:INFO:create_model() successfully completed......................................
2024-11-13 17:15:33,067:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:33,067:INFO:Creating metrics dataframe
2024-11-13 17:15:33,080:INFO:Initializing Extreme Gradient Boosting
2024-11-13 17:15:33,080:INFO:Total runtime is 0.5400006532669067 minutes
2024-11-13 17:15:33,084:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:33,084:INFO:Initializing create_model()
2024-11-13 17:15:33,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:33,084:INFO:Checking exceptions
2024-11-13 17:15:33,084:INFO:Importing libraries
2024-11-13 17:15:33,084:INFO:Copying training dataset
2024-11-13 17:15:33,093:INFO:Defining folds
2024-11-13 17:15:33,093:INFO:Declaring metric variables
2024-11-13 17:15:33,097:INFO:Importing untrained model
2024-11-13 17:15:33,106:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 17:15:33,114:INFO:Starting cross validation
2024-11-13 17:15:33,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:15:33,699:INFO:Calculating mean and std
2024-11-13 17:15:33,703:INFO:Creating metrics dataframe
2024-11-13 17:15:33,708:INFO:Uploading results into container
2024-11-13 17:15:33,709:INFO:Uploading model into container now
2024-11-13 17:15:33,710:INFO:_master_model_container: 17
2024-11-13 17:15:33,710:INFO:_display_container: 2
2024-11-13 17:15:33,711:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 17:15:33,711:INFO:create_model() successfully completed......................................
2024-11-13 17:15:33,853:INFO:SubProcess create_model() end ==================================
2024-11-13 17:15:33,853:INFO:Creating metrics dataframe
2024-11-13 17:15:33,866:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 17:15:33,866:INFO:Total runtime is 0.5530894557634989 minutes
2024-11-13 17:15:33,869:INFO:SubProcess create_model() called ==================================
2024-11-13 17:15:33,869:INFO:Initializing create_model()
2024-11-13 17:15:33,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:15:33,870:INFO:Checking exceptions
2024-11-13 17:15:33,870:INFO:Importing libraries
2024-11-13 17:15:33,870:INFO:Copying training dataset
2024-11-13 17:15:33,878:INFO:Defining folds
2024-11-13 17:15:33,878:INFO:Declaring metric variables
2024-11-13 17:15:33,882:INFO:Importing untrained model
2024-11-13 17:15:33,885:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 17:15:33,892:INFO:Starting cross validation
2024-11-13 17:15:33,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:22:34,050:INFO:Calculating mean and std
2024-11-13 17:22:34,053:INFO:Creating metrics dataframe
2024-11-13 17:22:34,060:INFO:Uploading results into container
2024-11-13 17:22:34,061:INFO:Uploading model into container now
2024-11-13 17:22:34,061:INFO:_master_model_container: 18
2024-11-13 17:22:34,061:INFO:_display_container: 2
2024-11-13 17:22:34,062:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:22:34,062:INFO:create_model() successfully completed......................................
2024-11-13 17:22:34,261:INFO:SubProcess create_model() end ==================================
2024-11-13 17:22:34,261:INFO:Creating metrics dataframe
2024-11-13 17:22:34,274:INFO:Initializing CatBoost Regressor
2024-11-13 17:22:34,274:INFO:Total runtime is 7.559898801644643 minutes
2024-11-13 17:22:34,278:INFO:SubProcess create_model() called ==================================
2024-11-13 17:22:34,278:INFO:Initializing create_model()
2024-11-13 17:22:34,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:22:34,278:INFO:Checking exceptions
2024-11-13 17:22:34,278:INFO:Importing libraries
2024-11-13 17:22:34,278:INFO:Copying training dataset
2024-11-13 17:22:34,288:INFO:Defining folds
2024-11-13 17:22:34,289:INFO:Declaring metric variables
2024-11-13 17:22:34,292:INFO:Importing untrained model
2024-11-13 17:22:34,295:INFO:CatBoost Regressor Imported successfully
2024-11-13 17:22:34,301:INFO:Starting cross validation
2024-11-13 17:22:34,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:22:47,390:INFO:Calculating mean and std
2024-11-13 17:22:47,394:INFO:Creating metrics dataframe
2024-11-13 17:22:47,401:INFO:Uploading results into container
2024-11-13 17:22:47,402:INFO:Uploading model into container now
2024-11-13 17:22:47,402:INFO:_master_model_container: 19
2024-11-13 17:22:47,402:INFO:_display_container: 2
2024-11-13 17:22:47,402:INFO:<catboost.core.CatBoostRegressor object at 0x7ff6b5655fa0>
2024-11-13 17:22:47,403:INFO:create_model() successfully completed......................................
2024-11-13 17:22:47,560:INFO:SubProcess create_model() end ==================================
2024-11-13 17:22:47,561:INFO:Creating metrics dataframe
2024-11-13 17:22:47,575:INFO:Initializing Dummy Regressor
2024-11-13 17:22:47,575:INFO:Total runtime is 7.781577412287394 minutes
2024-11-13 17:22:47,578:INFO:SubProcess create_model() called ==================================
2024-11-13 17:22:47,579:INFO:Initializing create_model()
2024-11-13 17:22:47,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6f254c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:22:47,579:INFO:Checking exceptions
2024-11-13 17:22:47,579:INFO:Importing libraries
2024-11-13 17:22:47,579:INFO:Copying training dataset
2024-11-13 17:22:47,588:INFO:Defining folds
2024-11-13 17:22:47,588:INFO:Declaring metric variables
2024-11-13 17:22:47,592:INFO:Importing untrained model
2024-11-13 17:22:47,595:INFO:Dummy Regressor Imported successfully
2024-11-13 17:22:47,602:INFO:Starting cross validation
2024-11-13 17:22:47,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:22:50,619:INFO:Calculating mean and std
2024-11-13 17:22:50,625:INFO:Creating metrics dataframe
2024-11-13 17:22:50,631:INFO:Uploading results into container
2024-11-13 17:22:50,632:INFO:Uploading model into container now
2024-11-13 17:22:50,633:INFO:_master_model_container: 20
2024-11-13 17:22:50,633:INFO:_display_container: 2
2024-11-13 17:22:50,633:INFO:DummyRegressor()
2024-11-13 17:22:50,633:INFO:create_model() successfully completed......................................
2024-11-13 17:22:50,837:INFO:SubProcess create_model() end ==================================
2024-11-13 17:22:50,837:INFO:Creating metrics dataframe
2024-11-13 17:22:50,863:INFO:Initializing create_model()
2024-11-13 17:22:50,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:22:50,863:INFO:Checking exceptions
2024-11-13 17:22:50,865:INFO:Importing libraries
2024-11-13 17:22:50,865:INFO:Copying training dataset
2024-11-13 17:22:50,874:INFO:Defining folds
2024-11-13 17:22:50,874:INFO:Declaring metric variables
2024-11-13 17:22:50,875:INFO:Importing untrained model
2024-11-13 17:22:50,875:INFO:Declaring custom model
2024-11-13 17:22:50,875:INFO:Linear Regression Imported successfully
2024-11-13 17:22:50,876:INFO:Cross validation set to False
2024-11-13 17:22:50,876:INFO:Fitting Model
2024-11-13 17:22:50,987:INFO:LinearRegression(n_jobs=-1)
2024-11-13 17:22:50,987:INFO:create_model() successfully completed......................................
2024-11-13 17:22:51,196:INFO:_master_model_container: 20
2024-11-13 17:22:51,196:INFO:_display_container: 2
2024-11-13 17:22:51,196:INFO:LinearRegression(n_jobs=-1)
2024-11-13 17:22:51,196:INFO:compare_models() successfully completed......................................
2024-11-13 17:23:41,967:INFO:Initializing plot_model()
2024-11-13 17:23:41,967:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bf44f0>, system=True)
2024-11-13 17:23:41,967:INFO:Checking exceptions
2024-11-13 17:23:41,976:INFO:Preloading libraries
2024-11-13 17:23:41,976:INFO:Copying training dataset
2024-11-13 17:23:41,976:INFO:Plot type: residuals
2024-11-13 17:23:42,379:INFO:Fitting Model
2024-11-13 17:23:42,379:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2024-11-13 17:23:42,459:INFO:Scoring test/hold-out set
2024-11-13 17:23:43,617:INFO:Visual Rendered Successfully
2024-11-13 17:23:43,782:INFO:plot_model() successfully completed......................................
2024-11-13 17:30:05,958:WARNING:<ipython-input-24-70ef97ec7642>:9: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.
To preserve the previous behavior, use

	>>> .groupby(..., group_keys=False)

To adopt the future behavior and silence this warning, use 

	>>> .groupby(..., group_keys=True)
  df_SHIPS_24 = filtered_df.groupby('Code').apply(lambda x: x[['Original_Times', 'Code', 'Times', 'Latitude', 'Longitude', 'Vmax', 'MSLP', 'Daily_SST_Avg', 'Mid_Level_RH', 'Vshear', 'Vert_Vel']]).reset_index(drop=True)

2024-11-13 17:31:04,628:WARNING:<ipython-input-29-70ef97ec7642>:9: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.
To preserve the previous behavior, use

	>>> .groupby(..., group_keys=False)

To adopt the future behavior and silence this warning, use 

	>>> .groupby(..., group_keys=True)
  df_SHIPS_24 = filtered_df.groupby('Code').apply(lambda x: x[['Original_Times', 'Code', 'Times', 'Latitude', 'Longitude', 'Vmax', 'MSLP', 'Daily_SST_Avg', 'Mid_Level_RH', 'Vshear', 'Vert_Vel']]).reset_index(drop=True)

2024-11-13 17:31:31,129:WARNING:<ipython-input-32-72a982439e21>:10: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_SHIPS_24_common.loc[:, 'New_Times'] = new_times #Add the new times to the DataFrame

2024-11-13 17:31:31,176:WARNING:<ipython-input-33-132cce1a3ba2>:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_BT_24_common['ISO_TIME'] = pd.to_datetime(df_BT_24_common['ISO_TIME'])

2024-11-13 17:33:00,649:WARNING:<ipython-input-37-cfb0873efbe0>:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_BT_24_common['ISO_TIME'] = pd.to_datetime(df_BT_24_common['ISO_TIME'])

2024-11-13 17:38:30,389:INFO:PyCaret RegressionExperiment
2024-11-13 17:38:30,389:INFO:Logging name: reg-default-name
2024-11-13 17:38:30,389:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:38:30,389:INFO:version 3.2.0
2024-11-13 17:38:30,389:INFO:Initializing setup()
2024-11-13 17:38:30,389:INFO:self.USI: e148
2024-11-13 17:38:30,389:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:38:30,389:INFO:Checking environment
2024-11-13 17:38:30,390:INFO:python_version: 3.8.13
2024-11-13 17:38:30,390:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:38:30,390:INFO:machine: x86_64
2024-11-13 17:38:30,390:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:38:30,390:INFO:Memory: svmem(total=270355722240, available=216871555072, percent=19.8, used=51403005952, free=55297449984, active=11558862848, inactive=143205117952, buffers=8888320, cached=163646377984, shared=187363328, slab=25018232832)
2024-11-13 17:38:30,392:INFO:Physical Core: 28
2024-11-13 17:38:30,392:INFO:Logical Core: 56
2024-11-13 17:38:30,392:INFO:Checking libraries
2024-11-13 17:38:30,392:INFO:System:
2024-11-13 17:38:30,392:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:38:30,392:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:38:30,393:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:38:30,393:INFO:PyCaret required dependencies:
2024-11-13 17:38:30,393:INFO:                 pip: 22.2.2
2024-11-13 17:38:30,393:INFO:          setuptools: 63.4.2
2024-11-13 17:38:30,393:INFO:             pycaret: 3.2.0
2024-11-13 17:38:30,393:INFO:             IPython: 8.12.2
2024-11-13 17:38:30,393:INFO:          ipywidgets: 7.7.1
2024-11-13 17:38:30,393:INFO:                tqdm: 4.64.1
2024-11-13 17:38:30,393:INFO:               numpy: 1.23.5
2024-11-13 17:38:30,393:INFO:              pandas: 1.5.3
2024-11-13 17:38:30,393:INFO:              jinja2: 3.1.2
2024-11-13 17:38:30,393:INFO:               scipy: 1.10.1
2024-11-13 17:38:30,393:INFO:              joblib: 1.3.0
2024-11-13 17:38:30,393:INFO:             sklearn: 1.1.2
2024-11-13 17:38:30,393:INFO:                pyod: 2.0.2
2024-11-13 17:38:30,393:INFO:            imblearn: 0.12.4
2024-11-13 17:38:30,393:INFO:   category_encoders: 2.6.4
2024-11-13 17:38:30,393:INFO:            lightgbm: 4.5.0
2024-11-13 17:38:30,393:INFO:               numba: 0.57.1
2024-11-13 17:38:30,393:INFO:            requests: 2.28.1
2024-11-13 17:38:30,393:INFO:          matplotlib: 3.5.1
2024-11-13 17:38:30,393:INFO:          scikitplot: 0.3.7
2024-11-13 17:38:30,393:INFO:         yellowbrick: 1.5
2024-11-13 17:38:30,393:INFO:              plotly: 5.24.1
2024-11-13 17:38:30,393:INFO:    plotly-resampler: Not installed
2024-11-13 17:38:30,393:INFO:             kaleido: 0.2.1
2024-11-13 17:38:30,393:INFO:           schemdraw: 0.15
2024-11-13 17:38:30,394:INFO:         statsmodels: 0.13.2
2024-11-13 17:38:30,394:INFO:              sktime: 0.21.1
2024-11-13 17:38:30,394:INFO:               tbats: 1.1.3
2024-11-13 17:38:30,394:INFO:            pmdarima: 2.0.4
2024-11-13 17:38:30,394:INFO:              psutil: 5.9.1
2024-11-13 17:38:30,394:INFO:          markupsafe: 2.1.1
2024-11-13 17:38:30,394:INFO:             pickle5: Not installed
2024-11-13 17:38:30,394:INFO:         cloudpickle: 2.1.0
2024-11-13 17:38:30,394:INFO:         deprecation: 2.1.0
2024-11-13 17:38:30,394:INFO:              xxhash: 3.5.0
2024-11-13 17:38:30,394:INFO:           wurlitzer: 3.1.1
2024-11-13 17:38:30,394:INFO:PyCaret optional dependencies:
2024-11-13 17:38:30,394:INFO:                shap: 0.44.1
2024-11-13 17:38:30,394:INFO:           interpret: 0.6.5
2024-11-13 17:38:30,394:INFO:                umap: 0.5.7
2024-11-13 17:38:30,394:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:38:30,394:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:38:30,394:INFO:             autoviz: Not installed
2024-11-13 17:38:30,394:INFO:           fairlearn: 0.7.0
2024-11-13 17:38:30,394:INFO:          deepchecks: Not installed
2024-11-13 17:38:30,394:INFO:             xgboost: 2.1.1
2024-11-13 17:38:30,394:INFO:            catboost: 1.2.7
2024-11-13 17:38:30,394:INFO:              kmodes: 0.12.2
2024-11-13 17:38:30,394:INFO:             mlxtend: 0.23.1
2024-11-13 17:38:30,394:INFO:       statsforecast: 1.5.0
2024-11-13 17:38:30,394:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:38:30,394:INFO:                 ray: 2.10.0
2024-11-13 17:38:30,394:INFO:            hyperopt: 0.2.7
2024-11-13 17:38:30,394:INFO:              optuna: 4.1.0
2024-11-13 17:38:30,394:INFO:               skopt: 0.10.2
2024-11-13 17:38:30,395:INFO:              mlflow: 1.30.1
2024-11-13 17:38:30,395:INFO:              gradio: 3.50.2
2024-11-13 17:38:30,395:INFO:             fastapi: 0.115.5
2024-11-13 17:38:30,395:INFO:             uvicorn: 0.32.0
2024-11-13 17:38:30,395:INFO:              m2cgen: 0.10.0
2024-11-13 17:38:30,395:INFO:           evidently: 0.2.8
2024-11-13 17:38:30,395:INFO:               fugue: 0.8.6
2024-11-13 17:38:30,395:INFO:           streamlit: Not installed
2024-11-13 17:38:30,395:INFO:             prophet: Not installed
2024-11-13 17:38:30,395:INFO:None
2024-11-13 17:38:30,395:INFO:Set up data.
2024-11-13 17:39:18,312:INFO:PyCaret RegressionExperiment
2024-11-13 17:39:18,312:INFO:Logging name: reg-default-name
2024-11-13 17:39:18,312:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:39:18,313:INFO:version 3.2.0
2024-11-13 17:39:18,313:INFO:Initializing setup()
2024-11-13 17:39:18,313:INFO:self.USI: 39c2
2024-11-13 17:39:18,313:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:39:18,313:INFO:Checking environment
2024-11-13 17:39:18,313:INFO:python_version: 3.8.13
2024-11-13 17:39:18,313:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:39:18,313:INFO:machine: x86_64
2024-11-13 17:39:18,313:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:18,313:INFO:Memory: svmem(total=270355722240, available=216870846464, percent=19.8, used=51403661312, free=55058685952, active=11558899712, inactive=143446773760, buffers=8888320, cached=163884486656, shared=187363328, slab=25018335232)
2024-11-13 17:39:18,316:INFO:Physical Core: 28
2024-11-13 17:39:18,316:INFO:Logical Core: 56
2024-11-13 17:39:18,316:INFO:Checking libraries
2024-11-13 17:39:18,316:INFO:System:
2024-11-13 17:39:18,316:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:39:18,316:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:39:18,316:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:18,316:INFO:PyCaret required dependencies:
2024-11-13 17:39:18,316:INFO:                 pip: 22.2.2
2024-11-13 17:39:18,316:INFO:          setuptools: 63.4.2
2024-11-13 17:39:18,316:INFO:             pycaret: 3.2.0
2024-11-13 17:39:18,316:INFO:             IPython: 8.12.2
2024-11-13 17:39:18,316:INFO:          ipywidgets: 7.7.1
2024-11-13 17:39:18,316:INFO:                tqdm: 4.64.1
2024-11-13 17:39:18,316:INFO:               numpy: 1.23.5
2024-11-13 17:39:18,317:INFO:              pandas: 1.5.3
2024-11-13 17:39:18,317:INFO:              jinja2: 3.1.2
2024-11-13 17:39:18,317:INFO:               scipy: 1.10.1
2024-11-13 17:39:18,317:INFO:              joblib: 1.3.0
2024-11-13 17:39:18,317:INFO:             sklearn: 1.1.2
2024-11-13 17:39:18,317:INFO:                pyod: 2.0.2
2024-11-13 17:39:18,317:INFO:            imblearn: 0.12.4
2024-11-13 17:39:18,317:INFO:   category_encoders: 2.6.4
2024-11-13 17:39:18,317:INFO:            lightgbm: 4.5.0
2024-11-13 17:39:18,317:INFO:               numba: 0.57.1
2024-11-13 17:39:18,317:INFO:            requests: 2.28.1
2024-11-13 17:39:18,317:INFO:          matplotlib: 3.5.1
2024-11-13 17:39:18,317:INFO:          scikitplot: 0.3.7
2024-11-13 17:39:18,317:INFO:         yellowbrick: 1.5
2024-11-13 17:39:18,317:INFO:              plotly: 5.24.1
2024-11-13 17:39:18,317:INFO:    plotly-resampler: Not installed
2024-11-13 17:39:18,317:INFO:             kaleido: 0.2.1
2024-11-13 17:39:18,317:INFO:           schemdraw: 0.15
2024-11-13 17:39:18,317:INFO:         statsmodels: 0.13.2
2024-11-13 17:39:18,317:INFO:              sktime: 0.21.1
2024-11-13 17:39:18,317:INFO:               tbats: 1.1.3
2024-11-13 17:39:18,317:INFO:            pmdarima: 2.0.4
2024-11-13 17:39:18,317:INFO:              psutil: 5.9.1
2024-11-13 17:39:18,317:INFO:          markupsafe: 2.1.1
2024-11-13 17:39:18,317:INFO:             pickle5: Not installed
2024-11-13 17:39:18,317:INFO:         cloudpickle: 2.1.0
2024-11-13 17:39:18,317:INFO:         deprecation: 2.1.0
2024-11-13 17:39:18,317:INFO:              xxhash: 3.5.0
2024-11-13 17:39:18,317:INFO:           wurlitzer: 3.1.1
2024-11-13 17:39:18,317:INFO:PyCaret optional dependencies:
2024-11-13 17:39:18,317:INFO:                shap: 0.44.1
2024-11-13 17:39:18,317:INFO:           interpret: 0.6.5
2024-11-13 17:39:18,318:INFO:                umap: 0.5.7
2024-11-13 17:39:18,318:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:39:18,318:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:39:18,318:INFO:             autoviz: Not installed
2024-11-13 17:39:18,318:INFO:           fairlearn: 0.7.0
2024-11-13 17:39:18,318:INFO:          deepchecks: Not installed
2024-11-13 17:39:18,318:INFO:             xgboost: 2.1.1
2024-11-13 17:39:18,318:INFO:            catboost: 1.2.7
2024-11-13 17:39:18,318:INFO:              kmodes: 0.12.2
2024-11-13 17:39:18,318:INFO:             mlxtend: 0.23.1
2024-11-13 17:39:18,318:INFO:       statsforecast: 1.5.0
2024-11-13 17:39:18,318:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:39:18,318:INFO:                 ray: 2.10.0
2024-11-13 17:39:18,318:INFO:            hyperopt: 0.2.7
2024-11-13 17:39:18,318:INFO:              optuna: 4.1.0
2024-11-13 17:39:18,318:INFO:               skopt: 0.10.2
2024-11-13 17:39:18,318:INFO:              mlflow: 1.30.1
2024-11-13 17:39:18,318:INFO:              gradio: 3.50.2
2024-11-13 17:39:18,318:INFO:             fastapi: 0.115.5
2024-11-13 17:39:18,318:INFO:             uvicorn: 0.32.0
2024-11-13 17:39:18,318:INFO:              m2cgen: 0.10.0
2024-11-13 17:39:18,318:INFO:           evidently: 0.2.8
2024-11-13 17:39:18,318:INFO:               fugue: 0.8.6
2024-11-13 17:39:18,318:INFO:           streamlit: Not installed
2024-11-13 17:39:18,318:INFO:             prophet: Not installed
2024-11-13 17:39:18,318:INFO:None
2024-11-13 17:39:18,318:INFO:Set up data.
2024-11-13 17:39:34,018:INFO:PyCaret RegressionExperiment
2024-11-13 17:39:34,018:INFO:Logging name: reg-default-name
2024-11-13 17:39:34,018:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:39:34,018:INFO:version 3.2.0
2024-11-13 17:39:34,019:INFO:Initializing setup()
2024-11-13 17:39:34,019:INFO:self.USI: 7207
2024-11-13 17:39:34,019:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:39:34,019:INFO:Checking environment
2024-11-13 17:39:34,019:INFO:python_version: 3.8.13
2024-11-13 17:39:34,019:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:39:34,019:INFO:machine: x86_64
2024-11-13 17:39:34,019:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:34,019:INFO:Memory: svmem(total=270355722240, available=216861130752, percent=19.8, used=51413438464, free=55228620800, active=11558920192, inactive=143269441536, buffers=8888320, cached=163704774656, shared=187363328, slab=25018122240)
2024-11-13 17:39:34,023:INFO:Physical Core: 28
2024-11-13 17:39:34,023:INFO:Logical Core: 56
2024-11-13 17:39:34,024:INFO:Checking libraries
2024-11-13 17:39:34,024:INFO:System:
2024-11-13 17:39:34,024:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:39:34,024:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:39:34,024:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:34,024:INFO:PyCaret required dependencies:
2024-11-13 17:39:34,024:INFO:                 pip: 22.2.2
2024-11-13 17:39:34,024:INFO:          setuptools: 63.4.2
2024-11-13 17:39:34,024:INFO:             pycaret: 3.2.0
2024-11-13 17:39:34,024:INFO:             IPython: 8.12.2
2024-11-13 17:39:34,024:INFO:          ipywidgets: 7.7.1
2024-11-13 17:39:34,024:INFO:                tqdm: 4.64.1
2024-11-13 17:39:34,024:INFO:               numpy: 1.23.5
2024-11-13 17:39:34,024:INFO:              pandas: 1.5.3
2024-11-13 17:39:34,024:INFO:              jinja2: 3.1.2
2024-11-13 17:39:34,025:INFO:               scipy: 1.10.1
2024-11-13 17:39:34,025:INFO:              joblib: 1.3.0
2024-11-13 17:39:34,025:INFO:             sklearn: 1.1.2
2024-11-13 17:39:34,025:INFO:                pyod: 2.0.2
2024-11-13 17:39:34,025:INFO:            imblearn: 0.12.4
2024-11-13 17:39:34,025:INFO:   category_encoders: 2.6.4
2024-11-13 17:39:34,025:INFO:            lightgbm: 4.5.0
2024-11-13 17:39:34,025:INFO:               numba: 0.57.1
2024-11-13 17:39:34,025:INFO:            requests: 2.28.1
2024-11-13 17:39:34,025:INFO:          matplotlib: 3.5.1
2024-11-13 17:39:34,025:INFO:          scikitplot: 0.3.7
2024-11-13 17:39:34,025:INFO:         yellowbrick: 1.5
2024-11-13 17:39:34,025:INFO:              plotly: 5.24.1
2024-11-13 17:39:34,025:INFO:    plotly-resampler: Not installed
2024-11-13 17:39:34,025:INFO:             kaleido: 0.2.1
2024-11-13 17:39:34,025:INFO:           schemdraw: 0.15
2024-11-13 17:39:34,025:INFO:         statsmodels: 0.13.2
2024-11-13 17:39:34,025:INFO:              sktime: 0.21.1
2024-11-13 17:39:34,025:INFO:               tbats: 1.1.3
2024-11-13 17:39:34,025:INFO:            pmdarima: 2.0.4
2024-11-13 17:39:34,025:INFO:              psutil: 5.9.1
2024-11-13 17:39:34,025:INFO:          markupsafe: 2.1.1
2024-11-13 17:39:34,025:INFO:             pickle5: Not installed
2024-11-13 17:39:34,025:INFO:         cloudpickle: 2.1.0
2024-11-13 17:39:34,025:INFO:         deprecation: 2.1.0
2024-11-13 17:39:34,025:INFO:              xxhash: 3.5.0
2024-11-13 17:39:34,025:INFO:           wurlitzer: 3.1.1
2024-11-13 17:39:34,025:INFO:PyCaret optional dependencies:
2024-11-13 17:39:34,025:INFO:                shap: 0.44.1
2024-11-13 17:39:34,025:INFO:           interpret: 0.6.5
2024-11-13 17:39:34,025:INFO:                umap: 0.5.7
2024-11-13 17:39:34,025:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:39:34,025:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:39:34,026:INFO:             autoviz: Not installed
2024-11-13 17:39:34,026:INFO:           fairlearn: 0.7.0
2024-11-13 17:39:34,026:INFO:          deepchecks: Not installed
2024-11-13 17:39:34,026:INFO:             xgboost: 2.1.1
2024-11-13 17:39:34,026:INFO:            catboost: 1.2.7
2024-11-13 17:39:34,026:INFO:              kmodes: 0.12.2
2024-11-13 17:39:34,026:INFO:             mlxtend: 0.23.1
2024-11-13 17:39:34,026:INFO:       statsforecast: 1.5.0
2024-11-13 17:39:34,026:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:39:34,026:INFO:                 ray: 2.10.0
2024-11-13 17:39:34,026:INFO:            hyperopt: 0.2.7
2024-11-13 17:39:34,026:INFO:              optuna: 4.1.0
2024-11-13 17:39:34,026:INFO:               skopt: 0.10.2
2024-11-13 17:39:34,026:INFO:              mlflow: 1.30.1
2024-11-13 17:39:34,026:INFO:              gradio: 3.50.2
2024-11-13 17:39:34,026:INFO:             fastapi: 0.115.5
2024-11-13 17:39:34,026:INFO:             uvicorn: 0.32.0
2024-11-13 17:39:34,026:INFO:              m2cgen: 0.10.0
2024-11-13 17:39:34,026:INFO:           evidently: 0.2.8
2024-11-13 17:39:34,026:INFO:               fugue: 0.8.6
2024-11-13 17:39:34,026:INFO:           streamlit: Not installed
2024-11-13 17:39:34,026:INFO:             prophet: Not installed
2024-11-13 17:39:34,026:INFO:None
2024-11-13 17:39:34,026:INFO:Set up data.
2024-11-13 17:39:34,037:INFO:Set up folding strategy.
2024-11-13 17:39:34,037:INFO:Set up train/test split.
2024-11-13 17:39:34,043:INFO:Set up index.
2024-11-13 17:39:34,044:INFO:Assigning column types.
2024-11-13 17:39:34,049:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 17:39:34,050:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,055:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,060:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,125:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,162:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,164:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,166:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,167:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,170:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,174:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,222:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,260:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,262:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,263:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 17:39:34,266:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,270:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,319:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,357:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,359:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,363:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,455:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,455:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,458:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,458:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 17:39:34,466:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,553:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,556:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,564:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,650:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,652:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,652:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 17:39:34,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,746:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,748:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,843:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,845:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:34,846:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 17:39:34,903:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:34,941:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:34,943:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,037:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,039:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,040:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 17:39:35,134:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,137:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,232:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,234:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,235:INFO:Preparing preprocessing pipeline...
2024-11-13 17:39:35,235:INFO:Set up simple imputation.
2024-11-13 17:39:35,252:INFO:Finished creating preprocessing pipeline.
2024-11-13 17:39:35,256:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 17:39:35,256:INFO:Creating final display dataframe.
2024-11-13 17:39:35,312:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              7207
2024-11-13 17:39:35,420:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,422:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,515:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,518:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,518:INFO:setup() successfully completed in 1.5s...............
2024-11-13 17:39:35,519:INFO:PyCaret RegressionExperiment
2024-11-13 17:39:35,519:INFO:Logging name: reg-default-name
2024-11-13 17:39:35,519:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:39:35,519:INFO:version 3.2.0
2024-11-13 17:39:35,519:INFO:Initializing setup()
2024-11-13 17:39:35,519:INFO:self.USI: a600
2024-11-13 17:39:35,519:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:39:35,520:INFO:Checking environment
2024-11-13 17:39:35,520:INFO:python_version: 3.8.13
2024-11-13 17:39:35,520:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:39:35,520:INFO:machine: x86_64
2024-11-13 17:39:35,520:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:35,520:INFO:Memory: svmem(total=270355722240, available=216854888448, percent=19.8, used=51419725824, free=55184830464, active=11558912000, inactive=143312265216, buffers=8888320, cached=163742277632, shared=187363328, slab=25018155008)
2024-11-13 17:39:35,522:INFO:Physical Core: 28
2024-11-13 17:39:35,522:INFO:Logical Core: 56
2024-11-13 17:39:35,522:INFO:Checking libraries
2024-11-13 17:39:35,522:INFO:System:
2024-11-13 17:39:35,522:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:39:35,522:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:39:35,522:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:39:35,522:INFO:PyCaret required dependencies:
2024-11-13 17:39:35,522:INFO:                 pip: 22.2.2
2024-11-13 17:39:35,522:INFO:          setuptools: 63.4.2
2024-11-13 17:39:35,522:INFO:             pycaret: 3.2.0
2024-11-13 17:39:35,522:INFO:             IPython: 8.12.2
2024-11-13 17:39:35,522:INFO:          ipywidgets: 7.7.1
2024-11-13 17:39:35,522:INFO:                tqdm: 4.64.1
2024-11-13 17:39:35,522:INFO:               numpy: 1.23.5
2024-11-13 17:39:35,522:INFO:              pandas: 1.5.3
2024-11-13 17:39:35,522:INFO:              jinja2: 3.1.2
2024-11-13 17:39:35,522:INFO:               scipy: 1.10.1
2024-11-13 17:39:35,522:INFO:              joblib: 1.3.0
2024-11-13 17:39:35,522:INFO:             sklearn: 1.1.2
2024-11-13 17:39:35,522:INFO:                pyod: 2.0.2
2024-11-13 17:39:35,522:INFO:            imblearn: 0.12.4
2024-11-13 17:39:35,522:INFO:   category_encoders: 2.6.4
2024-11-13 17:39:35,522:INFO:            lightgbm: 4.5.0
2024-11-13 17:39:35,522:INFO:               numba: 0.57.1
2024-11-13 17:39:35,522:INFO:            requests: 2.28.1
2024-11-13 17:39:35,522:INFO:          matplotlib: 3.5.1
2024-11-13 17:39:35,522:INFO:          scikitplot: 0.3.7
2024-11-13 17:39:35,522:INFO:         yellowbrick: 1.5
2024-11-13 17:39:35,522:INFO:              plotly: 5.24.1
2024-11-13 17:39:35,523:INFO:    plotly-resampler: Not installed
2024-11-13 17:39:35,523:INFO:             kaleido: 0.2.1
2024-11-13 17:39:35,523:INFO:           schemdraw: 0.15
2024-11-13 17:39:35,523:INFO:         statsmodels: 0.13.2
2024-11-13 17:39:35,523:INFO:              sktime: 0.21.1
2024-11-13 17:39:35,523:INFO:               tbats: 1.1.3
2024-11-13 17:39:35,523:INFO:            pmdarima: 2.0.4
2024-11-13 17:39:35,523:INFO:              psutil: 5.9.1
2024-11-13 17:39:35,523:INFO:          markupsafe: 2.1.1
2024-11-13 17:39:35,523:INFO:             pickle5: Not installed
2024-11-13 17:39:35,523:INFO:         cloudpickle: 2.1.0
2024-11-13 17:39:35,523:INFO:         deprecation: 2.1.0
2024-11-13 17:39:35,523:INFO:              xxhash: 3.5.0
2024-11-13 17:39:35,523:INFO:           wurlitzer: 3.1.1
2024-11-13 17:39:35,523:INFO:PyCaret optional dependencies:
2024-11-13 17:39:35,523:INFO:                shap: 0.44.1
2024-11-13 17:39:35,523:INFO:           interpret: 0.6.5
2024-11-13 17:39:35,523:INFO:                umap: 0.5.7
2024-11-13 17:39:35,523:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:39:35,523:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:39:35,523:INFO:             autoviz: Not installed
2024-11-13 17:39:35,523:INFO:           fairlearn: 0.7.0
2024-11-13 17:39:35,523:INFO:          deepchecks: Not installed
2024-11-13 17:39:35,523:INFO:             xgboost: 2.1.1
2024-11-13 17:39:35,523:INFO:            catboost: 1.2.7
2024-11-13 17:39:35,523:INFO:              kmodes: 0.12.2
2024-11-13 17:39:35,523:INFO:             mlxtend: 0.23.1
2024-11-13 17:39:35,523:INFO:       statsforecast: 1.5.0
2024-11-13 17:39:35,523:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:39:35,523:INFO:                 ray: 2.10.0
2024-11-13 17:39:35,523:INFO:            hyperopt: 0.2.7
2024-11-13 17:39:35,523:INFO:              optuna: 4.1.0
2024-11-13 17:39:35,523:INFO:               skopt: 0.10.2
2024-11-13 17:39:35,523:INFO:              mlflow: 1.30.1
2024-11-13 17:39:35,523:INFO:              gradio: 3.50.2
2024-11-13 17:39:35,523:INFO:             fastapi: 0.115.5
2024-11-13 17:39:35,523:INFO:             uvicorn: 0.32.0
2024-11-13 17:39:35,523:INFO:              m2cgen: 0.10.0
2024-11-13 17:39:35,523:INFO:           evidently: 0.2.8
2024-11-13 17:39:35,523:INFO:               fugue: 0.8.6
2024-11-13 17:39:35,523:INFO:           streamlit: Not installed
2024-11-13 17:39:35,524:INFO:             prophet: Not installed
2024-11-13 17:39:35,524:INFO:None
2024-11-13 17:39:35,524:INFO:Set up data.
2024-11-13 17:39:35,530:INFO:Set up folding strategy.
2024-11-13 17:39:35,530:INFO:Set up train/test split.
2024-11-13 17:39:35,534:INFO:Set up index.
2024-11-13 17:39:35,535:INFO:Assigning column types.
2024-11-13 17:39:35,539:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 17:39:35,539:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,543:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,547:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,633:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,635:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,636:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,639:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,643:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,729:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,731:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,732:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 17:39:35,736:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,788:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,825:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,827:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,831:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,835:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,920:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:35,922:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:35,923:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 17:39:35,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:35,980:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,017:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,018:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,021:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,029:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,078:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,115:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,117:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,118:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 17:39:36,172:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,209:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,211:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,267:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,304:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,306:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,306:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 17:39:36,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,400:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,403:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,458:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:39:36,494:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,497:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,497:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 17:39:36,589:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,591:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,686:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,689:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,690:INFO:Preparing preprocessing pipeline...
2024-11-13 17:39:36,690:INFO:Set up simple imputation.
2024-11-13 17:39:36,705:INFO:Finished creating preprocessing pipeline.
2024-11-13 17:39:36,708:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Latitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 17:39:36,709:INFO:Creating final display dataframe.
2024-11-13 17:39:36,764:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Longitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a600
2024-11-13 17:39:36,867:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,870:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,963:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:39:36,965:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:39:36,966:INFO:setup() successfully completed in 1.45s...............
2024-11-13 17:39:51,965:INFO:Initializing compare_models()
2024-11-13 17:39:51,965:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 17:39:51,965:INFO:Checking exceptions
2024-11-13 17:39:51,971:INFO:Preparing display monitor
2024-11-13 17:39:52,015:INFO:Initializing Linear Regression
2024-11-13 17:39:52,015:INFO:Total runtime is 2.5192896525065104e-06 minutes
2024-11-13 17:39:52,019:INFO:SubProcess create_model() called ==================================
2024-11-13 17:39:52,019:INFO:Initializing create_model()
2024-11-13 17:39:52,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:39:52,019:INFO:Checking exceptions
2024-11-13 17:39:52,019:INFO:Importing libraries
2024-11-13 17:39:52,019:INFO:Copying training dataset
2024-11-13 17:39:52,026:INFO:Defining folds
2024-11-13 17:39:52,026:INFO:Declaring metric variables
2024-11-13 17:39:52,030:INFO:Importing untrained model
2024-11-13 17:39:52,033:INFO:Linear Regression Imported successfully
2024-11-13 17:39:52,041:INFO:Starting cross validation
2024-11-13 17:39:52,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:39:55,751:INFO:Calculating mean and std
2024-11-13 17:39:55,756:INFO:Creating metrics dataframe
2024-11-13 17:39:55,762:INFO:Uploading results into container
2024-11-13 17:39:55,763:INFO:Uploading model into container now
2024-11-13 17:39:55,764:INFO:_master_model_container: 1
2024-11-13 17:39:55,764:INFO:_display_container: 2
2024-11-13 17:39:55,764:INFO:LinearRegression(n_jobs=-1)
2024-11-13 17:39:55,764:INFO:create_model() successfully completed......................................
2024-11-13 17:39:55,995:INFO:SubProcess create_model() end ==================================
2024-11-13 17:39:55,996:INFO:Creating metrics dataframe
2024-11-13 17:39:56,005:INFO:Initializing Lasso Regression
2024-11-13 17:39:56,005:INFO:Total runtime is 0.06649986108144124 minutes
2024-11-13 17:39:56,008:INFO:SubProcess create_model() called ==================================
2024-11-13 17:39:56,009:INFO:Initializing create_model()
2024-11-13 17:39:56,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:39:56,009:INFO:Checking exceptions
2024-11-13 17:39:56,009:INFO:Importing libraries
2024-11-13 17:39:56,009:INFO:Copying training dataset
2024-11-13 17:39:56,017:INFO:Defining folds
2024-11-13 17:39:56,017:INFO:Declaring metric variables
2024-11-13 17:39:56,021:INFO:Importing untrained model
2024-11-13 17:39:56,024:INFO:Lasso Regression Imported successfully
2024-11-13 17:39:56,030:INFO:Starting cross validation
2024-11-13 17:39:56,031:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:39:58,955:INFO:Calculating mean and std
2024-11-13 17:39:58,959:INFO:Creating metrics dataframe
2024-11-13 17:39:58,967:INFO:Uploading results into container
2024-11-13 17:39:58,967:INFO:Uploading model into container now
2024-11-13 17:39:58,968:INFO:_master_model_container: 2
2024-11-13 17:39:58,969:INFO:_display_container: 2
2024-11-13 17:39:58,969:INFO:Lasso(random_state=123)
2024-11-13 17:39:58,969:INFO:create_model() successfully completed......................................
2024-11-13 17:39:59,136:INFO:SubProcess create_model() end ==================================
2024-11-13 17:39:59,137:INFO:Creating metrics dataframe
2024-11-13 17:39:59,146:INFO:Initializing Ridge Regression
2024-11-13 17:39:59,147:INFO:Total runtime is 0.11886225541432698 minutes
2024-11-13 17:39:59,150:INFO:SubProcess create_model() called ==================================
2024-11-13 17:39:59,150:INFO:Initializing create_model()
2024-11-13 17:39:59,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:39:59,150:INFO:Checking exceptions
2024-11-13 17:39:59,151:INFO:Importing libraries
2024-11-13 17:39:59,151:INFO:Copying training dataset
2024-11-13 17:39:59,158:INFO:Defining folds
2024-11-13 17:39:59,158:INFO:Declaring metric variables
2024-11-13 17:39:59,161:INFO:Importing untrained model
2024-11-13 17:39:59,164:INFO:Ridge Regression Imported successfully
2024-11-13 17:39:59,171:INFO:Starting cross validation
2024-11-13 17:39:59,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:02,181:INFO:Calculating mean and std
2024-11-13 17:40:02,184:INFO:Creating metrics dataframe
2024-11-13 17:40:02,191:INFO:Uploading results into container
2024-11-13 17:40:02,192:INFO:Uploading model into container now
2024-11-13 17:40:02,192:INFO:_master_model_container: 3
2024-11-13 17:40:02,192:INFO:_display_container: 2
2024-11-13 17:40:02,193:INFO:Ridge(random_state=123)
2024-11-13 17:40:02,193:INFO:create_model() successfully completed......................................
2024-11-13 17:40:02,358:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:02,358:INFO:Creating metrics dataframe
2024-11-13 17:40:02,369:INFO:Initializing Elastic Net
2024-11-13 17:40:02,369:INFO:Total runtime is 0.172568408648173 minutes
2024-11-13 17:40:02,372:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:02,373:INFO:Initializing create_model()
2024-11-13 17:40:02,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:02,373:INFO:Checking exceptions
2024-11-13 17:40:02,373:INFO:Importing libraries
2024-11-13 17:40:02,373:INFO:Copying training dataset
2024-11-13 17:40:02,380:INFO:Defining folds
2024-11-13 17:40:02,380:INFO:Declaring metric variables
2024-11-13 17:40:02,384:INFO:Importing untrained model
2024-11-13 17:40:02,387:INFO:Elastic Net Imported successfully
2024-11-13 17:40:02,394:INFO:Starting cross validation
2024-11-13 17:40:02,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:05,315:INFO:Calculating mean and std
2024-11-13 17:40:05,318:INFO:Creating metrics dataframe
2024-11-13 17:40:05,326:INFO:Uploading results into container
2024-11-13 17:40:05,326:INFO:Uploading model into container now
2024-11-13 17:40:05,327:INFO:_master_model_container: 4
2024-11-13 17:40:05,327:INFO:_display_container: 2
2024-11-13 17:40:05,327:INFO:ElasticNet(random_state=123)
2024-11-13 17:40:05,327:INFO:create_model() successfully completed......................................
2024-11-13 17:40:05,509:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:05,509:INFO:Creating metrics dataframe
2024-11-13 17:40:05,522:INFO:Initializing Least Angle Regression
2024-11-13 17:40:05,522:INFO:Total runtime is 0.22511534293492633 minutes
2024-11-13 17:40:05,525:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:05,526:INFO:Initializing create_model()
2024-11-13 17:40:05,526:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:05,526:INFO:Checking exceptions
2024-11-13 17:40:05,526:INFO:Importing libraries
2024-11-13 17:40:05,526:INFO:Copying training dataset
2024-11-13 17:40:05,534:INFO:Defining folds
2024-11-13 17:40:05,534:INFO:Declaring metric variables
2024-11-13 17:40:05,538:INFO:Importing untrained model
2024-11-13 17:40:05,541:INFO:Least Angle Regression Imported successfully
2024-11-13 17:40:05,548:INFO:Starting cross validation
2024-11-13 17:40:05,549:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:08,162:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,259:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,259:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,260:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,264:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,268:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,334:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,354:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,364:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,368:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:08,385:INFO:Calculating mean and std
2024-11-13 17:40:08,388:INFO:Creating metrics dataframe
2024-11-13 17:40:08,395:INFO:Uploading results into container
2024-11-13 17:40:08,396:INFO:Uploading model into container now
2024-11-13 17:40:08,397:INFO:_master_model_container: 5
2024-11-13 17:40:08,397:INFO:_display_container: 2
2024-11-13 17:40:08,397:INFO:Lars(random_state=123)
2024-11-13 17:40:08,397:INFO:create_model() successfully completed......................................
2024-11-13 17:40:08,583:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:08,584:INFO:Creating metrics dataframe
2024-11-13 17:40:08,595:INFO:Initializing Lasso Least Angle Regression
2024-11-13 17:40:08,595:INFO:Total runtime is 0.27632927894592285 minutes
2024-11-13 17:40:08,598:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:08,598:INFO:Initializing create_model()
2024-11-13 17:40:08,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:08,598:INFO:Checking exceptions
2024-11-13 17:40:08,599:INFO:Importing libraries
2024-11-13 17:40:08,599:INFO:Copying training dataset
2024-11-13 17:40:08,606:INFO:Defining folds
2024-11-13 17:40:08,606:INFO:Declaring metric variables
2024-11-13 17:40:08,609:INFO:Importing untrained model
2024-11-13 17:40:08,613:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 17:40:08,620:INFO:Starting cross validation
2024-11-13 17:40:08,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:08,700:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:08,709:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:08,713:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:08,716:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,134:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,280:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,287:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,333:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,347:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,354:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 17:40:11,370:INFO:Calculating mean and std
2024-11-13 17:40:11,374:INFO:Creating metrics dataframe
2024-11-13 17:40:11,380:INFO:Uploading results into container
2024-11-13 17:40:11,381:INFO:Uploading model into container now
2024-11-13 17:40:11,381:INFO:_master_model_container: 6
2024-11-13 17:40:11,381:INFO:_display_container: 2
2024-11-13 17:40:11,381:INFO:LassoLars(random_state=123)
2024-11-13 17:40:11,382:INFO:create_model() successfully completed......................................
2024-11-13 17:40:11,564:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:11,564:INFO:Creating metrics dataframe
2024-11-13 17:40:11,575:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 17:40:11,575:INFO:Total runtime is 0.3260077913602193 minutes
2024-11-13 17:40:11,579:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:11,579:INFO:Initializing create_model()
2024-11-13 17:40:11,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:11,579:INFO:Checking exceptions
2024-11-13 17:40:11,580:INFO:Importing libraries
2024-11-13 17:40:11,580:INFO:Copying training dataset
2024-11-13 17:40:11,587:INFO:Defining folds
2024-11-13 17:40:11,587:INFO:Declaring metric variables
2024-11-13 17:40:11,590:INFO:Importing untrained model
2024-11-13 17:40:11,593:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 17:40:11,600:INFO:Starting cross validation
2024-11-13 17:40:11,601:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:11,636:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,640:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,657:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,663:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,668:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,689:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,690:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,698:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,704:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,707:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 17:40:11,727:INFO:Calculating mean and std
2024-11-13 17:40:11,731:INFO:Creating metrics dataframe
2024-11-13 17:40:11,738:INFO:Uploading results into container
2024-11-13 17:40:11,739:INFO:Uploading model into container now
2024-11-13 17:40:11,739:INFO:_master_model_container: 7
2024-11-13 17:40:11,740:INFO:_display_container: 2
2024-11-13 17:40:11,740:INFO:OrthogonalMatchingPursuit()
2024-11-13 17:40:11,740:INFO:create_model() successfully completed......................................
2024-11-13 17:40:11,888:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:11,888:INFO:Creating metrics dataframe
2024-11-13 17:40:11,899:INFO:Initializing Bayesian Ridge
2024-11-13 17:40:11,899:INFO:Total runtime is 0.33139901558558144 minutes
2024-11-13 17:40:11,902:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:11,902:INFO:Initializing create_model()
2024-11-13 17:40:11,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:11,903:INFO:Checking exceptions
2024-11-13 17:40:11,903:INFO:Importing libraries
2024-11-13 17:40:11,903:INFO:Copying training dataset
2024-11-13 17:40:11,910:INFO:Defining folds
2024-11-13 17:40:11,910:INFO:Declaring metric variables
2024-11-13 17:40:11,914:INFO:Importing untrained model
2024-11-13 17:40:11,917:INFO:Bayesian Ridge Imported successfully
2024-11-13 17:40:11,923:INFO:Starting cross validation
2024-11-13 17:40:11,924:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:12,020:INFO:Calculating mean and std
2024-11-13 17:40:12,023:INFO:Creating metrics dataframe
2024-11-13 17:40:12,031:INFO:Uploading results into container
2024-11-13 17:40:12,031:INFO:Uploading model into container now
2024-11-13 17:40:12,032:INFO:_master_model_container: 8
2024-11-13 17:40:12,032:INFO:_display_container: 2
2024-11-13 17:40:12,032:INFO:BayesianRidge()
2024-11-13 17:40:12,032:INFO:create_model() successfully completed......................................
2024-11-13 17:40:12,181:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:12,181:INFO:Creating metrics dataframe
2024-11-13 17:40:12,192:INFO:Initializing Passive Aggressive Regressor
2024-11-13 17:40:12,192:INFO:Total runtime is 0.33629222710927326 minutes
2024-11-13 17:40:12,196:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:12,196:INFO:Initializing create_model()
2024-11-13 17:40:12,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:12,196:INFO:Checking exceptions
2024-11-13 17:40:12,197:INFO:Importing libraries
2024-11-13 17:40:12,197:INFO:Copying training dataset
2024-11-13 17:40:12,204:INFO:Defining folds
2024-11-13 17:40:12,204:INFO:Declaring metric variables
2024-11-13 17:40:12,207:INFO:Importing untrained model
2024-11-13 17:40:12,211:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 17:40:12,217:INFO:Starting cross validation
2024-11-13 17:40:12,218:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:12,339:INFO:Calculating mean and std
2024-11-13 17:40:12,342:INFO:Creating metrics dataframe
2024-11-13 17:40:12,350:INFO:Uploading results into container
2024-11-13 17:40:12,351:INFO:Uploading model into container now
2024-11-13 17:40:12,351:INFO:_master_model_container: 9
2024-11-13 17:40:12,351:INFO:_display_container: 2
2024-11-13 17:40:12,352:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 17:40:12,352:INFO:create_model() successfully completed......................................
2024-11-13 17:40:12,538:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:12,538:INFO:Creating metrics dataframe
2024-11-13 17:40:12,550:INFO:Initializing Huber Regressor
2024-11-13 17:40:12,550:INFO:Total runtime is 0.3422567288080851 minutes
2024-11-13 17:40:12,554:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:12,554:INFO:Initializing create_model()
2024-11-13 17:40:12,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:12,554:INFO:Checking exceptions
2024-11-13 17:40:12,554:INFO:Importing libraries
2024-11-13 17:40:12,554:INFO:Copying training dataset
2024-11-13 17:40:12,561:INFO:Defining folds
2024-11-13 17:40:12,561:INFO:Declaring metric variables
2024-11-13 17:40:12,565:INFO:Importing untrained model
2024-11-13 17:40:12,568:INFO:Huber Regressor Imported successfully
2024-11-13 17:40:12,575:INFO:Starting cross validation
2024-11-13 17:40:12,575:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:12,825:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:40:12,905:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 17:40:12,922:INFO:Calculating mean and std
2024-11-13 17:40:12,926:INFO:Creating metrics dataframe
2024-11-13 17:40:12,932:INFO:Uploading results into container
2024-11-13 17:40:12,932:INFO:Uploading model into container now
2024-11-13 17:40:12,933:INFO:_master_model_container: 10
2024-11-13 17:40:12,933:INFO:_display_container: 2
2024-11-13 17:40:12,933:INFO:HuberRegressor()
2024-11-13 17:40:12,933:INFO:create_model() successfully completed......................................
2024-11-13 17:40:13,081:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:13,081:INFO:Creating metrics dataframe
2024-11-13 17:40:13,093:INFO:Initializing K Neighbors Regressor
2024-11-13 17:40:13,093:INFO:Total runtime is 0.3513080358505249 minutes
2024-11-13 17:40:13,097:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:13,097:INFO:Initializing create_model()
2024-11-13 17:40:13,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:13,097:INFO:Checking exceptions
2024-11-13 17:40:13,097:INFO:Importing libraries
2024-11-13 17:40:13,097:INFO:Copying training dataset
2024-11-13 17:40:13,104:INFO:Defining folds
2024-11-13 17:40:13,104:INFO:Declaring metric variables
2024-11-13 17:40:13,108:INFO:Importing untrained model
2024-11-13 17:40:13,111:INFO:K Neighbors Regressor Imported successfully
2024-11-13 17:40:13,118:INFO:Starting cross validation
2024-11-13 17:40:13,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:13,283:INFO:Calculating mean and std
2024-11-13 17:40:13,287:INFO:Creating metrics dataframe
2024-11-13 17:40:13,292:INFO:Uploading results into container
2024-11-13 17:40:13,292:INFO:Uploading model into container now
2024-11-13 17:40:13,293:INFO:_master_model_container: 11
2024-11-13 17:40:13,293:INFO:_display_container: 2
2024-11-13 17:40:13,293:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 17:40:13,293:INFO:create_model() successfully completed......................................
2024-11-13 17:40:13,441:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:13,441:INFO:Creating metrics dataframe
2024-11-13 17:40:13,453:INFO:Initializing Decision Tree Regressor
2024-11-13 17:40:13,453:INFO:Total runtime is 0.35730751355489093 minutes
2024-11-13 17:40:13,457:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:13,457:INFO:Initializing create_model()
2024-11-13 17:40:13,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:13,457:INFO:Checking exceptions
2024-11-13 17:40:13,457:INFO:Importing libraries
2024-11-13 17:40:13,457:INFO:Copying training dataset
2024-11-13 17:40:13,464:INFO:Defining folds
2024-11-13 17:40:13,464:INFO:Declaring metric variables
2024-11-13 17:40:13,468:INFO:Importing untrained model
2024-11-13 17:40:13,471:INFO:Decision Tree Regressor Imported successfully
2024-11-13 17:40:13,477:INFO:Starting cross validation
2024-11-13 17:40:13,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:13,662:INFO:Calculating mean and std
2024-11-13 17:40:13,663:INFO:Creating metrics dataframe
2024-11-13 17:40:13,669:INFO:Uploading results into container
2024-11-13 17:40:13,670:INFO:Uploading model into container now
2024-11-13 17:40:13,670:INFO:_master_model_container: 12
2024-11-13 17:40:13,671:INFO:_display_container: 2
2024-11-13 17:40:13,671:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 17:40:13,671:INFO:create_model() successfully completed......................................
2024-11-13 17:40:13,820:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:13,821:INFO:Creating metrics dataframe
2024-11-13 17:40:13,833:INFO:Initializing Random Forest Regressor
2024-11-13 17:40:13,833:INFO:Total runtime is 0.36363011201222734 minutes
2024-11-13 17:40:13,836:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:13,836:INFO:Initializing create_model()
2024-11-13 17:40:13,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:13,837:INFO:Checking exceptions
2024-11-13 17:40:13,837:INFO:Importing libraries
2024-11-13 17:40:13,837:INFO:Copying training dataset
2024-11-13 17:40:13,844:INFO:Defining folds
2024-11-13 17:40:13,844:INFO:Declaring metric variables
2024-11-13 17:40:13,847:INFO:Importing untrained model
2024-11-13 17:40:13,851:INFO:Random Forest Regressor Imported successfully
2024-11-13 17:40:13,857:INFO:Starting cross validation
2024-11-13 17:40:13,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:15,291:INFO:Calculating mean and std
2024-11-13 17:40:15,295:INFO:Creating metrics dataframe
2024-11-13 17:40:15,302:INFO:Uploading results into container
2024-11-13 17:40:15,303:INFO:Uploading model into container now
2024-11-13 17:40:15,303:INFO:_master_model_container: 13
2024-11-13 17:40:15,303:INFO:_display_container: 2
2024-11-13 17:40:15,304:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:40:15,304:INFO:create_model() successfully completed......................................
2024-11-13 17:40:15,449:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:15,449:INFO:Creating metrics dataframe
2024-11-13 17:40:15,462:INFO:Initializing Extra Trees Regressor
2024-11-13 17:40:15,462:INFO:Total runtime is 0.390779960155487 minutes
2024-11-13 17:40:15,465:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:15,465:INFO:Initializing create_model()
2024-11-13 17:40:15,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:15,465:INFO:Checking exceptions
2024-11-13 17:40:15,465:INFO:Importing libraries
2024-11-13 17:40:15,465:INFO:Copying training dataset
2024-11-13 17:40:15,472:INFO:Defining folds
2024-11-13 17:40:15,472:INFO:Declaring metric variables
2024-11-13 17:40:15,476:INFO:Importing untrained model
2024-11-13 17:40:15,480:INFO:Extra Trees Regressor Imported successfully
2024-11-13 17:40:15,486:INFO:Starting cross validation
2024-11-13 17:40:15,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:16,331:INFO:Calculating mean and std
2024-11-13 17:40:16,336:INFO:Creating metrics dataframe
2024-11-13 17:40:16,341:INFO:Uploading results into container
2024-11-13 17:40:16,342:INFO:Uploading model into container now
2024-11-13 17:40:16,342:INFO:_master_model_container: 14
2024-11-13 17:40:16,342:INFO:_display_container: 2
2024-11-13 17:40:16,343:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:40:16,343:INFO:create_model() successfully completed......................................
2024-11-13 17:40:16,511:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:16,511:INFO:Creating metrics dataframe
2024-11-13 17:40:16,524:INFO:Initializing AdaBoost Regressor
2024-11-13 17:40:16,524:INFO:Total runtime is 0.4084861834843953 minutes
2024-11-13 17:40:16,527:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:16,528:INFO:Initializing create_model()
2024-11-13 17:40:16,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:16,528:INFO:Checking exceptions
2024-11-13 17:40:16,528:INFO:Importing libraries
2024-11-13 17:40:16,528:INFO:Copying training dataset
2024-11-13 17:40:16,535:INFO:Defining folds
2024-11-13 17:40:16,536:INFO:Declaring metric variables
2024-11-13 17:40:16,539:INFO:Importing untrained model
2024-11-13 17:40:16,542:INFO:AdaBoost Regressor Imported successfully
2024-11-13 17:40:16,549:INFO:Starting cross validation
2024-11-13 17:40:16,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:17,321:INFO:Calculating mean and std
2024-11-13 17:40:17,331:INFO:Creating metrics dataframe
2024-11-13 17:40:17,337:INFO:Uploading results into container
2024-11-13 17:40:17,337:INFO:Uploading model into container now
2024-11-13 17:40:17,338:INFO:_master_model_container: 15
2024-11-13 17:40:17,338:INFO:_display_container: 2
2024-11-13 17:40:17,339:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 17:40:17,339:INFO:create_model() successfully completed......................................
2024-11-13 17:40:17,534:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:17,534:INFO:Creating metrics dataframe
2024-11-13 17:40:17,547:INFO:Initializing Gradient Boosting Regressor
2024-11-13 17:40:17,547:INFO:Total runtime is 0.42553798755009964 minutes
2024-11-13 17:40:17,550:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:17,551:INFO:Initializing create_model()
2024-11-13 17:40:17,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:17,551:INFO:Checking exceptions
2024-11-13 17:40:17,551:INFO:Importing libraries
2024-11-13 17:40:17,551:INFO:Copying training dataset
2024-11-13 17:40:17,558:INFO:Defining folds
2024-11-13 17:40:17,558:INFO:Declaring metric variables
2024-11-13 17:40:17,561:INFO:Importing untrained model
2024-11-13 17:40:17,565:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 17:40:17,571:INFO:Starting cross validation
2024-11-13 17:40:17,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:18,852:INFO:Calculating mean and std
2024-11-13 17:40:18,856:INFO:Creating metrics dataframe
2024-11-13 17:40:18,863:INFO:Uploading results into container
2024-11-13 17:40:18,863:INFO:Uploading model into container now
2024-11-13 17:40:18,864:INFO:_master_model_container: 16
2024-11-13 17:40:18,864:INFO:_display_container: 2
2024-11-13 17:40:18,865:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 17:40:18,865:INFO:create_model() successfully completed......................................
2024-11-13 17:40:19,011:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:19,011:INFO:Creating metrics dataframe
2024-11-13 17:40:19,023:INFO:Initializing Extreme Gradient Boosting
2024-11-13 17:40:19,023:INFO:Total runtime is 0.4501405239105224 minutes
2024-11-13 17:40:19,027:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:19,027:INFO:Initializing create_model()
2024-11-13 17:40:19,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:19,027:INFO:Checking exceptions
2024-11-13 17:40:19,027:INFO:Importing libraries
2024-11-13 17:40:19,027:INFO:Copying training dataset
2024-11-13 17:40:19,034:INFO:Defining folds
2024-11-13 17:40:19,034:INFO:Declaring metric variables
2024-11-13 17:40:19,038:INFO:Importing untrained model
2024-11-13 17:40:19,042:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 17:40:19,048:INFO:Starting cross validation
2024-11-13 17:40:19,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:40:19,428:INFO:Calculating mean and std
2024-11-13 17:40:19,432:INFO:Creating metrics dataframe
2024-11-13 17:40:19,439:INFO:Uploading results into container
2024-11-13 17:40:19,439:INFO:Uploading model into container now
2024-11-13 17:40:19,440:INFO:_master_model_container: 17
2024-11-13 17:40:19,440:INFO:_display_container: 2
2024-11-13 17:40:19,441:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 17:40:19,441:INFO:create_model() successfully completed......................................
2024-11-13 17:40:19,589:INFO:SubProcess create_model() end ==================================
2024-11-13 17:40:19,589:INFO:Creating metrics dataframe
2024-11-13 17:40:19,603:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 17:40:19,603:INFO:Total runtime is 0.4597971399625142 minutes
2024-11-13 17:40:19,606:INFO:SubProcess create_model() called ==================================
2024-11-13 17:40:19,606:INFO:Initializing create_model()
2024-11-13 17:40:19,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:40:19,607:INFO:Checking exceptions
2024-11-13 17:40:19,607:INFO:Importing libraries
2024-11-13 17:40:19,607:INFO:Copying training dataset
2024-11-13 17:40:19,614:INFO:Defining folds
2024-11-13 17:40:19,614:INFO:Declaring metric variables
2024-11-13 17:40:19,618:INFO:Importing untrained model
2024-11-13 17:40:19,621:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 17:40:19,628:INFO:Starting cross validation
2024-11-13 17:40:19,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:47:09,302:INFO:Calculating mean and std
2024-11-13 17:47:09,308:INFO:Creating metrics dataframe
2024-11-13 17:47:09,315:INFO:Uploading results into container
2024-11-13 17:47:09,315:INFO:Uploading model into container now
2024-11-13 17:47:09,316:INFO:_master_model_container: 18
2024-11-13 17:47:09,316:INFO:_display_container: 2
2024-11-13 17:47:09,317:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:47:09,317:INFO:create_model() successfully completed......................................
2024-11-13 17:47:09,519:INFO:SubProcess create_model() end ==================================
2024-11-13 17:47:09,519:INFO:Creating metrics dataframe
2024-11-13 17:47:09,532:INFO:Initializing CatBoost Regressor
2024-11-13 17:47:09,533:INFO:Total runtime is 7.291960883140564 minutes
2024-11-13 17:47:09,536:INFO:SubProcess create_model() called ==================================
2024-11-13 17:47:09,536:INFO:Initializing create_model()
2024-11-13 17:47:09,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:47:09,536:INFO:Checking exceptions
2024-11-13 17:47:09,537:INFO:Importing libraries
2024-11-13 17:47:09,537:INFO:Copying training dataset
2024-11-13 17:47:09,544:INFO:Defining folds
2024-11-13 17:47:09,545:INFO:Declaring metric variables
2024-11-13 17:47:09,548:INFO:Importing untrained model
2024-11-13 17:47:09,552:INFO:CatBoost Regressor Imported successfully
2024-11-13 17:47:09,558:INFO:Starting cross validation
2024-11-13 17:47:09,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:47:22,416:INFO:Calculating mean and std
2024-11-13 17:47:22,421:INFO:Creating metrics dataframe
2024-11-13 17:47:22,427:INFO:Uploading results into container
2024-11-13 17:47:22,428:INFO:Uploading model into container now
2024-11-13 17:47:22,429:INFO:_master_model_container: 19
2024-11-13 17:47:22,429:INFO:_display_container: 2
2024-11-13 17:47:22,429:INFO:<catboost.core.CatBoostRegressor object at 0x7ff4bc50a5b0>
2024-11-13 17:47:22,429:INFO:create_model() successfully completed......................................
2024-11-13 17:47:22,610:INFO:SubProcess create_model() end ==================================
2024-11-13 17:47:22,611:INFO:Creating metrics dataframe
2024-11-13 17:47:22,625:INFO:Initializing Dummy Regressor
2024-11-13 17:47:22,625:INFO:Total runtime is 7.5101671854654946 minutes
2024-11-13 17:47:22,628:INFO:SubProcess create_model() called ==================================
2024-11-13 17:47:22,629:INFO:Initializing create_model()
2024-11-13 17:47:22,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6b4c087c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:47:22,629:INFO:Checking exceptions
2024-11-13 17:47:22,629:INFO:Importing libraries
2024-11-13 17:47:22,629:INFO:Copying training dataset
2024-11-13 17:47:22,637:INFO:Defining folds
2024-11-13 17:47:22,637:INFO:Declaring metric variables
2024-11-13 17:47:22,641:INFO:Importing untrained model
2024-11-13 17:47:22,644:INFO:Dummy Regressor Imported successfully
2024-11-13 17:47:22,651:INFO:Starting cross validation
2024-11-13 17:47:22,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 17:47:25,596:INFO:Calculating mean and std
2024-11-13 17:47:25,601:INFO:Creating metrics dataframe
2024-11-13 17:47:25,608:INFO:Uploading results into container
2024-11-13 17:47:25,609:INFO:Uploading model into container now
2024-11-13 17:47:25,610:INFO:_master_model_container: 20
2024-11-13 17:47:25,610:INFO:_display_container: 2
2024-11-13 17:47:25,610:INFO:DummyRegressor()
2024-11-13 17:47:25,610:INFO:create_model() successfully completed......................................
2024-11-13 17:47:25,780:INFO:SubProcess create_model() end ==================================
2024-11-13 17:47:25,780:INFO:Creating metrics dataframe
2024-11-13 17:47:25,804:INFO:Initializing create_model()
2024-11-13 17:47:25,805:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 17:47:25,805:INFO:Checking exceptions
2024-11-13 17:47:25,807:INFO:Importing libraries
2024-11-13 17:47:25,807:INFO:Copying training dataset
2024-11-13 17:47:25,814:INFO:Defining folds
2024-11-13 17:47:25,814:INFO:Declaring metric variables
2024-11-13 17:47:25,814:INFO:Importing untrained model
2024-11-13 17:47:25,814:INFO:Declaring custom model
2024-11-13 17:47:25,815:INFO:Extra Trees Regressor Imported successfully
2024-11-13 17:47:25,816:INFO:Cross validation set to False
2024-11-13 17:47:25,816:INFO:Fitting Model
2024-11-13 17:47:26,055:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:47:26,055:INFO:create_model() successfully completed......................................
2024-11-13 17:47:26,279:INFO:_master_model_container: 20
2024-11-13 17:47:26,279:INFO:_display_container: 2
2024-11-13 17:47:26,280:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 17:47:26,280:INFO:compare_models() successfully completed......................................
2024-11-13 17:47:46,349:INFO:Initializing plot_model()
2024-11-13 17:47:46,349:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, system=True)
2024-11-13 17:47:46,349:INFO:Checking exceptions
2024-11-13 17:47:46,417:INFO:Preloading libraries
2024-11-13 17:47:46,613:INFO:Copying training dataset
2024-11-13 17:47:46,613:INFO:Plot type: residuals
2024-11-13 17:47:46,692:INFO:Fitting Model
2024-11-13 17:47:46,692:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-13 17:47:46,868:INFO:Scoring test/hold-out set
2024-11-13 17:47:47,619:INFO:Visual Rendered Successfully
2024-11-13 17:47:47,839:INFO:plot_model() successfully completed......................................
2024-11-13 17:49:10,637:INFO:Initializing plot_model()
2024-11-13 17:49:10,638:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, system=True)
2024-11-13 17:49:10,638:INFO:Checking exceptions
2024-11-13 17:49:10,702:INFO:Preloading libraries
2024-11-13 17:49:10,875:INFO:Copying training dataset
2024-11-13 17:49:10,875:INFO:Plot type: error
2024-11-13 17:49:10,929:INFO:Fitting Model
2024-11-13 17:49:10,929:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-13 17:49:10,929:INFO:Scoring test/hold-out set
2024-11-13 17:49:11,389:INFO:Visual Rendered Successfully
2024-11-13 17:49:11,569:INFO:plot_model() successfully completed......................................
2024-11-13 17:50:24,994:INFO:Initializing plot_model()
2024-11-13 17:50:24,995:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c6bead30>, system=True)
2024-11-13 17:50:24,995:INFO:Checking exceptions
2024-11-13 17:50:25,048:INFO:Preloading libraries
2024-11-13 17:50:25,223:INFO:Copying training dataset
2024-11-13 17:50:25,223:INFO:Plot type: feature
2024-11-13 17:50:25,224:WARNING:No coef_ found. Trying feature_importances_
2024-11-13 17:50:25,399:INFO:Visual Rendered Successfully
2024-11-13 17:50:25,570:INFO:plot_model() successfully completed......................................
2024-11-13 17:59:59,572:INFO:PyCaret RegressionExperiment
2024-11-13 17:59:59,572:INFO:Logging name: reg-default-name
2024-11-13 17:59:59,572:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 17:59:59,572:INFO:version 3.2.0
2024-11-13 17:59:59,572:INFO:Initializing setup()
2024-11-13 17:59:59,572:INFO:self.USI: 4bf0
2024-11-13 17:59:59,572:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 17:59:59,573:INFO:Checking environment
2024-11-13 17:59:59,573:INFO:python_version: 3.8.13
2024-11-13 17:59:59,573:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 17:59:59,573:INFO:machine: x86_64
2024-11-13 17:59:59,573:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:59:59,573:INFO:Memory: svmem(total=270355722240, available=218218041344, percent=19.3, used=50056511488, free=56192413696, active=11650326528, inactive=142257721344, buffers=8888320, cached=164097908736, shared=187363328, slab=25014046720)
2024-11-13 17:59:59,576:INFO:Physical Core: 28
2024-11-13 17:59:59,576:INFO:Logical Core: 56
2024-11-13 17:59:59,576:INFO:Checking libraries
2024-11-13 17:59:59,576:INFO:System:
2024-11-13 17:59:59,576:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 17:59:59,576:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 17:59:59,576:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 17:59:59,576:INFO:PyCaret required dependencies:
2024-11-13 17:59:59,576:INFO:                 pip: 22.2.2
2024-11-13 17:59:59,576:INFO:          setuptools: 63.4.2
2024-11-13 17:59:59,576:INFO:             pycaret: 3.2.0
2024-11-13 17:59:59,576:INFO:             IPython: 8.12.2
2024-11-13 17:59:59,576:INFO:          ipywidgets: 7.7.1
2024-11-13 17:59:59,576:INFO:                tqdm: 4.64.1
2024-11-13 17:59:59,576:INFO:               numpy: 1.23.5
2024-11-13 17:59:59,576:INFO:              pandas: 1.5.3
2024-11-13 17:59:59,576:INFO:              jinja2: 3.1.2
2024-11-13 17:59:59,576:INFO:               scipy: 1.10.1
2024-11-13 17:59:59,576:INFO:              joblib: 1.3.0
2024-11-13 17:59:59,576:INFO:             sklearn: 1.1.2
2024-11-13 17:59:59,576:INFO:                pyod: 2.0.2
2024-11-13 17:59:59,576:INFO:            imblearn: 0.12.4
2024-11-13 17:59:59,576:INFO:   category_encoders: 2.6.4
2024-11-13 17:59:59,577:INFO:            lightgbm: 4.5.0
2024-11-13 17:59:59,577:INFO:               numba: 0.57.1
2024-11-13 17:59:59,577:INFO:            requests: 2.28.1
2024-11-13 17:59:59,577:INFO:          matplotlib: 3.5.1
2024-11-13 17:59:59,577:INFO:          scikitplot: 0.3.7
2024-11-13 17:59:59,577:INFO:         yellowbrick: 1.5
2024-11-13 17:59:59,577:INFO:              plotly: 5.24.1
2024-11-13 17:59:59,577:INFO:    plotly-resampler: Not installed
2024-11-13 17:59:59,577:INFO:             kaleido: 0.2.1
2024-11-13 17:59:59,577:INFO:           schemdraw: 0.15
2024-11-13 17:59:59,577:INFO:         statsmodels: 0.13.2
2024-11-13 17:59:59,577:INFO:              sktime: 0.21.1
2024-11-13 17:59:59,577:INFO:               tbats: 1.1.3
2024-11-13 17:59:59,577:INFO:            pmdarima: 2.0.4
2024-11-13 17:59:59,577:INFO:              psutil: 5.9.1
2024-11-13 17:59:59,577:INFO:          markupsafe: 2.1.1
2024-11-13 17:59:59,577:INFO:             pickle5: Not installed
2024-11-13 17:59:59,577:INFO:         cloudpickle: 2.1.0
2024-11-13 17:59:59,577:INFO:         deprecation: 2.1.0
2024-11-13 17:59:59,577:INFO:              xxhash: 3.5.0
2024-11-13 17:59:59,577:INFO:           wurlitzer: 3.1.1
2024-11-13 17:59:59,577:INFO:PyCaret optional dependencies:
2024-11-13 17:59:59,577:INFO:                shap: 0.44.1
2024-11-13 17:59:59,577:INFO:           interpret: 0.6.5
2024-11-13 17:59:59,577:INFO:                umap: 0.5.7
2024-11-13 17:59:59,577:INFO:     ydata_profiling: 4.6.0
2024-11-13 17:59:59,577:INFO:  explainerdashboard: 0.4.7
2024-11-13 17:59:59,577:INFO:             autoviz: Not installed
2024-11-13 17:59:59,577:INFO:           fairlearn: 0.7.0
2024-11-13 17:59:59,577:INFO:          deepchecks: Not installed
2024-11-13 17:59:59,577:INFO:             xgboost: 2.1.1
2024-11-13 17:59:59,577:INFO:            catboost: 1.2.7
2024-11-13 17:59:59,578:INFO:              kmodes: 0.12.2
2024-11-13 17:59:59,578:INFO:             mlxtend: 0.23.1
2024-11-13 17:59:59,578:INFO:       statsforecast: 1.5.0
2024-11-13 17:59:59,578:INFO:        tune_sklearn: 0.5.0
2024-11-13 17:59:59,578:INFO:                 ray: 2.10.0
2024-11-13 17:59:59,578:INFO:            hyperopt: 0.2.7
2024-11-13 17:59:59,578:INFO:              optuna: 4.1.0
2024-11-13 17:59:59,578:INFO:               skopt: 0.10.2
2024-11-13 17:59:59,578:INFO:              mlflow: 1.30.1
2024-11-13 17:59:59,578:INFO:              gradio: 3.50.2
2024-11-13 17:59:59,578:INFO:             fastapi: 0.115.5
2024-11-13 17:59:59,578:INFO:             uvicorn: 0.32.0
2024-11-13 17:59:59,578:INFO:              m2cgen: 0.10.0
2024-11-13 17:59:59,578:INFO:           evidently: 0.2.8
2024-11-13 17:59:59,578:INFO:               fugue: 0.8.6
2024-11-13 17:59:59,578:INFO:           streamlit: Not installed
2024-11-13 17:59:59,578:INFO:             prophet: Not installed
2024-11-13 17:59:59,578:INFO:None
2024-11-13 17:59:59,578:INFO:Set up data.
2024-11-13 17:59:59,589:INFO:Set up folding strategy.
2024-11-13 17:59:59,589:INFO:Set up train/test split.
2024-11-13 17:59:59,594:INFO:Set up index.
2024-11-13 17:59:59,595:INFO:Assigning column types.
2024-11-13 17:59:59,600:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 17:59:59,600:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,605:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,610:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,708:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,709:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:59:59,711:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:59:59,712:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,716:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,719:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,768:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,805:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,806:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:59:59,808:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:59:59,809:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 17:59:59,812:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,816:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,864:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,903:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 17:59:59,905:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 17:59:59,909:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,913:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 17:59:59,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,000:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,002:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,003:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:00:00,011:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,098:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,100:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,108:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,156:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,194:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,196:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,197:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:00:00,253:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,290:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,292:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,387:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,388:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,390:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,391:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:00:00,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,485:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,488:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:00:00,583:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,585:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,585:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:00:00,679:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,681:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,776:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,778:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:00,779:INFO:Preparing preprocessing pipeline...
2024-11-13 18:00:00,779:INFO:Set up simple imputation.
2024-11-13 18:00:00,796:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:00:00,800:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['USA_WSPD', 'MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:00:00,800:INFO:Creating final display dataframe.
2024-11-13 18:00:00,854:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 8)
4        Transformed data shape        (31316, 8)
5   Transformed train set shape        (21921, 8)
6    Transformed test set shape         (9395, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4bf0
2024-11-13 18:00:00,962:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:00,964:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:01,058:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:00:01,060:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:00:01,061:INFO:setup() successfully completed in 1.49s...............
2024-11-13 18:02:40,355:INFO:Initializing compare_models()
2024-11-13 18:02:40,356:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:02:40,356:INFO:Checking exceptions
2024-11-13 18:02:40,363:INFO:Preparing display monitor
2024-11-13 18:02:40,407:INFO:Initializing Linear Regression
2024-11-13 18:02:40,407:INFO:Total runtime is 2.4040540059407553e-06 minutes
2024-11-13 18:02:40,410:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:40,411:INFO:Initializing create_model()
2024-11-13 18:02:40,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:40,411:INFO:Checking exceptions
2024-11-13 18:02:40,411:INFO:Importing libraries
2024-11-13 18:02:40,411:INFO:Copying training dataset
2024-11-13 18:02:40,418:INFO:Defining folds
2024-11-13 18:02:40,418:INFO:Declaring metric variables
2024-11-13 18:02:40,421:INFO:Importing untrained model
2024-11-13 18:02:40,425:INFO:Linear Regression Imported successfully
2024-11-13 18:02:40,433:INFO:Starting cross validation
2024-11-13 18:02:40,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:44,421:INFO:Calculating mean and std
2024-11-13 18:02:44,426:INFO:Creating metrics dataframe
2024-11-13 18:02:44,433:INFO:Uploading results into container
2024-11-13 18:02:44,434:INFO:Uploading model into container now
2024-11-13 18:02:44,434:INFO:_master_model_container: 1
2024-11-13 18:02:44,435:INFO:_display_container: 2
2024-11-13 18:02:44,435:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:02:44,435:INFO:create_model() successfully completed......................................
2024-11-13 18:02:44,690:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:44,691:INFO:Creating metrics dataframe
2024-11-13 18:02:44,701:INFO:Initializing Lasso Regression
2024-11-13 18:02:44,701:INFO:Total runtime is 0.07156848112742106 minutes
2024-11-13 18:02:44,705:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:44,705:INFO:Initializing create_model()
2024-11-13 18:02:44,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:44,705:INFO:Checking exceptions
2024-11-13 18:02:44,705:INFO:Importing libraries
2024-11-13 18:02:44,705:INFO:Copying training dataset
2024-11-13 18:02:44,714:INFO:Defining folds
2024-11-13 18:02:44,714:INFO:Declaring metric variables
2024-11-13 18:02:44,718:INFO:Importing untrained model
2024-11-13 18:02:44,721:INFO:Lasso Regression Imported successfully
2024-11-13 18:02:44,728:INFO:Starting cross validation
2024-11-13 18:02:44,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:47,610:INFO:Calculating mean and std
2024-11-13 18:02:47,613:INFO:Creating metrics dataframe
2024-11-13 18:02:47,619:INFO:Uploading results into container
2024-11-13 18:02:47,620:INFO:Uploading model into container now
2024-11-13 18:02:47,620:INFO:_master_model_container: 2
2024-11-13 18:02:47,620:INFO:_display_container: 2
2024-11-13 18:02:47,621:INFO:Lasso(random_state=123)
2024-11-13 18:02:47,621:INFO:create_model() successfully completed......................................
2024-11-13 18:02:47,797:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:47,797:INFO:Creating metrics dataframe
2024-11-13 18:02:47,807:INFO:Initializing Ridge Regression
2024-11-13 18:02:47,807:INFO:Total runtime is 0.1233436147371928 minutes
2024-11-13 18:02:47,811:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:47,811:INFO:Initializing create_model()
2024-11-13 18:02:47,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:47,811:INFO:Checking exceptions
2024-11-13 18:02:47,811:INFO:Importing libraries
2024-11-13 18:02:47,811:INFO:Copying training dataset
2024-11-13 18:02:47,818:INFO:Defining folds
2024-11-13 18:02:47,818:INFO:Declaring metric variables
2024-11-13 18:02:47,822:INFO:Importing untrained model
2024-11-13 18:02:47,825:INFO:Ridge Regression Imported successfully
2024-11-13 18:02:47,832:INFO:Starting cross validation
2024-11-13 18:02:47,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:50,608:INFO:Calculating mean and std
2024-11-13 18:02:50,612:INFO:Creating metrics dataframe
2024-11-13 18:02:50,619:INFO:Uploading results into container
2024-11-13 18:02:50,620:INFO:Uploading model into container now
2024-11-13 18:02:50,621:INFO:_master_model_container: 3
2024-11-13 18:02:50,621:INFO:_display_container: 2
2024-11-13 18:02:50,621:INFO:Ridge(random_state=123)
2024-11-13 18:02:50,621:INFO:create_model() successfully completed......................................
2024-11-13 18:02:50,796:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:50,796:INFO:Creating metrics dataframe
2024-11-13 18:02:50,807:INFO:Initializing Elastic Net
2024-11-13 18:02:50,807:INFO:Total runtime is 0.17333312034606935 minutes
2024-11-13 18:02:50,810:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:50,810:INFO:Initializing create_model()
2024-11-13 18:02:50,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:50,811:INFO:Checking exceptions
2024-11-13 18:02:50,811:INFO:Importing libraries
2024-11-13 18:02:50,811:INFO:Copying training dataset
2024-11-13 18:02:50,817:INFO:Defining folds
2024-11-13 18:02:50,818:INFO:Declaring metric variables
2024-11-13 18:02:50,821:INFO:Importing untrained model
2024-11-13 18:02:50,824:INFO:Elastic Net Imported successfully
2024-11-13 18:02:50,831:INFO:Starting cross validation
2024-11-13 18:02:50,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:53,715:INFO:Calculating mean and std
2024-11-13 18:02:53,719:INFO:Creating metrics dataframe
2024-11-13 18:02:53,725:INFO:Uploading results into container
2024-11-13 18:02:53,725:INFO:Uploading model into container now
2024-11-13 18:02:53,726:INFO:_master_model_container: 4
2024-11-13 18:02:53,726:INFO:_display_container: 2
2024-11-13 18:02:53,726:INFO:ElasticNet(random_state=123)
2024-11-13 18:02:53,726:INFO:create_model() successfully completed......................................
2024-11-13 18:02:53,912:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:53,912:INFO:Creating metrics dataframe
2024-11-13 18:02:53,925:INFO:Initializing Least Angle Regression
2024-11-13 18:02:53,925:INFO:Total runtime is 0.22530497709910074 minutes
2024-11-13 18:02:53,928:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:53,929:INFO:Initializing create_model()
2024-11-13 18:02:53,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:53,929:INFO:Checking exceptions
2024-11-13 18:02:53,929:INFO:Importing libraries
2024-11-13 18:02:53,929:INFO:Copying training dataset
2024-11-13 18:02:53,936:INFO:Defining folds
2024-11-13 18:02:53,937:INFO:Declaring metric variables
2024-11-13 18:02:53,940:INFO:Importing untrained model
2024-11-13 18:02:53,944:INFO:Least Angle Regression Imported successfully
2024-11-13 18:02:53,950:INFO:Starting cross validation
2024-11-13 18:02:53,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:56,615:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,624:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,628:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.407e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:02:56,650:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,663:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,694:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,720:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,721:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,728:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,761:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,764:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.478e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:02:56,768:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:02:56,772:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.949e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:02:56,772:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.974e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:02:56,789:INFO:Calculating mean and std
2024-11-13 18:02:56,793:INFO:Creating metrics dataframe
2024-11-13 18:02:56,800:INFO:Uploading results into container
2024-11-13 18:02:56,800:INFO:Uploading model into container now
2024-11-13 18:02:56,801:INFO:_master_model_container: 5
2024-11-13 18:02:56,801:INFO:_display_container: 2
2024-11-13 18:02:56,802:INFO:Lars(random_state=123)
2024-11-13 18:02:56,802:INFO:create_model() successfully completed......................................
2024-11-13 18:02:57,003:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:57,003:INFO:Creating metrics dataframe
2024-11-13 18:02:57,015:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:02:57,015:INFO:Total runtime is 0.27679969867070514 minutes
2024-11-13 18:02:57,018:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:57,018:INFO:Initializing create_model()
2024-11-13 18:02:57,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:57,019:INFO:Checking exceptions
2024-11-13 18:02:57,019:INFO:Importing libraries
2024-11-13 18:02:57,019:INFO:Copying training dataset
2024-11-13 18:02:57,025:INFO:Defining folds
2024-11-13 18:02:57,026:INFO:Declaring metric variables
2024-11-13 18:02:57,029:INFO:Importing untrained model
2024-11-13 18:02:57,033:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:02:57,039:INFO:Starting cross validation
2024-11-13 18:02:57,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:02:57,129:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:57,135:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:57,141:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:57,146:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,555:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,587:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,726:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,743:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,757:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,801:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:02:59,813:INFO:Calculating mean and std
2024-11-13 18:02:59,817:INFO:Creating metrics dataframe
2024-11-13 18:02:59,823:INFO:Uploading results into container
2024-11-13 18:02:59,824:INFO:Uploading model into container now
2024-11-13 18:02:59,825:INFO:_master_model_container: 6
2024-11-13 18:02:59,825:INFO:_display_container: 2
2024-11-13 18:02:59,825:INFO:LassoLars(random_state=123)
2024-11-13 18:02:59,825:INFO:create_model() successfully completed......................................
2024-11-13 18:02:59,980:INFO:SubProcess create_model() end ==================================
2024-11-13 18:02:59,981:INFO:Creating metrics dataframe
2024-11-13 18:02:59,991:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:02:59,992:INFO:Total runtime is 0.326414414246877 minutes
2024-11-13 18:02:59,995:INFO:SubProcess create_model() called ==================================
2024-11-13 18:02:59,995:INFO:Initializing create_model()
2024-11-13 18:02:59,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:02:59,995:INFO:Checking exceptions
2024-11-13 18:02:59,996:INFO:Importing libraries
2024-11-13 18:02:59,996:INFO:Copying training dataset
2024-11-13 18:03:00,002:INFO:Defining folds
2024-11-13 18:03:00,003:INFO:Declaring metric variables
2024-11-13 18:03:00,006:INFO:Importing untrained model
2024-11-13 18:03:00,010:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:03:00,016:INFO:Starting cross validation
2024-11-13 18:03:00,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:00,048:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,053:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,060:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,066:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,074:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,082:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,082:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,092:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,096:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,116:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:03:00,133:INFO:Calculating mean and std
2024-11-13 18:03:00,135:INFO:Creating metrics dataframe
2024-11-13 18:03:00,141:INFO:Uploading results into container
2024-11-13 18:03:00,142:INFO:Uploading model into container now
2024-11-13 18:03:00,142:INFO:_master_model_container: 7
2024-11-13 18:03:00,142:INFO:_display_container: 2
2024-11-13 18:03:00,143:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:03:00,143:INFO:create_model() successfully completed......................................
2024-11-13 18:03:00,294:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:00,295:INFO:Creating metrics dataframe
2024-11-13 18:03:00,306:INFO:Initializing Bayesian Ridge
2024-11-13 18:03:00,306:INFO:Total runtime is 0.331656547387441 minutes
2024-11-13 18:03:00,309:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:00,310:INFO:Initializing create_model()
2024-11-13 18:03:00,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:00,310:INFO:Checking exceptions
2024-11-13 18:03:00,310:INFO:Importing libraries
2024-11-13 18:03:00,310:INFO:Copying training dataset
2024-11-13 18:03:00,316:INFO:Defining folds
2024-11-13 18:03:00,317:INFO:Declaring metric variables
2024-11-13 18:03:00,320:INFO:Importing untrained model
2024-11-13 18:03:00,323:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:03:00,329:INFO:Starting cross validation
2024-11-13 18:03:00,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:00,476:INFO:Calculating mean and std
2024-11-13 18:03:00,480:INFO:Creating metrics dataframe
2024-11-13 18:03:00,487:INFO:Uploading results into container
2024-11-13 18:03:00,488:INFO:Uploading model into container now
2024-11-13 18:03:00,488:INFO:_master_model_container: 8
2024-11-13 18:03:00,488:INFO:_display_container: 2
2024-11-13 18:03:00,489:INFO:BayesianRidge()
2024-11-13 18:03:00,489:INFO:create_model() successfully completed......................................
2024-11-13 18:03:00,654:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:00,654:INFO:Creating metrics dataframe
2024-11-13 18:03:00,665:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:03:00,665:INFO:Total runtime is 0.33764466842015584 minutes
2024-11-13 18:03:00,669:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:00,669:INFO:Initializing create_model()
2024-11-13 18:03:00,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:00,670:INFO:Checking exceptions
2024-11-13 18:03:00,670:INFO:Importing libraries
2024-11-13 18:03:00,670:INFO:Copying training dataset
2024-11-13 18:03:00,676:INFO:Defining folds
2024-11-13 18:03:00,676:INFO:Declaring metric variables
2024-11-13 18:03:00,680:INFO:Importing untrained model
2024-11-13 18:03:00,683:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:03:00,689:INFO:Starting cross validation
2024-11-13 18:03:00,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:00,801:INFO:Calculating mean and std
2024-11-13 18:03:00,805:INFO:Creating metrics dataframe
2024-11-13 18:03:00,811:INFO:Uploading results into container
2024-11-13 18:03:00,812:INFO:Uploading model into container now
2024-11-13 18:03:00,812:INFO:_master_model_container: 9
2024-11-13 18:03:00,812:INFO:_display_container: 2
2024-11-13 18:03:00,813:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:03:00,813:INFO:create_model() successfully completed......................................
2024-11-13 18:03:00,978:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:00,978:INFO:Creating metrics dataframe
2024-11-13 18:03:00,990:INFO:Initializing Huber Regressor
2024-11-13 18:03:00,991:INFO:Total runtime is 0.34306368430455525 minutes
2024-11-13 18:03:00,994:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:00,994:INFO:Initializing create_model()
2024-11-13 18:03:00,994:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:00,994:INFO:Checking exceptions
2024-11-13 18:03:00,994:INFO:Importing libraries
2024-11-13 18:03:00,995:INFO:Copying training dataset
2024-11-13 18:03:01,003:INFO:Defining folds
2024-11-13 18:03:01,003:INFO:Declaring metric variables
2024-11-13 18:03:01,006:INFO:Importing untrained model
2024-11-13 18:03:01,009:INFO:Huber Regressor Imported successfully
2024-11-13 18:03:01,016:INFO:Starting cross validation
2024-11-13 18:03:01,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:01,288:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,298:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,310:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,323:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,336:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,341:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,367:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,367:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,371:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:03:01,384:INFO:Calculating mean and std
2024-11-13 18:03:01,387:INFO:Creating metrics dataframe
2024-11-13 18:03:01,394:INFO:Uploading results into container
2024-11-13 18:03:01,395:INFO:Uploading model into container now
2024-11-13 18:03:01,395:INFO:_master_model_container: 10
2024-11-13 18:03:01,396:INFO:_display_container: 2
2024-11-13 18:03:01,396:INFO:HuberRegressor()
2024-11-13 18:03:01,396:INFO:create_model() successfully completed......................................
2024-11-13 18:03:01,544:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:01,544:INFO:Creating metrics dataframe
2024-11-13 18:03:01,556:INFO:Initializing K Neighbors Regressor
2024-11-13 18:03:01,556:INFO:Total runtime is 0.35249264240264894 minutes
2024-11-13 18:03:01,560:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:01,560:INFO:Initializing create_model()
2024-11-13 18:03:01,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:01,560:INFO:Checking exceptions
2024-11-13 18:03:01,560:INFO:Importing libraries
2024-11-13 18:03:01,560:INFO:Copying training dataset
2024-11-13 18:03:01,567:INFO:Defining folds
2024-11-13 18:03:01,567:INFO:Declaring metric variables
2024-11-13 18:03:01,571:INFO:Importing untrained model
2024-11-13 18:03:01,574:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:03:01,580:INFO:Starting cross validation
2024-11-13 18:03:01,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:01,802:INFO:Calculating mean and std
2024-11-13 18:03:01,806:INFO:Creating metrics dataframe
2024-11-13 18:03:01,812:INFO:Uploading results into container
2024-11-13 18:03:01,813:INFO:Uploading model into container now
2024-11-13 18:03:01,814:INFO:_master_model_container: 11
2024-11-13 18:03:01,814:INFO:_display_container: 2
2024-11-13 18:03:01,815:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:03:01,815:INFO:create_model() successfully completed......................................
2024-11-13 18:03:02,001:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:02,001:INFO:Creating metrics dataframe
2024-11-13 18:03:02,013:INFO:Initializing Decision Tree Regressor
2024-11-13 18:03:02,013:INFO:Total runtime is 0.3601103901863098 minutes
2024-11-13 18:03:02,017:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:02,017:INFO:Initializing create_model()
2024-11-13 18:03:02,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:02,017:INFO:Checking exceptions
2024-11-13 18:03:02,017:INFO:Importing libraries
2024-11-13 18:03:02,017:INFO:Copying training dataset
2024-11-13 18:03:02,024:INFO:Defining folds
2024-11-13 18:03:02,024:INFO:Declaring metric variables
2024-11-13 18:03:02,028:INFO:Importing untrained model
2024-11-13 18:03:02,031:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:03:02,038:INFO:Starting cross validation
2024-11-13 18:03:02,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:02,170:INFO:Calculating mean and std
2024-11-13 18:03:02,173:INFO:Creating metrics dataframe
2024-11-13 18:03:02,180:INFO:Uploading results into container
2024-11-13 18:03:02,180:INFO:Uploading model into container now
2024-11-13 18:03:02,181:INFO:_master_model_container: 12
2024-11-13 18:03:02,181:INFO:_display_container: 2
2024-11-13 18:03:02,182:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:03:02,182:INFO:create_model() successfully completed......................................
2024-11-13 18:03:02,355:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:02,355:INFO:Creating metrics dataframe
2024-11-13 18:03:02,367:INFO:Initializing Random Forest Regressor
2024-11-13 18:03:02,367:INFO:Total runtime is 0.3660059054692586 minutes
2024-11-13 18:03:02,370:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:02,371:INFO:Initializing create_model()
2024-11-13 18:03:02,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:02,371:INFO:Checking exceptions
2024-11-13 18:03:02,371:INFO:Importing libraries
2024-11-13 18:03:02,371:INFO:Copying training dataset
2024-11-13 18:03:02,378:INFO:Defining folds
2024-11-13 18:03:02,378:INFO:Declaring metric variables
2024-11-13 18:03:02,381:INFO:Importing untrained model
2024-11-13 18:03:02,385:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:03:02,391:INFO:Starting cross validation
2024-11-13 18:03:02,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:03,345:INFO:Calculating mean and std
2024-11-13 18:03:03,350:INFO:Creating metrics dataframe
2024-11-13 18:03:03,355:INFO:Uploading results into container
2024-11-13 18:03:03,356:INFO:Uploading model into container now
2024-11-13 18:03:03,357:INFO:_master_model_container: 13
2024-11-13 18:03:03,357:INFO:_display_container: 2
2024-11-13 18:03:03,357:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:03:03,358:INFO:create_model() successfully completed......................................
2024-11-13 18:03:03,522:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:03,522:INFO:Creating metrics dataframe
2024-11-13 18:03:03,535:INFO:Initializing Extra Trees Regressor
2024-11-13 18:03:03,535:INFO:Total runtime is 0.38546599149703975 minutes
2024-11-13 18:03:03,538:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:03,538:INFO:Initializing create_model()
2024-11-13 18:03:03,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:03,539:INFO:Checking exceptions
2024-11-13 18:03:03,539:INFO:Importing libraries
2024-11-13 18:03:03,539:INFO:Copying training dataset
2024-11-13 18:03:03,547:INFO:Defining folds
2024-11-13 18:03:03,547:INFO:Declaring metric variables
2024-11-13 18:03:03,550:INFO:Importing untrained model
2024-11-13 18:03:03,554:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:03:03,561:INFO:Starting cross validation
2024-11-13 18:03:03,562:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:04,088:INFO:Calculating mean and std
2024-11-13 18:03:04,091:INFO:Creating metrics dataframe
2024-11-13 18:03:04,099:INFO:Uploading results into container
2024-11-13 18:03:04,099:INFO:Uploading model into container now
2024-11-13 18:03:04,100:INFO:_master_model_container: 14
2024-11-13 18:03:04,100:INFO:_display_container: 2
2024-11-13 18:03:04,100:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:03:04,100:INFO:create_model() successfully completed......................................
2024-11-13 18:03:04,250:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:04,250:INFO:Creating metrics dataframe
2024-11-13 18:03:04,263:INFO:Initializing AdaBoost Regressor
2024-11-13 18:03:04,263:INFO:Total runtime is 0.39761166969935097 minutes
2024-11-13 18:03:04,267:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:04,267:INFO:Initializing create_model()
2024-11-13 18:03:04,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:04,267:INFO:Checking exceptions
2024-11-13 18:03:04,267:INFO:Importing libraries
2024-11-13 18:03:04,267:INFO:Copying training dataset
2024-11-13 18:03:04,274:INFO:Defining folds
2024-11-13 18:03:04,274:INFO:Declaring metric variables
2024-11-13 18:03:04,278:INFO:Importing untrained model
2024-11-13 18:03:04,281:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:03:04,293:INFO:Starting cross validation
2024-11-13 18:03:04,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:05,029:INFO:Calculating mean and std
2024-11-13 18:03:05,034:INFO:Creating metrics dataframe
2024-11-13 18:03:05,041:INFO:Uploading results into container
2024-11-13 18:03:05,041:INFO:Uploading model into container now
2024-11-13 18:03:05,042:INFO:_master_model_container: 15
2024-11-13 18:03:05,042:INFO:_display_container: 2
2024-11-13 18:03:05,043:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:03:05,043:INFO:create_model() successfully completed......................................
2024-11-13 18:03:05,225:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:05,226:INFO:Creating metrics dataframe
2024-11-13 18:03:05,239:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:03:05,239:INFO:Total runtime is 0.41386729081471757 minutes
2024-11-13 18:03:05,242:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:05,242:INFO:Initializing create_model()
2024-11-13 18:03:05,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:05,243:INFO:Checking exceptions
2024-11-13 18:03:05,243:INFO:Importing libraries
2024-11-13 18:03:05,243:INFO:Copying training dataset
2024-11-13 18:03:05,250:INFO:Defining folds
2024-11-13 18:03:05,250:INFO:Declaring metric variables
2024-11-13 18:03:05,253:INFO:Importing untrained model
2024-11-13 18:03:05,257:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:03:05,263:INFO:Starting cross validation
2024-11-13 18:03:05,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:07,074:INFO:Calculating mean and std
2024-11-13 18:03:07,078:INFO:Creating metrics dataframe
2024-11-13 18:03:07,084:INFO:Uploading results into container
2024-11-13 18:03:07,085:INFO:Uploading model into container now
2024-11-13 18:03:07,085:INFO:_master_model_container: 16
2024-11-13 18:03:07,085:INFO:_display_container: 2
2024-11-13 18:03:07,086:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:03:07,086:INFO:create_model() successfully completed......................................
2024-11-13 18:03:07,309:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:07,310:INFO:Creating metrics dataframe
2024-11-13 18:03:07,324:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:03:07,324:INFO:Total runtime is 0.4486217419306437 minutes
2024-11-13 18:03:07,327:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:07,328:INFO:Initializing create_model()
2024-11-13 18:03:07,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:07,328:INFO:Checking exceptions
2024-11-13 18:03:07,328:INFO:Importing libraries
2024-11-13 18:03:07,328:INFO:Copying training dataset
2024-11-13 18:03:07,336:INFO:Defining folds
2024-11-13 18:03:07,336:INFO:Declaring metric variables
2024-11-13 18:03:07,339:INFO:Importing untrained model
2024-11-13 18:03:07,343:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:03:07,350:INFO:Starting cross validation
2024-11-13 18:03:07,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:03:07,737:INFO:Calculating mean and std
2024-11-13 18:03:07,741:INFO:Creating metrics dataframe
2024-11-13 18:03:07,748:INFO:Uploading results into container
2024-11-13 18:03:07,748:INFO:Uploading model into container now
2024-11-13 18:03:07,749:INFO:_master_model_container: 17
2024-11-13 18:03:07,749:INFO:_display_container: 2
2024-11-13 18:03:07,750:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:03:07,750:INFO:create_model() successfully completed......................................
2024-11-13 18:03:07,914:INFO:SubProcess create_model() end ==================================
2024-11-13 18:03:07,914:INFO:Creating metrics dataframe
2024-11-13 18:03:07,928:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:03:07,928:INFO:Total runtime is 0.4586907863616943 minutes
2024-11-13 18:03:07,932:INFO:SubProcess create_model() called ==================================
2024-11-13 18:03:07,932:INFO:Initializing create_model()
2024-11-13 18:03:07,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4a489f8b0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c573cc10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:03:07,932:INFO:Checking exceptions
2024-11-13 18:03:07,932:INFO:Importing libraries
2024-11-13 18:03:07,933:INFO:Copying training dataset
2024-11-13 18:03:07,939:INFO:Defining folds
2024-11-13 18:03:07,940:INFO:Declaring metric variables
2024-11-13 18:03:07,943:INFO:Importing untrained model
2024-11-13 18:03:07,947:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:03:07,953:INFO:Starting cross validation
2024-11-13 18:03:07,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:06:55,577:INFO:PyCaret RegressionExperiment
2024-11-13 18:06:55,577:INFO:Logging name: reg-default-name
2024-11-13 18:06:55,577:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:06:55,577:INFO:version 3.2.0
2024-11-13 18:06:55,578:INFO:Initializing setup()
2024-11-13 18:06:55,578:INFO:self.USI: 54d3
2024-11-13 18:06:55,578:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:06:55,578:INFO:Checking environment
2024-11-13 18:06:55,578:INFO:python_version: 3.8.13
2024-11-13 18:06:55,578:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:06:55,578:INFO:machine: x86_64
2024-11-13 18:06:55,578:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:06:55,578:INFO:Memory: svmem(total=270355722240, available=218247380992, percent=19.3, used=50027212800, free=56461357056, active=11654262784, inactive=141947662336, buffers=9957376, cached=163857195008, shared=187338752, slab=25020047360)
2024-11-13 18:06:55,581:INFO:Physical Core: 28
2024-11-13 18:06:55,581:INFO:Logical Core: 56
2024-11-13 18:06:55,581:INFO:Checking libraries
2024-11-13 18:06:55,581:INFO:System:
2024-11-13 18:06:55,581:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:06:55,581:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:06:55,581:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:06:55,581:INFO:PyCaret required dependencies:
2024-11-13 18:06:55,581:INFO:                 pip: 22.2.2
2024-11-13 18:06:55,581:INFO:          setuptools: 63.4.2
2024-11-13 18:06:55,581:INFO:             pycaret: 3.2.0
2024-11-13 18:06:55,581:INFO:             IPython: 8.12.2
2024-11-13 18:06:55,581:INFO:          ipywidgets: 7.7.1
2024-11-13 18:06:55,581:INFO:                tqdm: 4.64.1
2024-11-13 18:06:55,581:INFO:               numpy: 1.23.5
2024-11-13 18:06:55,581:INFO:              pandas: 1.5.3
2024-11-13 18:06:55,581:INFO:              jinja2: 3.1.2
2024-11-13 18:06:55,581:INFO:               scipy: 1.10.1
2024-11-13 18:06:55,581:INFO:              joblib: 1.3.0
2024-11-13 18:06:55,581:INFO:             sklearn: 1.1.2
2024-11-13 18:06:55,581:INFO:                pyod: 2.0.2
2024-11-13 18:06:55,581:INFO:            imblearn: 0.12.4
2024-11-13 18:06:55,582:INFO:   category_encoders: 2.6.4
2024-11-13 18:06:55,582:INFO:            lightgbm: 4.5.0
2024-11-13 18:06:55,582:INFO:               numba: 0.57.1
2024-11-13 18:06:55,582:INFO:            requests: 2.28.1
2024-11-13 18:06:55,582:INFO:          matplotlib: 3.5.1
2024-11-13 18:06:55,582:INFO:          scikitplot: 0.3.7
2024-11-13 18:06:55,582:INFO:         yellowbrick: 1.5
2024-11-13 18:06:55,582:INFO:              plotly: 5.24.1
2024-11-13 18:06:55,582:INFO:    plotly-resampler: Not installed
2024-11-13 18:06:55,582:INFO:             kaleido: 0.2.1
2024-11-13 18:06:55,582:INFO:           schemdraw: 0.15
2024-11-13 18:06:55,582:INFO:         statsmodels: 0.13.2
2024-11-13 18:06:55,582:INFO:              sktime: 0.21.1
2024-11-13 18:06:55,582:INFO:               tbats: 1.1.3
2024-11-13 18:06:55,582:INFO:            pmdarima: 2.0.4
2024-11-13 18:06:55,582:INFO:              psutil: 5.9.1
2024-11-13 18:06:55,582:INFO:          markupsafe: 2.1.1
2024-11-13 18:06:55,582:INFO:             pickle5: Not installed
2024-11-13 18:06:55,582:INFO:         cloudpickle: 2.1.0
2024-11-13 18:06:55,582:INFO:         deprecation: 2.1.0
2024-11-13 18:06:55,582:INFO:              xxhash: 3.5.0
2024-11-13 18:06:55,582:INFO:           wurlitzer: 3.1.1
2024-11-13 18:06:55,582:INFO:PyCaret optional dependencies:
2024-11-13 18:06:55,582:INFO:                shap: 0.44.1
2024-11-13 18:06:55,582:INFO:           interpret: 0.6.5
2024-11-13 18:06:55,582:INFO:                umap: 0.5.7
2024-11-13 18:06:55,582:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:06:55,582:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:06:55,582:INFO:             autoviz: Not installed
2024-11-13 18:06:55,582:INFO:           fairlearn: 0.7.0
2024-11-13 18:06:55,583:INFO:          deepchecks: Not installed
2024-11-13 18:06:55,583:INFO:             xgboost: 2.1.1
2024-11-13 18:06:55,583:INFO:            catboost: 1.2.7
2024-11-13 18:06:55,583:INFO:              kmodes: 0.12.2
2024-11-13 18:06:55,583:INFO:             mlxtend: 0.23.1
2024-11-13 18:06:55,583:INFO:       statsforecast: 1.5.0
2024-11-13 18:06:55,583:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:06:55,583:INFO:                 ray: 2.10.0
2024-11-13 18:06:55,583:INFO:            hyperopt: 0.2.7
2024-11-13 18:06:55,583:INFO:              optuna: 4.1.0
2024-11-13 18:06:55,583:INFO:               skopt: 0.10.2
2024-11-13 18:06:55,583:INFO:              mlflow: 1.30.1
2024-11-13 18:06:55,583:INFO:              gradio: 3.50.2
2024-11-13 18:06:55,583:INFO:             fastapi: 0.115.5
2024-11-13 18:06:55,583:INFO:             uvicorn: 0.32.0
2024-11-13 18:06:55,583:INFO:              m2cgen: 0.10.0
2024-11-13 18:06:55,583:INFO:           evidently: 0.2.8
2024-11-13 18:06:55,583:INFO:               fugue: 0.8.6
2024-11-13 18:06:55,583:INFO:           streamlit: Not installed
2024-11-13 18:06:55,583:INFO:             prophet: Not installed
2024-11-13 18:06:55,583:INFO:None
2024-11-13 18:06:55,583:INFO:Set up data.
2024-11-13 18:06:55,595:INFO:Set up folding strategy.
2024-11-13 18:06:55,595:INFO:Set up train/test split.
2024-11-13 18:06:55,601:INFO:Set up index.
2024-11-13 18:06:55,602:INFO:Assigning column types.
2024-11-13 18:06:55,606:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:06:55,607:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,613:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,618:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,689:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,732:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:55,734:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:55,735:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,739:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,843:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:55,846:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:55,847:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:06:55,851:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,856:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,912:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,954:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,954:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:55,957:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:55,961:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:06:55,966:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,063:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,065:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,066:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:06:56,074:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,130:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,173:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,175:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,184:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,240:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,282:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,285:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,285:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:06:56,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,390:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,393:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,499:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,502:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,502:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:06:56,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,608:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,611:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:06:56,716:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,719:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,719:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:06:56,824:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,827:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,932:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:56,939:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:56,941:INFO:Preparing preprocessing pipeline...
2024-11-13 18:06:56,941:INFO:Set up simple imputation.
2024-11-13 18:06:56,957:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:06:56,961:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:06:56,961:INFO:Creating final display dataframe.
2024-11-13 18:06:57,017:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 7)
4        Transformed data shape        (31316, 7)
5   Transformed train set shape        (21921, 7)
6    Transformed test set shape         (9395, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              54d3
2024-11-13 18:06:57,132:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:57,134:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:57,238:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:06:57,241:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:06:57,242:INFO:setup() successfully completed in 1.67s...............
2024-11-13 18:06:58,878:INFO:Initializing compare_models()
2024-11-13 18:06:58,878:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:06:58,878:INFO:Checking exceptions
2024-11-13 18:06:58,884:INFO:Preparing display monitor
2024-11-13 18:06:58,927:INFO:Initializing Linear Regression
2024-11-13 18:06:58,927:INFO:Total runtime is 1.9470850626627603e-06 minutes
2024-11-13 18:06:58,931:INFO:SubProcess create_model() called ==================================
2024-11-13 18:06:58,931:INFO:Initializing create_model()
2024-11-13 18:06:58,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:06:58,932:INFO:Checking exceptions
2024-11-13 18:06:58,932:INFO:Importing libraries
2024-11-13 18:06:58,932:INFO:Copying training dataset
2024-11-13 18:06:58,938:INFO:Defining folds
2024-11-13 18:06:58,938:INFO:Declaring metric variables
2024-11-13 18:06:58,942:INFO:Importing untrained model
2024-11-13 18:06:58,946:INFO:Linear Regression Imported successfully
2024-11-13 18:06:58,954:INFO:Starting cross validation
2024-11-13 18:06:58,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:03,071:INFO:Calculating mean and std
2024-11-13 18:07:03,077:INFO:Creating metrics dataframe
2024-11-13 18:07:03,083:INFO:Uploading results into container
2024-11-13 18:07:03,084:INFO:Uploading model into container now
2024-11-13 18:07:03,084:INFO:_master_model_container: 1
2024-11-13 18:07:03,085:INFO:_display_container: 2
2024-11-13 18:07:03,085:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:07:03,085:INFO:create_model() successfully completed......................................
2024-11-13 18:07:03,362:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:03,362:INFO:Creating metrics dataframe
2024-11-13 18:07:03,371:INFO:Initializing Lasso Regression
2024-11-13 18:07:03,371:INFO:Total runtime is 0.07408057053883871 minutes
2024-11-13 18:07:03,375:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:03,375:INFO:Initializing create_model()
2024-11-13 18:07:03,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:03,375:INFO:Checking exceptions
2024-11-13 18:07:03,376:INFO:Importing libraries
2024-11-13 18:07:03,376:INFO:Copying training dataset
2024-11-13 18:07:03,383:INFO:Defining folds
2024-11-13 18:07:03,384:INFO:Declaring metric variables
2024-11-13 18:07:03,387:INFO:Importing untrained model
2024-11-13 18:07:03,390:INFO:Lasso Regression Imported successfully
2024-11-13 18:07:03,397:INFO:Starting cross validation
2024-11-13 18:07:03,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:06,198:INFO:Calculating mean and std
2024-11-13 18:07:06,202:INFO:Creating metrics dataframe
2024-11-13 18:07:06,208:INFO:Uploading results into container
2024-11-13 18:07:06,209:INFO:Uploading model into container now
2024-11-13 18:07:06,209:INFO:_master_model_container: 2
2024-11-13 18:07:06,210:INFO:_display_container: 2
2024-11-13 18:07:06,210:INFO:Lasso(random_state=123)
2024-11-13 18:07:06,210:INFO:create_model() successfully completed......................................
2024-11-13 18:07:06,392:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:06,393:INFO:Creating metrics dataframe
2024-11-13 18:07:06,403:INFO:Initializing Ridge Regression
2024-11-13 18:07:06,403:INFO:Total runtime is 0.12460718552271526 minutes
2024-11-13 18:07:06,406:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:06,407:INFO:Initializing create_model()
2024-11-13 18:07:06,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:06,407:INFO:Checking exceptions
2024-11-13 18:07:06,407:INFO:Importing libraries
2024-11-13 18:07:06,407:INFO:Copying training dataset
2024-11-13 18:07:06,413:INFO:Defining folds
2024-11-13 18:07:06,414:INFO:Declaring metric variables
2024-11-13 18:07:06,417:INFO:Importing untrained model
2024-11-13 18:07:06,420:INFO:Ridge Regression Imported successfully
2024-11-13 18:07:06,427:INFO:Starting cross validation
2024-11-13 18:07:06,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:09,204:INFO:Calculating mean and std
2024-11-13 18:07:09,208:INFO:Creating metrics dataframe
2024-11-13 18:07:09,215:INFO:Uploading results into container
2024-11-13 18:07:09,216:INFO:Uploading model into container now
2024-11-13 18:07:09,216:INFO:_master_model_container: 3
2024-11-13 18:07:09,217:INFO:_display_container: 2
2024-11-13 18:07:09,217:INFO:Ridge(random_state=123)
2024-11-13 18:07:09,217:INFO:create_model() successfully completed......................................
2024-11-13 18:07:09,399:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:09,399:INFO:Creating metrics dataframe
2024-11-13 18:07:09,409:INFO:Initializing Elastic Net
2024-11-13 18:07:09,409:INFO:Total runtime is 0.1747101624806722 minutes
2024-11-13 18:07:09,413:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:09,413:INFO:Initializing create_model()
2024-11-13 18:07:09,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:09,413:INFO:Checking exceptions
2024-11-13 18:07:09,413:INFO:Importing libraries
2024-11-13 18:07:09,413:INFO:Copying training dataset
2024-11-13 18:07:09,420:INFO:Defining folds
2024-11-13 18:07:09,420:INFO:Declaring metric variables
2024-11-13 18:07:09,423:INFO:Importing untrained model
2024-11-13 18:07:09,427:INFO:Elastic Net Imported successfully
2024-11-13 18:07:09,439:INFO:Starting cross validation
2024-11-13 18:07:09,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:12,302:INFO:Calculating mean and std
2024-11-13 18:07:12,305:INFO:Creating metrics dataframe
2024-11-13 18:07:12,312:INFO:Uploading results into container
2024-11-13 18:07:12,313:INFO:Uploading model into container now
2024-11-13 18:07:12,313:INFO:_master_model_container: 4
2024-11-13 18:07:12,314:INFO:_display_container: 2
2024-11-13 18:07:12,314:INFO:ElasticNet(random_state=123)
2024-11-13 18:07:12,315:INFO:create_model() successfully completed......................................
2024-11-13 18:07:12,499:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:12,499:INFO:Creating metrics dataframe
2024-11-13 18:07:12,509:INFO:Initializing Least Angle Regression
2024-11-13 18:07:12,509:INFO:Total runtime is 0.22637803157170613 minutes
2024-11-13 18:07:12,513:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:12,513:INFO:Initializing create_model()
2024-11-13 18:07:12,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:12,513:INFO:Checking exceptions
2024-11-13 18:07:12,513:INFO:Importing libraries
2024-11-13 18:07:12,514:INFO:Copying training dataset
2024-11-13 18:07:12,520:INFO:Defining folds
2024-11-13 18:07:12,520:INFO:Declaring metric variables
2024-11-13 18:07:12,524:INFO:Importing untrained model
2024-11-13 18:07:12,528:INFO:Least Angle Regression Imported successfully
2024-11-13 18:07:12,534:INFO:Starting cross validation
2024-11-13 18:07:12,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:15,090:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,093:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.473e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,094:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.237e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,094:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.274e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,094:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.874e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,095:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.283e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,144:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,262:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,265:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.384e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,266:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.231e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,266:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.564e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,266:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.598e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,276:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,282:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,284:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,291:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,300:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,304:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=4.536e-03, with an active set of 1 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,304:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.268e-03, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,304:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.267e-03, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,305:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.818e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,305:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.112e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:07:15,308:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,369:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:15,384:INFO:Calculating mean and std
2024-11-13 18:07:15,387:INFO:Creating metrics dataframe
2024-11-13 18:07:15,393:INFO:Uploading results into container
2024-11-13 18:07:15,394:INFO:Uploading model into container now
2024-11-13 18:07:15,395:INFO:_master_model_container: 5
2024-11-13 18:07:15,395:INFO:_display_container: 2
2024-11-13 18:07:15,396:INFO:Lars(random_state=123)
2024-11-13 18:07:15,396:INFO:create_model() successfully completed......................................
2024-11-13 18:07:15,562:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:15,562:INFO:Creating metrics dataframe
2024-11-13 18:07:15,573:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:07:15,573:INFO:Total runtime is 0.2774429480234782 minutes
2024-11-13 18:07:15,576:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:15,577:INFO:Initializing create_model()
2024-11-13 18:07:15,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:15,577:INFO:Checking exceptions
2024-11-13 18:07:15,577:INFO:Importing libraries
2024-11-13 18:07:15,577:INFO:Copying training dataset
2024-11-13 18:07:15,584:INFO:Defining folds
2024-11-13 18:07:15,584:INFO:Declaring metric variables
2024-11-13 18:07:15,587:INFO:Importing untrained model
2024-11-13 18:07:15,591:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:07:15,597:INFO:Starting cross validation
2024-11-13 18:07:15,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:15,682:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:15,684:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:15,690:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:15,698:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,118:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,118:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,172:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,235:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,336:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,437:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:07:18,457:INFO:Calculating mean and std
2024-11-13 18:07:18,460:INFO:Creating metrics dataframe
2024-11-13 18:07:18,467:INFO:Uploading results into container
2024-11-13 18:07:18,468:INFO:Uploading model into container now
2024-11-13 18:07:18,468:INFO:_master_model_container: 6
2024-11-13 18:07:18,468:INFO:_display_container: 2
2024-11-13 18:07:18,469:INFO:LassoLars(random_state=123)
2024-11-13 18:07:18,469:INFO:create_model() successfully completed......................................
2024-11-13 18:07:18,683:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:18,683:INFO:Creating metrics dataframe
2024-11-13 18:07:18,695:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:07:18,695:INFO:Total runtime is 0.32947830359141034 minutes
2024-11-13 18:07:18,699:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:18,699:INFO:Initializing create_model()
2024-11-13 18:07:18,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:18,699:INFO:Checking exceptions
2024-11-13 18:07:18,699:INFO:Importing libraries
2024-11-13 18:07:18,699:INFO:Copying training dataset
2024-11-13 18:07:18,707:INFO:Defining folds
2024-11-13 18:07:18,707:INFO:Declaring metric variables
2024-11-13 18:07:18,710:INFO:Importing untrained model
2024-11-13 18:07:18,714:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:07:18,720:INFO:Starting cross validation
2024-11-13 18:07:18,721:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:18,755:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,761:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,768:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,771:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,777:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,782:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,787:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,794:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,798:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,806:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:07:18,826:INFO:Calculating mean and std
2024-11-13 18:07:18,830:INFO:Creating metrics dataframe
2024-11-13 18:07:18,836:INFO:Uploading results into container
2024-11-13 18:07:18,836:INFO:Uploading model into container now
2024-11-13 18:07:18,837:INFO:_master_model_container: 7
2024-11-13 18:07:18,837:INFO:_display_container: 2
2024-11-13 18:07:18,837:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:07:18,837:INFO:create_model() successfully completed......................................
2024-11-13 18:07:19,045:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:19,045:INFO:Creating metrics dataframe
2024-11-13 18:07:19,056:INFO:Initializing Bayesian Ridge
2024-11-13 18:07:19,057:INFO:Total runtime is 0.3354992469151815 minutes
2024-11-13 18:07:19,060:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:19,060:INFO:Initializing create_model()
2024-11-13 18:07:19,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:19,061:INFO:Checking exceptions
2024-11-13 18:07:19,061:INFO:Importing libraries
2024-11-13 18:07:19,061:INFO:Copying training dataset
2024-11-13 18:07:19,068:INFO:Defining folds
2024-11-13 18:07:19,068:INFO:Declaring metric variables
2024-11-13 18:07:19,071:INFO:Importing untrained model
2024-11-13 18:07:19,075:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:07:19,081:INFO:Starting cross validation
2024-11-13 18:07:19,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:19,189:INFO:Calculating mean and std
2024-11-13 18:07:19,192:INFO:Creating metrics dataframe
2024-11-13 18:07:19,199:INFO:Uploading results into container
2024-11-13 18:07:19,200:INFO:Uploading model into container now
2024-11-13 18:07:19,200:INFO:_master_model_container: 8
2024-11-13 18:07:19,200:INFO:_display_container: 2
2024-11-13 18:07:19,201:INFO:BayesianRidge()
2024-11-13 18:07:19,201:INFO:create_model() successfully completed......................................
2024-11-13 18:07:19,393:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:19,394:INFO:Creating metrics dataframe
2024-11-13 18:07:19,405:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:07:19,405:INFO:Total runtime is 0.3413140455881755 minutes
2024-11-13 18:07:19,409:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:19,409:INFO:Initializing create_model()
2024-11-13 18:07:19,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:19,409:INFO:Checking exceptions
2024-11-13 18:07:19,409:INFO:Importing libraries
2024-11-13 18:07:19,409:INFO:Copying training dataset
2024-11-13 18:07:19,416:INFO:Defining folds
2024-11-13 18:07:19,416:INFO:Declaring metric variables
2024-11-13 18:07:19,420:INFO:Importing untrained model
2024-11-13 18:07:19,423:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:07:19,429:INFO:Starting cross validation
2024-11-13 18:07:19,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:19,554:INFO:Calculating mean and std
2024-11-13 18:07:19,557:INFO:Creating metrics dataframe
2024-11-13 18:07:19,564:INFO:Uploading results into container
2024-11-13 18:07:19,564:INFO:Uploading model into container now
2024-11-13 18:07:19,565:INFO:_master_model_container: 9
2024-11-13 18:07:19,565:INFO:_display_container: 2
2024-11-13 18:07:19,566:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:07:19,566:INFO:create_model() successfully completed......................................
2024-11-13 18:07:19,747:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:19,747:INFO:Creating metrics dataframe
2024-11-13 18:07:19,758:INFO:Initializing Huber Regressor
2024-11-13 18:07:19,758:INFO:Total runtime is 0.3471907138824464 minutes
2024-11-13 18:07:19,762:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:19,762:INFO:Initializing create_model()
2024-11-13 18:07:19,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:19,762:INFO:Checking exceptions
2024-11-13 18:07:19,762:INFO:Importing libraries
2024-11-13 18:07:19,762:INFO:Copying training dataset
2024-11-13 18:07:19,769:INFO:Defining folds
2024-11-13 18:07:19,769:INFO:Declaring metric variables
2024-11-13 18:07:19,773:INFO:Importing untrained model
2024-11-13 18:07:19,777:INFO:Huber Regressor Imported successfully
2024-11-13 18:07:19,783:INFO:Starting cross validation
2024-11-13 18:07:19,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:20,105:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:07:20,105:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:07:20,120:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:07:20,188:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:07:20,201:INFO:Calculating mean and std
2024-11-13 18:07:20,205:INFO:Creating metrics dataframe
2024-11-13 18:07:20,211:INFO:Uploading results into container
2024-11-13 18:07:20,212:INFO:Uploading model into container now
2024-11-13 18:07:20,213:INFO:_master_model_container: 10
2024-11-13 18:07:20,213:INFO:_display_container: 2
2024-11-13 18:07:20,213:INFO:HuberRegressor()
2024-11-13 18:07:20,213:INFO:create_model() successfully completed......................................
2024-11-13 18:07:20,404:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:20,404:INFO:Creating metrics dataframe
2024-11-13 18:07:20,416:INFO:Initializing K Neighbors Regressor
2024-11-13 18:07:20,416:INFO:Total runtime is 0.35815302530924487 minutes
2024-11-13 18:07:20,419:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:20,419:INFO:Initializing create_model()
2024-11-13 18:07:20,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:20,420:INFO:Checking exceptions
2024-11-13 18:07:20,420:INFO:Importing libraries
2024-11-13 18:07:20,420:INFO:Copying training dataset
2024-11-13 18:07:20,427:INFO:Defining folds
2024-11-13 18:07:20,427:INFO:Declaring metric variables
2024-11-13 18:07:20,431:INFO:Importing untrained model
2024-11-13 18:07:20,434:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:07:20,441:INFO:Starting cross validation
2024-11-13 18:07:20,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:20,630:INFO:Calculating mean and std
2024-11-13 18:07:20,633:INFO:Creating metrics dataframe
2024-11-13 18:07:20,643:INFO:Uploading results into container
2024-11-13 18:07:20,645:INFO:Uploading model into container now
2024-11-13 18:07:20,645:INFO:_master_model_container: 11
2024-11-13 18:07:20,646:INFO:_display_container: 2
2024-11-13 18:07:20,646:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:07:20,646:INFO:create_model() successfully completed......................................
2024-11-13 18:07:20,830:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:20,830:INFO:Creating metrics dataframe
2024-11-13 18:07:20,842:INFO:Initializing Decision Tree Regressor
2024-11-13 18:07:20,843:INFO:Total runtime is 0.3652656316757203 minutes
2024-11-13 18:07:20,846:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:20,846:INFO:Initializing create_model()
2024-11-13 18:07:20,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:20,846:INFO:Checking exceptions
2024-11-13 18:07:20,847:INFO:Importing libraries
2024-11-13 18:07:20,847:INFO:Copying training dataset
2024-11-13 18:07:20,854:INFO:Defining folds
2024-11-13 18:07:20,854:INFO:Declaring metric variables
2024-11-13 18:07:20,858:INFO:Importing untrained model
2024-11-13 18:07:20,861:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:07:20,868:INFO:Starting cross validation
2024-11-13 18:07:20,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:21,059:INFO:Calculating mean and std
2024-11-13 18:07:21,062:INFO:Creating metrics dataframe
2024-11-13 18:07:21,068:INFO:Uploading results into container
2024-11-13 18:07:21,068:INFO:Uploading model into container now
2024-11-13 18:07:21,069:INFO:_master_model_container: 12
2024-11-13 18:07:21,069:INFO:_display_container: 2
2024-11-13 18:07:21,070:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:07:21,070:INFO:create_model() successfully completed......................................
2024-11-13 18:07:21,276:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:21,276:INFO:Creating metrics dataframe
2024-11-13 18:07:21,288:INFO:Initializing Random Forest Regressor
2024-11-13 18:07:21,288:INFO:Total runtime is 0.372696348031362 minutes
2024-11-13 18:07:21,292:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:21,292:INFO:Initializing create_model()
2024-11-13 18:07:21,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:21,292:INFO:Checking exceptions
2024-11-13 18:07:21,292:INFO:Importing libraries
2024-11-13 18:07:21,292:INFO:Copying training dataset
2024-11-13 18:07:21,299:INFO:Defining folds
2024-11-13 18:07:21,299:INFO:Declaring metric variables
2024-11-13 18:07:21,303:INFO:Importing untrained model
2024-11-13 18:07:21,306:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:07:21,312:INFO:Starting cross validation
2024-11-13 18:07:21,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:22,890:INFO:Calculating mean and std
2024-11-13 18:07:22,893:INFO:Creating metrics dataframe
2024-11-13 18:07:22,899:INFO:Uploading results into container
2024-11-13 18:07:22,900:INFO:Uploading model into container now
2024-11-13 18:07:22,900:INFO:_master_model_container: 13
2024-11-13 18:07:22,900:INFO:_display_container: 2
2024-11-13 18:07:22,901:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:07:22,901:INFO:create_model() successfully completed......................................
2024-11-13 18:07:23,072:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:23,072:INFO:Creating metrics dataframe
2024-11-13 18:07:23,084:INFO:Initializing Extra Trees Regressor
2024-11-13 18:07:23,085:INFO:Total runtime is 0.4026317715644837 minutes
2024-11-13 18:07:23,088:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:23,088:INFO:Initializing create_model()
2024-11-13 18:07:23,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:23,088:INFO:Checking exceptions
2024-11-13 18:07:23,088:INFO:Importing libraries
2024-11-13 18:07:23,088:INFO:Copying training dataset
2024-11-13 18:07:23,095:INFO:Defining folds
2024-11-13 18:07:23,095:INFO:Declaring metric variables
2024-11-13 18:07:23,098:INFO:Importing untrained model
2024-11-13 18:07:23,102:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:07:23,108:INFO:Starting cross validation
2024-11-13 18:07:23,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:23,962:INFO:Calculating mean and std
2024-11-13 18:07:23,965:INFO:Creating metrics dataframe
2024-11-13 18:07:23,971:INFO:Uploading results into container
2024-11-13 18:07:23,972:INFO:Uploading model into container now
2024-11-13 18:07:23,973:INFO:_master_model_container: 14
2024-11-13 18:07:23,973:INFO:_display_container: 2
2024-11-13 18:07:23,973:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:07:23,973:INFO:create_model() successfully completed......................................
2024-11-13 18:07:24,143:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:24,143:INFO:Creating metrics dataframe
2024-11-13 18:07:24,156:INFO:Initializing AdaBoost Regressor
2024-11-13 18:07:24,157:INFO:Total runtime is 0.42049788236618046 minutes
2024-11-13 18:07:24,160:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:24,160:INFO:Initializing create_model()
2024-11-13 18:07:24,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:24,161:INFO:Checking exceptions
2024-11-13 18:07:24,161:INFO:Importing libraries
2024-11-13 18:07:24,161:INFO:Copying training dataset
2024-11-13 18:07:24,168:INFO:Defining folds
2024-11-13 18:07:24,168:INFO:Declaring metric variables
2024-11-13 18:07:24,172:INFO:Importing untrained model
2024-11-13 18:07:24,175:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:07:24,182:INFO:Starting cross validation
2024-11-13 18:07:24,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:24,965:INFO:Calculating mean and std
2024-11-13 18:07:24,968:INFO:Creating metrics dataframe
2024-11-13 18:07:24,975:INFO:Uploading results into container
2024-11-13 18:07:24,976:INFO:Uploading model into container now
2024-11-13 18:07:24,976:INFO:_master_model_container: 15
2024-11-13 18:07:24,976:INFO:_display_container: 2
2024-11-13 18:07:24,977:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:07:24,977:INFO:create_model() successfully completed......................................
2024-11-13 18:07:25,154:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:25,154:INFO:Creating metrics dataframe
2024-11-13 18:07:25,166:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:07:25,167:INFO:Total runtime is 0.43733329772949225 minutes
2024-11-13 18:07:25,170:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:25,170:INFO:Initializing create_model()
2024-11-13 18:07:25,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:25,170:INFO:Checking exceptions
2024-11-13 18:07:25,171:INFO:Importing libraries
2024-11-13 18:07:25,171:INFO:Copying training dataset
2024-11-13 18:07:25,177:INFO:Defining folds
2024-11-13 18:07:25,177:INFO:Declaring metric variables
2024-11-13 18:07:25,181:INFO:Importing untrained model
2024-11-13 18:07:25,184:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:07:25,190:INFO:Starting cross validation
2024-11-13 18:07:25,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:27,107:INFO:Calculating mean and std
2024-11-13 18:07:27,110:INFO:Creating metrics dataframe
2024-11-13 18:07:27,121:INFO:Uploading results into container
2024-11-13 18:07:27,122:INFO:Uploading model into container now
2024-11-13 18:07:27,123:INFO:_master_model_container: 16
2024-11-13 18:07:27,123:INFO:_display_container: 2
2024-11-13 18:07:27,123:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:07:27,123:INFO:create_model() successfully completed......................................
2024-11-13 18:07:27,337:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:27,337:INFO:Creating metrics dataframe
2024-11-13 18:07:27,351:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:07:27,351:INFO:Total runtime is 0.4737399538358053 minutes
2024-11-13 18:07:27,354:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:27,355:INFO:Initializing create_model()
2024-11-13 18:07:27,355:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:27,355:INFO:Checking exceptions
2024-11-13 18:07:27,355:INFO:Importing libraries
2024-11-13 18:07:27,355:INFO:Copying training dataset
2024-11-13 18:07:27,362:INFO:Defining folds
2024-11-13 18:07:27,362:INFO:Declaring metric variables
2024-11-13 18:07:27,365:INFO:Importing untrained model
2024-11-13 18:07:27,369:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:07:27,376:INFO:Starting cross validation
2024-11-13 18:07:27,377:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:07:27,703:INFO:Calculating mean and std
2024-11-13 18:07:27,706:INFO:Creating metrics dataframe
2024-11-13 18:07:27,712:INFO:Uploading results into container
2024-11-13 18:07:27,713:INFO:Uploading model into container now
2024-11-13 18:07:27,713:INFO:_master_model_container: 17
2024-11-13 18:07:27,713:INFO:_display_container: 2
2024-11-13 18:07:27,714:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:07:27,714:INFO:create_model() successfully completed......................................
2024-11-13 18:07:27,903:INFO:SubProcess create_model() end ==================================
2024-11-13 18:07:27,903:INFO:Creating metrics dataframe
2024-11-13 18:07:27,916:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:07:27,917:INFO:Total runtime is 0.48316738208134974 minutes
2024-11-13 18:07:27,920:INFO:SubProcess create_model() called ==================================
2024-11-13 18:07:27,920:INFO:Initializing create_model()
2024-11-13 18:07:27,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:07:27,921:INFO:Checking exceptions
2024-11-13 18:07:27,921:INFO:Importing libraries
2024-11-13 18:07:27,921:INFO:Copying training dataset
2024-11-13 18:07:27,927:INFO:Defining folds
2024-11-13 18:07:27,928:INFO:Declaring metric variables
2024-11-13 18:07:27,931:INFO:Importing untrained model
2024-11-13 18:07:27,935:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:07:27,941:INFO:Starting cross validation
2024-11-13 18:07:27,942:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:14:19,955:INFO:Calculating mean and std
2024-11-13 18:14:19,959:INFO:Creating metrics dataframe
2024-11-13 18:14:19,970:INFO:Uploading results into container
2024-11-13 18:14:19,972:INFO:Uploading model into container now
2024-11-13 18:14:19,973:INFO:_master_model_container: 18
2024-11-13 18:14:19,973:INFO:_display_container: 2
2024-11-13 18:14:19,974:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:14:19,974:INFO:create_model() successfully completed......................................
2024-11-13 18:14:20,193:INFO:SubProcess create_model() end ==================================
2024-11-13 18:14:20,193:INFO:Creating metrics dataframe
2024-11-13 18:14:20,208:INFO:Initializing CatBoost Regressor
2024-11-13 18:14:20,208:INFO:Total runtime is 7.354694394270579 minutes
2024-11-13 18:14:20,212:INFO:SubProcess create_model() called ==================================
2024-11-13 18:14:20,212:INFO:Initializing create_model()
2024-11-13 18:14:20,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:14:20,213:INFO:Checking exceptions
2024-11-13 18:14:20,213:INFO:Importing libraries
2024-11-13 18:14:20,213:INFO:Copying training dataset
2024-11-13 18:14:20,220:INFO:Defining folds
2024-11-13 18:14:20,220:INFO:Declaring metric variables
2024-11-13 18:14:20,224:INFO:Importing untrained model
2024-11-13 18:14:20,227:INFO:CatBoost Regressor Imported successfully
2024-11-13 18:14:20,234:INFO:Starting cross validation
2024-11-13 18:14:20,235:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:14:32,274:INFO:Calculating mean and std
2024-11-13 18:14:32,279:INFO:Creating metrics dataframe
2024-11-13 18:14:32,286:INFO:Uploading results into container
2024-11-13 18:14:32,286:INFO:Uploading model into container now
2024-11-13 18:14:32,287:INFO:_master_model_container: 19
2024-11-13 18:14:32,287:INFO:_display_container: 2
2024-11-13 18:14:32,287:INFO:<catboost.core.CatBoostRegressor object at 0x7ff4c561d5b0>
2024-11-13 18:14:32,287:INFO:create_model() successfully completed......................................
2024-11-13 18:14:32,494:INFO:SubProcess create_model() end ==================================
2024-11-13 18:14:32,494:INFO:Creating metrics dataframe
2024-11-13 18:14:32,509:INFO:Initializing Dummy Regressor
2024-11-13 18:14:32,509:INFO:Total runtime is 7.559710693359375 minutes
2024-11-13 18:14:32,513:INFO:SubProcess create_model() called ==================================
2024-11-13 18:14:32,513:INFO:Initializing create_model()
2024-11-13 18:14:32,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff687303f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:14:32,513:INFO:Checking exceptions
2024-11-13 18:14:32,514:INFO:Importing libraries
2024-11-13 18:14:32,514:INFO:Copying training dataset
2024-11-13 18:14:32,521:INFO:Defining folds
2024-11-13 18:14:32,521:INFO:Declaring metric variables
2024-11-13 18:14:32,525:INFO:Importing untrained model
2024-11-13 18:14:32,528:INFO:Dummy Regressor Imported successfully
2024-11-13 18:14:32,535:INFO:Starting cross validation
2024-11-13 18:14:32,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:14:35,729:INFO:Calculating mean and std
2024-11-13 18:14:35,734:INFO:Creating metrics dataframe
2024-11-13 18:14:35,741:INFO:Uploading results into container
2024-11-13 18:14:35,742:INFO:Uploading model into container now
2024-11-13 18:14:35,742:INFO:_master_model_container: 20
2024-11-13 18:14:35,743:INFO:_display_container: 2
2024-11-13 18:14:35,743:INFO:DummyRegressor()
2024-11-13 18:14:35,743:INFO:create_model() successfully completed......................................
2024-11-13 18:14:35,970:INFO:SubProcess create_model() end ==================================
2024-11-13 18:14:35,970:INFO:Creating metrics dataframe
2024-11-13 18:14:35,997:INFO:Initializing create_model()
2024-11-13 18:14:35,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff687251ee0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:14:35,997:INFO:Checking exceptions
2024-11-13 18:14:36,000:INFO:Importing libraries
2024-11-13 18:14:36,000:INFO:Copying training dataset
2024-11-13 18:14:36,005:INFO:Defining folds
2024-11-13 18:14:36,006:INFO:Declaring metric variables
2024-11-13 18:14:36,006:INFO:Importing untrained model
2024-11-13 18:14:36,006:INFO:Declaring custom model
2024-11-13 18:14:36,006:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:14:36,007:INFO:Cross validation set to False
2024-11-13 18:14:36,007:INFO:Fitting Model
2024-11-13 18:14:36,249:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:14:36,249:INFO:create_model() successfully completed......................................
2024-11-13 18:14:36,540:INFO:_master_model_container: 20
2024-11-13 18:14:36,541:INFO:_display_container: 2
2024-11-13 18:14:36,541:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:14:36,541:INFO:compare_models() successfully completed......................................
2024-11-13 18:15:23,767:INFO:PyCaret RegressionExperiment
2024-11-13 18:15:23,768:INFO:Logging name: reg-default-name
2024-11-13 18:15:23,768:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:15:23,768:INFO:version 3.2.0
2024-11-13 18:15:23,768:INFO:Initializing setup()
2024-11-13 18:15:23,768:INFO:self.USI: 7f5f
2024-11-13 18:15:23,768:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:15:23,768:INFO:Checking environment
2024-11-13 18:15:23,768:INFO:python_version: 3.8.13
2024-11-13 18:15:23,768:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:15:23,768:INFO:machine: x86_64
2024-11-13 18:15:23,768:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:15:23,768:INFO:Memory: svmem(total=270355722240, available=213997654016, percent=20.8, used=54288515072, free=52052815872, active=11655049216, inactive=146339053568, buffers=8888320, cached=164005502976, shared=187588608, slab=25029918720)
2024-11-13 18:15:23,770:INFO:Physical Core: 28
2024-11-13 18:15:23,771:INFO:Logical Core: 56
2024-11-13 18:15:23,771:INFO:Checking libraries
2024-11-13 18:15:23,771:INFO:System:
2024-11-13 18:15:23,771:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:15:23,771:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:15:23,771:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:15:23,771:INFO:PyCaret required dependencies:
2024-11-13 18:15:23,771:INFO:                 pip: 22.2.2
2024-11-13 18:15:23,771:INFO:          setuptools: 63.4.2
2024-11-13 18:15:23,771:INFO:             pycaret: 3.2.0
2024-11-13 18:15:23,771:INFO:             IPython: 8.12.2
2024-11-13 18:15:23,771:INFO:          ipywidgets: 7.7.1
2024-11-13 18:15:23,771:INFO:                tqdm: 4.64.1
2024-11-13 18:15:23,771:INFO:               numpy: 1.23.5
2024-11-13 18:15:23,771:INFO:              pandas: 1.5.3
2024-11-13 18:15:23,771:INFO:              jinja2: 3.1.2
2024-11-13 18:15:23,771:INFO:               scipy: 1.10.1
2024-11-13 18:15:23,771:INFO:              joblib: 1.3.0
2024-11-13 18:15:23,771:INFO:             sklearn: 1.1.2
2024-11-13 18:15:23,771:INFO:                pyod: 2.0.2
2024-11-13 18:15:23,771:INFO:            imblearn: 0.12.4
2024-11-13 18:15:23,771:INFO:   category_encoders: 2.6.4
2024-11-13 18:15:23,771:INFO:            lightgbm: 4.5.0
2024-11-13 18:15:23,771:INFO:               numba: 0.57.1
2024-11-13 18:15:23,772:INFO:            requests: 2.28.1
2024-11-13 18:15:23,772:INFO:          matplotlib: 3.5.1
2024-11-13 18:15:23,772:INFO:          scikitplot: 0.3.7
2024-11-13 18:15:23,772:INFO:         yellowbrick: 1.5
2024-11-13 18:15:23,772:INFO:              plotly: 5.24.1
2024-11-13 18:15:23,772:INFO:    plotly-resampler: Not installed
2024-11-13 18:15:23,772:INFO:             kaleido: 0.2.1
2024-11-13 18:15:23,772:INFO:           schemdraw: 0.15
2024-11-13 18:15:23,772:INFO:         statsmodels: 0.13.2
2024-11-13 18:15:23,772:INFO:              sktime: 0.21.1
2024-11-13 18:15:23,772:INFO:               tbats: 1.1.3
2024-11-13 18:15:23,772:INFO:            pmdarima: 2.0.4
2024-11-13 18:15:23,772:INFO:              psutil: 5.9.1
2024-11-13 18:15:23,772:INFO:          markupsafe: 2.1.1
2024-11-13 18:15:23,772:INFO:             pickle5: Not installed
2024-11-13 18:15:23,772:INFO:         cloudpickle: 2.1.0
2024-11-13 18:15:23,772:INFO:         deprecation: 2.1.0
2024-11-13 18:15:23,772:INFO:              xxhash: 3.5.0
2024-11-13 18:15:23,772:INFO:           wurlitzer: 3.1.1
2024-11-13 18:15:23,772:INFO:PyCaret optional dependencies:
2024-11-13 18:15:23,772:INFO:                shap: 0.44.1
2024-11-13 18:15:23,772:INFO:           interpret: 0.6.5
2024-11-13 18:15:23,772:INFO:                umap: 0.5.7
2024-11-13 18:15:23,772:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:15:23,772:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:15:23,772:INFO:             autoviz: Not installed
2024-11-13 18:15:23,772:INFO:           fairlearn: 0.7.0
2024-11-13 18:15:23,772:INFO:          deepchecks: Not installed
2024-11-13 18:15:23,772:INFO:             xgboost: 2.1.1
2024-11-13 18:15:23,773:INFO:            catboost: 1.2.7
2024-11-13 18:15:23,773:INFO:              kmodes: 0.12.2
2024-11-13 18:15:23,773:INFO:             mlxtend: 0.23.1
2024-11-13 18:15:23,773:INFO:       statsforecast: 1.5.0
2024-11-13 18:15:23,773:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:15:23,773:INFO:                 ray: 2.10.0
2024-11-13 18:15:23,773:INFO:            hyperopt: 0.2.7
2024-11-13 18:15:23,773:INFO:              optuna: 4.1.0
2024-11-13 18:15:23,773:INFO:               skopt: 0.10.2
2024-11-13 18:15:23,773:INFO:              mlflow: 1.30.1
2024-11-13 18:15:23,773:INFO:              gradio: 3.50.2
2024-11-13 18:15:23,773:INFO:             fastapi: 0.115.5
2024-11-13 18:15:23,773:INFO:             uvicorn: 0.32.0
2024-11-13 18:15:23,773:INFO:              m2cgen: 0.10.0
2024-11-13 18:15:23,773:INFO:           evidently: 0.2.8
2024-11-13 18:15:23,773:INFO:               fugue: 0.8.6
2024-11-13 18:15:23,773:INFO:           streamlit: Not installed
2024-11-13 18:15:23,773:INFO:             prophet: Not installed
2024-11-13 18:15:23,773:INFO:None
2024-11-13 18:15:23,773:INFO:Set up data.
2024-11-13 18:15:23,787:INFO:Set up folding strategy.
2024-11-13 18:15:23,787:INFO:Set up train/test split.
2024-11-13 18:15:23,793:INFO:Set up index.
2024-11-13 18:15:23,794:INFO:Assigning column types.
2024-11-13 18:15:23,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:15:23,799:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,804:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,873:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,924:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:23,928:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:23,929:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,933:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,937:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:23,987:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,023:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,024:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,026:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,027:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:15:24,030:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,034:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,082:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,119:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,121:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,126:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,130:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,182:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,218:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,220:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,222:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:15:24,229:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,277:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,314:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,316:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,324:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,408:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,408:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,410:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,411:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:15:24,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,502:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,503:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,505:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,560:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,597:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,597:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,599:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,599:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:15:24,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,693:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,695:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:15:24,789:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,791:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,792:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:15:24,884:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,886:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,983:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:24,985:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:24,987:INFO:Preparing preprocessing pipeline...
2024-11-13 18:15:24,987:INFO:Set up simple imputation.
2024-11-13 18:15:25,004:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:15:25,009:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['USA_WSPD', 'MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:15:25,009:INFO:Creating final display dataframe.
2024-11-13 18:15:25,066:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 8)
4        Transformed data shape        (31316, 8)
5   Transformed train set shape        (21921, 8)
6    Transformed test set shape         (9395, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              7f5f
2024-11-13 18:15:25,167:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:25,170:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:25,262:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:15:25,264:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:15:25,265:INFO:setup() successfully completed in 1.5s...............
2024-11-13 18:15:26,696:INFO:Initializing compare_models()
2024-11-13 18:15:26,696:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:15:26,696:INFO:Checking exceptions
2024-11-13 18:15:26,702:INFO:Preparing display monitor
2024-11-13 18:15:26,736:INFO:Initializing Linear Regression
2024-11-13 18:15:26,736:INFO:Total runtime is 2.6186307271321613e-06 minutes
2024-11-13 18:15:26,741:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:26,741:INFO:Initializing create_model()
2024-11-13 18:15:26,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:26,742:INFO:Checking exceptions
2024-11-13 18:15:26,742:INFO:Importing libraries
2024-11-13 18:15:26,742:INFO:Copying training dataset
2024-11-13 18:15:26,748:INFO:Defining folds
2024-11-13 18:15:26,748:INFO:Declaring metric variables
2024-11-13 18:15:26,752:INFO:Importing untrained model
2024-11-13 18:15:26,756:INFO:Linear Regression Imported successfully
2024-11-13 18:15:26,762:INFO:Starting cross validation
2024-11-13 18:15:26,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:29,799:INFO:Calculating mean and std
2024-11-13 18:15:29,804:INFO:Creating metrics dataframe
2024-11-13 18:15:29,811:INFO:Uploading results into container
2024-11-13 18:15:29,812:INFO:Uploading model into container now
2024-11-13 18:15:29,812:INFO:_master_model_container: 1
2024-11-13 18:15:29,812:INFO:_display_container: 2
2024-11-13 18:15:29,813:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:15:29,813:INFO:create_model() successfully completed......................................
2024-11-13 18:15:30,094:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:30,094:INFO:Creating metrics dataframe
2024-11-13 18:15:30,106:INFO:Initializing Lasso Regression
2024-11-13 18:15:30,106:INFO:Total runtime is 0.056162710984547934 minutes
2024-11-13 18:15:30,109:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:30,110:INFO:Initializing create_model()
2024-11-13 18:15:30,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:30,110:INFO:Checking exceptions
2024-11-13 18:15:30,110:INFO:Importing libraries
2024-11-13 18:15:30,110:INFO:Copying training dataset
2024-11-13 18:15:30,119:INFO:Defining folds
2024-11-13 18:15:30,119:INFO:Declaring metric variables
2024-11-13 18:15:30,122:INFO:Importing untrained model
2024-11-13 18:15:30,125:INFO:Lasso Regression Imported successfully
2024-11-13 18:15:30,132:INFO:Starting cross validation
2024-11-13 18:15:30,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:32,914:INFO:Calculating mean and std
2024-11-13 18:15:32,918:INFO:Creating metrics dataframe
2024-11-13 18:15:32,924:INFO:Uploading results into container
2024-11-13 18:15:32,925:INFO:Uploading model into container now
2024-11-13 18:15:32,926:INFO:_master_model_container: 2
2024-11-13 18:15:32,926:INFO:_display_container: 2
2024-11-13 18:15:32,926:INFO:Lasso(random_state=123)
2024-11-13 18:15:32,926:INFO:create_model() successfully completed......................................
2024-11-13 18:15:33,147:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:33,148:INFO:Creating metrics dataframe
2024-11-13 18:15:33,158:INFO:Initializing Ridge Regression
2024-11-13 18:15:33,159:INFO:Total runtime is 0.10704161723454794 minutes
2024-11-13 18:15:33,162:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:33,162:INFO:Initializing create_model()
2024-11-13 18:15:33,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:33,162:INFO:Checking exceptions
2024-11-13 18:15:33,163:INFO:Importing libraries
2024-11-13 18:15:33,163:INFO:Copying training dataset
2024-11-13 18:15:33,169:INFO:Defining folds
2024-11-13 18:15:33,170:INFO:Declaring metric variables
2024-11-13 18:15:33,173:INFO:Importing untrained model
2024-11-13 18:15:33,176:INFO:Ridge Regression Imported successfully
2024-11-13 18:15:33,183:INFO:Starting cross validation
2024-11-13 18:15:33,184:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:36,161:INFO:Calculating mean and std
2024-11-13 18:15:36,165:INFO:Creating metrics dataframe
2024-11-13 18:15:36,172:INFO:Uploading results into container
2024-11-13 18:15:36,172:INFO:Uploading model into container now
2024-11-13 18:15:36,173:INFO:_master_model_container: 3
2024-11-13 18:15:36,173:INFO:_display_container: 2
2024-11-13 18:15:36,173:INFO:Ridge(random_state=123)
2024-11-13 18:15:36,173:INFO:create_model() successfully completed......................................
2024-11-13 18:15:36,387:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:36,387:INFO:Creating metrics dataframe
2024-11-13 18:15:36,398:INFO:Initializing Elastic Net
2024-11-13 18:15:36,398:INFO:Total runtime is 0.16103380918502808 minutes
2024-11-13 18:15:36,401:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:36,402:INFO:Initializing create_model()
2024-11-13 18:15:36,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:36,402:INFO:Checking exceptions
2024-11-13 18:15:36,402:INFO:Importing libraries
2024-11-13 18:15:36,402:INFO:Copying training dataset
2024-11-13 18:15:36,409:INFO:Defining folds
2024-11-13 18:15:36,409:INFO:Declaring metric variables
2024-11-13 18:15:36,413:INFO:Importing untrained model
2024-11-13 18:15:36,416:INFO:Elastic Net Imported successfully
2024-11-13 18:15:36,422:INFO:Starting cross validation
2024-11-13 18:15:36,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:39,131:INFO:Calculating mean and std
2024-11-13 18:15:39,135:INFO:Creating metrics dataframe
2024-11-13 18:15:39,143:INFO:Uploading results into container
2024-11-13 18:15:39,143:INFO:Uploading model into container now
2024-11-13 18:15:39,144:INFO:_master_model_container: 4
2024-11-13 18:15:39,144:INFO:_display_container: 2
2024-11-13 18:15:39,145:INFO:ElasticNet(random_state=123)
2024-11-13 18:15:39,145:INFO:create_model() successfully completed......................................
2024-11-13 18:15:39,381:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:39,381:INFO:Creating metrics dataframe
2024-11-13 18:15:39,393:INFO:Initializing Least Angle Regression
2024-11-13 18:15:39,393:INFO:Total runtime is 0.21095072428385417 minutes
2024-11-13 18:15:39,396:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:39,397:INFO:Initializing create_model()
2024-11-13 18:15:39,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:39,397:INFO:Checking exceptions
2024-11-13 18:15:39,397:INFO:Importing libraries
2024-11-13 18:15:39,397:INFO:Copying training dataset
2024-11-13 18:15:39,404:INFO:Defining folds
2024-11-13 18:15:39,404:INFO:Declaring metric variables
2024-11-13 18:15:39,408:INFO:Importing untrained model
2024-11-13 18:15:39,411:INFO:Least Angle Regression Imported successfully
2024-11-13 18:15:39,418:INFO:Starting cross validation
2024-11-13 18:15:39,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:39,492:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:39,500:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:39,505:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:39,508:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:39,509:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.478e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:15:39,511:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.949e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:15:39,512:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.974e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:15:39,516:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:41,896:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:41,933:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:42,050:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:42,125:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:42,129:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.407e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:15:42,164:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:42,176:INFO:Calculating mean and std
2024-11-13 18:15:42,180:INFO:Creating metrics dataframe
2024-11-13 18:15:42,187:INFO:Uploading results into container
2024-11-13 18:15:42,188:INFO:Uploading model into container now
2024-11-13 18:15:42,189:INFO:_master_model_container: 5
2024-11-13 18:15:42,189:INFO:_display_container: 2
2024-11-13 18:15:42,189:INFO:Lars(random_state=123)
2024-11-13 18:15:42,189:INFO:create_model() successfully completed......................................
2024-11-13 18:15:42,378:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:42,378:INFO:Creating metrics dataframe
2024-11-13 18:15:42,390:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:15:42,391:INFO:Total runtime is 0.260908039410909 minutes
2024-11-13 18:15:42,394:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:42,394:INFO:Initializing create_model()
2024-11-13 18:15:42,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:42,395:INFO:Checking exceptions
2024-11-13 18:15:42,395:INFO:Importing libraries
2024-11-13 18:15:42,395:INFO:Copying training dataset
2024-11-13 18:15:42,402:INFO:Defining folds
2024-11-13 18:15:42,402:INFO:Declaring metric variables
2024-11-13 18:15:42,405:INFO:Importing untrained model
2024-11-13 18:15:42,409:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:15:42,415:INFO:Starting cross validation
2024-11-13 18:15:42,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:42,454:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,470:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,470:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,474:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,479:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,494:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,501:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,503:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:42,511:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:44,707:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:15:44,723:INFO:Calculating mean and std
2024-11-13 18:15:44,727:INFO:Creating metrics dataframe
2024-11-13 18:15:44,735:INFO:Uploading results into container
2024-11-13 18:15:44,735:INFO:Uploading model into container now
2024-11-13 18:15:44,736:INFO:_master_model_container: 6
2024-11-13 18:15:44,736:INFO:_display_container: 2
2024-11-13 18:15:44,737:INFO:LassoLars(random_state=123)
2024-11-13 18:15:44,737:INFO:create_model() successfully completed......................................
2024-11-13 18:15:44,939:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:44,939:INFO:Creating metrics dataframe
2024-11-13 18:15:44,950:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:15:44,950:INFO:Total runtime is 0.3035678466161092 minutes
2024-11-13 18:15:44,954:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:44,954:INFO:Initializing create_model()
2024-11-13 18:15:44,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:44,954:INFO:Checking exceptions
2024-11-13 18:15:44,954:INFO:Importing libraries
2024-11-13 18:15:44,954:INFO:Copying training dataset
2024-11-13 18:15:44,961:INFO:Defining folds
2024-11-13 18:15:44,961:INFO:Declaring metric variables
2024-11-13 18:15:44,965:INFO:Importing untrained model
2024-11-13 18:15:44,968:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:15:44,975:INFO:Starting cross validation
2024-11-13 18:15:44,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:45,004:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,012:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,015:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,021:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,027:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,030:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,038:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,040:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,044:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,051:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:15:45,067:INFO:Calculating mean and std
2024-11-13 18:15:45,071:INFO:Creating metrics dataframe
2024-11-13 18:15:45,078:INFO:Uploading results into container
2024-11-13 18:15:45,079:INFO:Uploading model into container now
2024-11-13 18:15:45,079:INFO:_master_model_container: 7
2024-11-13 18:15:45,079:INFO:_display_container: 2
2024-11-13 18:15:45,080:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:15:45,080:INFO:create_model() successfully completed......................................
2024-11-13 18:15:45,254:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:45,254:INFO:Creating metrics dataframe
2024-11-13 18:15:45,266:INFO:Initializing Bayesian Ridge
2024-11-13 18:15:45,266:INFO:Total runtime is 0.30882927179336545 minutes
2024-11-13 18:15:45,269:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:45,269:INFO:Initializing create_model()
2024-11-13 18:15:45,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:45,269:INFO:Checking exceptions
2024-11-13 18:15:45,270:INFO:Importing libraries
2024-11-13 18:15:45,270:INFO:Copying training dataset
2024-11-13 18:15:45,278:INFO:Defining folds
2024-11-13 18:15:45,278:INFO:Declaring metric variables
2024-11-13 18:15:45,282:INFO:Importing untrained model
2024-11-13 18:15:45,285:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:15:45,292:INFO:Starting cross validation
2024-11-13 18:15:45,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:45,455:INFO:Calculating mean and std
2024-11-13 18:15:45,459:INFO:Creating metrics dataframe
2024-11-13 18:15:45,465:INFO:Uploading results into container
2024-11-13 18:15:45,466:INFO:Uploading model into container now
2024-11-13 18:15:45,467:INFO:_master_model_container: 8
2024-11-13 18:15:45,467:INFO:_display_container: 2
2024-11-13 18:15:45,468:INFO:BayesianRidge()
2024-11-13 18:15:45,468:INFO:create_model() successfully completed......................................
2024-11-13 18:15:45,645:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:45,645:INFO:Creating metrics dataframe
2024-11-13 18:15:45,656:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:15:45,656:INFO:Total runtime is 0.31533221801122024 minutes
2024-11-13 18:15:45,659:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:45,660:INFO:Initializing create_model()
2024-11-13 18:15:45,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:45,660:INFO:Checking exceptions
2024-11-13 18:15:45,660:INFO:Importing libraries
2024-11-13 18:15:45,660:INFO:Copying training dataset
2024-11-13 18:15:45,667:INFO:Defining folds
2024-11-13 18:15:45,667:INFO:Declaring metric variables
2024-11-13 18:15:45,671:INFO:Importing untrained model
2024-11-13 18:15:45,674:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:15:45,680:INFO:Starting cross validation
2024-11-13 18:15:45,681:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:45,817:INFO:Calculating mean and std
2024-11-13 18:15:45,821:INFO:Creating metrics dataframe
2024-11-13 18:15:45,829:INFO:Uploading results into container
2024-11-13 18:15:45,830:INFO:Uploading model into container now
2024-11-13 18:15:45,830:INFO:_master_model_container: 9
2024-11-13 18:15:45,831:INFO:_display_container: 2
2024-11-13 18:15:45,831:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:15:45,831:INFO:create_model() successfully completed......................................
2024-11-13 18:15:46,057:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:46,058:INFO:Creating metrics dataframe
2024-11-13 18:15:46,070:INFO:Initializing Huber Regressor
2024-11-13 18:15:46,070:INFO:Total runtime is 0.3222341895103454 minutes
2024-11-13 18:15:46,074:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:46,074:INFO:Initializing create_model()
2024-11-13 18:15:46,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:46,074:INFO:Checking exceptions
2024-11-13 18:15:46,074:INFO:Importing libraries
2024-11-13 18:15:46,074:INFO:Copying training dataset
2024-11-13 18:15:46,081:INFO:Defining folds
2024-11-13 18:15:46,081:INFO:Declaring metric variables
2024-11-13 18:15:46,085:INFO:Importing untrained model
2024-11-13 18:15:46,088:INFO:Huber Regressor Imported successfully
2024-11-13 18:15:46,095:INFO:Starting cross validation
2024-11-13 18:15:46,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:46,360:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,361:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,384:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,433:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,463:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,520:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,528:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,532:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,557:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:15:46,575:INFO:Calculating mean and std
2024-11-13 18:15:46,578:INFO:Creating metrics dataframe
2024-11-13 18:15:46,584:INFO:Uploading results into container
2024-11-13 18:15:46,584:INFO:Uploading model into container now
2024-11-13 18:15:46,585:INFO:_master_model_container: 10
2024-11-13 18:15:46,585:INFO:_display_container: 2
2024-11-13 18:15:46,585:INFO:HuberRegressor()
2024-11-13 18:15:46,586:INFO:create_model() successfully completed......................................
2024-11-13 18:15:46,752:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:46,752:INFO:Creating metrics dataframe
2024-11-13 18:15:46,764:INFO:Initializing K Neighbors Regressor
2024-11-13 18:15:46,764:INFO:Total runtime is 0.3337962667147318 minutes
2024-11-13 18:15:46,767:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:46,767:INFO:Initializing create_model()
2024-11-13 18:15:46,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:46,768:INFO:Checking exceptions
2024-11-13 18:15:46,768:INFO:Importing libraries
2024-11-13 18:15:46,768:INFO:Copying training dataset
2024-11-13 18:15:46,775:INFO:Defining folds
2024-11-13 18:15:46,775:INFO:Declaring metric variables
2024-11-13 18:15:46,779:INFO:Importing untrained model
2024-11-13 18:15:46,782:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:15:46,788:INFO:Starting cross validation
2024-11-13 18:15:46,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:47,046:INFO:Calculating mean and std
2024-11-13 18:15:47,050:INFO:Creating metrics dataframe
2024-11-13 18:15:47,055:INFO:Uploading results into container
2024-11-13 18:15:47,055:INFO:Uploading model into container now
2024-11-13 18:15:47,056:INFO:_master_model_container: 11
2024-11-13 18:15:47,056:INFO:_display_container: 2
2024-11-13 18:15:47,057:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:15:47,057:INFO:create_model() successfully completed......................................
2024-11-13 18:15:47,241:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:47,241:INFO:Creating metrics dataframe
2024-11-13 18:15:47,254:INFO:Initializing Decision Tree Regressor
2024-11-13 18:15:47,254:INFO:Total runtime is 0.3419704635938008 minutes
2024-11-13 18:15:47,257:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:47,258:INFO:Initializing create_model()
2024-11-13 18:15:47,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:47,258:INFO:Checking exceptions
2024-11-13 18:15:47,258:INFO:Importing libraries
2024-11-13 18:15:47,258:INFO:Copying training dataset
2024-11-13 18:15:47,266:INFO:Defining folds
2024-11-13 18:15:47,267:INFO:Declaring metric variables
2024-11-13 18:15:47,270:INFO:Importing untrained model
2024-11-13 18:15:47,274:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:15:47,280:INFO:Starting cross validation
2024-11-13 18:15:47,281:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:47,421:INFO:Calculating mean and std
2024-11-13 18:15:47,425:INFO:Creating metrics dataframe
2024-11-13 18:15:47,435:INFO:Uploading results into container
2024-11-13 18:15:47,437:INFO:Uploading model into container now
2024-11-13 18:15:47,438:INFO:_master_model_container: 12
2024-11-13 18:15:47,438:INFO:_display_container: 2
2024-11-13 18:15:47,438:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:15:47,438:INFO:create_model() successfully completed......................................
2024-11-13 18:15:47,656:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:47,657:INFO:Creating metrics dataframe
2024-11-13 18:15:47,671:INFO:Initializing Random Forest Regressor
2024-11-13 18:15:47,672:INFO:Total runtime is 0.3489264090855916 minutes
2024-11-13 18:15:47,676:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:47,676:INFO:Initializing create_model()
2024-11-13 18:15:47,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:47,676:INFO:Checking exceptions
2024-11-13 18:15:47,676:INFO:Importing libraries
2024-11-13 18:15:47,677:INFO:Copying training dataset
2024-11-13 18:15:47,683:INFO:Defining folds
2024-11-13 18:15:47,684:INFO:Declaring metric variables
2024-11-13 18:15:47,687:INFO:Importing untrained model
2024-11-13 18:15:47,691:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:15:47,697:INFO:Starting cross validation
2024-11-13 18:15:47,698:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:48,647:INFO:Calculating mean and std
2024-11-13 18:15:48,650:INFO:Creating metrics dataframe
2024-11-13 18:15:48,656:INFO:Uploading results into container
2024-11-13 18:15:48,657:INFO:Uploading model into container now
2024-11-13 18:15:48,657:INFO:_master_model_container: 13
2024-11-13 18:15:48,657:INFO:_display_container: 2
2024-11-13 18:15:48,658:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:15:48,658:INFO:create_model() successfully completed......................................
2024-11-13 18:15:48,835:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:48,835:INFO:Creating metrics dataframe
2024-11-13 18:15:48,848:INFO:Initializing Extra Trees Regressor
2024-11-13 18:15:48,848:INFO:Total runtime is 0.3685339609781901 minutes
2024-11-13 18:15:48,851:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:48,852:INFO:Initializing create_model()
2024-11-13 18:15:48,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:48,852:INFO:Checking exceptions
2024-11-13 18:15:48,852:INFO:Importing libraries
2024-11-13 18:15:48,852:INFO:Copying training dataset
2024-11-13 18:15:48,859:INFO:Defining folds
2024-11-13 18:15:48,859:INFO:Declaring metric variables
2024-11-13 18:15:48,863:INFO:Importing untrained model
2024-11-13 18:15:48,866:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:15:48,873:INFO:Starting cross validation
2024-11-13 18:15:48,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:49,385:INFO:Calculating mean and std
2024-11-13 18:15:49,387:INFO:Creating metrics dataframe
2024-11-13 18:15:49,393:INFO:Uploading results into container
2024-11-13 18:15:49,394:INFO:Uploading model into container now
2024-11-13 18:15:49,395:INFO:_master_model_container: 14
2024-11-13 18:15:49,395:INFO:_display_container: 2
2024-11-13 18:15:49,396:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:15:49,396:INFO:create_model() successfully completed......................................
2024-11-13 18:15:49,565:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:49,565:INFO:Creating metrics dataframe
2024-11-13 18:15:49,580:INFO:Initializing AdaBoost Regressor
2024-11-13 18:15:49,580:INFO:Total runtime is 0.3807297309239705 minutes
2024-11-13 18:15:49,584:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:49,584:INFO:Initializing create_model()
2024-11-13 18:15:49,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:49,584:INFO:Checking exceptions
2024-11-13 18:15:49,585:INFO:Importing libraries
2024-11-13 18:15:49,585:INFO:Copying training dataset
2024-11-13 18:15:49,593:INFO:Defining folds
2024-11-13 18:15:49,593:INFO:Declaring metric variables
2024-11-13 18:15:49,597:INFO:Importing untrained model
2024-11-13 18:15:49,600:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:15:49,607:INFO:Starting cross validation
2024-11-13 18:15:49,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:50,301:INFO:Calculating mean and std
2024-11-13 18:15:50,305:INFO:Creating metrics dataframe
2024-11-13 18:15:50,312:INFO:Uploading results into container
2024-11-13 18:15:50,312:INFO:Uploading model into container now
2024-11-13 18:15:50,313:INFO:_master_model_container: 15
2024-11-13 18:15:50,313:INFO:_display_container: 2
2024-11-13 18:15:50,313:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:15:50,313:INFO:create_model() successfully completed......................................
2024-11-13 18:15:50,491:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:50,491:INFO:Creating metrics dataframe
2024-11-13 18:15:50,503:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:15:50,503:INFO:Total runtime is 0.39612113237380975 minutes
2024-11-13 18:15:50,507:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:50,507:INFO:Initializing create_model()
2024-11-13 18:15:50,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:50,507:INFO:Checking exceptions
2024-11-13 18:15:50,507:INFO:Importing libraries
2024-11-13 18:15:50,508:INFO:Copying training dataset
2024-11-13 18:15:50,514:INFO:Defining folds
2024-11-13 18:15:50,515:INFO:Declaring metric variables
2024-11-13 18:15:50,518:INFO:Importing untrained model
2024-11-13 18:15:50,522:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:15:50,528:INFO:Starting cross validation
2024-11-13 18:15:50,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:52,296:INFO:Calculating mean and std
2024-11-13 18:15:52,299:INFO:Creating metrics dataframe
2024-11-13 18:15:52,307:INFO:Uploading results into container
2024-11-13 18:15:52,307:INFO:Uploading model into container now
2024-11-13 18:15:52,308:INFO:_master_model_container: 16
2024-11-13 18:15:52,308:INFO:_display_container: 2
2024-11-13 18:15:52,308:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:15:52,308:INFO:create_model() successfully completed......................................
2024-11-13 18:15:52,512:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:52,512:INFO:Creating metrics dataframe
2024-11-13 18:15:52,525:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:15:52,525:INFO:Total runtime is 0.4298223177591959 minutes
2024-11-13 18:15:52,529:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:52,529:INFO:Initializing create_model()
2024-11-13 18:15:52,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:52,529:INFO:Checking exceptions
2024-11-13 18:15:52,529:INFO:Importing libraries
2024-11-13 18:15:52,529:INFO:Copying training dataset
2024-11-13 18:15:52,536:INFO:Defining folds
2024-11-13 18:15:52,536:INFO:Declaring metric variables
2024-11-13 18:15:52,540:INFO:Importing untrained model
2024-11-13 18:15:52,544:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:15:52,550:INFO:Starting cross validation
2024-11-13 18:15:52,551:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:15:52,908:INFO:Calculating mean and std
2024-11-13 18:15:52,912:INFO:Creating metrics dataframe
2024-11-13 18:15:52,919:INFO:Uploading results into container
2024-11-13 18:15:52,919:INFO:Uploading model into container now
2024-11-13 18:15:52,920:INFO:_master_model_container: 17
2024-11-13 18:15:52,920:INFO:_display_container: 2
2024-11-13 18:15:52,921:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:15:52,921:INFO:create_model() successfully completed......................................
2024-11-13 18:15:53,098:INFO:SubProcess create_model() end ==================================
2024-11-13 18:15:53,099:INFO:Creating metrics dataframe
2024-11-13 18:15:53,113:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:15:53,113:INFO:Total runtime is 0.4396182298660278 minutes
2024-11-13 18:15:53,116:INFO:SubProcess create_model() called ==================================
2024-11-13 18:15:53,117:INFO:Initializing create_model()
2024-11-13 18:15:53,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:15:53,117:INFO:Checking exceptions
2024-11-13 18:15:53,117:INFO:Importing libraries
2024-11-13 18:15:53,117:INFO:Copying training dataset
2024-11-13 18:15:53,124:INFO:Defining folds
2024-11-13 18:15:53,124:INFO:Declaring metric variables
2024-11-13 18:15:53,128:INFO:Importing untrained model
2024-11-13 18:15:53,132:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:15:53,138:INFO:Starting cross validation
2024-11-13 18:15:53,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:22:46,535:INFO:Calculating mean and std
2024-11-13 18:22:46,539:INFO:Creating metrics dataframe
2024-11-13 18:22:46,545:INFO:Uploading results into container
2024-11-13 18:22:46,546:INFO:Uploading model into container now
2024-11-13 18:22:46,547:INFO:_master_model_container: 18
2024-11-13 18:22:46,547:INFO:_display_container: 2
2024-11-13 18:22:46,548:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:22:46,548:INFO:create_model() successfully completed......................................
2024-11-13 18:22:46,761:INFO:SubProcess create_model() end ==================================
2024-11-13 18:22:46,761:INFO:Creating metrics dataframe
2024-11-13 18:22:46,775:INFO:Initializing CatBoost Regressor
2024-11-13 18:22:46,775:INFO:Total runtime is 7.333981847763061 minutes
2024-11-13 18:22:46,778:INFO:SubProcess create_model() called ==================================
2024-11-13 18:22:46,779:INFO:Initializing create_model()
2024-11-13 18:22:46,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:22:46,779:INFO:Checking exceptions
2024-11-13 18:22:46,779:INFO:Importing libraries
2024-11-13 18:22:46,779:INFO:Copying training dataset
2024-11-13 18:22:46,787:INFO:Defining folds
2024-11-13 18:22:46,788:INFO:Declaring metric variables
2024-11-13 18:22:46,791:INFO:Importing untrained model
2024-11-13 18:22:46,795:INFO:CatBoost Regressor Imported successfully
2024-11-13 18:22:46,801:INFO:Starting cross validation
2024-11-13 18:22:46,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:22:57,501:INFO:Calculating mean and std
2024-11-13 18:22:57,505:INFO:Creating metrics dataframe
2024-11-13 18:22:57,513:INFO:Uploading results into container
2024-11-13 18:22:57,514:INFO:Uploading model into container now
2024-11-13 18:22:57,515:INFO:_master_model_container: 19
2024-11-13 18:22:57,515:INFO:_display_container: 2
2024-11-13 18:22:57,515:INFO:<catboost.core.CatBoostRegressor object at 0x7ff4bc1cef10>
2024-11-13 18:22:57,516:INFO:create_model() successfully completed......................................
2024-11-13 18:22:57,744:INFO:SubProcess create_model() end ==================================
2024-11-13 18:22:57,744:INFO:Creating metrics dataframe
2024-11-13 18:22:57,759:INFO:Initializing Dummy Regressor
2024-11-13 18:22:57,759:INFO:Total runtime is 7.517054319381714 minutes
2024-11-13 18:22:57,763:INFO:SubProcess create_model() called ==================================
2024-11-13 18:22:57,763:INFO:Initializing create_model()
2024-11-13 18:22:57,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff6c4750730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:22:57,763:INFO:Checking exceptions
2024-11-13 18:22:57,763:INFO:Importing libraries
2024-11-13 18:22:57,763:INFO:Copying training dataset
2024-11-13 18:22:57,773:INFO:Defining folds
2024-11-13 18:22:57,773:INFO:Declaring metric variables
2024-11-13 18:22:57,777:INFO:Importing untrained model
2024-11-13 18:22:57,780:INFO:Dummy Regressor Imported successfully
2024-11-13 18:22:57,787:INFO:Starting cross validation
2024-11-13 18:22:57,788:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:23:00,977:INFO:Calculating mean and std
2024-11-13 18:23:00,982:INFO:Creating metrics dataframe
2024-11-13 18:23:00,989:INFO:Uploading results into container
2024-11-13 18:23:00,990:INFO:Uploading model into container now
2024-11-13 18:23:00,991:INFO:_master_model_container: 20
2024-11-13 18:23:00,991:INFO:_display_container: 2
2024-11-13 18:23:00,992:INFO:DummyRegressor()
2024-11-13 18:23:00,992:INFO:create_model() successfully completed......................................
2024-11-13 18:23:01,240:INFO:SubProcess create_model() end ==================================
2024-11-13 18:23:01,240:INFO:Creating metrics dataframe
2024-11-13 18:23:01,264:INFO:Initializing create_model()
2024-11-13 18:23:01,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:23:01,265:INFO:Checking exceptions
2024-11-13 18:23:01,266:INFO:Importing libraries
2024-11-13 18:23:01,266:INFO:Copying training dataset
2024-11-13 18:23:01,273:INFO:Defining folds
2024-11-13 18:23:01,273:INFO:Declaring metric variables
2024-11-13 18:23:01,273:INFO:Importing untrained model
2024-11-13 18:23:01,273:INFO:Declaring custom model
2024-11-13 18:23:01,274:INFO:Linear Regression Imported successfully
2024-11-13 18:23:01,274:INFO:Cross validation set to False
2024-11-13 18:23:01,274:INFO:Fitting Model
2024-11-13 18:23:01,292:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:23:01,292:INFO:create_model() successfully completed......................................
2024-11-13 18:23:01,550:INFO:_master_model_container: 20
2024-11-13 18:23:01,550:INFO:_display_container: 2
2024-11-13 18:23:01,550:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:23:01,551:INFO:compare_models() successfully completed......................................
2024-11-13 18:25:27,014:INFO:Initializing plot_model()
2024-11-13 18:25:27,014:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, system=True)
2024-11-13 18:25:27,015:INFO:Checking exceptions
2024-11-13 18:25:27,025:INFO:Preloading libraries
2024-11-13 18:25:27,026:INFO:Copying training dataset
2024-11-13 18:25:27,026:INFO:Plot type: residuals
2024-11-13 18:25:27,125:INFO:Fitting Model
2024-11-13 18:25:27,125:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2024-11-13 18:25:27,201:INFO:Scoring test/hold-out set
2024-11-13 18:25:27,937:INFO:Visual Rendered Successfully
2024-11-13 18:25:28,122:INFO:plot_model() successfully completed......................................
2024-11-13 18:25:55,296:INFO:Initializing plot_model()
2024-11-13 18:25:55,297:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, system=True)
2024-11-13 18:25:55,297:INFO:Checking exceptions
2024-11-13 18:25:55,306:INFO:Preloading libraries
2024-11-13 18:25:55,306:INFO:Copying training dataset
2024-11-13 18:25:55,306:INFO:Plot type: error
2024-11-13 18:25:55,373:INFO:Fitting Model
2024-11-13 18:25:55,374:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2024-11-13 18:25:55,374:INFO:Scoring test/hold-out set
2024-11-13 18:25:55,689:INFO:Visual Rendered Successfully
2024-11-13 18:25:55,881:INFO:plot_model() successfully completed......................................
2024-11-13 18:26:27,635:INFO:Initializing plot_model()
2024-11-13 18:26:27,635:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5650b20>, system=True)
2024-11-13 18:26:27,635:INFO:Checking exceptions
2024-11-13 18:26:27,643:INFO:Preloading libraries
2024-11-13 18:26:27,643:INFO:Copying training dataset
2024-11-13 18:26:27,643:INFO:Plot type: feature
2024-11-13 18:26:27,793:INFO:Visual Rendered Successfully
2024-11-13 18:26:27,973:INFO:plot_model() successfully completed......................................
2024-11-13 18:36:51,064:INFO:PyCaret RegressionExperiment
2024-11-13 18:36:51,064:INFO:Logging name: reg-default-name
2024-11-13 18:36:51,064:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:36:51,064:INFO:version 3.2.0
2024-11-13 18:36:51,065:INFO:Initializing setup()
2024-11-13 18:36:51,065:INFO:self.USI: 4560
2024-11-13 18:36:51,065:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:36:51,065:INFO:Checking environment
2024-11-13 18:36:51,065:INFO:python_version: 3.8.13
2024-11-13 18:36:51,065:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:36:51,065:INFO:machine: x86_64
2024-11-13 18:36:51,065:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:36:51,065:INFO:Memory: svmem(total=270355722240, available=218183782400, percent=19.3, used=50090749952, free=55994060800, active=11659644928, inactive=142444417024, buffers=9957376, cached=164260954112, shared=187375616, slab=25015971840)
2024-11-13 18:36:51,069:INFO:Physical Core: 28
2024-11-13 18:36:51,069:INFO:Logical Core: 56
2024-11-13 18:36:51,069:INFO:Checking libraries
2024-11-13 18:36:51,069:INFO:System:
2024-11-13 18:36:51,069:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:36:51,069:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:36:51,069:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:36:51,069:INFO:PyCaret required dependencies:
2024-11-13 18:36:51,069:INFO:                 pip: 22.2.2
2024-11-13 18:36:51,069:INFO:          setuptools: 63.4.2
2024-11-13 18:36:51,069:INFO:             pycaret: 3.2.0
2024-11-13 18:36:51,069:INFO:             IPython: 8.12.2
2024-11-13 18:36:51,069:INFO:          ipywidgets: 7.7.1
2024-11-13 18:36:51,069:INFO:                tqdm: 4.64.1
2024-11-13 18:36:51,069:INFO:               numpy: 1.23.5
2024-11-13 18:36:51,069:INFO:              pandas: 1.5.3
2024-11-13 18:36:51,070:INFO:              jinja2: 3.1.2
2024-11-13 18:36:51,070:INFO:               scipy: 1.10.1
2024-11-13 18:36:51,070:INFO:              joblib: 1.3.0
2024-11-13 18:36:51,070:INFO:             sklearn: 1.1.2
2024-11-13 18:36:51,070:INFO:                pyod: 2.0.2
2024-11-13 18:36:51,070:INFO:            imblearn: 0.12.4
2024-11-13 18:36:51,070:INFO:   category_encoders: 2.6.4
2024-11-13 18:36:51,070:INFO:            lightgbm: 4.5.0
2024-11-13 18:36:51,070:INFO:               numba: 0.57.1
2024-11-13 18:36:51,070:INFO:            requests: 2.28.1
2024-11-13 18:36:51,070:INFO:          matplotlib: 3.5.1
2024-11-13 18:36:51,070:INFO:          scikitplot: 0.3.7
2024-11-13 18:36:51,070:INFO:         yellowbrick: 1.5
2024-11-13 18:36:51,070:INFO:              plotly: 5.24.1
2024-11-13 18:36:51,070:INFO:    plotly-resampler: Not installed
2024-11-13 18:36:51,070:INFO:             kaleido: 0.2.1
2024-11-13 18:36:51,070:INFO:           schemdraw: 0.15
2024-11-13 18:36:51,070:INFO:         statsmodels: 0.13.2
2024-11-13 18:36:51,070:INFO:              sktime: 0.21.1
2024-11-13 18:36:51,070:INFO:               tbats: 1.1.3
2024-11-13 18:36:51,071:INFO:            pmdarima: 2.0.4
2024-11-13 18:36:51,071:INFO:              psutil: 5.9.1
2024-11-13 18:36:51,071:INFO:          markupsafe: 2.1.1
2024-11-13 18:36:51,071:INFO:             pickle5: Not installed
2024-11-13 18:36:51,071:INFO:         cloudpickle: 2.1.0
2024-11-13 18:36:51,071:INFO:         deprecation: 2.1.0
2024-11-13 18:36:51,071:INFO:              xxhash: 3.5.0
2024-11-13 18:36:51,071:INFO:           wurlitzer: 3.1.1
2024-11-13 18:36:51,071:INFO:PyCaret optional dependencies:
2024-11-13 18:36:51,071:INFO:                shap: 0.44.1
2024-11-13 18:36:51,071:INFO:           interpret: 0.6.5
2024-11-13 18:36:51,071:INFO:                umap: 0.5.7
2024-11-13 18:36:51,071:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:36:51,071:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:36:51,071:INFO:             autoviz: Not installed
2024-11-13 18:36:51,071:INFO:           fairlearn: 0.7.0
2024-11-13 18:36:51,071:INFO:          deepchecks: Not installed
2024-11-13 18:36:51,071:INFO:             xgboost: 2.1.1
2024-11-13 18:36:51,071:INFO:            catboost: 1.2.7
2024-11-13 18:36:51,071:INFO:              kmodes: 0.12.2
2024-11-13 18:36:51,071:INFO:             mlxtend: 0.23.1
2024-11-13 18:36:51,071:INFO:       statsforecast: 1.5.0
2024-11-13 18:36:51,071:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:36:51,071:INFO:                 ray: 2.10.0
2024-11-13 18:36:51,071:INFO:            hyperopt: 0.2.7
2024-11-13 18:36:51,071:INFO:              optuna: 4.1.0
2024-11-13 18:36:51,072:INFO:               skopt: 0.10.2
2024-11-13 18:36:51,072:INFO:              mlflow: 1.30.1
2024-11-13 18:36:51,072:INFO:              gradio: 3.50.2
2024-11-13 18:36:51,072:INFO:             fastapi: 0.115.5
2024-11-13 18:36:51,072:INFO:             uvicorn: 0.32.0
2024-11-13 18:36:51,072:INFO:              m2cgen: 0.10.0
2024-11-13 18:36:51,072:INFO:           evidently: 0.2.8
2024-11-13 18:36:51,072:INFO:               fugue: 0.8.6
2024-11-13 18:36:51,072:INFO:           streamlit: Not installed
2024-11-13 18:36:51,072:INFO:             prophet: Not installed
2024-11-13 18:36:51,072:INFO:None
2024-11-13 18:36:51,072:INFO:Set up data.
2024-11-13 18:36:51,079:INFO:Set up folding strategy.
2024-11-13 18:36:51,079:INFO:Set up train/test split.
2024-11-13 18:36:51,085:INFO:Set up index.
2024-11-13 18:36:51,086:INFO:Assigning column types.
2024-11-13 18:36:51,091:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:36:51,091:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,096:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,101:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,210:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,213:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,213:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,217:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,221:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,269:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,305:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,305:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,308:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,308:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:36:51,312:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,316:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,363:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,400:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,402:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,406:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,410:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,494:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,496:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,497:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:36:51,504:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,554:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,590:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,592:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,600:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,648:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,684:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,686:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,686:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:36:51,741:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,777:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,780:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,871:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,872:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,874:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:51,874:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:36:51,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:51,966:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:51,968:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,023:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:36:52,060:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:52,062:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,062:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:36:52,156:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:52,159:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,252:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:52,254:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,255:INFO:Preparing preprocessing pipeline...
2024-11-13 18:36:52,255:INFO:Set up simple imputation.
2024-11-13 18:36:52,272:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:36:52,275:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:36:52,275:INFO:Creating final display dataframe.
2024-11-13 18:36:52,330:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4560
2024-11-13 18:36:52,437:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:52,439:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,531:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:36:52,533:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:36:52,534:INFO:setup() successfully completed in 1.47s...............
2024-11-13 18:38:43,222:INFO:PyCaret RegressionExperiment
2024-11-13 18:38:43,222:INFO:Logging name: reg-default-name
2024-11-13 18:38:43,222:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:38:43,222:INFO:version 3.2.0
2024-11-13 18:38:43,222:INFO:Initializing setup()
2024-11-13 18:38:43,222:INFO:self.USI: 512d
2024-11-13 18:38:43,222:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:38:43,222:INFO:Checking environment
2024-11-13 18:38:43,222:INFO:python_version: 3.8.13
2024-11-13 18:38:43,222:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:38:43,223:INFO:machine: x86_64
2024-11-13 18:38:43,223:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:38:43,223:INFO:Memory: svmem(total=270355722240, available=218161405952, percent=19.3, used=50113228800, free=56245051392, active=11659640832, inactive=142188494848, buffers=8888320, cached=163988553728, shared=187375616, slab=25015148544)
2024-11-13 18:38:43,227:INFO:Physical Core: 28
2024-11-13 18:38:43,227:INFO:Logical Core: 56
2024-11-13 18:38:43,227:INFO:Checking libraries
2024-11-13 18:38:43,227:INFO:System:
2024-11-13 18:38:43,227:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:38:43,227:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:38:43,227:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:38:43,227:INFO:PyCaret required dependencies:
2024-11-13 18:38:43,228:INFO:                 pip: 22.2.2
2024-11-13 18:38:43,228:INFO:          setuptools: 63.4.2
2024-11-13 18:38:43,228:INFO:             pycaret: 3.2.0
2024-11-13 18:38:43,228:INFO:             IPython: 8.12.2
2024-11-13 18:38:43,228:INFO:          ipywidgets: 7.7.1
2024-11-13 18:38:43,228:INFO:                tqdm: 4.64.1
2024-11-13 18:38:43,228:INFO:               numpy: 1.23.5
2024-11-13 18:38:43,228:INFO:              pandas: 1.5.3
2024-11-13 18:38:43,228:INFO:              jinja2: 3.1.2
2024-11-13 18:38:43,228:INFO:               scipy: 1.10.1
2024-11-13 18:38:43,228:INFO:              joblib: 1.3.0
2024-11-13 18:38:43,228:INFO:             sklearn: 1.1.2
2024-11-13 18:38:43,228:INFO:                pyod: 2.0.2
2024-11-13 18:38:43,228:INFO:            imblearn: 0.12.4
2024-11-13 18:38:43,228:INFO:   category_encoders: 2.6.4
2024-11-13 18:38:43,228:INFO:            lightgbm: 4.5.0
2024-11-13 18:38:43,229:INFO:               numba: 0.57.1
2024-11-13 18:38:43,229:INFO:            requests: 2.28.1
2024-11-13 18:38:43,229:INFO:          matplotlib: 3.5.1
2024-11-13 18:38:43,229:INFO:          scikitplot: 0.3.7
2024-11-13 18:38:43,229:INFO:         yellowbrick: 1.5
2024-11-13 18:38:43,229:INFO:              plotly: 5.24.1
2024-11-13 18:38:43,229:INFO:    plotly-resampler: Not installed
2024-11-13 18:38:43,229:INFO:             kaleido: 0.2.1
2024-11-13 18:38:43,229:INFO:           schemdraw: 0.15
2024-11-13 18:38:43,229:INFO:         statsmodels: 0.13.2
2024-11-13 18:38:43,229:INFO:              sktime: 0.21.1
2024-11-13 18:38:43,229:INFO:               tbats: 1.1.3
2024-11-13 18:38:43,229:INFO:            pmdarima: 2.0.4
2024-11-13 18:38:43,229:INFO:              psutil: 5.9.1
2024-11-13 18:38:43,229:INFO:          markupsafe: 2.1.1
2024-11-13 18:38:43,229:INFO:             pickle5: Not installed
2024-11-13 18:38:43,230:INFO:         cloudpickle: 2.1.0
2024-11-13 18:38:43,230:INFO:         deprecation: 2.1.0
2024-11-13 18:38:43,230:INFO:              xxhash: 3.5.0
2024-11-13 18:38:43,230:INFO:           wurlitzer: 3.1.1
2024-11-13 18:38:43,230:INFO:PyCaret optional dependencies:
2024-11-13 18:38:43,230:INFO:                shap: 0.44.1
2024-11-13 18:38:43,230:INFO:           interpret: 0.6.5
2024-11-13 18:38:43,230:INFO:                umap: 0.5.7
2024-11-13 18:38:43,230:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:38:43,230:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:38:43,230:INFO:             autoviz: Not installed
2024-11-13 18:38:43,230:INFO:           fairlearn: 0.7.0
2024-11-13 18:38:43,230:INFO:          deepchecks: Not installed
2024-11-13 18:38:43,230:INFO:             xgboost: 2.1.1
2024-11-13 18:38:43,231:INFO:            catboost: 1.2.7
2024-11-13 18:38:43,231:INFO:              kmodes: 0.12.2
2024-11-13 18:38:43,231:INFO:             mlxtend: 0.23.1
2024-11-13 18:38:43,231:INFO:       statsforecast: 1.5.0
2024-11-13 18:38:43,231:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:38:43,231:INFO:                 ray: 2.10.0
2024-11-13 18:38:43,231:INFO:            hyperopt: 0.2.7
2024-11-13 18:38:43,231:INFO:              optuna: 4.1.0
2024-11-13 18:38:43,231:INFO:               skopt: 0.10.2
2024-11-13 18:38:43,231:INFO:              mlflow: 1.30.1
2024-11-13 18:38:43,231:INFO:              gradio: 3.50.2
2024-11-13 18:38:43,231:INFO:             fastapi: 0.115.5
2024-11-13 18:38:43,231:INFO:             uvicorn: 0.32.0
2024-11-13 18:38:43,231:INFO:              m2cgen: 0.10.0
2024-11-13 18:38:43,231:INFO:           evidently: 0.2.8
2024-11-13 18:38:43,231:INFO:               fugue: 0.8.6
2024-11-13 18:38:43,231:INFO:           streamlit: Not installed
2024-11-13 18:38:43,231:INFO:             prophet: Not installed
2024-11-13 18:38:43,232:INFO:None
2024-11-13 18:38:43,232:INFO:Set up data.
2024-11-13 18:38:43,244:INFO:Set up folding strategy.
2024-11-13 18:38:43,244:INFO:Set up train/test split.
2024-11-13 18:38:43,249:INFO:Set up index.
2024-11-13 18:38:43,252:INFO:Assigning column types.
2024-11-13 18:38:43,257:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:38:43,257:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,262:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,267:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,374:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,376:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,377:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,381:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,385:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,469:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,471:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,472:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:38:43,476:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,479:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,563:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,565:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,569:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,573:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,656:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,658:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,659:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:38:43,666:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,714:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,749:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,750:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,752:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,760:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,843:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,846:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,846:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:38:43,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:43,937:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:43,940:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:43,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:44,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:38:44,031:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,033:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,034:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:38:44,091:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:44,129:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,132:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,190:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:38:44,227:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,229:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,230:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:38:44,321:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,323:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,421:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,423:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,425:INFO:Preparing preprocessing pipeline...
2024-11-13 18:38:44,425:INFO:Set up simple imputation.
2024-11-13 18:38:44,441:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:38:44,444:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Longitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:38:44,444:INFO:Creating final display dataframe.
2024-11-13 18:38:44,498:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Latitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              512d
2024-11-13 18:38:44,601:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,603:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,695:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:38:44,697:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:38:44,698:INFO:setup() successfully completed in 1.48s...............
2024-11-13 18:39:14,328:INFO:Initializing compare_models()
2024-11-13 18:39:14,329:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:39:14,329:INFO:Checking exceptions
2024-11-13 18:39:14,335:INFO:Preparing display monitor
2024-11-13 18:39:14,375:INFO:Initializing Linear Regression
2024-11-13 18:39:14,376:INFO:Total runtime is 3.6160151163736978e-06 minutes
2024-11-13 18:39:14,379:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:14,379:INFO:Initializing create_model()
2024-11-13 18:39:14,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:14,380:INFO:Checking exceptions
2024-11-13 18:39:14,380:INFO:Importing libraries
2024-11-13 18:39:14,380:INFO:Copying training dataset
2024-11-13 18:39:14,386:INFO:Defining folds
2024-11-13 18:39:14,386:INFO:Declaring metric variables
2024-11-13 18:39:14,390:INFO:Importing untrained model
2024-11-13 18:39:14,394:INFO:Linear Regression Imported successfully
2024-11-13 18:39:14,401:INFO:Starting cross validation
2024-11-13 18:39:14,402:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:18,759:INFO:Calculating mean and std
2024-11-13 18:39:18,764:INFO:Creating metrics dataframe
2024-11-13 18:39:18,772:INFO:Uploading results into container
2024-11-13 18:39:18,772:INFO:Uploading model into container now
2024-11-13 18:39:18,773:INFO:_master_model_container: 1
2024-11-13 18:39:18,773:INFO:_display_container: 2
2024-11-13 18:39:18,774:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:39:18,774:INFO:create_model() successfully completed......................................
2024-11-13 18:39:19,053:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:19,053:INFO:Creating metrics dataframe
2024-11-13 18:39:19,063:INFO:Initializing Lasso Regression
2024-11-13 18:39:19,063:INFO:Total runtime is 0.0781342109044393 minutes
2024-11-13 18:39:19,067:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:19,067:INFO:Initializing create_model()
2024-11-13 18:39:19,067:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:19,067:INFO:Checking exceptions
2024-11-13 18:39:19,067:INFO:Importing libraries
2024-11-13 18:39:19,068:INFO:Copying training dataset
2024-11-13 18:39:19,076:INFO:Defining folds
2024-11-13 18:39:19,076:INFO:Declaring metric variables
2024-11-13 18:39:19,080:INFO:Importing untrained model
2024-11-13 18:39:19,083:INFO:Lasso Regression Imported successfully
2024-11-13 18:39:19,090:INFO:Starting cross validation
2024-11-13 18:39:19,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:21,954:INFO:Calculating mean and std
2024-11-13 18:39:21,958:INFO:Creating metrics dataframe
2024-11-13 18:39:21,964:INFO:Uploading results into container
2024-11-13 18:39:21,965:INFO:Uploading model into container now
2024-11-13 18:39:21,966:INFO:_master_model_container: 2
2024-11-13 18:39:21,966:INFO:_display_container: 2
2024-11-13 18:39:21,966:INFO:Lasso(random_state=123)
2024-11-13 18:39:21,966:INFO:create_model() successfully completed......................................
2024-11-13 18:39:22,151:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:22,152:INFO:Creating metrics dataframe
2024-11-13 18:39:22,162:INFO:Initializing Ridge Regression
2024-11-13 18:39:22,162:INFO:Total runtime is 0.12978219588597617 minutes
2024-11-13 18:39:22,165:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:22,166:INFO:Initializing create_model()
2024-11-13 18:39:22,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:22,166:INFO:Checking exceptions
2024-11-13 18:39:22,166:INFO:Importing libraries
2024-11-13 18:39:22,166:INFO:Copying training dataset
2024-11-13 18:39:22,173:INFO:Defining folds
2024-11-13 18:39:22,173:INFO:Declaring metric variables
2024-11-13 18:39:22,177:INFO:Importing untrained model
2024-11-13 18:39:22,180:INFO:Ridge Regression Imported successfully
2024-11-13 18:39:22,186:INFO:Starting cross validation
2024-11-13 18:39:22,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:25,027:INFO:Calculating mean and std
2024-11-13 18:39:25,031:INFO:Creating metrics dataframe
2024-11-13 18:39:25,037:INFO:Uploading results into container
2024-11-13 18:39:25,037:INFO:Uploading model into container now
2024-11-13 18:39:25,038:INFO:_master_model_container: 3
2024-11-13 18:39:25,039:INFO:_display_container: 2
2024-11-13 18:39:25,039:INFO:Ridge(random_state=123)
2024-11-13 18:39:25,039:INFO:create_model() successfully completed......................................
2024-11-13 18:39:25,219:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:25,219:INFO:Creating metrics dataframe
2024-11-13 18:39:25,229:INFO:Initializing Elastic Net
2024-11-13 18:39:25,229:INFO:Total runtime is 0.1809010148048401 minutes
2024-11-13 18:39:25,233:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:25,233:INFO:Initializing create_model()
2024-11-13 18:39:25,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:25,234:INFO:Checking exceptions
2024-11-13 18:39:25,234:INFO:Importing libraries
2024-11-13 18:39:25,234:INFO:Copying training dataset
2024-11-13 18:39:25,241:INFO:Defining folds
2024-11-13 18:39:25,241:INFO:Declaring metric variables
2024-11-13 18:39:25,244:INFO:Importing untrained model
2024-11-13 18:39:25,248:INFO:Elastic Net Imported successfully
2024-11-13 18:39:25,255:INFO:Starting cross validation
2024-11-13 18:39:25,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:28,116:INFO:Calculating mean and std
2024-11-13 18:39:28,120:INFO:Creating metrics dataframe
2024-11-13 18:39:28,127:INFO:Uploading results into container
2024-11-13 18:39:28,128:INFO:Uploading model into container now
2024-11-13 18:39:28,128:INFO:_master_model_container: 4
2024-11-13 18:39:28,128:INFO:_display_container: 2
2024-11-13 18:39:28,129:INFO:ElasticNet(random_state=123)
2024-11-13 18:39:28,129:INFO:create_model() successfully completed......................................
2024-11-13 18:39:28,304:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:28,305:INFO:Creating metrics dataframe
2024-11-13 18:39:28,316:INFO:Initializing Least Angle Regression
2024-11-13 18:39:28,316:INFO:Total runtime is 0.23234000205993655 minutes
2024-11-13 18:39:28,319:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:28,319:INFO:Initializing create_model()
2024-11-13 18:39:28,319:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:28,320:INFO:Checking exceptions
2024-11-13 18:39:28,320:INFO:Importing libraries
2024-11-13 18:39:28,320:INFO:Copying training dataset
2024-11-13 18:39:28,329:INFO:Defining folds
2024-11-13 18:39:28,329:INFO:Declaring metric variables
2024-11-13 18:39:28,333:INFO:Importing untrained model
2024-11-13 18:39:28,336:INFO:Least Angle Regression Imported successfully
2024-11-13 18:39:28,343:INFO:Starting cross validation
2024-11-13 18:39:28,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:30,883:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:30,885:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,029:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,034:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,053:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,121:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,126:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,170:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,261:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,371:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:31,384:INFO:Calculating mean and std
2024-11-13 18:39:31,388:INFO:Creating metrics dataframe
2024-11-13 18:39:31,395:INFO:Uploading results into container
2024-11-13 18:39:31,396:INFO:Uploading model into container now
2024-11-13 18:39:31,396:INFO:_master_model_container: 5
2024-11-13 18:39:31,397:INFO:_display_container: 2
2024-11-13 18:39:31,397:INFO:Lars(random_state=123)
2024-11-13 18:39:31,397:INFO:create_model() successfully completed......................................
2024-11-13 18:39:31,582:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:31,582:INFO:Creating metrics dataframe
2024-11-13 18:39:31,593:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:39:31,593:INFO:Total runtime is 0.2869676907857259 minutes
2024-11-13 18:39:31,597:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:31,597:INFO:Initializing create_model()
2024-11-13 18:39:31,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:31,597:INFO:Checking exceptions
2024-11-13 18:39:31,598:INFO:Importing libraries
2024-11-13 18:39:31,598:INFO:Copying training dataset
2024-11-13 18:39:31,604:INFO:Defining folds
2024-11-13 18:39:31,605:INFO:Declaring metric variables
2024-11-13 18:39:31,608:INFO:Importing untrained model
2024-11-13 18:39:31,612:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:39:31,619:INFO:Starting cross validation
2024-11-13 18:39:31,620:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:31,698:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:31,704:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:31,709:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:31,712:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,128:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,152:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,205:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,338:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,463:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,488:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:39:34,503:INFO:Calculating mean and std
2024-11-13 18:39:34,507:INFO:Creating metrics dataframe
2024-11-13 18:39:34,512:INFO:Uploading results into container
2024-11-13 18:39:34,513:INFO:Uploading model into container now
2024-11-13 18:39:34,513:INFO:_master_model_container: 6
2024-11-13 18:39:34,513:INFO:_display_container: 2
2024-11-13 18:39:34,514:INFO:LassoLars(random_state=123)
2024-11-13 18:39:34,514:INFO:create_model() successfully completed......................................
2024-11-13 18:39:34,703:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:34,704:INFO:Creating metrics dataframe
2024-11-13 18:39:34,715:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:39:34,715:INFO:Total runtime is 0.3390020330746969 minutes
2024-11-13 18:39:34,719:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:34,719:INFO:Initializing create_model()
2024-11-13 18:39:34,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:34,719:INFO:Checking exceptions
2024-11-13 18:39:34,719:INFO:Importing libraries
2024-11-13 18:39:34,720:INFO:Copying training dataset
2024-11-13 18:39:34,727:INFO:Defining folds
2024-11-13 18:39:34,727:INFO:Declaring metric variables
2024-11-13 18:39:34,731:INFO:Importing untrained model
2024-11-13 18:39:34,734:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:39:34,743:INFO:Starting cross validation
2024-11-13 18:39:34,744:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:34,782:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,789:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,796:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,799:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,803:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,813:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,819:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,822:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,826:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,833:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:39:34,853:INFO:Calculating mean and std
2024-11-13 18:39:34,857:INFO:Creating metrics dataframe
2024-11-13 18:39:34,863:INFO:Uploading results into container
2024-11-13 18:39:34,864:INFO:Uploading model into container now
2024-11-13 18:39:34,865:INFO:_master_model_container: 7
2024-11-13 18:39:34,865:INFO:_display_container: 2
2024-11-13 18:39:34,865:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:39:34,865:INFO:create_model() successfully completed......................................
2024-11-13 18:39:35,071:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:35,071:INFO:Creating metrics dataframe
2024-11-13 18:39:35,085:INFO:Initializing Bayesian Ridge
2024-11-13 18:39:35,085:INFO:Total runtime is 0.345161259174347 minutes
2024-11-13 18:39:35,089:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:35,089:INFO:Initializing create_model()
2024-11-13 18:39:35,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:35,089:INFO:Checking exceptions
2024-11-13 18:39:35,090:INFO:Importing libraries
2024-11-13 18:39:35,090:INFO:Copying training dataset
2024-11-13 18:39:35,098:INFO:Defining folds
2024-11-13 18:39:35,098:INFO:Declaring metric variables
2024-11-13 18:39:35,102:INFO:Importing untrained model
2024-11-13 18:39:35,106:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:39:35,114:INFO:Starting cross validation
2024-11-13 18:39:35,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:35,224:INFO:Calculating mean and std
2024-11-13 18:39:35,228:INFO:Creating metrics dataframe
2024-11-13 18:39:35,235:INFO:Uploading results into container
2024-11-13 18:39:35,235:INFO:Uploading model into container now
2024-11-13 18:39:35,236:INFO:_master_model_container: 8
2024-11-13 18:39:35,236:INFO:_display_container: 2
2024-11-13 18:39:35,237:INFO:BayesianRidge()
2024-11-13 18:39:35,237:INFO:create_model() successfully completed......................................
2024-11-13 18:39:35,420:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:35,421:INFO:Creating metrics dataframe
2024-11-13 18:39:35,432:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:39:35,432:INFO:Total runtime is 0.3509482900301616 minutes
2024-11-13 18:39:35,436:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:35,436:INFO:Initializing create_model()
2024-11-13 18:39:35,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:35,436:INFO:Checking exceptions
2024-11-13 18:39:35,436:INFO:Importing libraries
2024-11-13 18:39:35,437:INFO:Copying training dataset
2024-11-13 18:39:35,443:INFO:Defining folds
2024-11-13 18:39:35,444:INFO:Declaring metric variables
2024-11-13 18:39:35,447:INFO:Importing untrained model
2024-11-13 18:39:35,450:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:39:35,457:INFO:Starting cross validation
2024-11-13 18:39:35,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:35,654:INFO:Calculating mean and std
2024-11-13 18:39:35,658:INFO:Creating metrics dataframe
2024-11-13 18:39:35,664:INFO:Uploading results into container
2024-11-13 18:39:35,664:INFO:Uploading model into container now
2024-11-13 18:39:35,665:INFO:_master_model_container: 9
2024-11-13 18:39:35,665:INFO:_display_container: 2
2024-11-13 18:39:35,666:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:39:35,666:INFO:create_model() successfully completed......................................
2024-11-13 18:39:35,914:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:35,914:INFO:Creating metrics dataframe
2024-11-13 18:39:35,933:INFO:Initializing Huber Regressor
2024-11-13 18:39:35,934:INFO:Total runtime is 0.35930647452672326 minutes
2024-11-13 18:39:35,938:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:35,938:INFO:Initializing create_model()
2024-11-13 18:39:35,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:35,938:INFO:Checking exceptions
2024-11-13 18:39:35,939:INFO:Importing libraries
2024-11-13 18:39:35,939:INFO:Copying training dataset
2024-11-13 18:39:35,947:INFO:Defining folds
2024-11-13 18:39:35,947:INFO:Declaring metric variables
2024-11-13 18:39:35,951:INFO:Importing untrained model
2024-11-13 18:39:35,956:INFO:Huber Regressor Imported successfully
2024-11-13 18:39:35,963:INFO:Starting cross validation
2024-11-13 18:39:35,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:36,231:INFO:Calculating mean and std
2024-11-13 18:39:36,235:INFO:Creating metrics dataframe
2024-11-13 18:39:36,242:INFO:Uploading results into container
2024-11-13 18:39:36,242:INFO:Uploading model into container now
2024-11-13 18:39:36,243:INFO:_master_model_container: 10
2024-11-13 18:39:36,243:INFO:_display_container: 2
2024-11-13 18:39:36,243:INFO:HuberRegressor()
2024-11-13 18:39:36,244:INFO:create_model() successfully completed......................................
2024-11-13 18:39:36,444:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:36,444:INFO:Creating metrics dataframe
2024-11-13 18:39:36,457:INFO:Initializing K Neighbors Regressor
2024-11-13 18:39:36,457:INFO:Total runtime is 0.3680347839991252 minutes
2024-11-13 18:39:36,461:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:36,461:INFO:Initializing create_model()
2024-11-13 18:39:36,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:36,461:INFO:Checking exceptions
2024-11-13 18:39:36,461:INFO:Importing libraries
2024-11-13 18:39:36,461:INFO:Copying training dataset
2024-11-13 18:39:36,470:INFO:Defining folds
2024-11-13 18:39:36,470:INFO:Declaring metric variables
2024-11-13 18:39:36,474:INFO:Importing untrained model
2024-11-13 18:39:36,477:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:39:36,484:INFO:Starting cross validation
2024-11-13 18:39:36,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:36,651:INFO:Calculating mean and std
2024-11-13 18:39:36,655:INFO:Creating metrics dataframe
2024-11-13 18:39:36,662:INFO:Uploading results into container
2024-11-13 18:39:36,663:INFO:Uploading model into container now
2024-11-13 18:39:36,663:INFO:_master_model_container: 11
2024-11-13 18:39:36,663:INFO:_display_container: 2
2024-11-13 18:39:36,664:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:39:36,664:INFO:create_model() successfully completed......................................
2024-11-13 18:39:36,834:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:36,834:INFO:Creating metrics dataframe
2024-11-13 18:39:36,846:INFO:Initializing Decision Tree Regressor
2024-11-13 18:39:36,846:INFO:Total runtime is 0.3745107332865398 minutes
2024-11-13 18:39:36,849:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:36,849:INFO:Initializing create_model()
2024-11-13 18:39:36,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:36,850:INFO:Checking exceptions
2024-11-13 18:39:36,850:INFO:Importing libraries
2024-11-13 18:39:36,850:INFO:Copying training dataset
2024-11-13 18:39:36,857:INFO:Defining folds
2024-11-13 18:39:36,857:INFO:Declaring metric variables
2024-11-13 18:39:36,860:INFO:Importing untrained model
2024-11-13 18:39:36,863:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:39:36,869:INFO:Starting cross validation
2024-11-13 18:39:36,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:37,035:INFO:Calculating mean and std
2024-11-13 18:39:37,039:INFO:Creating metrics dataframe
2024-11-13 18:39:37,046:INFO:Uploading results into container
2024-11-13 18:39:37,047:INFO:Uploading model into container now
2024-11-13 18:39:37,048:INFO:_master_model_container: 12
2024-11-13 18:39:37,048:INFO:_display_container: 2
2024-11-13 18:39:37,048:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:39:37,048:INFO:create_model() successfully completed......................................
2024-11-13 18:39:37,229:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:37,229:INFO:Creating metrics dataframe
2024-11-13 18:39:37,241:INFO:Initializing Random Forest Regressor
2024-11-13 18:39:37,241:INFO:Total runtime is 0.3810944040616354 minutes
2024-11-13 18:39:37,244:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:37,244:INFO:Initializing create_model()
2024-11-13 18:39:37,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:37,245:INFO:Checking exceptions
2024-11-13 18:39:37,245:INFO:Importing libraries
2024-11-13 18:39:37,245:INFO:Copying training dataset
2024-11-13 18:39:37,252:INFO:Defining folds
2024-11-13 18:39:37,252:INFO:Declaring metric variables
2024-11-13 18:39:37,255:INFO:Importing untrained model
2024-11-13 18:39:37,259:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:39:37,265:INFO:Starting cross validation
2024-11-13 18:39:37,266:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:38,763:INFO:Calculating mean and std
2024-11-13 18:39:38,767:INFO:Creating metrics dataframe
2024-11-13 18:39:38,775:INFO:Uploading results into container
2024-11-13 18:39:38,775:INFO:Uploading model into container now
2024-11-13 18:39:38,776:INFO:_master_model_container: 13
2024-11-13 18:39:38,776:INFO:_display_container: 2
2024-11-13 18:39:38,776:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:39:38,776:INFO:create_model() successfully completed......................................
2024-11-13 18:39:38,951:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:38,951:INFO:Creating metrics dataframe
2024-11-13 18:39:38,964:INFO:Initializing Extra Trees Regressor
2024-11-13 18:39:38,964:INFO:Total runtime is 0.4098136425018311 minutes
2024-11-13 18:39:38,967:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:38,968:INFO:Initializing create_model()
2024-11-13 18:39:38,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:38,968:INFO:Checking exceptions
2024-11-13 18:39:38,968:INFO:Importing libraries
2024-11-13 18:39:38,968:INFO:Copying training dataset
2024-11-13 18:39:38,976:INFO:Defining folds
2024-11-13 18:39:38,976:INFO:Declaring metric variables
2024-11-13 18:39:38,980:INFO:Importing untrained model
2024-11-13 18:39:38,983:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:39:38,989:INFO:Starting cross validation
2024-11-13 18:39:38,990:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:39,822:INFO:Calculating mean and std
2024-11-13 18:39:39,825:INFO:Creating metrics dataframe
2024-11-13 18:39:39,830:INFO:Uploading results into container
2024-11-13 18:39:39,831:INFO:Uploading model into container now
2024-11-13 18:39:39,831:INFO:_master_model_container: 14
2024-11-13 18:39:39,832:INFO:_display_container: 2
2024-11-13 18:39:39,832:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:39:39,832:INFO:create_model() successfully completed......................................
2024-11-13 18:39:40,004:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:40,004:INFO:Creating metrics dataframe
2024-11-13 18:39:40,017:INFO:Initializing AdaBoost Regressor
2024-11-13 18:39:40,017:INFO:Total runtime is 0.4273564418156942 minutes
2024-11-13 18:39:40,020:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:40,020:INFO:Initializing create_model()
2024-11-13 18:39:40,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:40,021:INFO:Checking exceptions
2024-11-13 18:39:40,021:INFO:Importing libraries
2024-11-13 18:39:40,021:INFO:Copying training dataset
2024-11-13 18:39:40,028:INFO:Defining folds
2024-11-13 18:39:40,028:INFO:Declaring metric variables
2024-11-13 18:39:40,032:INFO:Importing untrained model
2024-11-13 18:39:40,035:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:39:40,042:INFO:Starting cross validation
2024-11-13 18:39:40,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:40,909:INFO:Calculating mean and std
2024-11-13 18:39:40,912:INFO:Creating metrics dataframe
2024-11-13 18:39:40,919:INFO:Uploading results into container
2024-11-13 18:39:40,920:INFO:Uploading model into container now
2024-11-13 18:39:40,920:INFO:_master_model_container: 15
2024-11-13 18:39:40,920:INFO:_display_container: 2
2024-11-13 18:39:40,920:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:39:40,921:INFO:create_model() successfully completed......................................
2024-11-13 18:39:41,085:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:41,086:INFO:Creating metrics dataframe
2024-11-13 18:39:41,098:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:39:41,098:INFO:Total runtime is 0.445381776491801 minutes
2024-11-13 18:39:41,101:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:41,102:INFO:Initializing create_model()
2024-11-13 18:39:41,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:41,102:INFO:Checking exceptions
2024-11-13 18:39:41,102:INFO:Importing libraries
2024-11-13 18:39:41,102:INFO:Copying training dataset
2024-11-13 18:39:41,109:INFO:Defining folds
2024-11-13 18:39:41,109:INFO:Declaring metric variables
2024-11-13 18:39:41,112:INFO:Importing untrained model
2024-11-13 18:39:41,116:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:39:41,122:INFO:Starting cross validation
2024-11-13 18:39:41,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:42,665:INFO:Calculating mean and std
2024-11-13 18:39:42,667:INFO:Creating metrics dataframe
2024-11-13 18:39:42,673:INFO:Uploading results into container
2024-11-13 18:39:42,674:INFO:Uploading model into container now
2024-11-13 18:39:42,674:INFO:_master_model_container: 16
2024-11-13 18:39:42,674:INFO:_display_container: 2
2024-11-13 18:39:42,675:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:39:42,675:INFO:create_model() successfully completed......................................
2024-11-13 18:39:42,873:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:42,873:INFO:Creating metrics dataframe
2024-11-13 18:39:42,887:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:39:42,887:INFO:Total runtime is 0.4751961906750997 minutes
2024-11-13 18:39:42,890:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:42,891:INFO:Initializing create_model()
2024-11-13 18:39:42,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:42,891:INFO:Checking exceptions
2024-11-13 18:39:42,891:INFO:Importing libraries
2024-11-13 18:39:42,891:INFO:Copying training dataset
2024-11-13 18:39:42,898:INFO:Defining folds
2024-11-13 18:39:42,899:INFO:Declaring metric variables
2024-11-13 18:39:42,902:INFO:Importing untrained model
2024-11-13 18:39:42,906:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:39:42,913:INFO:Starting cross validation
2024-11-13 18:39:42,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:39:43,300:INFO:Calculating mean and std
2024-11-13 18:39:43,304:INFO:Creating metrics dataframe
2024-11-13 18:39:43,311:INFO:Uploading results into container
2024-11-13 18:39:43,311:INFO:Uploading model into container now
2024-11-13 18:39:43,312:INFO:_master_model_container: 17
2024-11-13 18:39:43,312:INFO:_display_container: 2
2024-11-13 18:39:43,313:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:39:43,313:INFO:create_model() successfully completed......................................
2024-11-13 18:39:43,487:INFO:SubProcess create_model() end ==================================
2024-11-13 18:39:43,487:INFO:Creating metrics dataframe
2024-11-13 18:39:43,501:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:39:43,501:INFO:Total runtime is 0.48542280991872155 minutes
2024-11-13 18:39:43,504:INFO:SubProcess create_model() called ==================================
2024-11-13 18:39:43,504:INFO:Initializing create_model()
2024-11-13 18:39:43,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:39:43,505:INFO:Checking exceptions
2024-11-13 18:39:43,505:INFO:Importing libraries
2024-11-13 18:39:43,505:INFO:Copying training dataset
2024-11-13 18:39:43,512:INFO:Defining folds
2024-11-13 18:39:43,512:INFO:Declaring metric variables
2024-11-13 18:39:43,516:INFO:Importing untrained model
2024-11-13 18:39:43,519:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:39:43,526:INFO:Starting cross validation
2024-11-13 18:39:43,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:46:35,183:INFO:Calculating mean and std
2024-11-13 18:46:35,186:INFO:Creating metrics dataframe
2024-11-13 18:46:35,193:INFO:Uploading results into container
2024-11-13 18:46:35,194:INFO:Uploading model into container now
2024-11-13 18:46:35,194:INFO:_master_model_container: 18
2024-11-13 18:46:35,195:INFO:_display_container: 2
2024-11-13 18:46:35,195:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:46:35,195:INFO:create_model() successfully completed......................................
2024-11-13 18:46:35,405:INFO:SubProcess create_model() end ==================================
2024-11-13 18:46:35,405:INFO:Creating metrics dataframe
2024-11-13 18:46:35,418:INFO:Initializing CatBoost Regressor
2024-11-13 18:46:35,419:INFO:Total runtime is 7.350722237428029 minutes
2024-11-13 18:46:35,422:INFO:SubProcess create_model() called ==================================
2024-11-13 18:46:35,422:INFO:Initializing create_model()
2024-11-13 18:46:35,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:46:35,423:INFO:Checking exceptions
2024-11-13 18:46:35,423:INFO:Importing libraries
2024-11-13 18:46:35,423:INFO:Copying training dataset
2024-11-13 18:46:35,431:INFO:Defining folds
2024-11-13 18:46:35,431:INFO:Declaring metric variables
2024-11-13 18:46:35,434:INFO:Importing untrained model
2024-11-13 18:46:35,438:INFO:CatBoost Regressor Imported successfully
2024-11-13 18:46:35,444:INFO:Starting cross validation
2024-11-13 18:46:35,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:46:48,104:INFO:Calculating mean and std
2024-11-13 18:46:48,109:INFO:Creating metrics dataframe
2024-11-13 18:46:48,117:INFO:Uploading results into container
2024-11-13 18:46:48,118:INFO:Uploading model into container now
2024-11-13 18:46:48,118:INFO:_master_model_container: 19
2024-11-13 18:46:48,118:INFO:_display_container: 2
2024-11-13 18:46:48,118:INFO:<catboost.core.CatBoostRegressor object at 0x7ff6b5461c10>
2024-11-13 18:46:48,119:INFO:create_model() successfully completed......................................
2024-11-13 18:46:48,326:INFO:SubProcess create_model() end ==================================
2024-11-13 18:46:48,327:INFO:Creating metrics dataframe
2024-11-13 18:46:48,343:INFO:Initializing Dummy Regressor
2024-11-13 18:46:48,343:INFO:Total runtime is 7.566124173005422 minutes
2024-11-13 18:46:48,346:INFO:SubProcess create_model() called ==================================
2024-11-13 18:46:48,347:INFO:Initializing create_model()
2024-11-13 18:46:48,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4bc270c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:46:48,347:INFO:Checking exceptions
2024-11-13 18:46:48,347:INFO:Importing libraries
2024-11-13 18:46:48,347:INFO:Copying training dataset
2024-11-13 18:46:48,356:INFO:Defining folds
2024-11-13 18:46:48,356:INFO:Declaring metric variables
2024-11-13 18:46:48,360:INFO:Importing untrained model
2024-11-13 18:46:48,363:INFO:Dummy Regressor Imported successfully
2024-11-13 18:46:48,370:INFO:Starting cross validation
2024-11-13 18:46:48,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:46:51,276:INFO:Calculating mean and std
2024-11-13 18:46:51,282:INFO:Creating metrics dataframe
2024-11-13 18:46:51,289:INFO:Uploading results into container
2024-11-13 18:46:51,290:INFO:Uploading model into container now
2024-11-13 18:46:51,291:INFO:_master_model_container: 20
2024-11-13 18:46:51,291:INFO:_display_container: 2
2024-11-13 18:46:51,291:INFO:DummyRegressor()
2024-11-13 18:46:51,291:INFO:create_model() successfully completed......................................
2024-11-13 18:46:51,514:INFO:SubProcess create_model() end ==================================
2024-11-13 18:46:51,514:INFO:Creating metrics dataframe
2024-11-13 18:46:51,543:INFO:Initializing create_model()
2024-11-13 18:46:51,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4bc519e20>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:46:51,543:INFO:Checking exceptions
2024-11-13 18:46:51,546:INFO:Importing libraries
2024-11-13 18:46:51,546:INFO:Copying training dataset
2024-11-13 18:46:51,554:INFO:Defining folds
2024-11-13 18:46:51,554:INFO:Declaring metric variables
2024-11-13 18:46:51,554:INFO:Importing untrained model
2024-11-13 18:46:51,554:INFO:Declaring custom model
2024-11-13 18:46:51,555:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:46:51,556:INFO:Cross validation set to False
2024-11-13 18:46:51,556:INFO:Fitting Model
2024-11-13 18:46:51,826:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:46:51,826:INFO:create_model() successfully completed......................................
2024-11-13 18:46:52,078:INFO:_master_model_container: 20
2024-11-13 18:46:52,078:INFO:_display_container: 2
2024-11-13 18:46:52,079:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:46:52,079:INFO:compare_models() successfully completed......................................
2024-11-13 18:46:52,176:INFO:PyCaret RegressionExperiment
2024-11-13 18:46:52,176:INFO:Logging name: reg-default-name
2024-11-13 18:46:52,176:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:46:52,176:INFO:version 3.2.0
2024-11-13 18:46:52,176:INFO:Initializing setup()
2024-11-13 18:46:52,176:INFO:self.USI: 9634
2024-11-13 18:46:52,176:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:46:52,176:INFO:Checking environment
2024-11-13 18:46:52,176:INFO:python_version: 3.8.13
2024-11-13 18:46:52,176:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:46:52,176:INFO:machine: x86_64
2024-11-13 18:46:52,176:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:46:52,177:INFO:Memory: svmem(total=270355722240, available=213269176320, percent=21.1, used=55016202240, free=50934038528, active=11660058624, inactive=147416322048, buffers=9957376, cached=164395524096, shared=187604992, slab=25030881280)
2024-11-13 18:46:52,180:INFO:Physical Core: 28
2024-11-13 18:46:52,180:INFO:Logical Core: 56
2024-11-13 18:46:52,180:INFO:Checking libraries
2024-11-13 18:46:52,180:INFO:System:
2024-11-13 18:46:52,180:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:46:52,180:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:46:52,180:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:46:52,180:INFO:PyCaret required dependencies:
2024-11-13 18:46:52,180:INFO:                 pip: 22.2.2
2024-11-13 18:46:52,180:INFO:          setuptools: 63.4.2
2024-11-13 18:46:52,180:INFO:             pycaret: 3.2.0
2024-11-13 18:46:52,180:INFO:             IPython: 8.12.2
2024-11-13 18:46:52,180:INFO:          ipywidgets: 7.7.1
2024-11-13 18:46:52,180:INFO:                tqdm: 4.64.1
2024-11-13 18:46:52,180:INFO:               numpy: 1.23.5
2024-11-13 18:46:52,180:INFO:              pandas: 1.5.3
2024-11-13 18:46:52,180:INFO:              jinja2: 3.1.2
2024-11-13 18:46:52,180:INFO:               scipy: 1.10.1
2024-11-13 18:46:52,181:INFO:              joblib: 1.3.0
2024-11-13 18:46:52,181:INFO:             sklearn: 1.1.2
2024-11-13 18:46:52,181:INFO:                pyod: 2.0.2
2024-11-13 18:46:52,181:INFO:            imblearn: 0.12.4
2024-11-13 18:46:52,181:INFO:   category_encoders: 2.6.4
2024-11-13 18:46:52,181:INFO:            lightgbm: 4.5.0
2024-11-13 18:46:52,181:INFO:               numba: 0.57.1
2024-11-13 18:46:52,181:INFO:            requests: 2.28.1
2024-11-13 18:46:52,181:INFO:          matplotlib: 3.5.1
2024-11-13 18:46:52,181:INFO:          scikitplot: 0.3.7
2024-11-13 18:46:52,181:INFO:         yellowbrick: 1.5
2024-11-13 18:46:52,181:INFO:              plotly: 5.24.1
2024-11-13 18:46:52,181:INFO:    plotly-resampler: Not installed
2024-11-13 18:46:52,181:INFO:             kaleido: 0.2.1
2024-11-13 18:46:52,181:INFO:           schemdraw: 0.15
2024-11-13 18:46:52,181:INFO:         statsmodels: 0.13.2
2024-11-13 18:46:52,181:INFO:              sktime: 0.21.1
2024-11-13 18:46:52,181:INFO:               tbats: 1.1.3
2024-11-13 18:46:52,181:INFO:            pmdarima: 2.0.4
2024-11-13 18:46:52,181:INFO:              psutil: 5.9.1
2024-11-13 18:46:52,181:INFO:          markupsafe: 2.1.1
2024-11-13 18:46:52,181:INFO:             pickle5: Not installed
2024-11-13 18:46:52,181:INFO:         cloudpickle: 2.1.0
2024-11-13 18:46:52,181:INFO:         deprecation: 2.1.0
2024-11-13 18:46:52,182:INFO:              xxhash: 3.5.0
2024-11-13 18:46:52,182:INFO:           wurlitzer: 3.1.1
2024-11-13 18:46:52,182:INFO:PyCaret optional dependencies:
2024-11-13 18:46:52,182:INFO:                shap: 0.44.1
2024-11-13 18:46:52,182:INFO:           interpret: 0.6.5
2024-11-13 18:46:52,182:INFO:                umap: 0.5.7
2024-11-13 18:46:52,182:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:46:52,182:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:46:52,182:INFO:             autoviz: Not installed
2024-11-13 18:46:52,182:INFO:           fairlearn: 0.7.0
2024-11-13 18:46:52,182:INFO:          deepchecks: Not installed
2024-11-13 18:46:52,182:INFO:             xgboost: 2.1.1
2024-11-13 18:46:52,182:INFO:            catboost: 1.2.7
2024-11-13 18:46:52,182:INFO:              kmodes: 0.12.2
2024-11-13 18:46:52,182:INFO:             mlxtend: 0.23.1
2024-11-13 18:46:52,182:INFO:       statsforecast: 1.5.0
2024-11-13 18:46:52,182:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:46:52,182:INFO:                 ray: 2.10.0
2024-11-13 18:46:52,182:INFO:            hyperopt: 0.2.7
2024-11-13 18:46:52,182:INFO:              optuna: 4.1.0
2024-11-13 18:46:52,183:INFO:               skopt: 0.10.2
2024-11-13 18:46:52,183:INFO:              mlflow: 1.30.1
2024-11-13 18:46:52,183:INFO:              gradio: 3.50.2
2024-11-13 18:46:52,183:INFO:             fastapi: 0.115.5
2024-11-13 18:46:52,183:INFO:             uvicorn: 0.32.0
2024-11-13 18:46:52,183:INFO:              m2cgen: 0.10.0
2024-11-13 18:46:52,183:INFO:           evidently: 0.2.8
2024-11-13 18:46:52,183:INFO:               fugue: 0.8.6
2024-11-13 18:46:52,183:INFO:           streamlit: Not installed
2024-11-13 18:46:52,183:INFO:             prophet: Not installed
2024-11-13 18:46:52,183:INFO:None
2024-11-13 18:46:52,183:INFO:Set up data.
2024-11-13 18:46:52,189:INFO:Set up folding strategy.
2024-11-13 18:46:52,190:INFO:Set up train/test split.
2024-11-13 18:46:52,197:INFO:Set up index.
2024-11-13 18:46:52,199:INFO:Assigning column types.
2024-11-13 18:46:52,204:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:46:52,204:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,208:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,212:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,261:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,297:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,300:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,301:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,304:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,308:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,393:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,393:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,395:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,396:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:46:52,400:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,403:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,451:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,489:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,491:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,496:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,499:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,584:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,586:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,587:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:46:52,594:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,642:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,679:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,681:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,689:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,775:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,777:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,778:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:46:52,834:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,870:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,870:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,872:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,928:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:46:52,965:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:52,967:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:52,967:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:46:53,023:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:53,062:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,064:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:46:53,158:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,160:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,161:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:46:53,253:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,255:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,352:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,354:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,356:INFO:Preparing preprocessing pipeline...
2024-11-13 18:46:53,356:INFO:Set up simple imputation.
2024-11-13 18:46:53,373:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:46:53,376:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Latitude', 'STORM_DIR', 'Vshear',
                                             'Daily_SST_Avg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:46:53,376:INFO:Creating final display dataframe.
2024-11-13 18:46:53,435:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Longitude
2                   Target type        Regression
3           Original data shape        (31316, 5)
4        Transformed data shape        (31316, 5)
5   Transformed train set shape        (21921, 5)
6    Transformed test set shape         (9395, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              9634
2024-11-13 18:46:53,536:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,538:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,629:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:46:53,632:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:46:53,632:INFO:setup() successfully completed in 1.46s...............
2024-11-13 18:46:53,634:INFO:Initializing compare_models()
2024-11-13 18:46:53,634:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:46:53,634:INFO:Checking exceptions
2024-11-13 18:46:53,637:INFO:Preparing display monitor
2024-11-13 18:46:53,668:INFO:Initializing Linear Regression
2024-11-13 18:46:53,668:INFO:Total runtime is 2.658367156982422e-06 minutes
2024-11-13 18:46:53,671:INFO:SubProcess create_model() called ==================================
2024-11-13 18:46:53,672:INFO:Initializing create_model()
2024-11-13 18:46:53,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:46:53,672:INFO:Checking exceptions
2024-11-13 18:46:53,674:INFO:Importing libraries
2024-11-13 18:46:53,674:INFO:Copying training dataset
2024-11-13 18:46:53,679:INFO:Defining folds
2024-11-13 18:46:53,679:INFO:Declaring metric variables
2024-11-13 18:46:53,682:INFO:Importing untrained model
2024-11-13 18:46:53,686:INFO:Linear Regression Imported successfully
2024-11-13 18:46:53,692:INFO:Starting cross validation
2024-11-13 18:46:53,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:46:56,703:INFO:Calculating mean and std
2024-11-13 18:46:56,709:INFO:Creating metrics dataframe
2024-11-13 18:46:56,715:INFO:Uploading results into container
2024-11-13 18:46:56,716:INFO:Uploading model into container now
2024-11-13 18:46:56,717:INFO:_master_model_container: 1
2024-11-13 18:46:56,717:INFO:_display_container: 2
2024-11-13 18:46:56,718:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:46:56,718:INFO:create_model() successfully completed......................................
2024-11-13 18:46:56,967:INFO:SubProcess create_model() end ==================================
2024-11-13 18:46:56,967:INFO:Creating metrics dataframe
2024-11-13 18:46:56,977:INFO:Initializing Lasso Regression
2024-11-13 18:46:56,977:INFO:Total runtime is 0.05514726638793945 minutes
2024-11-13 18:46:56,980:INFO:SubProcess create_model() called ==================================
2024-11-13 18:46:56,981:INFO:Initializing create_model()
2024-11-13 18:46:56,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:46:56,981:INFO:Checking exceptions
2024-11-13 18:46:56,981:INFO:Importing libraries
2024-11-13 18:46:56,981:INFO:Copying training dataset
2024-11-13 18:46:56,989:INFO:Defining folds
2024-11-13 18:46:56,989:INFO:Declaring metric variables
2024-11-13 18:46:56,992:INFO:Importing untrained model
2024-11-13 18:46:56,996:INFO:Lasso Regression Imported successfully
2024-11-13 18:46:57,003:INFO:Starting cross validation
2024-11-13 18:46:57,004:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:00,525:INFO:Calculating mean and std
2024-11-13 18:47:00,530:INFO:Creating metrics dataframe
2024-11-13 18:47:00,537:INFO:Uploading results into container
2024-11-13 18:47:00,538:INFO:Uploading model into container now
2024-11-13 18:47:00,539:INFO:_master_model_container: 2
2024-11-13 18:47:00,539:INFO:_display_container: 2
2024-11-13 18:47:00,540:INFO:Lasso(random_state=123)
2024-11-13 18:47:00,540:INFO:create_model() successfully completed......................................
2024-11-13 18:47:00,775:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:00,775:INFO:Creating metrics dataframe
2024-11-13 18:47:00,786:INFO:Initializing Ridge Regression
2024-11-13 18:47:00,786:INFO:Total runtime is 0.11862649520238241 minutes
2024-11-13 18:47:00,789:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:00,789:INFO:Initializing create_model()
2024-11-13 18:47:00,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:00,790:INFO:Checking exceptions
2024-11-13 18:47:00,790:INFO:Importing libraries
2024-11-13 18:47:00,790:INFO:Copying training dataset
2024-11-13 18:47:00,798:INFO:Defining folds
2024-11-13 18:47:00,799:INFO:Declaring metric variables
2024-11-13 18:47:00,802:INFO:Importing untrained model
2024-11-13 18:47:00,805:INFO:Ridge Regression Imported successfully
2024-11-13 18:47:00,812:INFO:Starting cross validation
2024-11-13 18:47:00,813:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:03,654:INFO:Calculating mean and std
2024-11-13 18:47:03,658:INFO:Creating metrics dataframe
2024-11-13 18:47:03,664:INFO:Uploading results into container
2024-11-13 18:47:03,665:INFO:Uploading model into container now
2024-11-13 18:47:03,665:INFO:_master_model_container: 3
2024-11-13 18:47:03,666:INFO:_display_container: 2
2024-11-13 18:47:03,666:INFO:Ridge(random_state=123)
2024-11-13 18:47:03,666:INFO:create_model() successfully completed......................................
2024-11-13 18:47:03,883:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:03,883:INFO:Creating metrics dataframe
2024-11-13 18:47:03,895:INFO:Initializing Elastic Net
2024-11-13 18:47:03,895:INFO:Total runtime is 0.1704444726308187 minutes
2024-11-13 18:47:03,898:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:03,899:INFO:Initializing create_model()
2024-11-13 18:47:03,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:03,899:INFO:Checking exceptions
2024-11-13 18:47:03,899:INFO:Importing libraries
2024-11-13 18:47:03,899:INFO:Copying training dataset
2024-11-13 18:47:03,906:INFO:Defining folds
2024-11-13 18:47:03,907:INFO:Declaring metric variables
2024-11-13 18:47:03,910:INFO:Importing untrained model
2024-11-13 18:47:03,913:INFO:Elastic Net Imported successfully
2024-11-13 18:47:03,919:INFO:Starting cross validation
2024-11-13 18:47:03,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:06,619:INFO:Calculating mean and std
2024-11-13 18:47:06,622:INFO:Creating metrics dataframe
2024-11-13 18:47:06,628:INFO:Uploading results into container
2024-11-13 18:47:06,629:INFO:Uploading model into container now
2024-11-13 18:47:06,629:INFO:_master_model_container: 4
2024-11-13 18:47:06,629:INFO:_display_container: 2
2024-11-13 18:47:06,630:INFO:ElasticNet(random_state=123)
2024-11-13 18:47:06,630:INFO:create_model() successfully completed......................................
2024-11-13 18:47:06,831:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:06,831:INFO:Creating metrics dataframe
2024-11-13 18:47:06,842:INFO:Initializing Least Angle Regression
2024-11-13 18:47:06,842:INFO:Total runtime is 0.21956852674484253 minutes
2024-11-13 18:47:06,845:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:06,846:INFO:Initializing create_model()
2024-11-13 18:47:06,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:06,846:INFO:Checking exceptions
2024-11-13 18:47:06,846:INFO:Importing libraries
2024-11-13 18:47:06,846:INFO:Copying training dataset
2024-11-13 18:47:06,853:INFO:Defining folds
2024-11-13 18:47:06,853:INFO:Declaring metric variables
2024-11-13 18:47:06,857:INFO:Importing untrained model
2024-11-13 18:47:06,860:INFO:Least Angle Regression Imported successfully
2024-11-13 18:47:06,866:INFO:Starting cross validation
2024-11-13 18:47:06,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:06,902:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:06,959:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:06,971:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:06,979:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:06,991:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:06,995:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:09,453:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:09,486:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:09,534:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:09,541:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:09,557:INFO:Calculating mean and std
2024-11-13 18:47:09,560:INFO:Creating metrics dataframe
2024-11-13 18:47:09,567:INFO:Uploading results into container
2024-11-13 18:47:09,568:INFO:Uploading model into container now
2024-11-13 18:47:09,569:INFO:_master_model_container: 5
2024-11-13 18:47:09,569:INFO:_display_container: 2
2024-11-13 18:47:09,569:INFO:Lars(random_state=123)
2024-11-13 18:47:09,569:INFO:create_model() successfully completed......................................
2024-11-13 18:47:09,778:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:09,778:INFO:Creating metrics dataframe
2024-11-13 18:47:09,789:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:47:09,789:INFO:Total runtime is 0.26868749062220254 minutes
2024-11-13 18:47:09,793:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:09,793:INFO:Initializing create_model()
2024-11-13 18:47:09,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:09,793:INFO:Checking exceptions
2024-11-13 18:47:09,793:INFO:Importing libraries
2024-11-13 18:47:09,794:INFO:Copying training dataset
2024-11-13 18:47:09,801:INFO:Defining folds
2024-11-13 18:47:09,802:INFO:Declaring metric variables
2024-11-13 18:47:09,805:INFO:Importing untrained model
2024-11-13 18:47:09,808:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:47:09,815:INFO:Starting cross validation
2024-11-13 18:47:09,816:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:09,854:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,859:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,860:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,869:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,874:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,884:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,885:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,893:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:09,901:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:12,121:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:47:12,135:INFO:Calculating mean and std
2024-11-13 18:47:12,139:INFO:Creating metrics dataframe
2024-11-13 18:47:12,146:INFO:Uploading results into container
2024-11-13 18:47:12,147:INFO:Uploading model into container now
2024-11-13 18:47:12,148:INFO:_master_model_container: 6
2024-11-13 18:47:12,148:INFO:_display_container: 2
2024-11-13 18:47:12,148:INFO:LassoLars(random_state=123)
2024-11-13 18:47:12,148:INFO:create_model() successfully completed......................................
2024-11-13 18:47:12,338:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:12,338:INFO:Creating metrics dataframe
2024-11-13 18:47:12,348:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:47:12,349:INFO:Total runtime is 0.31134126583735144 minutes
2024-11-13 18:47:12,352:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:12,352:INFO:Initializing create_model()
2024-11-13 18:47:12,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:12,353:INFO:Checking exceptions
2024-11-13 18:47:12,353:INFO:Importing libraries
2024-11-13 18:47:12,353:INFO:Copying training dataset
2024-11-13 18:47:12,360:INFO:Defining folds
2024-11-13 18:47:12,360:INFO:Declaring metric variables
2024-11-13 18:47:12,363:INFO:Importing untrained model
2024-11-13 18:47:12,367:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:47:12,373:INFO:Starting cross validation
2024-11-13 18:47:12,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:12,409:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,414:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,425:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,429:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,439:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,444:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,449:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,449:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,453:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,461:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:47:12,480:INFO:Calculating mean and std
2024-11-13 18:47:12,484:INFO:Creating metrics dataframe
2024-11-13 18:47:12,491:INFO:Uploading results into container
2024-11-13 18:47:12,492:INFO:Uploading model into container now
2024-11-13 18:47:12,492:INFO:_master_model_container: 7
2024-11-13 18:47:12,492:INFO:_display_container: 2
2024-11-13 18:47:12,492:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:47:12,493:INFO:create_model() successfully completed......................................
2024-11-13 18:47:12,677:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:12,677:INFO:Creating metrics dataframe
2024-11-13 18:47:12,689:INFO:Initializing Bayesian Ridge
2024-11-13 18:47:12,689:INFO:Total runtime is 0.31701076030731196 minutes
2024-11-13 18:47:12,692:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:12,692:INFO:Initializing create_model()
2024-11-13 18:47:12,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:12,692:INFO:Checking exceptions
2024-11-13 18:47:12,693:INFO:Importing libraries
2024-11-13 18:47:12,693:INFO:Copying training dataset
2024-11-13 18:47:12,700:INFO:Defining folds
2024-11-13 18:47:12,700:INFO:Declaring metric variables
2024-11-13 18:47:12,703:INFO:Importing untrained model
2024-11-13 18:47:12,706:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:47:12,713:INFO:Starting cross validation
2024-11-13 18:47:12,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:12,823:INFO:Calculating mean and std
2024-11-13 18:47:12,826:INFO:Creating metrics dataframe
2024-11-13 18:47:12,832:INFO:Uploading results into container
2024-11-13 18:47:12,832:INFO:Uploading model into container now
2024-11-13 18:47:12,833:INFO:_master_model_container: 8
2024-11-13 18:47:12,833:INFO:_display_container: 2
2024-11-13 18:47:12,833:INFO:BayesianRidge()
2024-11-13 18:47:12,833:INFO:create_model() successfully completed......................................
2024-11-13 18:47:13,026:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:13,026:INFO:Creating metrics dataframe
2024-11-13 18:47:13,038:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:47:13,038:INFO:Total runtime is 0.32283161083857215 minutes
2024-11-13 18:47:13,041:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:13,042:INFO:Initializing create_model()
2024-11-13 18:47:13,042:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:13,042:INFO:Checking exceptions
2024-11-13 18:47:13,042:INFO:Importing libraries
2024-11-13 18:47:13,042:INFO:Copying training dataset
2024-11-13 18:47:13,049:INFO:Defining folds
2024-11-13 18:47:13,050:INFO:Declaring metric variables
2024-11-13 18:47:13,053:INFO:Importing untrained model
2024-11-13 18:47:13,057:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:47:13,063:INFO:Starting cross validation
2024-11-13 18:47:13,064:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:13,216:INFO:Calculating mean and std
2024-11-13 18:47:13,219:INFO:Creating metrics dataframe
2024-11-13 18:47:13,225:INFO:Uploading results into container
2024-11-13 18:47:13,226:INFO:Uploading model into container now
2024-11-13 18:47:13,227:INFO:_master_model_container: 9
2024-11-13 18:47:13,227:INFO:_display_container: 2
2024-11-13 18:47:13,228:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:47:13,228:INFO:create_model() successfully completed......................................
2024-11-13 18:47:13,449:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:13,449:INFO:Creating metrics dataframe
2024-11-13 18:47:13,461:INFO:Initializing Huber Regressor
2024-11-13 18:47:13,462:INFO:Total runtime is 0.32989167769749955 minutes
2024-11-13 18:47:13,465:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:13,465:INFO:Initializing create_model()
2024-11-13 18:47:13,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:13,465:INFO:Checking exceptions
2024-11-13 18:47:13,466:INFO:Importing libraries
2024-11-13 18:47:13,466:INFO:Copying training dataset
2024-11-13 18:47:13,480:INFO:Defining folds
2024-11-13 18:47:13,480:INFO:Declaring metric variables
2024-11-13 18:47:13,484:INFO:Importing untrained model
2024-11-13 18:47:13,488:INFO:Huber Regressor Imported successfully
2024-11-13 18:47:13,496:INFO:Starting cross validation
2024-11-13 18:47:13,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:13,757:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:47:13,757:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:47:13,769:INFO:Calculating mean and std
2024-11-13 18:47:13,773:INFO:Creating metrics dataframe
2024-11-13 18:47:13,779:INFO:Uploading results into container
2024-11-13 18:47:13,780:INFO:Uploading model into container now
2024-11-13 18:47:13,780:INFO:_master_model_container: 10
2024-11-13 18:47:13,781:INFO:_display_container: 2
2024-11-13 18:47:13,781:INFO:HuberRegressor()
2024-11-13 18:47:13,781:INFO:create_model() successfully completed......................................
2024-11-13 18:47:13,993:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:13,993:INFO:Creating metrics dataframe
2024-11-13 18:47:14,005:INFO:Initializing K Neighbors Regressor
2024-11-13 18:47:14,005:INFO:Total runtime is 0.33895553350448604 minutes
2024-11-13 18:47:14,009:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:14,009:INFO:Initializing create_model()
2024-11-13 18:47:14,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:14,009:INFO:Checking exceptions
2024-11-13 18:47:14,009:INFO:Importing libraries
2024-11-13 18:47:14,010:INFO:Copying training dataset
2024-11-13 18:47:14,017:INFO:Defining folds
2024-11-13 18:47:14,017:INFO:Declaring metric variables
2024-11-13 18:47:14,020:INFO:Importing untrained model
2024-11-13 18:47:14,024:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:47:14,030:INFO:Starting cross validation
2024-11-13 18:47:14,031:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:14,195:INFO:Calculating mean and std
2024-11-13 18:47:14,198:INFO:Creating metrics dataframe
2024-11-13 18:47:14,206:INFO:Uploading results into container
2024-11-13 18:47:14,207:INFO:Uploading model into container now
2024-11-13 18:47:14,207:INFO:_master_model_container: 11
2024-11-13 18:47:14,207:INFO:_display_container: 2
2024-11-13 18:47:14,208:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:47:14,208:INFO:create_model() successfully completed......................................
2024-11-13 18:47:14,378:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:14,379:INFO:Creating metrics dataframe
2024-11-13 18:47:14,391:INFO:Initializing Decision Tree Regressor
2024-11-13 18:47:14,391:INFO:Total runtime is 0.345377759138743 minutes
2024-11-13 18:47:14,394:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:14,395:INFO:Initializing create_model()
2024-11-13 18:47:14,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:14,395:INFO:Checking exceptions
2024-11-13 18:47:14,395:INFO:Importing libraries
2024-11-13 18:47:14,395:INFO:Copying training dataset
2024-11-13 18:47:14,403:INFO:Defining folds
2024-11-13 18:47:14,403:INFO:Declaring metric variables
2024-11-13 18:47:14,407:INFO:Importing untrained model
2024-11-13 18:47:14,410:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:47:14,417:INFO:Starting cross validation
2024-11-13 18:47:14,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:14,582:INFO:Calculating mean and std
2024-11-13 18:47:14,586:INFO:Creating metrics dataframe
2024-11-13 18:47:14,592:INFO:Uploading results into container
2024-11-13 18:47:14,592:INFO:Uploading model into container now
2024-11-13 18:47:14,593:INFO:_master_model_container: 12
2024-11-13 18:47:14,593:INFO:_display_container: 2
2024-11-13 18:47:14,594:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:47:14,594:INFO:create_model() successfully completed......................................
2024-11-13 18:47:14,756:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:14,756:INFO:Creating metrics dataframe
2024-11-13 18:47:14,768:INFO:Initializing Random Forest Regressor
2024-11-13 18:47:14,768:INFO:Total runtime is 0.3516717990239461 minutes
2024-11-13 18:47:14,772:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:14,772:INFO:Initializing create_model()
2024-11-13 18:47:14,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:14,772:INFO:Checking exceptions
2024-11-13 18:47:14,773:INFO:Importing libraries
2024-11-13 18:47:14,773:INFO:Copying training dataset
2024-11-13 18:47:14,780:INFO:Defining folds
2024-11-13 18:47:14,780:INFO:Declaring metric variables
2024-11-13 18:47:14,783:INFO:Importing untrained model
2024-11-13 18:47:14,787:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:47:14,793:INFO:Starting cross validation
2024-11-13 18:47:14,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:16,250:INFO:Calculating mean and std
2024-11-13 18:47:16,254:INFO:Creating metrics dataframe
2024-11-13 18:47:16,260:INFO:Uploading results into container
2024-11-13 18:47:16,260:INFO:Uploading model into container now
2024-11-13 18:47:16,261:INFO:_master_model_container: 13
2024-11-13 18:47:16,261:INFO:_display_container: 2
2024-11-13 18:47:16,261:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:47:16,261:INFO:create_model() successfully completed......................................
2024-11-13 18:47:16,427:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:16,427:INFO:Creating metrics dataframe
2024-11-13 18:47:16,439:INFO:Initializing Extra Trees Regressor
2024-11-13 18:47:16,440:INFO:Total runtime is 0.379524552822113 minutes
2024-11-13 18:47:16,443:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:16,443:INFO:Initializing create_model()
2024-11-13 18:47:16,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:16,443:INFO:Checking exceptions
2024-11-13 18:47:16,443:INFO:Importing libraries
2024-11-13 18:47:16,444:INFO:Copying training dataset
2024-11-13 18:47:16,450:INFO:Defining folds
2024-11-13 18:47:16,451:INFO:Declaring metric variables
2024-11-13 18:47:16,454:INFO:Importing untrained model
2024-11-13 18:47:16,457:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:47:16,464:INFO:Starting cross validation
2024-11-13 18:47:16,465:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:17,309:INFO:Calculating mean and std
2024-11-13 18:47:17,313:INFO:Creating metrics dataframe
2024-11-13 18:47:17,319:INFO:Uploading results into container
2024-11-13 18:47:17,320:INFO:Uploading model into container now
2024-11-13 18:47:17,320:INFO:_master_model_container: 14
2024-11-13 18:47:17,320:INFO:_display_container: 2
2024-11-13 18:47:17,321:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:47:17,321:INFO:create_model() successfully completed......................................
2024-11-13 18:47:17,519:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:17,520:INFO:Creating metrics dataframe
2024-11-13 18:47:17,532:INFO:Initializing AdaBoost Regressor
2024-11-13 18:47:17,532:INFO:Total runtime is 0.39773809512456254 minutes
2024-11-13 18:47:17,536:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:17,536:INFO:Initializing create_model()
2024-11-13 18:47:17,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:17,536:INFO:Checking exceptions
2024-11-13 18:47:17,536:INFO:Importing libraries
2024-11-13 18:47:17,536:INFO:Copying training dataset
2024-11-13 18:47:17,543:INFO:Defining folds
2024-11-13 18:47:17,544:INFO:Declaring metric variables
2024-11-13 18:47:17,547:INFO:Importing untrained model
2024-11-13 18:47:17,550:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:47:17,557:INFO:Starting cross validation
2024-11-13 18:47:17,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:18,348:INFO:Calculating mean and std
2024-11-13 18:47:18,352:INFO:Creating metrics dataframe
2024-11-13 18:47:18,359:INFO:Uploading results into container
2024-11-13 18:47:18,360:INFO:Uploading model into container now
2024-11-13 18:47:18,360:INFO:_master_model_container: 15
2024-11-13 18:47:18,360:INFO:_display_container: 2
2024-11-13 18:47:18,361:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:47:18,361:INFO:create_model() successfully completed......................................
2024-11-13 18:47:18,542:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:18,542:INFO:Creating metrics dataframe
2024-11-13 18:47:18,555:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:47:18,555:INFO:Total runtime is 0.4147790829340616 minutes
2024-11-13 18:47:18,558:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:18,558:INFO:Initializing create_model()
2024-11-13 18:47:18,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:18,559:INFO:Checking exceptions
2024-11-13 18:47:18,559:INFO:Importing libraries
2024-11-13 18:47:18,559:INFO:Copying training dataset
2024-11-13 18:47:18,566:INFO:Defining folds
2024-11-13 18:47:18,566:INFO:Declaring metric variables
2024-11-13 18:47:18,570:INFO:Importing untrained model
2024-11-13 18:47:18,573:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:47:18,579:INFO:Starting cross validation
2024-11-13 18:47:18,580:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:20,022:INFO:Calculating mean and std
2024-11-13 18:47:20,026:INFO:Creating metrics dataframe
2024-11-13 18:47:20,032:INFO:Uploading results into container
2024-11-13 18:47:20,032:INFO:Uploading model into container now
2024-11-13 18:47:20,033:INFO:_master_model_container: 16
2024-11-13 18:47:20,033:INFO:_display_container: 2
2024-11-13 18:47:20,034:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:47:20,034:INFO:create_model() successfully completed......................................
2024-11-13 18:47:20,214:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:20,215:INFO:Creating metrics dataframe
2024-11-13 18:47:20,228:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:47:20,228:INFO:Total runtime is 0.4426716804504394 minutes
2024-11-13 18:47:20,232:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:20,232:INFO:Initializing create_model()
2024-11-13 18:47:20,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:20,232:INFO:Checking exceptions
2024-11-13 18:47:20,232:INFO:Importing libraries
2024-11-13 18:47:20,233:INFO:Copying training dataset
2024-11-13 18:47:20,240:INFO:Defining folds
2024-11-13 18:47:20,240:INFO:Declaring metric variables
2024-11-13 18:47:20,244:INFO:Importing untrained model
2024-11-13 18:47:20,248:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:47:20,254:INFO:Starting cross validation
2024-11-13 18:47:20,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:47:20,604:INFO:Calculating mean and std
2024-11-13 18:47:20,608:INFO:Creating metrics dataframe
2024-11-13 18:47:20,615:INFO:Uploading results into container
2024-11-13 18:47:20,615:INFO:Uploading model into container now
2024-11-13 18:47:20,616:INFO:_master_model_container: 17
2024-11-13 18:47:20,616:INFO:_display_container: 2
2024-11-13 18:47:20,617:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:47:20,617:INFO:create_model() successfully completed......................................
2024-11-13 18:47:20,793:INFO:SubProcess create_model() end ==================================
2024-11-13 18:47:20,793:INFO:Creating metrics dataframe
2024-11-13 18:47:20,806:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:47:20,807:INFO:Total runtime is 0.4523066401481628 minutes
2024-11-13 18:47:20,810:INFO:SubProcess create_model() called ==================================
2024-11-13 18:47:20,810:INFO:Initializing create_model()
2024-11-13 18:47:20,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:47:20,810:INFO:Checking exceptions
2024-11-13 18:47:20,810:INFO:Importing libraries
2024-11-13 18:47:20,810:INFO:Copying training dataset
2024-11-13 18:47:20,818:INFO:Defining folds
2024-11-13 18:47:20,818:INFO:Declaring metric variables
2024-11-13 18:47:20,821:INFO:Importing untrained model
2024-11-13 18:47:20,825:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:47:20,831:INFO:Starting cross validation
2024-11-13 18:47:20,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:08,840:INFO:Calculating mean and std
2024-11-13 18:54:08,846:INFO:Creating metrics dataframe
2024-11-13 18:54:08,854:INFO:Uploading results into container
2024-11-13 18:54:08,854:INFO:Uploading model into container now
2024-11-13 18:54:08,855:INFO:_master_model_container: 18
2024-11-13 18:54:08,855:INFO:_display_container: 2
2024-11-13 18:54:08,856:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:54:08,856:INFO:create_model() successfully completed......................................
2024-11-13 18:54:09,090:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:09,090:INFO:Creating metrics dataframe
2024-11-13 18:54:09,104:INFO:Initializing CatBoost Regressor
2024-11-13 18:54:09,104:INFO:Total runtime is 7.257263306776682 minutes
2024-11-13 18:54:09,107:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:09,108:INFO:Initializing create_model()
2024-11-13 18:54:09,108:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:09,108:INFO:Checking exceptions
2024-11-13 18:54:09,108:INFO:Importing libraries
2024-11-13 18:54:09,108:INFO:Copying training dataset
2024-11-13 18:54:09,116:INFO:Defining folds
2024-11-13 18:54:09,116:INFO:Declaring metric variables
2024-11-13 18:54:09,120:INFO:Importing untrained model
2024-11-13 18:54:09,123:INFO:CatBoost Regressor Imported successfully
2024-11-13 18:54:09,129:INFO:Starting cross validation
2024-11-13 18:54:09,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:22,230:INFO:Calculating mean and std
2024-11-13 18:54:22,234:INFO:Creating metrics dataframe
2024-11-13 18:54:22,241:INFO:Uploading results into container
2024-11-13 18:54:22,242:INFO:Uploading model into container now
2024-11-13 18:54:22,243:INFO:_master_model_container: 19
2024-11-13 18:54:22,243:INFO:_display_container: 2
2024-11-13 18:54:22,243:INFO:<catboost.core.CatBoostRegressor object at 0x7ff4bc221310>
2024-11-13 18:54:22,243:INFO:create_model() successfully completed......................................
2024-11-13 18:54:22,480:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:22,480:INFO:Creating metrics dataframe
2024-11-13 18:54:22,495:INFO:Initializing Dummy Regressor
2024-11-13 18:54:22,496:INFO:Total runtime is 7.4804585536321 minutes
2024-11-13 18:54:22,499:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:22,500:INFO:Initializing create_model()
2024-11-13 18:54:22,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff4c6542df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:22,500:INFO:Checking exceptions
2024-11-13 18:54:22,500:INFO:Importing libraries
2024-11-13 18:54:22,500:INFO:Copying training dataset
2024-11-13 18:54:22,509:INFO:Defining folds
2024-11-13 18:54:22,509:INFO:Declaring metric variables
2024-11-13 18:54:22,513:INFO:Importing untrained model
2024-11-13 18:54:22,517:INFO:Dummy Regressor Imported successfully
2024-11-13 18:54:22,523:INFO:Starting cross validation
2024-11-13 18:54:22,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:25,563:INFO:Calculating mean and std
2024-11-13 18:54:25,568:INFO:Creating metrics dataframe
2024-11-13 18:54:25,574:INFO:Uploading results into container
2024-11-13 18:54:25,575:INFO:Uploading model into container now
2024-11-13 18:54:25,576:INFO:_master_model_container: 20
2024-11-13 18:54:25,576:INFO:_display_container: 2
2024-11-13 18:54:25,576:INFO:DummyRegressor()
2024-11-13 18:54:25,576:INFO:create_model() successfully completed......................................
2024-11-13 18:54:25,785:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:25,786:INFO:Creating metrics dataframe
2024-11-13 18:54:25,809:INFO:Initializing create_model()
2024-11-13 18:54:25,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff686978af0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:25,810:INFO:Checking exceptions
2024-11-13 18:54:25,812:INFO:Importing libraries
2024-11-13 18:54:25,812:INFO:Copying training dataset
2024-11-13 18:54:25,818:INFO:Defining folds
2024-11-13 18:54:25,818:INFO:Declaring metric variables
2024-11-13 18:54:25,818:INFO:Importing untrained model
2024-11-13 18:54:25,818:INFO:Declaring custom model
2024-11-13 18:54:25,819:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:54:25,820:INFO:Cross validation set to False
2024-11-13 18:54:25,820:INFO:Fitting Model
2024-11-13 18:54:26,076:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:54:26,076:INFO:create_model() successfully completed......................................
2024-11-13 18:54:26,366:INFO:_master_model_container: 20
2024-11-13 18:54:26,367:INFO:_display_container: 2
2024-11-13 18:54:26,368:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:54:26,368:INFO:compare_models() successfully completed......................................
2024-11-13 18:54:26,433:INFO:PyCaret RegressionExperiment
2024-11-13 18:54:26,433:INFO:Logging name: reg-default-name
2024-11-13 18:54:26,433:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-13 18:54:26,433:INFO:version 3.2.0
2024-11-13 18:54:26,433:INFO:Initializing setup()
2024-11-13 18:54:26,433:INFO:self.USI: e41e
2024-11-13 18:54:26,433:INFO:self._variable_keys: {'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'target_param', 'memory', '_ml_usecase', 'pipeline', 'fold_generator', 'y_test', 'y', 'y_train', 'n_jobs_param', 'exp_name_log', 'X_test', 'USI', 'logging_param', 'html_param', 'X', 'exp_id', 'log_plots_param', 'X_train', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_available_plots', 'data'}
2024-11-13 18:54:26,433:INFO:Checking environment
2024-11-13 18:54:26,433:INFO:python_version: 3.8.13
2024-11-13 18:54:26,434:INFO:python_build: ('default', 'Mar 25 2022 06:04:10')
2024-11-13 18:54:26,434:INFO:machine: x86_64
2024-11-13 18:54:26,434:INFO:platform: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:54:26,434:INFO:Memory: svmem(total=270355722240, available=213611134976, percent=21.0, used=54676021248, free=51250532352, active=11658366976, inactive=147092914176, buffers=8888320, cached=164420280320, shared=187604992, slab=25030275072)
2024-11-13 18:54:26,437:INFO:Physical Core: 28
2024-11-13 18:54:26,438:INFO:Logical Core: 56
2024-11-13 18:54:26,438:INFO:Checking libraries
2024-11-13 18:54:26,438:INFO:System:
2024-11-13 18:54:26,438:INFO:    python: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10)  [GCC 10.3.0]
2024-11-13 18:54:26,438:INFO:executable: /home/disk/orca/adaley17/anaconda3/envs/geo_env/bin/python
2024-11-13 18:54:26,438:INFO:   machine: Linux-5.10.0-0.deb10.17-amd64-x86_64-with-glibc2.10
2024-11-13 18:54:26,438:INFO:PyCaret required dependencies:
2024-11-13 18:54:26,438:INFO:                 pip: 22.2.2
2024-11-13 18:54:26,438:INFO:          setuptools: 63.4.2
2024-11-13 18:54:26,438:INFO:             pycaret: 3.2.0
2024-11-13 18:54:26,438:INFO:             IPython: 8.12.2
2024-11-13 18:54:26,438:INFO:          ipywidgets: 7.7.1
2024-11-13 18:54:26,438:INFO:                tqdm: 4.64.1
2024-11-13 18:54:26,438:INFO:               numpy: 1.23.5
2024-11-13 18:54:26,438:INFO:              pandas: 1.5.3
2024-11-13 18:54:26,438:INFO:              jinja2: 3.1.2
2024-11-13 18:54:26,438:INFO:               scipy: 1.10.1
2024-11-13 18:54:26,438:INFO:              joblib: 1.3.0
2024-11-13 18:54:26,438:INFO:             sklearn: 1.1.2
2024-11-13 18:54:26,438:INFO:                pyod: 2.0.2
2024-11-13 18:54:26,438:INFO:            imblearn: 0.12.4
2024-11-13 18:54:26,439:INFO:   category_encoders: 2.6.4
2024-11-13 18:54:26,439:INFO:            lightgbm: 4.5.0
2024-11-13 18:54:26,439:INFO:               numba: 0.57.1
2024-11-13 18:54:26,439:INFO:            requests: 2.28.1
2024-11-13 18:54:26,439:INFO:          matplotlib: 3.5.1
2024-11-13 18:54:26,439:INFO:          scikitplot: 0.3.7
2024-11-13 18:54:26,439:INFO:         yellowbrick: 1.5
2024-11-13 18:54:26,439:INFO:              plotly: 5.24.1
2024-11-13 18:54:26,439:INFO:    plotly-resampler: Not installed
2024-11-13 18:54:26,439:INFO:             kaleido: 0.2.1
2024-11-13 18:54:26,439:INFO:           schemdraw: 0.15
2024-11-13 18:54:26,439:INFO:         statsmodels: 0.13.2
2024-11-13 18:54:26,439:INFO:              sktime: 0.21.1
2024-11-13 18:54:26,439:INFO:               tbats: 1.1.3
2024-11-13 18:54:26,439:INFO:            pmdarima: 2.0.4
2024-11-13 18:54:26,439:INFO:              psutil: 5.9.1
2024-11-13 18:54:26,439:INFO:          markupsafe: 2.1.1
2024-11-13 18:54:26,439:INFO:             pickle5: Not installed
2024-11-13 18:54:26,439:INFO:         cloudpickle: 2.1.0
2024-11-13 18:54:26,439:INFO:         deprecation: 2.1.0
2024-11-13 18:54:26,439:INFO:              xxhash: 3.5.0
2024-11-13 18:54:26,439:INFO:           wurlitzer: 3.1.1
2024-11-13 18:54:26,439:INFO:PyCaret optional dependencies:
2024-11-13 18:54:26,439:INFO:                shap: 0.44.1
2024-11-13 18:54:26,439:INFO:           interpret: 0.6.5
2024-11-13 18:54:26,439:INFO:                umap: 0.5.7
2024-11-13 18:54:26,439:INFO:     ydata_profiling: 4.6.0
2024-11-13 18:54:26,439:INFO:  explainerdashboard: 0.4.7
2024-11-13 18:54:26,439:INFO:             autoviz: Not installed
2024-11-13 18:54:26,439:INFO:           fairlearn: 0.7.0
2024-11-13 18:54:26,439:INFO:          deepchecks: Not installed
2024-11-13 18:54:26,439:INFO:             xgboost: 2.1.1
2024-11-13 18:54:26,440:INFO:            catboost: 1.2.7
2024-11-13 18:54:26,440:INFO:              kmodes: 0.12.2
2024-11-13 18:54:26,440:INFO:             mlxtend: 0.23.1
2024-11-13 18:54:26,440:INFO:       statsforecast: 1.5.0
2024-11-13 18:54:26,440:INFO:        tune_sklearn: 0.5.0
2024-11-13 18:54:26,440:INFO:                 ray: 2.10.0
2024-11-13 18:54:26,440:INFO:            hyperopt: 0.2.7
2024-11-13 18:54:26,440:INFO:              optuna: 4.1.0
2024-11-13 18:54:26,440:INFO:               skopt: 0.10.2
2024-11-13 18:54:26,440:INFO:              mlflow: 1.30.1
2024-11-13 18:54:26,440:INFO:              gradio: 3.50.2
2024-11-13 18:54:26,440:INFO:             fastapi: 0.115.5
2024-11-13 18:54:26,440:INFO:             uvicorn: 0.32.0
2024-11-13 18:54:26,440:INFO:              m2cgen: 0.10.0
2024-11-13 18:54:26,440:INFO:           evidently: 0.2.8
2024-11-13 18:54:26,440:INFO:               fugue: 0.8.6
2024-11-13 18:54:26,440:INFO:           streamlit: Not installed
2024-11-13 18:54:26,440:INFO:             prophet: Not installed
2024-11-13 18:54:26,440:INFO:None
2024-11-13 18:54:26,440:INFO:Set up data.
2024-11-13 18:54:26,451:INFO:Set up folding strategy.
2024-11-13 18:54:26,451:INFO:Set up train/test split.
2024-11-13 18:54:26,455:INFO:Set up index.
2024-11-13 18:54:26,457:INFO:Assigning column types.
2024-11-13 18:54:26,460:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-13 18:54:26,461:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,465:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,468:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,517:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,554:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:26,556:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:26,557:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,560:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,564:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,648:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:26,651:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:26,651:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-13 18:54:26,655:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,659:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,706:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,745:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:26,747:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:26,752:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,755:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,842:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:26,844:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:26,844:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-13 18:54:26,852:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,899:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,936:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:26,938:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:26,946:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-13 18:54:26,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,032:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,034:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,034:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-13 18:54:27,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,126:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,128:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,183:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,220:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,222:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,222:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-13 18:54:27,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,314:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,316:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-13 18:54:27,411:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,413:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,414:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-13 18:54:27,506:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,508:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,604:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,606:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,607:INFO:Preparing preprocessing pipeline...
2024-11-13 18:54:27,607:INFO:Set up simple imputation.
2024-11-13 18:54:27,622:INFO:Finished creating preprocessing pipeline.
2024-11-13 18:54:27,626:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['USA_WSPD', 'MSLP', 'USA_PRES',
                                             'Daily_SST_Avg', 'Mid_Level_RH',
                                             'Vshear', 'Vert_Vel'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-11-13 18:54:27,626:INFO:Creating final display dataframe.
2024-11-13 18:54:27,684:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target              Vmax
2                   Target type        Regression
3           Original data shape        (31316, 8)
4        Transformed data shape        (31316, 8)
5   Transformed train set shape        (21921, 8)
6    Transformed test set shape         (9395, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              e41e
2024-11-13 18:54:27,786:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,788:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,879:INFO:Soft dependency imported: xgboost: 2.1.1
2024-11-13 18:54:27,882:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-13 18:54:27,882:INFO:setup() successfully completed in 1.45s...............
2024-11-13 18:54:27,940:INFO:Initializing compare_models()
2024-11-13 18:54:27,940:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-13 18:54:27,941:INFO:Checking exceptions
2024-11-13 18:54:27,946:INFO:Preparing display monitor
2024-11-13 18:54:27,982:INFO:Initializing Linear Regression
2024-11-13 18:54:27,982:INFO:Total runtime is 2.47955322265625e-06 minutes
2024-11-13 18:54:27,985:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:27,985:INFO:Initializing create_model()
2024-11-13 18:54:27,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:27,986:INFO:Checking exceptions
2024-11-13 18:54:27,986:INFO:Importing libraries
2024-11-13 18:54:27,986:INFO:Copying training dataset
2024-11-13 18:54:27,991:INFO:Defining folds
2024-11-13 18:54:27,991:INFO:Declaring metric variables
2024-11-13 18:54:27,994:INFO:Importing untrained model
2024-11-13 18:54:27,997:INFO:Linear Regression Imported successfully
2024-11-13 18:54:28,004:INFO:Starting cross validation
2024-11-13 18:54:28,005:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:30,957:INFO:Calculating mean and std
2024-11-13 18:54:30,961:INFO:Creating metrics dataframe
2024-11-13 18:54:30,970:INFO:Uploading results into container
2024-11-13 18:54:30,971:INFO:Uploading model into container now
2024-11-13 18:54:30,971:INFO:_master_model_container: 1
2024-11-13 18:54:30,972:INFO:_display_container: 2
2024-11-13 18:54:30,972:INFO:LinearRegression(n_jobs=-1)
2024-11-13 18:54:30,972:INFO:create_model() successfully completed......................................
2024-11-13 18:54:31,217:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:31,217:INFO:Creating metrics dataframe
2024-11-13 18:54:31,227:INFO:Initializing Lasso Regression
2024-11-13 18:54:31,227:INFO:Total runtime is 0.0540927251180013 minutes
2024-11-13 18:54:31,231:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:31,231:INFO:Initializing create_model()
2024-11-13 18:54:31,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:31,232:INFO:Checking exceptions
2024-11-13 18:54:31,232:INFO:Importing libraries
2024-11-13 18:54:31,232:INFO:Copying training dataset
2024-11-13 18:54:31,241:INFO:Defining folds
2024-11-13 18:54:31,241:INFO:Declaring metric variables
2024-11-13 18:54:31,245:INFO:Importing untrained model
2024-11-13 18:54:31,248:INFO:Lasso Regression Imported successfully
2024-11-13 18:54:31,255:INFO:Starting cross validation
2024-11-13 18:54:31,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:34,117:INFO:Calculating mean and std
2024-11-13 18:54:34,121:INFO:Creating metrics dataframe
2024-11-13 18:54:34,128:INFO:Uploading results into container
2024-11-13 18:54:34,129:INFO:Uploading model into container now
2024-11-13 18:54:34,129:INFO:_master_model_container: 2
2024-11-13 18:54:34,129:INFO:_display_container: 2
2024-11-13 18:54:34,130:INFO:Lasso(random_state=123)
2024-11-13 18:54:34,130:INFO:create_model() successfully completed......................................
2024-11-13 18:54:34,315:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:34,315:INFO:Creating metrics dataframe
2024-11-13 18:54:34,325:INFO:Initializing Ridge Regression
2024-11-13 18:54:34,326:INFO:Total runtime is 0.10572757720947265 minutes
2024-11-13 18:54:34,329:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:34,329:INFO:Initializing create_model()
2024-11-13 18:54:34,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:34,330:INFO:Checking exceptions
2024-11-13 18:54:34,330:INFO:Importing libraries
2024-11-13 18:54:34,330:INFO:Copying training dataset
2024-11-13 18:54:34,336:INFO:Defining folds
2024-11-13 18:54:34,337:INFO:Declaring metric variables
2024-11-13 18:54:34,340:INFO:Importing untrained model
2024-11-13 18:54:34,344:INFO:Ridge Regression Imported successfully
2024-11-13 18:54:34,350:INFO:Starting cross validation
2024-11-13 18:54:34,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:37,172:INFO:Calculating mean and std
2024-11-13 18:54:37,175:INFO:Creating metrics dataframe
2024-11-13 18:54:37,183:INFO:Uploading results into container
2024-11-13 18:54:37,183:INFO:Uploading model into container now
2024-11-13 18:54:37,184:INFO:_master_model_container: 3
2024-11-13 18:54:37,184:INFO:_display_container: 2
2024-11-13 18:54:37,184:INFO:Ridge(random_state=123)
2024-11-13 18:54:37,184:INFO:create_model() successfully completed......................................
2024-11-13 18:54:37,401:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:37,401:INFO:Creating metrics dataframe
2024-11-13 18:54:37,412:INFO:Initializing Elastic Net
2024-11-13 18:54:37,413:INFO:Total runtime is 0.1571786602338155 minutes
2024-11-13 18:54:37,416:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:37,416:INFO:Initializing create_model()
2024-11-13 18:54:37,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:37,417:INFO:Checking exceptions
2024-11-13 18:54:37,417:INFO:Importing libraries
2024-11-13 18:54:37,417:INFO:Copying training dataset
2024-11-13 18:54:37,424:INFO:Defining folds
2024-11-13 18:54:37,424:INFO:Declaring metric variables
2024-11-13 18:54:37,427:INFO:Importing untrained model
2024-11-13 18:54:37,431:INFO:Elastic Net Imported successfully
2024-11-13 18:54:37,437:INFO:Starting cross validation
2024-11-13 18:54:37,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:40,676:INFO:Calculating mean and std
2024-11-13 18:54:40,679:INFO:Creating metrics dataframe
2024-11-13 18:54:40,686:INFO:Uploading results into container
2024-11-13 18:54:40,687:INFO:Uploading model into container now
2024-11-13 18:54:40,688:INFO:_master_model_container: 4
2024-11-13 18:54:40,688:INFO:_display_container: 2
2024-11-13 18:54:40,688:INFO:ElasticNet(random_state=123)
2024-11-13 18:54:40,688:INFO:create_model() successfully completed......................................
2024-11-13 18:54:40,866:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:40,866:INFO:Creating metrics dataframe
2024-11-13 18:54:40,877:INFO:Initializing Least Angle Regression
2024-11-13 18:54:40,877:INFO:Total runtime is 0.21492094596227007 minutes
2024-11-13 18:54:40,880:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:40,881:INFO:Initializing create_model()
2024-11-13 18:54:40,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:40,881:INFO:Checking exceptions
2024-11-13 18:54:40,881:INFO:Importing libraries
2024-11-13 18:54:40,881:INFO:Copying training dataset
2024-11-13 18:54:40,888:INFO:Defining folds
2024-11-13 18:54:40,888:INFO:Declaring metric variables
2024-11-13 18:54:40,891:INFO:Importing untrained model
2024-11-13 18:54:40,895:INFO:Least Angle Regression Imported successfully
2024-11-13 18:54:40,901:INFO:Starting cross validation
2024-11-13 18:54:40,902:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:40,971:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:40,975:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.407e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:54:40,979:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:40,981:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:40,990:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:40,994:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.478e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:54:40,996:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:41,000:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:41,000:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.949e-07, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:54:41,000:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.974e-07, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-11-13 18:54:43,429:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:43,429:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:43,444:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:43,445:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:43,461:INFO:Calculating mean and std
2024-11-13 18:54:43,465:INFO:Creating metrics dataframe
2024-11-13 18:54:43,472:INFO:Uploading results into container
2024-11-13 18:54:43,472:INFO:Uploading model into container now
2024-11-13 18:54:43,473:INFO:_master_model_container: 5
2024-11-13 18:54:43,473:INFO:_display_container: 2
2024-11-13 18:54:43,474:INFO:Lars(random_state=123)
2024-11-13 18:54:43,474:INFO:create_model() successfully completed......................................
2024-11-13 18:54:43,701:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:43,701:INFO:Creating metrics dataframe
2024-11-13 18:54:43,712:INFO:Initializing Lasso Least Angle Regression
2024-11-13 18:54:43,712:INFO:Total runtime is 0.2621651212374369 minutes
2024-11-13 18:54:43,715:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:43,715:INFO:Initializing create_model()
2024-11-13 18:54:43,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:43,716:INFO:Checking exceptions
2024-11-13 18:54:43,716:INFO:Importing libraries
2024-11-13 18:54:43,716:INFO:Copying training dataset
2024-11-13 18:54:43,722:INFO:Defining folds
2024-11-13 18:54:43,722:INFO:Declaring metric variables
2024-11-13 18:54:43,726:INFO:Importing untrained model
2024-11-13 18:54:43,729:INFO:Lasso Least Angle Regression Imported successfully
2024-11-13 18:54:43,736:INFO:Starting cross validation
2024-11-13 18:54:43,736:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:43,771:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,777:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,783:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,793:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,809:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,818:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,823:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:43,823:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:46,157:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:46,157:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-11-13 18:54:46,172:INFO:Calculating mean and std
2024-11-13 18:54:46,175:INFO:Creating metrics dataframe
2024-11-13 18:54:46,181:INFO:Uploading results into container
2024-11-13 18:54:46,182:INFO:Uploading model into container now
2024-11-13 18:54:46,182:INFO:_master_model_container: 6
2024-11-13 18:54:46,182:INFO:_display_container: 2
2024-11-13 18:54:46,183:INFO:LassoLars(random_state=123)
2024-11-13 18:54:46,183:INFO:create_model() successfully completed......................................
2024-11-13 18:54:46,365:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:46,366:INFO:Creating metrics dataframe
2024-11-13 18:54:46,379:INFO:Initializing Orthogonal Matching Pursuit
2024-11-13 18:54:46,379:INFO:Total runtime is 0.3066184083620707 minutes
2024-11-13 18:54:46,382:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:46,383:INFO:Initializing create_model()
2024-11-13 18:54:46,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:46,383:INFO:Checking exceptions
2024-11-13 18:54:46,383:INFO:Importing libraries
2024-11-13 18:54:46,383:INFO:Copying training dataset
2024-11-13 18:54:46,391:INFO:Defining folds
2024-11-13 18:54:46,391:INFO:Declaring metric variables
2024-11-13 18:54:46,394:INFO:Importing untrained model
2024-11-13 18:54:46,398:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-13 18:54:46,404:INFO:Starting cross validation
2024-11-13 18:54:46,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:46,441:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,447:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,451:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,455:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,473:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,477:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,487:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,492:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,501:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,503:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-11-13 18:54:46,520:INFO:Calculating mean and std
2024-11-13 18:54:46,524:INFO:Creating metrics dataframe
2024-11-13 18:54:46,531:INFO:Uploading results into container
2024-11-13 18:54:46,532:INFO:Uploading model into container now
2024-11-13 18:54:46,532:INFO:_master_model_container: 7
2024-11-13 18:54:46,532:INFO:_display_container: 2
2024-11-13 18:54:46,532:INFO:OrthogonalMatchingPursuit()
2024-11-13 18:54:46,533:INFO:create_model() successfully completed......................................
2024-11-13 18:54:46,705:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:46,705:INFO:Creating metrics dataframe
2024-11-13 18:54:46,716:INFO:Initializing Bayesian Ridge
2024-11-13 18:54:46,716:INFO:Total runtime is 0.31223843097686765 minutes
2024-11-13 18:54:46,720:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:46,720:INFO:Initializing create_model()
2024-11-13 18:54:46,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:46,720:INFO:Checking exceptions
2024-11-13 18:54:46,720:INFO:Importing libraries
2024-11-13 18:54:46,720:INFO:Copying training dataset
2024-11-13 18:54:46,727:INFO:Defining folds
2024-11-13 18:54:46,727:INFO:Declaring metric variables
2024-11-13 18:54:46,731:INFO:Importing untrained model
2024-11-13 18:54:46,734:INFO:Bayesian Ridge Imported successfully
2024-11-13 18:54:46,741:INFO:Starting cross validation
2024-11-13 18:54:46,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:46,893:INFO:Calculating mean and std
2024-11-13 18:54:46,897:INFO:Creating metrics dataframe
2024-11-13 18:54:46,904:INFO:Uploading results into container
2024-11-13 18:54:46,905:INFO:Uploading model into container now
2024-11-13 18:54:46,905:INFO:_master_model_container: 8
2024-11-13 18:54:46,905:INFO:_display_container: 2
2024-11-13 18:54:46,906:INFO:BayesianRidge()
2024-11-13 18:54:46,906:INFO:create_model() successfully completed......................................
2024-11-13 18:54:47,120:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:47,120:INFO:Creating metrics dataframe
2024-11-13 18:54:47,132:INFO:Initializing Passive Aggressive Regressor
2024-11-13 18:54:47,132:INFO:Total runtime is 0.319174579779307 minutes
2024-11-13 18:54:47,136:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:47,136:INFO:Initializing create_model()
2024-11-13 18:54:47,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:47,136:INFO:Checking exceptions
2024-11-13 18:54:47,136:INFO:Importing libraries
2024-11-13 18:54:47,137:INFO:Copying training dataset
2024-11-13 18:54:47,143:INFO:Defining folds
2024-11-13 18:54:47,144:INFO:Declaring metric variables
2024-11-13 18:54:47,147:INFO:Importing untrained model
2024-11-13 18:54:47,150:INFO:Passive Aggressive Regressor Imported successfully
2024-11-13 18:54:47,157:INFO:Starting cross validation
2024-11-13 18:54:47,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:47,315:INFO:Calculating mean and std
2024-11-13 18:54:47,320:INFO:Creating metrics dataframe
2024-11-13 18:54:47,327:INFO:Uploading results into container
2024-11-13 18:54:47,327:INFO:Uploading model into container now
2024-11-13 18:54:47,328:INFO:_master_model_container: 9
2024-11-13 18:54:47,328:INFO:_display_container: 2
2024-11-13 18:54:47,329:INFO:PassiveAggressiveRegressor(random_state=123)
2024-11-13 18:54:47,329:INFO:create_model() successfully completed......................................
2024-11-13 18:54:47,552:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:47,552:INFO:Creating metrics dataframe
2024-11-13 18:54:47,563:INFO:Initializing Huber Regressor
2024-11-13 18:54:47,564:INFO:Total runtime is 0.32636140982309975 minutes
2024-11-13 18:54:47,567:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:47,567:INFO:Initializing create_model()
2024-11-13 18:54:47,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:47,568:INFO:Checking exceptions
2024-11-13 18:54:47,568:INFO:Importing libraries
2024-11-13 18:54:47,568:INFO:Copying training dataset
2024-11-13 18:54:47,574:INFO:Defining folds
2024-11-13 18:54:47,575:INFO:Declaring metric variables
2024-11-13 18:54:47,578:INFO:Importing untrained model
2024-11-13 18:54:47,582:INFO:Huber Regressor Imported successfully
2024-11-13 18:54:47,588:INFO:Starting cross validation
2024-11-13 18:54:47,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:47,862:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,863:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,892:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,897:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,898:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,950:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:47,976:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:48,019:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:48,026:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-13 18:54:48,044:INFO:Calculating mean and std
2024-11-13 18:54:48,047:INFO:Creating metrics dataframe
2024-11-13 18:54:48,055:INFO:Uploading results into container
2024-11-13 18:54:48,055:INFO:Uploading model into container now
2024-11-13 18:54:48,056:INFO:_master_model_container: 10
2024-11-13 18:54:48,056:INFO:_display_container: 2
2024-11-13 18:54:48,056:INFO:HuberRegressor()
2024-11-13 18:54:48,056:INFO:create_model() successfully completed......................................
2024-11-13 18:54:48,220:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:48,220:INFO:Creating metrics dataframe
2024-11-13 18:54:48,232:INFO:Initializing K Neighbors Regressor
2024-11-13 18:54:48,232:INFO:Total runtime is 0.33750462134679154 minutes
2024-11-13 18:54:48,235:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:48,236:INFO:Initializing create_model()
2024-11-13 18:54:48,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:48,236:INFO:Checking exceptions
2024-11-13 18:54:48,236:INFO:Importing libraries
2024-11-13 18:54:48,236:INFO:Copying training dataset
2024-11-13 18:54:48,243:INFO:Defining folds
2024-11-13 18:54:48,243:INFO:Declaring metric variables
2024-11-13 18:54:48,246:INFO:Importing untrained model
2024-11-13 18:54:48,250:INFO:K Neighbors Regressor Imported successfully
2024-11-13 18:54:48,256:INFO:Starting cross validation
2024-11-13 18:54:48,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:48,482:INFO:Calculating mean and std
2024-11-13 18:54:48,485:INFO:Creating metrics dataframe
2024-11-13 18:54:48,491:INFO:Uploading results into container
2024-11-13 18:54:48,492:INFO:Uploading model into container now
2024-11-13 18:54:48,492:INFO:_master_model_container: 11
2024-11-13 18:54:48,492:INFO:_display_container: 2
2024-11-13 18:54:48,493:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-13 18:54:48,493:INFO:create_model() successfully completed......................................
2024-11-13 18:54:48,681:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:48,682:INFO:Creating metrics dataframe
2024-11-13 18:54:48,696:INFO:Initializing Decision Tree Regressor
2024-11-13 18:54:48,697:INFO:Total runtime is 0.3452465017636617 minutes
2024-11-13 18:54:48,701:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:48,701:INFO:Initializing create_model()
2024-11-13 18:54:48,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:48,702:INFO:Checking exceptions
2024-11-13 18:54:48,702:INFO:Importing libraries
2024-11-13 18:54:48,702:INFO:Copying training dataset
2024-11-13 18:54:48,710:INFO:Defining folds
2024-11-13 18:54:48,710:INFO:Declaring metric variables
2024-11-13 18:54:48,714:INFO:Importing untrained model
2024-11-13 18:54:48,719:INFO:Decision Tree Regressor Imported successfully
2024-11-13 18:54:48,726:INFO:Starting cross validation
2024-11-13 18:54:48,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:48,871:INFO:Calculating mean and std
2024-11-13 18:54:48,875:INFO:Creating metrics dataframe
2024-11-13 18:54:48,883:INFO:Uploading results into container
2024-11-13 18:54:48,884:INFO:Uploading model into container now
2024-11-13 18:54:48,885:INFO:_master_model_container: 12
2024-11-13 18:54:48,885:INFO:_display_container: 2
2024-11-13 18:54:48,885:INFO:DecisionTreeRegressor(random_state=123)
2024-11-13 18:54:48,885:INFO:create_model() successfully completed......................................
2024-11-13 18:54:49,050:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:49,050:INFO:Creating metrics dataframe
2024-11-13 18:54:49,062:INFO:Initializing Random Forest Regressor
2024-11-13 18:54:49,062:INFO:Total runtime is 0.35134084224700923 minutes
2024-11-13 18:54:49,066:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:49,066:INFO:Initializing create_model()
2024-11-13 18:54:49,066:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:49,066:INFO:Checking exceptions
2024-11-13 18:54:49,066:INFO:Importing libraries
2024-11-13 18:54:49,067:INFO:Copying training dataset
2024-11-13 18:54:49,073:INFO:Defining folds
2024-11-13 18:54:49,073:INFO:Declaring metric variables
2024-11-13 18:54:49,077:INFO:Importing untrained model
2024-11-13 18:54:49,080:INFO:Random Forest Regressor Imported successfully
2024-11-13 18:54:49,087:INFO:Starting cross validation
2024-11-13 18:54:49,088:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:50,016:INFO:Calculating mean and std
2024-11-13 18:54:50,019:INFO:Creating metrics dataframe
2024-11-13 18:54:50,024:INFO:Uploading results into container
2024-11-13 18:54:50,025:INFO:Uploading model into container now
2024-11-13 18:54:50,025:INFO:_master_model_container: 13
2024-11-13 18:54:50,026:INFO:_display_container: 2
2024-11-13 18:54:50,026:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:54:50,026:INFO:create_model() successfully completed......................................
2024-11-13 18:54:50,196:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:50,196:INFO:Creating metrics dataframe
2024-11-13 18:54:50,208:INFO:Initializing Extra Trees Regressor
2024-11-13 18:54:50,209:INFO:Total runtime is 0.37044362227121985 minutes
2024-11-13 18:54:50,212:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:50,212:INFO:Initializing create_model()
2024-11-13 18:54:50,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:50,212:INFO:Checking exceptions
2024-11-13 18:54:50,213:INFO:Importing libraries
2024-11-13 18:54:50,213:INFO:Copying training dataset
2024-11-13 18:54:50,219:INFO:Defining folds
2024-11-13 18:54:50,220:INFO:Declaring metric variables
2024-11-13 18:54:50,223:INFO:Importing untrained model
2024-11-13 18:54:50,227:INFO:Extra Trees Regressor Imported successfully
2024-11-13 18:54:50,233:INFO:Starting cross validation
2024-11-13 18:54:50,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:50,753:INFO:Calculating mean and std
2024-11-13 18:54:50,757:INFO:Creating metrics dataframe
2024-11-13 18:54:50,762:INFO:Uploading results into container
2024-11-13 18:54:50,763:INFO:Uploading model into container now
2024-11-13 18:54:50,763:INFO:_master_model_container: 14
2024-11-13 18:54:50,764:INFO:_display_container: 2
2024-11-13 18:54:50,764:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-11-13 18:54:50,765:INFO:create_model() successfully completed......................................
2024-11-13 18:54:50,958:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:50,959:INFO:Creating metrics dataframe
2024-11-13 18:54:50,974:INFO:Initializing AdaBoost Regressor
2024-11-13 18:54:50,974:INFO:Total runtime is 0.38320453961690265 minutes
2024-11-13 18:54:50,978:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:50,979:INFO:Initializing create_model()
2024-11-13 18:54:50,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:50,979:INFO:Checking exceptions
2024-11-13 18:54:50,979:INFO:Importing libraries
2024-11-13 18:54:50,979:INFO:Copying training dataset
2024-11-13 18:54:50,988:INFO:Defining folds
2024-11-13 18:54:50,988:INFO:Declaring metric variables
2024-11-13 18:54:50,992:INFO:Importing untrained model
2024-11-13 18:54:50,996:INFO:AdaBoost Regressor Imported successfully
2024-11-13 18:54:51,004:INFO:Starting cross validation
2024-11-13 18:54:51,005:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:51,655:INFO:Calculating mean and std
2024-11-13 18:54:51,659:INFO:Creating metrics dataframe
2024-11-13 18:54:51,666:INFO:Uploading results into container
2024-11-13 18:54:51,667:INFO:Uploading model into container now
2024-11-13 18:54:51,668:INFO:_master_model_container: 15
2024-11-13 18:54:51,668:INFO:_display_container: 2
2024-11-13 18:54:51,668:INFO:AdaBoostRegressor(random_state=123)
2024-11-13 18:54:51,668:INFO:create_model() successfully completed......................................
2024-11-13 18:54:51,886:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:51,887:INFO:Creating metrics dataframe
2024-11-13 18:54:51,900:INFO:Initializing Gradient Boosting Regressor
2024-11-13 18:54:51,900:INFO:Total runtime is 0.3986332535743713 minutes
2024-11-13 18:54:51,903:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:51,904:INFO:Initializing create_model()
2024-11-13 18:54:51,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:51,904:INFO:Checking exceptions
2024-11-13 18:54:51,904:INFO:Importing libraries
2024-11-13 18:54:51,904:INFO:Copying training dataset
2024-11-13 18:54:51,911:INFO:Defining folds
2024-11-13 18:54:51,911:INFO:Declaring metric variables
2024-11-13 18:54:51,915:INFO:Importing untrained model
2024-11-13 18:54:51,918:INFO:Gradient Boosting Regressor Imported successfully
2024-11-13 18:54:51,924:INFO:Starting cross validation
2024-11-13 18:54:51,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:54,293:INFO:Calculating mean and std
2024-11-13 18:54:54,296:INFO:Creating metrics dataframe
2024-11-13 18:54:54,303:INFO:Uploading results into container
2024-11-13 18:54:54,304:INFO:Uploading model into container now
2024-11-13 18:54:54,304:INFO:_master_model_container: 16
2024-11-13 18:54:54,304:INFO:_display_container: 2
2024-11-13 18:54:54,305:INFO:GradientBoostingRegressor(random_state=123)
2024-11-13 18:54:54,305:INFO:create_model() successfully completed......................................
2024-11-13 18:54:54,481:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:54,481:INFO:Creating metrics dataframe
2024-11-13 18:54:54,494:INFO:Initializing Extreme Gradient Boosting
2024-11-13 18:54:54,494:INFO:Total runtime is 0.44187271595001215 minutes
2024-11-13 18:54:54,497:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:54,498:INFO:Initializing create_model()
2024-11-13 18:54:54,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:54,498:INFO:Checking exceptions
2024-11-13 18:54:54,498:INFO:Importing libraries
2024-11-13 18:54:54,498:INFO:Copying training dataset
2024-11-13 18:54:54,505:INFO:Defining folds
2024-11-13 18:54:54,505:INFO:Declaring metric variables
2024-11-13 18:54:54,508:INFO:Importing untrained model
2024-11-13 18:54:54,512:INFO:Extreme Gradient Boosting Imported successfully
2024-11-13 18:54:54,518:INFO:Starting cross validation
2024-11-13 18:54:54,519:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 18:54:54,911:INFO:Calculating mean and std
2024-11-13 18:54:54,915:INFO:Creating metrics dataframe
2024-11-13 18:54:54,922:INFO:Uploading results into container
2024-11-13 18:54:54,923:INFO:Uploading model into container now
2024-11-13 18:54:54,923:INFO:_master_model_container: 17
2024-11-13 18:54:54,924:INFO:_display_container: 2
2024-11-13 18:54:54,924:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-11-13 18:54:54,925:INFO:create_model() successfully completed......................................
2024-11-13 18:54:55,105:INFO:SubProcess create_model() end ==================================
2024-11-13 18:54:55,105:INFO:Creating metrics dataframe
2024-11-13 18:54:55,118:INFO:Initializing Light Gradient Boosting Machine
2024-11-13 18:54:55,118:INFO:Total runtime is 0.4522675911585489 minutes
2024-11-13 18:54:55,121:INFO:SubProcess create_model() called ==================================
2024-11-13 18:54:55,121:INFO:Initializing create_model()
2024-11-13 18:54:55,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 18:54:55,122:INFO:Checking exceptions
2024-11-13 18:54:55,122:INFO:Importing libraries
2024-11-13 18:54:55,122:INFO:Copying training dataset
2024-11-13 18:54:55,128:INFO:Defining folds
2024-11-13 18:54:55,129:INFO:Declaring metric variables
2024-11-13 18:54:55,132:INFO:Importing untrained model
2024-11-13 18:54:55,136:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-13 18:54:55,142:INFO:Starting cross validation
2024-11-13 18:54:55,143:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 19:01:47,907:INFO:Calculating mean and std
2024-11-13 19:01:47,910:INFO:Creating metrics dataframe
2024-11-13 19:01:47,917:INFO:Uploading results into container
2024-11-13 19:01:47,917:INFO:Uploading model into container now
2024-11-13 19:01:47,918:INFO:_master_model_container: 18
2024-11-13 19:01:47,918:INFO:_display_container: 2
2024-11-13 19:01:47,919:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-11-13 19:01:47,919:INFO:create_model() successfully completed......................................
2024-11-13 19:01:48,122:INFO:SubProcess create_model() end ==================================
2024-11-13 19:01:48,122:INFO:Creating metrics dataframe
2024-11-13 19:01:48,135:INFO:Initializing CatBoost Regressor
2024-11-13 19:01:48,136:INFO:Total runtime is 7.335893412431081 minutes
2024-11-13 19:01:48,139:INFO:SubProcess create_model() called ==================================
2024-11-13 19:01:48,139:INFO:Initializing create_model()
2024-11-13 19:01:48,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 19:01:48,139:INFO:Checking exceptions
2024-11-13 19:01:48,139:INFO:Importing libraries
2024-11-13 19:01:48,140:INFO:Copying training dataset
2024-11-13 19:01:48,148:INFO:Defining folds
2024-11-13 19:01:48,148:INFO:Declaring metric variables
2024-11-13 19:01:48,151:INFO:Importing untrained model
2024-11-13 19:01:48,155:INFO:CatBoost Regressor Imported successfully
2024-11-13 19:01:48,161:INFO:Starting cross validation
2024-11-13 19:01:48,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 19:01:59,434:INFO:Calculating mean and std
2024-11-13 19:01:59,438:INFO:Creating metrics dataframe
2024-11-13 19:01:59,445:INFO:Uploading results into container
2024-11-13 19:01:59,446:INFO:Uploading model into container now
2024-11-13 19:01:59,447:INFO:_master_model_container: 19
2024-11-13 19:01:59,447:INFO:_display_container: 2
2024-11-13 19:01:59,447:INFO:<catboost.core.CatBoostRegressor object at 0x7ff6871760a0>
2024-11-13 19:01:59,447:INFO:create_model() successfully completed......................................
2024-11-13 19:01:59,637:INFO:SubProcess create_model() end ==================================
2024-11-13 19:01:59,637:INFO:Creating metrics dataframe
2024-11-13 19:01:59,652:INFO:Initializing Dummy Regressor
2024-11-13 19:01:59,652:INFO:Total runtime is 7.527840868631999 minutes
2024-11-13 19:01:59,656:INFO:SubProcess create_model() called ==================================
2024-11-13 19:01:59,656:INFO:Initializing create_model()
2024-11-13 19:01:59,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff686dc0e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 19:01:59,656:INFO:Checking exceptions
2024-11-13 19:01:59,656:INFO:Importing libraries
2024-11-13 19:01:59,656:INFO:Copying training dataset
2024-11-13 19:01:59,668:INFO:Defining folds
2024-11-13 19:01:59,668:INFO:Declaring metric variables
2024-11-13 19:01:59,672:INFO:Importing untrained model
2024-11-13 19:01:59,676:INFO:Dummy Regressor Imported successfully
2024-11-13 19:01:59,683:INFO:Starting cross validation
2024-11-13 19:01:59,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-13 19:02:02,853:INFO:Calculating mean and std
2024-11-13 19:02:02,858:INFO:Creating metrics dataframe
2024-11-13 19:02:02,866:INFO:Uploading results into container
2024-11-13 19:02:02,866:INFO:Uploading model into container now
2024-11-13 19:02:02,867:INFO:_master_model_container: 20
2024-11-13 19:02:02,867:INFO:_display_container: 2
2024-11-13 19:02:02,868:INFO:DummyRegressor()
2024-11-13 19:02:02,868:INFO:create_model() successfully completed......................................
2024-11-13 19:02:03,105:INFO:SubProcess create_model() end ==================================
2024-11-13 19:02:03,105:INFO:Creating metrics dataframe
2024-11-13 19:02:03,130:INFO:Initializing create_model()
2024-11-13 19:02:03,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-13 19:02:03,130:INFO:Checking exceptions
2024-11-13 19:02:03,132:INFO:Importing libraries
2024-11-13 19:02:03,132:INFO:Copying training dataset
2024-11-13 19:02:03,138:INFO:Defining folds
2024-11-13 19:02:03,138:INFO:Declaring metric variables
2024-11-13 19:02:03,138:INFO:Importing untrained model
2024-11-13 19:02:03,138:INFO:Declaring custom model
2024-11-13 19:02:03,139:INFO:Linear Regression Imported successfully
2024-11-13 19:02:03,139:INFO:Cross validation set to False
2024-11-13 19:02:03,140:INFO:Fitting Model
2024-11-13 19:02:03,157:INFO:LinearRegression(n_jobs=-1)
2024-11-13 19:02:03,157:INFO:create_model() successfully completed......................................
2024-11-13 19:02:03,425:INFO:_master_model_container: 20
2024-11-13 19:02:03,425:INFO:_display_container: 2
2024-11-13 19:02:03,425:INFO:LinearRegression(n_jobs=-1)
2024-11-13 19:02:03,425:INFO:compare_models() successfully completed......................................
2024-11-13 19:15:10,938:INFO:Initializing plot_model()
2024-11-13 19:15:10,938:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, system=True)
2024-11-13 19:15:10,938:INFO:Checking exceptions
2024-11-13 19:15:11,008:INFO:Preloading libraries
2024-11-13 19:15:11,177:INFO:Copying training dataset
2024-11-13 19:15:11,178:INFO:Plot type: residuals
2024-11-13 19:15:11,256:INFO:Fitting Model
2024-11-13 19:15:11,256:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-13 19:15:11,256:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- MSLP
- Mid_Level_RH
- USA_PRES
- USA_WSPD
- Vert_Vel
Feature names seen at fit time, yet now missing:
- Longitude
- STORM_DIR

  warnings.warn(message, FutureWarning)

2024-11-13 19:15:38,909:INFO:Initializing plot_model()
2024-11-13 19:15:38,909:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7ff4c5652970>, system=True)
2024-11-13 19:15:38,909:INFO:Checking exceptions
2024-11-13 19:15:38,975:INFO:Preloading libraries
2024-11-13 19:15:39,127:INFO:Copying training dataset
2024-11-13 19:15:39,127:INFO:Plot type: residuals
2024-11-13 19:15:39,210:INFO:Fitting Model
2024-11-13 19:15:39,211:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-11-13 19:15:39,211:WARNING:/home/disk/orca/adaley17/anaconda3/envs/geo_env/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- MSLP
- Mid_Level_RH
- USA_PRES
- USA_WSPD
- Vert_Vel
Feature names seen at fit time, yet now missing:
- Latitude
- STORM_DIR

  warnings.warn(message, FutureWarning)

