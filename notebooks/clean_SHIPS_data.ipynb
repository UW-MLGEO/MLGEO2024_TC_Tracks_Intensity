{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/disk/orca/adaley17/Research/Stress_Separation/'\n",
    "with open(PATH + 'lsdiaga_1982_2022_sat_ts_5day.txt', 'r') as file:\n",
    "    # content = file.read()\n",
    "    # print(content)\n",
    "    # print(file.readline())\n",
    "    file.seek(0)\n",
    "    for i, line in enumerate(file):\n",
    "        if 'LAST' in line:\n",
    "            print(f\"Line {i}: {line}\")\n",
    "    # lines_with_AL = [line for line in file if 'LAST' in line]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_entries = 139\n",
    "column_names = [np.nan] * num_entries\n",
    "\n",
    "with open(PATH + 'lsdiaga_1982_2022_sat_ts_5day.txt', 'r') as file:\n",
    "    # Move the file pointer to the beginning of the file\n",
    "    file.seek(0)\n",
    "\n",
    "    # Read lines 0 to 138\n",
    "    lines = [file.readline().split() for _ in range(139)]\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        # print(lines[i][-1])\n",
    "        column_names[i] = lines[i][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_with_LAT = [line for line in lines if line[-1] == 'LAT']\n",
    "for i, line in enumerate(lines_with_LAT):\n",
    "    print(f\"Line {i}: {line}\")\n",
    "    # lat_data = np.array([float(item) if item != '9999' else np.nan for sublist in lines_with_LAT for item in sublist if item != 'LAT'])\n",
    "    # lat_data = np.array([float(line[0]) for line in lines_with_LAT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/disk/orca/adaley17/Research/Stress_Separation/'\n",
    "with open(PATH + 'lsdiaga_1982_2022_sat_ts_5day.txt', 'r') as file:\n",
    "    # Move the file pointer to the beginning of the file\n",
    "    file.seek(0)\n",
    "    # file.readline().split()\n",
    "    # Read lines 0 to 138\n",
    "    lines = [file.readline().split() for _ in range(1925149)]\n",
    "    # lines.split()\n",
    "\n",
    "    # # Combine the lines into one line\n",
    "    # combined_line = ''.join(lines)\n",
    "\n",
    "    # # Print the combined line\n",
    "    # print(combined_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_of_interest(start, lines, data_of_interest):\n",
    "    count=0\n",
    "    for i in range(start, len(lines), 139):\n",
    "        # print(i, lines[i])\n",
    "        for j in range(len(lines[i])-1): #Here we are skipping the last element of the line which is the variable name\n",
    "            data_of_interest[count:,] = lines[i][j]\n",
    "            count+=1\n",
    "\n",
    "        return data_of_interest;\n",
    "\n",
    "def extract_names_and_codes(start, lines, data, choice):\n",
    "\n",
    "    #Choice is the index of the variable name we want to extract, 0 for names and -2 for codes\n",
    "    count=0 #Counter variable\n",
    "    for i in range(start, len(lines), 139):\n",
    "\n",
    "        names_and_codes = [lines[i][choice]] * 22 #every time period has 22 predictions but the storm name is the same for all of them\n",
    "        data[count*22:(count+1)*22, :] = np.array(names_and_codes).reshape(-1, 1) #Reshape the array to be a column vector and assign it to the name array\n",
    "\n",
    "        count+=1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name    Code Times Latitude Longitude Vmax    MSLP    Nature  \\\n",
      "0  ALBE  AL0119 -12.0   9999.0    9999.0  NaN     NaN       NaN   \n",
      "1  ALBE  AL0119  -6.0   9999.0    9999.0  NaN     NaN       NaN   \n",
      "2  ALBE  AL0119   0.0    217.0     871.0  2.0  1005.0  Tropical   \n",
      "3  ALBE  AL0119   6.0    222.0     865.0  2.5  1004.0  Tropical   \n",
      "4  ALBE  AL0119  12.0    226.0     858.0  3.0  1003.0  Tropical   \n",
      "\n",
      "  Delta_Intensity Vshear Vert_Vel  \n",
      "0             1.0   29.6    12.89  \n",
      "1             0.0   30.2     7.71  \n",
      "2             0.0   29.8     8.56  \n",
      "3             0.0   36.2    10.45  \n",
      "4             0.0   34.0     8.08  \n"
     ]
    }
   ],
   "source": [
    "size = 13850 * 22 #Number of time periods * number of predictions per time period\n",
    "\n",
    "times = np.full((size, 1), np.nan)\n",
    "lat = np.full((size, 1), np.nan)\n",
    "lon = np.full((size, 1), np.nan)\n",
    "vmax = np.full((size, 1), np.nan)\n",
    "mslp = np.full((size, 1), np.nan)\n",
    "nature = np.full((size, 1), np.nan)\n",
    "delta_intensity = np.full((size, 1), np.nan)\n",
    "name = np.full((size, 1), 'np.nan')\n",
    "code = np.full((size, 1), 'np.nan')\n",
    "daily_sst_avg = np.full((size, 1), np.nan)\n",
    "mid_level_rh = np.full((size, 1), np.nan)\n",
    "vshear = np.full((size, 1), np.nan)\n",
    "vert_vel = np.full((size, 1), np.nan)\n",
    "\n",
    "# Extracting Data of interest\n",
    "name = extract_names_and_codes(0, lines,name, 0).astype(object)\n",
    "code = extract_names_and_codes(0, lines, code, -2).astype(object)\n",
    "times = extract_data_of_interest(1, lines, times).astype(object)\n",
    "vmax = extract_data_of_interest(2, lines, vmax).astype(object)\n",
    "mslp = extract_data_of_interest(3, lines, mslp).astype(object)\n",
    "nature = extract_data_of_interest(4, lines, nature).astype(object)\n",
    "delta_intensity = extract_data_of_interest(5, lines, delta_intensity).astype(object)\n",
    "lat = extract_data_of_interest(8, lines, lat).astype(object)\n",
    "lon = extract_data_of_interest(9, lines, lon).astype(object)\n",
    "\n",
    "#Fix here\n",
    "# daily_sst_avg = extract_data_of_interest(19, lines, daily_sst_avg)\n",
    "# mid_level_rh = extract_data_of_interest(29, lines, mid_level_rh)\n",
    "vshear = extract_data_of_interest(64, lines, vshear).astype(object)\n",
    "vert_vel = extract_data_of_interest(67, lines, vert_vel).astype(object)\n",
    "\n",
    "#Changing 9999 to nans and didvide by 10 to get the correct values\n",
    "vmax[vmax==9999] = np.nan\n",
    "vmax = vmax / 10\n",
    "\n",
    "mslp[mslp == 9999] = np.nan\n",
    "\n",
    "nature[nature == 9999] = np.nan\n",
    "nature[nature == 0] = 'Wave'\n",
    "nature[nature == 1] = 'Tropical'\n",
    "nature[nature == 2] = 'Subtropical'\n",
    "nature[nature == 3] = 'Extratropical'\n",
    "\n",
    "vshear[vshear == 9999] = np.nan\n",
    "vshear = vshear / 10\n",
    "\n",
    "vert_vel[vert_vel == 9999] = np.nan\n",
    "vert_vel = vert_vel / 100\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame with the extracted data\n",
    "data = {\n",
    "    'Name': name.flatten(),\n",
    "    'Code': code.flatten(),\n",
    "    'Times': times.flatten(),\n",
    "    'Latitude': lat.flatten(),\n",
    "    'Longitude': lon.flatten(),\n",
    "    'Vmax': vmax.flatten(),\n",
    "    'MSLP': mslp.flatten(),\n",
    "    'Nature': nature.flatten(),\n",
    "    'Delta_Intensity': delta_intensity.flatten(),\n",
    "    # 'Daily_SST_Avg': daily_sst_avg.flatten(),\n",
    "    # 'Mid_Level_RH': mid_level_rh.flatten(),\n",
    "    'Vshear': vshear.flatten(),\n",
    "    'Vert_Vel': vert_vel.flatten()\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Times</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Vmax</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>Nature</th>\n",
       "      <th>Delta_Intensity</th>\n",
       "      <th>Vshear</th>\n",
       "      <th>Vert_Vel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304695</th>\n",
       "      <td>NICO</td>\n",
       "      <td>AL1720</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304696</th>\n",
       "      <td>NICO</td>\n",
       "      <td>AL1720</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304697</th>\n",
       "      <td>NICO</td>\n",
       "      <td>AL1720</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304698</th>\n",
       "      <td>NICO</td>\n",
       "      <td>AL1720</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304699</th>\n",
       "      <td>NICO</td>\n",
       "      <td>AL1720</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name    Code  Times Latitude Longitude Vmax MSLP Nature  \\\n",
       "304695  NICO  AL1720  120.0   9999.0    9999.0  NaN  NaN    NaN   \n",
       "304696  NICO  AL1720  120.0   9999.0    9999.0  NaN  NaN    NaN   \n",
       "304697  NICO  AL1720  120.0   9999.0    9999.0  NaN  NaN    NaN   \n",
       "304698  NICO  AL1720  120.0   9999.0    9999.0  NaN  NaN    NaN   \n",
       "304699  NICO  AL1720  120.0   9999.0    9999.0  NaN  NaN    NaN   \n",
       "\n",
       "       Delta_Intensity Vshear Vert_Vel  \n",
       "304695             0.0    NaN      NaN  \n",
       "304696             0.0    NaN      NaN  \n",
       "304697             0.0    NaN      NaN  \n",
       "304698             0.0    NaN      NaN  \n",
       "304699             0.0    NaN      NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304700, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.full((len(lines[1])-1, 1), 'np.nan')\n",
    "vmax = np.full((len(lines[2])-1, 1), 'np.nan')\n",
    "mslp = np.full((len(lines[3])-1, 1), 'np.nan')\n",
    "nature = np.full((len(lines[4])-1, 1), 'np.nan')\n",
    "delta_intensity = np.full((len(lines[5])-1, 1), 'np.nan')\n",
    "lat = np.full((len(lines[8])-1, 1), 'np.nan')\n",
    "lon = np.full((len(lines[9])-1, 1), 'np.nan')\n",
    "daily_sst_avg = np.full((len(lines[19])-1, 1), 'np.nan')\n",
    "mid_level_rh = np.full((len(lines[29])-1, 1), np.nan)\n",
    "\n",
    "shear = np.full((len(lines[64])-1, 1), np.nan)\n",
    "\"\"\" Generalized 850-200 hPa shear magnitude (kt *10) vs time (takes into account all levels from 1000 to 100 hPa) \"\"\" \n",
    "vert_vel = np.full((len(lines[67])-1, 1), np.nan)\n",
    "\n",
    "\n",
    "# Times\n",
    "for i in range(len(lines[1])-1):\n",
    "    times[i,:] = lines[1][i]\n",
    "\n",
    "# Vmax\n",
    "for i in range(len(lines[2])-1):\n",
    "    vmax[i,:] = lines[2][i]\n",
    "\n",
    "# MSLP\n",
    "for i in range(len(lines[3])-1):\n",
    "    mslp[i,:] = lines[3][i]\n",
    "\n",
    "# Nature\n",
    "for i in range(len(lines[4])-1):\n",
    "    nature[i,:] = lines[4][i]\n",
    "\n",
    "# Delta Intensity\n",
    "for i in range(len(lines[5])-1):\n",
    "    delta_intensity[i,:] = lines[5][i]\n",
    "\n",
    "# Latitude\n",
    "for i in range(len(lines[8])-1):\n",
    "    lat[i,:] = lines[8][i]\n",
    "\n",
    "# Longitude\n",
    "for i in range(len(lines[9])-1):\n",
    "    lon[i,:] = lines[9][i]\n",
    "\n",
    "# Daily SST Avg\n",
    "for i in range(len(lines[19])-1):\n",
    "    # print(i)\n",
    "    daily_sst_avg[i,:] = lines[19][i]\n",
    "\n",
    "# Mid Level RH\n",
    "for i in range(len(lines[29])-1):\n",
    "    mid_level_rh[i,:] = float(lines[29][i])\n",
    "\n",
    "# Shear\n",
    "for i in range(len(lines[64])-1):\n",
    "    shear[i,:] = float(lines[64][i])/10\n",
    "\n",
    "# Vert Vel\n",
    "for i in range(len(lines[67])-1):\n",
    "    vert_vel[i,:] = float(lines[67][i])/100\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mu-Chieh Ko,Xiaomin Chen, Miroslav Kubat and Sundararaman Gopalakrishnan\n",
    "delv = np.full((len(lines[6])-1, 1), np.nan)\n",
    "incv = np.full((len(lines[7])-1, 1), np.nan)\n",
    "lat = np.full((len(lines[8])-1, 1), np.nan)\n",
    "lon = np.full((len(lines[9])-1, 1), np.nan)\n",
    "dist_to_land = np.full((len(lines[14])-1, 1), np.nan)\n",
    "daily_sst_avg = np.full((len(lines[19])-1, 1), np.nan)\n",
    "mid_level_rh = np.full((len(lines[29])-1, 1), np.nan)\n",
    "div_200 = np.full((len(lines[33])-1, 1), np.nan)\n",
    "rad_max_wind = np.full((len(lines[-7])-1, 1), np.nan) #Needs further investifgation since the brightness temp is used\n",
    "shear = np.full((len(lines[64])-1, 1), np.nan) #Generalized 850-200 hPa shear magnitude (kt *10) vs time (takes into account all levels from 1000 to 100 hPa) \"\"\" \n",
    "\n",
    "#ShearS\n",
    "#ShdirS\n",
    "#ShearM\n",
    "#ShdirM\n",
    "#ShearD\n",
    "#ShdirD\n",
    "#CAPE_US\n",
    "#CAPE_DS\n",
    "# HLCY_US\n",
    "# HLCY_DS\n",
    "#Convergence\n",
    "#Temperature Difference between core and environment\n",
    "# Wavenumber1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Delta V\n",
    "for i in range(len(lines[6])-1):\n",
    "    delv[i,:] = float(lines[6][i])\n",
    "\n",
    "# Inc V\n",
    "for i in range(len(lines[7])-1):\n",
    "    incv[i,:] = float(lines[7][i])\n",
    "\n",
    "# Latitude\n",
    "for i in range(len(lines[8])-1):\n",
    "    lat[i,:] = float(lines[8][i])\n",
    "\n",
    "# Longitude\n",
    "for i in range(len(lines[9])-1):\n",
    "    lon[i,:] = float(lines[9][i])\n",
    "\n",
    "# Distance to Land\n",
    "for i in range(len(lines[14])-1):\n",
    "    dist_to_land[i,:] = float(lines[14][i])\n",
    "    dist_to_land[dist_to_land == 9999.] = np.nan\n",
    "    \n",
    "# Daily SST Avg\n",
    "for i in range(len(lines[19])-2):\n",
    "    daily_sst_avg[i,:] = float(lines[19][i])\n",
    "    daily_sst_avg[daily_sst_avg == 9999.] = np.nan\n",
    "\n",
    "# Mid Level RH\n",
    "for i in range(len(lines[29])-1):\n",
    "    mid_level_rh[i,:] = float(lines[29][i])\n",
    "    mid_level_rh[mid_level_rh == 9999.] = np.nan\n",
    "\n",
    "# Div 200\n",
    "for i in range(len(lines[33])-1):\n",
    "    div_200[i,:] = float(lines[33][i])\n",
    "    div_200[div_200 == 9999.] = np.nan\n",
    "\n",
    "# Shear\n",
    "for i in range(len(lines[64])-1):\n",
    "    shear[i,:] = float(lines[64][i])/10 #Convert to m/s\n",
    "\n",
    "# Rad Max Wind\n",
    "for i in range(len(lines[-7])-1):\n",
    "    rad_max_wind[i,:] = float(lines[-7][i])\n",
    "    rad_max_wind[rad_max_wind == 9999.] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 64.],\n",
       "       [ 65.],\n",
       "       [ 84.],\n",
       "       [ 70.],\n",
       "       [ 51.],\n",
       "       [114.],\n",
       "       [ 42.],\n",
       "       [ 27.],\n",
       "       [ -7.],\n",
       "       [  8.],\n",
       "       [-17.],\n",
       "       [-37.],\n",
       "       [-48.],\n",
       "       [-52.],\n",
       "       [-25.],\n",
       "       [-32.],\n",
       "       [-41.],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "' ALBE 820602 12   20   21.7   87.1 1005 AL0119' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m combined_line_list \u001b[38;5;241m=\u001b[39m combined_line\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Find the index of the substring in the list\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m start_index \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_line_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Print every 4th string after the substring\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_index, \u001b[38;5;28mlen\u001b[39m(combined_line_list), \u001b[38;5;241m4\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: ' ALBE 820602 12   20   21.7   87.1 1005 AL0119' is not in list"
     ]
    }
   ],
   "source": [
    "# Extract the substring\n",
    "substring = combined_line[0:46]\n",
    "\n",
    "# Split the combined_line into a list of strings\n",
    "combined_line_list = combined_line.split()\n",
    "\n",
    "# Find the index of the substring in the list\n",
    "start_index = combined_line_list.index(substring)\n",
    "\n",
    "# Print every 4th string after the substring\n",
    "for i in range(start_index, len(combined_line_list), 4):\n",
    "    print(combined_line_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LAST'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_line_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Assuming you have an xarray DataArray named 'data_array'\n",
    "nan_indices = np.argwhere(data_array.isnull().values)\n",
    "print(nan_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waves",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
